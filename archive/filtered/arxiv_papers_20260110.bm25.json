{
  "top_k": 100,
  "generated_at": "2026-01-10T10:49:44.394781+00:00",
  "papers": [
    {
      "id": "2601.05251v1",
      "title": "Mesh4D: 4D Mesh Reconstruction and Tracking from Monocular Video",
      "abstract": "We propose Mesh4D, a feed-forward model for monocular 4D mesh reconstruction. Given a monocular video of a dynamic object, our model reconstructs the object's complete 3D shape and motion, represented as a deformation field. Our key contribution is a compact latent space that encodes the entire animation sequence in a single pass. This latent space is learned by an autoencoder that, during training, is guided by the skeletal structure of the training objects, providing strong priors on plausible deformations. Crucially, skeletal information is not required at inference time. The encoder employs spatio-temporal attention, yielding a more stable representation of the object's overall deformation. Building on this representation, we train a latent diffusion model that, conditioned on the input video and the mesh reconstructed from the first frame, predicts the full animation in one shot. We evaluate Mesh4D on reconstruction and novel view synthesis benchmarks, outperforming prior methods in recovering accurate 3D shape and deformation.",
      "authors": [
        "Zeren Jiang",
        "Chuanxia Zheng",
        "Iro Laina",
        "Diane Larlus",
        "Andrea Vedaldi"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 18:59:56+00:00",
      "link": "https://arxiv.org/pdf/2601.05251v1",
      "tags": [
        "keyword:大语言模型",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05249v1",
      "title": "RL-AWB: Deep Reinforcement Learning for Auto White Balance Correction in Low-Light Night-time Scenes",
      "abstract": "Nighttime color constancy remains a challenging problem in computational photography due to low-light noise and complex illumination conditions. We present RL-AWB, a novel framework combining statistical methods with deep reinforcement learning for nighttime white balance. Our method begins with a statistical algorithm tailored for nighttime scenes, integrating salient gray pixel detection with novel illumination estimation. Building on this foundation, we develop the first deep reinforcement learning approach for color constancy that leverages the statistical algorithm as its core, mimicking professional AWB tuning experts by dynamically optimizing parameters for each image. To facilitate cross-sensor evaluation, we introduce the first multi-sensor nighttime dataset. Experiment results demonstrate that our method achieves superior generalization capability across low-light and well-illuminated images. Project page: https://ntuneillee.github.io/research/rl-awb/",
      "authors": [
        "Yuan-Kang Lee",
        "Kuan-Lin Chen",
        "Chia-Che Chang",
        "Yu-Lun Liu"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 18:59:55+00:00",
      "link": "https://arxiv.org/pdf/2601.05249v1",
      "tags": [
        "keyword:resnet",
        "keyword:resnet中文",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05250v1",
      "title": "QNeRF: Neural Radiance Fields on a Simulated Gate-Based Quantum Computer",
      "abstract": "Recently, Quantum Visual Fields (QVFs) have shown promising improvements in model compactness and convergence speed for learning the provided 2D or 3D signals. Meanwhile, novel-view synthesis has seen major advances with Neural Radiance Fields (NeRFs), where models learn a compact representation from 2D images to render 3D scenes, albeit at the cost of larger models and intensive training. In this work, we extend the approach of QVFs by introducing QNeRF, the first hybrid quantum-classical model designed for novel-view synthesis from 2D images. QNeRF leverages parameterised quantum circuits to encode spatial and view-dependent information via quantum superposition and entanglement, resulting in more compact models compared to the classical counterpart. We present two architectural variants. Full QNeRF maximally exploits all quantum amplitudes to enhance representational capabilities. In contrast, Dual-Branch QNeRF introduces a task-informed inductive bias by branching spatial and view-dependent quantum state preparations, drastically reducing the complexity of this operation and ensuring scalability and potential hardware compatibility. Our experiments demonstrate that -- when trained on images of moderate resolution -- QNeRF matches or outperforms classical NeRF baselines while using less than half the number of parameters. These results suggest that quantum machine learning can serve as a competitive alternative for continuous signal representation in mid-level tasks in computer vision, such as 3D representation learning from 2D observations.",
      "authors": [
        "Daniele Lizzio Bosco",
        "Shuteng Wang",
        "Giuseppe Serra",
        "Vladislav Golyanik"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 18:59:55+00:00",
      "link": "https://arxiv.org/pdf/2601.05250v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05248v1",
      "title": "LaST$_{0}$: Latent Spatio-Temporal Chain-of-Thought for Robotic Vision-Language-Action Model",
      "abstract": "Vision-Language-Action (VLA) models have recently demonstrated strong generalization capabilities in robotic manipulation. Some existing VLA approaches attempt to improve action accuracy by explicitly generating linguistic reasoning traces or future visual observations before action execution. However, explicit reasoning typically incurs non-negligible inference latency, which constrains the temporal resolution required for robotic manipulation. Moreover, such reasoning is confined to the linguistic space, imposing a representational bottleneck that struggles to faithfully capture ineffable physical attributes. To mitigate these limitations, we propose LaST$_0$, a framework that enables efficient reasoning before acting through a Latent Spatio-Temporal Chain-of-Thought (CoT), capturing fine-grained physical and robotic dynamics that are often difficult to verbalize. Specifically, we introduce a token-efficient latent CoT space that models future visual dynamics, 3D structural information, and robot proprioceptive states, and further extends these representations across time to enable temporally consistent implicit reasoning trajectories. Furthermore, LaST$_0$ adopts a dual-system architecture implemented via a Mixture-of-Transformers design, where a reasoning expert conducts low-frequency latent inference and an acting expert generates high-frequency actions conditioned on robotics-oriented latent representations. To facilitate coordination, LaST$_0$ is trained with heterogeneous operation frequencies, enabling adaptive switching between reasoning and action inference rates during deployment. Across ten simulated and six real-world manipulation tasks, LaST$_0$ improves mean success rates by 8% and 13% over prior VLA methods, respectively, while achieving substantially faster inference. Project website: https://sites.google.com/view/last0",
      "authors": [
        "Zhuoyang Liu",
        "Jiaming Liu",
        "Hao Chen",
        "Ziyu Guo",
        "Chengkai Hou",
        "Chenyang Gu",
        "Jiale Yu",
        "Xiangju Mi",
        "Renrui Zhang",
        "Zhengping Che",
        "Jian Tang",
        "Pheng-Ann Heng",
        "Shanghang Zhang"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-01-08 18:59:53+00:00",
      "link": "https://arxiv.org/pdf/2601.05248v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05247v1",
      "title": "Random Models and Guarded Logic",
      "abstract": "Building on ideas of Gurevich and Shelah for the Gödel Class, we present a new probabilistic proof of the finite model property for the Guarded Fragment of First-Order Logic. Our proof is conceptually simple and yields the optimal doubly-exponential upper bound on the size of minimal models. We precisely analyse the obtained bound, up to constant factors in the exponents, and construct sentences that enforce models of tightly matching size. The probabilistic approach adapts naturally to the Triguarded Fragment, an extension of the Guarded Fragment that also subsumes the Two-Variable Fragment. Finally, we derandomise the probabilistic proof by providing an explicit model construction which replaces randomness with deterministic hash functions.",
      "authors": [
        "Oskar Fiuk"
      ],
      "primary_category": "cs.LO",
      "categories": [
        "cs.LO"
      ],
      "published": "2026-01-08 18:59:50+00:00",
      "link": "https://arxiv.org/pdf/2601.05247v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05246v1",
      "title": "Pixel-Perfect Visual Geometry Estimation",
      "abstract": "Recovering clean and accurate geometry from images is essential for robotics and augmented reality. However, existing geometry foundation models still suffer severely from flying pixels and the loss of fine details. In this paper, we present pixel-perfect visual geometry models that can predict high-quality, flying-pixel-free point clouds by leveraging generative modeling in the pixel space. We first introduce Pixel-Perfect Depth (PPD), a monocular depth foundation model built upon pixel-space diffusion transformers (DiT). To address the high computational complexity associated with pixel-space diffusion, we propose two key designs: 1) Semantics-Prompted DiT, which incorporates semantic representations from vision foundation models to prompt the diffusion process, preserving global semantics while enhancing fine-grained visual details; and 2) Cascade DiT architecture that progressively increases the number of image tokens, improving both efficiency and accuracy. To further extend PPD to video (PPVD), we introduce a new Semantics-Consistent DiT, which extracts temporally consistent semantics from a multi-view geometry foundation model. We then perform reference-guided token propagation within the DiT to maintain temporal coherence with minimal computational and memory overhead. Our models achieve the best performance among all generative monocular and video depth estimation models and produce significantly cleaner point clouds than all other models.",
      "authors": [
        "Gangwei Xu",
        "Haotong Lin",
        "Hongcheng Luo",
        "Haiyang Sun",
        "Bing Wang",
        "Guang Chen",
        "Sida Peng",
        "Hangjun Ye",
        "Xin Yang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 18:59:49+00:00",
      "link": "https://arxiv.org/pdf/2601.05246v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05245v1",
      "title": "Optimal Lower Bounds for Online Multicalibration",
      "abstract": "We prove tight lower bounds for online multicalibration, establishing an information-theoretic separation from marginal calibration.   In the general setting where group functions can depend on both context and the learner's predictions, we prove an $Ω(T^{2/3})$ lower bound on expected multicalibration error using just three disjoint binary groups. This matches the upper bounds of Noarov et al. (2025) up to logarithmic factors and exceeds the $O(T^{2/3-\\varepsilon})$ upper bound for marginal calibration (Dagan et al., 2025), thereby separating the two problems.   We then turn to lower bounds for the more difficult case of group functions that may depend on context but not on the learner's predictions. In this case, we establish an $\\widetildeΩ(T^{2/3})$ lower bound for online multicalibration via a $Θ(T)$-sized group family constructed using orthogonal function systems, again matching upper bounds up to logarithmic factors.",
      "authors": [
        "Natalie Collina",
        "Jiuyao Lu",
        "Georgy Noarov",
        "Aaron Roth"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "math.ST",
        "stat.ML"
      ],
      "published": "2026-01-08 18:59:32+00:00",
      "link": "https://arxiv.org/pdf/2601.05245v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05244v1",
      "title": "GREx: Generalized Referring Expression Segmentation, Comprehension, and Generation",
      "abstract": "Referring Expression Segmentation (RES) and Comprehension (REC) respectively segment and detect the object described by an expression, while Referring Expression Generation (REG) generates an expression for the selected object. Existing datasets and methods commonly support single-target expressions only, i.e., one expression refers to one object, not considering multi-target and no-target expressions. This greatly limits the real applications of REx (RES/REC/REG). This paper introduces three new benchmarks called Generalized Referring Expression Segmentation (GRES), Comprehension (GREC), and Generation (GREG), collectively denoted as GREx, which extend the classic REx to allow expressions to identify an arbitrary number of objects. We construct the first large-scale GREx dataset gRefCOCO that contains multi-target, no-target, and single-target expressions and their corresponding images with labeled targets. GREx and gRefCOCO are designed to be backward-compatible with REx, facilitating extensive experiments to study the performance gap of the existing REx methods on GREx tasks. One of the challenges of GRES/GREC is complex relationship modeling, for which we propose a baseline ReLA that adaptively divides the image into regions with sub-instance clues and explicitly models the region-region and region-language dependencies. The proposed ReLA achieves the state-of-the-art results on the both GRES and GREC tasks. The proposed gRefCOCO dataset and method are available at https://henghuiding.github.io/GREx.",
      "authors": [
        "Henghui Ding",
        "Chang Liu",
        "Shuting He",
        "Xudong Jiang",
        "Yu-Gang Jiang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 18:59:30+00:00",
      "link": "https://arxiv.org/pdf/2601.05244v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05243v1",
      "title": "Generate, Transfer, Adapt: Learning Functional Dexterous Grasping from a Single Human Demonstration",
      "abstract": "Functional grasping with dexterous robotic hands is a key capability for enabling tool use and complex manipulation, yet progress has been constrained by two persistent bottlenecks: the scarcity of large-scale datasets and the absence of integrated semantic and geometric reasoning in learned models. In this work, we present CorDex, a framework that robustly learns dexterous functional grasps of novel objects from synthetic data generated from just a single human demonstration. At the core of our approach is a correspondence-based data engine that generates diverse, high-quality training data in simulation. Based on the human demonstration, our data engine generates diverse object instances of the same category, transfers the expert grasp to the generated objects through correspondence estimation, and adapts the grasp through optimization. Building on the generated data, we introduce a multimodal prediction network that integrates visual and geometric information. By devising a local-global fusion module and an importance-aware sampling mechanism, we enable robust and computationally efficient prediction of functional dexterous grasps. Through extensive experiments across various object categories, we demonstrate that CorDex generalizes well to unseen object instances and significantly outperforms state-of-the-art baselines.",
      "authors": [
        "Xingyi He",
        "Adhitya Polavaram",
        "Yunhao Cao",
        "Om Deshmukh",
        "Tianrui Wang",
        "Xiaowei Zhou",
        "Kuan Fang"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.CV"
      ],
      "published": "2026-01-08 18:59:30+00:00",
      "link": "https://arxiv.org/pdf/2601.05243v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05242v1",
      "title": "GDPO: Group reward-Decoupled Normalization Policy Optimization for Multi-reward RL Optimization",
      "abstract": "As language models become increasingly capable, users expect them to provide not only accurate responses but also behaviors aligned with diverse human preferences across a variety of scenarios. To achieve this, Reinforcement learning (RL) pipelines have begun incorporating multiple rewards, each capturing a distinct preference, to guide models toward these desired behaviors. However, recent work has defaulted to apply Group Relative Policy Optimization (GRPO) under multi-reward setting without examining its suitability. In this paper, we demonstrate that directly applying GRPO to normalize distinct rollout reward combinations causes them to collapse into identical advantage values, reducing the resolution of the training signal and resulting in suboptimal convergence and, in some cases, early training failure. We then introduce Group reward-Decoupled Normalization Policy Optimization (GDPO), a new policy optimization method to resolve these issues by decoupling the normalization of individual rewards, more faithfully preserving their relative differences and enabling more accurate multi-reward optimization, along with substantially improved training stability. We compare GDPO with GRPO across three tasks: tool calling, math reasoning, and coding reasoning, evaluating both correctness metrics (accuracy, bug ratio) and constraint adherence metrics (format, length). Across all settings, GDPO consistently outperforms GRPO, demonstrating its effectiveness and generalizability for multi-reward reinforcement learning optimization.",
      "authors": [
        "Shih-Yang Liu",
        "Xin Dong",
        "Ximing Lu",
        "Shizhe Diao",
        "Peter Belcak",
        "Mingjie Liu",
        "Min-Hung Chen",
        "Hongxu Yin",
        "Yu-Chiang Frank Wang",
        "Kwang-Ting Cheng",
        "Yejin Choi",
        "Jan Kautz",
        "Pavlo Molchanov"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-08 18:59:24+00:00",
      "link": "https://arxiv.org/pdf/2601.05242v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05241v1",
      "title": "RoboVIP: Multi-View Video Generation with Visual Identity Prompting Augments Robot Manipulation",
      "abstract": "The diversity, quantity, and quality of manipulation data are critical for training effective robot policies. However, due to hardware and physical setup constraints, collecting large-scale real-world manipulation data remains difficult to scale across diverse environments. Recent work uses text-prompt conditioned image diffusion models to augment manipulation data by altering the backgrounds and tabletop objects in the visual observations. However, these approaches often overlook the practical need for multi-view and temporally coherent observations required by state-of-the-art policy models. Further, text prompts alone cannot reliably specify the scene setup. To provide the diffusion model with explicit visual guidance, we introduce visual identity prompting, which supplies exemplar images as conditioning inputs to guide the generation of the desired scene setup. To this end, we also build a scalable pipeline to curate a visual identity pool from large robotics datasets. Using our augmented manipulation data to train downstream vision-language-action and visuomotor policy models yields consistent performance gains in both simulation and real-robot settings.",
      "authors": [
        "Boyang Wang",
        "Haoran Zhang",
        "Shujie Zhang",
        "Jinkun Hao",
        "Mingda Jia",
        "Qi Lv",
        "Yucheng Mao",
        "Zhaoyang Lyu",
        "Jia Zeng",
        "Xudong Xu",
        "Jiangmiao Pang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "published": "2026-01-08 18:59:22+00:00",
      "link": "https://arxiv.org/pdf/2601.05241v1",
      "tags": [
        "keyword:resnet",
        "keyword:resnet中文",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05240v1",
      "title": "Robust Reasoning as a Symmetry-Protected Topological Phase",
      "abstract": "Large language models suffer from \"hallucinations\"-logical inconsistencies induced by semantic noise. We propose that current architectures operate in a \"Metric Phase,\" where causal order is vulnerable to spontaneous symmetry breaking. Here, we identify robust inference as an effective Symmetry-Protected Topological phase, where logical operations are formally isomorphic to non-Abelian anyon braiding, replacing fragile geometric interpolation with robust topological invariants. Empirically, we demonstrate a sharp topological phase transition: while Transformers and RNNs exhibit gapless decay, our Holonomic Network reveals a macroscopic \"mass gap,\" maintaining invariant fidelity below a critical noise threshold. Furthermore, in a variable-binding task on $S_{10}$ ($3.6 \\times 10^6$ states) representing symbolic manipulation, we demonstrate holonomic generalization: the topological model maintains perfect fidelity extrapolating $100\\times$ beyond training ($L=50 \\to 5000$), consistent with a theoretically indefinite causal horizon, whereas Transformers lose logical coherence. Ablation studies indicate this protection emerges strictly from non-Abelian gauge symmetry. This provides strong evidence for a new universality class for logical reasoning, linking causal stability to the topology of the semantic manifold.",
      "authors": [
        "Ilmo Sung"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cond-mat.dis-nn",
        "cs.AI",
        "hep-th"
      ],
      "published": "2026-01-08 18:58:34+00:00",
      "link": "https://arxiv.org/pdf/2601.05240v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05239v1",
      "title": "Plenoptic Video Generation",
      "abstract": "Camera-controlled generative video re-rendering methods, such as ReCamMaster, have achieved remarkable progress. However, despite their success in single-view setting, these works often struggle to maintain consistency across multi-view scenarios. Ensuring spatio-temporal coherence in hallucinated regions remains challenging due to the inherent stochasticity of generative models. To address it, we introduce PlenopticDreamer, a framework that synchronizes generative hallucinations to maintain spatio-temporal memory. The core idea is to train a multi-in-single-out video-conditioned model in an autoregressive manner, aided by a camera-guided video retrieval strategy that adaptively selects salient videos from previous generations as conditional inputs. In addition, Our training incorporates progressive context-scaling to improve convergence, self-conditioning to enhance robustness against long-range visual degradation caused by error accumulation, and a long-video conditioning mechanism to support extended video generation. Extensive experiments on the Basic and Agibot benchmarks demonstrate that PlenopticDreamer achieves state-of-the-art video re-rendering, delivering superior view synchronization, high-fidelity visuals, accurate camera control, and diverse view transformations (e.g., third-person to third-person, and head-view to gripper-view in robotic manipulation). Project page: https://research.nvidia.com/labs/dir/plenopticdreamer/",
      "authors": [
        "Xiao Fu",
        "Shitao Tang",
        "Min Shi",
        "Xian Liu",
        "Jinwei Gu",
        "Ming-Yu Liu",
        "Dahua Lin",
        "Chen-Hsuan Lin"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 18:58:32+00:00",
      "link": "https://arxiv.org/pdf/2601.05239v1",
      "tags": [
        "keyword:大语言模型",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05237v1",
      "title": "ObjectForesight: Predicting Future 3D Object Trajectories from Human Videos",
      "abstract": "Humans can effortlessly anticipate how objects might move or change through interaction--imagining a cup being lifted, a knife slicing, or a lid being closed. We aim to endow computational systems with a similar ability to predict plausible future object motions directly from passive visual observation. We introduce ObjectForesight, a 3D object-centric dynamics model that predicts future 6-DoF poses and trajectories of rigid objects from short egocentric video sequences. Unlike conventional world or dynamics models that operate in pixel or latent space, ObjectForesight represents the world explicitly in 3D at the object level, enabling geometrically grounded and temporally coherent predictions that capture object affordances and trajectories. To train such a model at scale, we leverage recent advances in segmentation, mesh reconstruction, and 3D pose estimation to curate a dataset of 2 million plus short clips with pseudo-ground-truth 3D object trajectories. Through extensive experiments, we show that ObjectForesight achieves significant gains in accuracy, geometric consistency, and generalization to unseen objects and scenes, establishing a scalable framework for learning physically grounded, object-centric dynamics models directly from observation. objectforesight.github.io",
      "authors": [
        "Rustin Soraki",
        "Homanga Bharadhwaj",
        "Ali Farhadi",
        "Roozbeh Mottaghi"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 18:58:08+00:00",
      "link": "https://arxiv.org/pdf/2601.05237v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05232v1",
      "title": "Measuring and Fostering Peace through Machine Learning and Artificial Intelligence",
      "abstract": "We used machine learning and artificial intelligence: 1) to measure levels of peace in countries from news and social media and 2) to develop on-line tools that promote peace by helping users better understand their own media diet. For news media, we used neural networks to measure levels of peace from text embeddings of on-line news sources. The model, trained on one news media dataset also showed high accuracy when used to analyze a different news dataset. For social media, such as YouTube, we developed other models to measure levels of social dimensions important in peace using word level (GoEmotions) and context level (Large Language Model) methods. To promote peace, we note that 71% of people 20-40 years old daily view most of their news through short videos on social media. Content creators of these videos are biased towards creating videos with emotional activation, making you angry to engage you, to increase clicks. We developed and tested a Chrome extension, MirrorMirror, which provides real-time feedback to YouTube viewers about the peacefulness of the media they are watching. Our long term goal is for MirrorMirror to evolve into an open-source tool for content creators, journalists, researchers, platforms, and individual users to better understand the tone of their media creation and consumption and its effects on viewers. Moving beyond simple engagement metrics, we hope to encourage more respectful, nuanced, and informative communication.",
      "authors": [
        "P. Gilda",
        "P. Dungarwal",
        "A. Thongkham",
        "E. T. Ajayi",
        "S. Choudhary",
        "T. M. Terol",
        "C. Lam",
        "J. P. Araujo",
        "M. McFadyen-Mungalln",
        "L. S. Liebovitch",
        "P. T. Coleman",
        "H. West",
        "K. Sieck",
        "S. Carter"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.CY",
        "cs.LG"
      ],
      "published": "2026-01-08 18:57:01+00:00",
      "link": "https://arxiv.org/pdf/2601.05232v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05230v1",
      "title": "Learning Latent Action World Models In The Wild",
      "abstract": "Agents capable of reasoning and planning in the real world require the ability of predicting the consequences of their actions. While world models possess this capability, they most often require action labels, that can be complex to obtain at scale. This motivates the learning of latent action models, that can learn an action space from videos alone. Our work addresses the problem of learning latent actions world models on in-the-wild videos, expanding the scope of existing works that focus on simple robotics simulations, video games, or manipulation data. While this allows us to capture richer actions, it also introduces challenges stemming from the video diversity, such as environmental noise, or the lack of a common embodiment across videos. To address some of the challenges, we discuss properties that actions should follow as well as relevant architectural choices and evaluations. We find that continuous, but constrained, latent actions are able to capture the complexity of actions from in-the-wild videos, something that the common vector quantization does not. We for example find that changes in the environment coming from agents, such as humans entering the room, can be transferred across videos. This highlights the capability of learning actions that are specific to in-the-wild videos. In the absence of a common embodiment across videos, we are mainly able to learn latent actions that become localized in space, relative to the camera. Nonetheless, we are able to train a controller that maps known actions to latent ones, allowing us to use latent actions as a universal interface and solve planning tasks with our world model with similar performance as action-conditioned baselines. Our analyses and experiments provide a step towards scaling latent action models to the real world.",
      "authors": [
        "Quentin Garrido",
        "Tushar Nagarajan",
        "Basile Terver",
        "Nicolas Ballas",
        "Yann LeCun",
        "Michael Rabbat"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "published": "2026-01-08 18:55:39+00:00",
      "link": "https://arxiv.org/pdf/2601.05230v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05227v1",
      "title": "Stochastic Deep Learning: A Probabilistic Framework for Modeling Uncertainty in Structured Temporal Data",
      "abstract": "I propose a novel framework that integrates stochastic differential equations (SDEs) with deep generative models to improve uncertainty quantification in machine learning applications involving structured and temporal data. This approach, termed Stochastic Latent Differential Inference (SLDI), embeds an Itô SDE in the latent space of a variational autoencoder, allowing for flexible, continuous-time modeling of uncertainty while preserving a principled mathematical foundation. The drift and diffusion terms of the SDE are parameterized by neural networks, enabling data-driven inference and generalizing classical time series models to handle irregular sampling and complex dynamic structure.   A central theoretical contribution is the co-parameterization of the adjoint state with a dedicated neural network, forming a coupled forward-backward system that captures not only latent evolution but also gradient dynamics. I introduce a pathwise-regularized adjoint loss and analyze variance-reduced gradient flows through the lens of stochastic calculus, offering new tools for improving training stability in deep latent SDEs. My paper unifies and extends variational inference, continuous-time generative modeling, and control-theoretic optimization, providing a rigorous foundation for future developments in stochastic probabilistic machine learning.",
      "authors": [
        "James Rice"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.LG",
        "econ.EM",
        "math.ST"
      ],
      "published": "2026-01-08 18:53:59+00:00",
      "link": "https://arxiv.org/pdf/2601.05227v1",
      "tags": [
        "keyword:resnet",
        "keyword:resnet中文",
        "keyword:符号回归（示例）",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05225v1",
      "title": "Concurrent Balanced Augmented Trees",
      "abstract": "Augmentation makes search trees tremendously more versatile, allowing them to support efficient aggregation queries, order-statistic queries, and range queries in addition to insertion, deletion, and lookup. In this paper, we present the first lock-free augmented balanced search tree. Our algorithmic ideas build upon a recent augmented unbalanced search tree presented by Fatourou and Ruppert [DISC, 2024]. We implement both data structures, solving some memory reclamation challenges in the process, and provide an experimental performance analysis of them. We also present optimized versions of our balanced tree that use delegation to achieve better scalability and performance (by more than 2x in some workloads). Our experiments show that our augmented balanced tree is 2.2 to 30 times faster than the unbalanced augmented tree, and up to several orders of magnitude faster than unaugmented trees on 120 threads.",
      "authors": [
        "Evan Wrench",
        "Ajay Singh",
        "Younghun Roh",
        "Panagiota Fatourou",
        "Siddhartha Jayanti",
        "Eric Ruppert",
        "Yuanhao Wei"
      ],
      "primary_category": "cs.DS",
      "categories": [
        "cs.DS"
      ],
      "published": "2026-01-08 18:53:52+00:00",
      "link": "https://arxiv.org/pdf/2601.05225v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05219v1",
      "title": "CAOS: Conformal Aggregation of One-Shot Predictors",
      "abstract": "One-shot prediction enables rapid adaptation of pretrained foundation models to new tasks using only one labeled example, but lacks principled uncertainty quantification. While conformal prediction provides finite-sample coverage guarantees, standard split conformal methods are inefficient in the one-shot setting due to data splitting and reliance on a single predictor. We propose Conformal Aggregation of One-Shot Predictors (CAOS), a conformal framework that adaptively aggregates multiple one-shot predictors and uses a leave-one-out calibration scheme to fully exploit scarce labeled data. Despite violating classical exchangeability assumptions, we prove that CAOS achieves valid marginal coverage using a monotonicity-based argument. Experiments on one-shot facial landmarking and RAFT text classification tasks show that CAOS produces substantially smaller prediction sets than split conformal baselines while maintaining reliable coverage.",
      "authors": [
        "Maja Waldron"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-08 18:44:21+00:00",
      "link": "https://arxiv.org/pdf/2601.05219v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05217v1",
      "title": "A complete characterization of testable hypotheses",
      "abstract": "We revisit a fundamental question in hypothesis testing: given two sets of probability measures $\\mathcal{P}$ and $\\mathcal{Q}$, when does a nontrivial (i.e.\\ strictly unbiased) test for $\\mathcal{P}$ against $\\mathcal{Q}$ exist? Le~Cam showed that, when $\\mathcal{P}$ and $\\mathcal{Q}$ have a common dominating measure, a test that has power exceeding its level by more than $\\varepsilon$ exists if and only if the convex hulls of $\\mathcal{P}$ and $\\mathcal{Q}$ are separated in total variation distance by more than $\\varepsilon$. The requirement of a dominating measure is frequently violated in nonparametric statistics. In a passing remark, Le~Cam described an approach to address more general scenarios, but he stopped short of stating a formal theorem. This work completes Le~Cam's program, by presenting a matching necessary and sufficient condition for testability: for the aforementioned theorem to hold without assumptions, one must take the closures of the convex hulls of $\\mathcal{P}$ and $\\mathcal{Q}$ in the space of bounded finitely additive measures. We provide simple elucidating examples, and elaborate on various subtle measure theoretic and topological points regarding compactness and achievability.",
      "authors": [
        "Martin Larsson",
        "Johannes Ruf",
        "Aaditya Ramdas"
      ],
      "primary_category": "math.ST",
      "categories": [
        "math.ST",
        "cs.IT",
        "math.PR"
      ],
      "published": "2026-01-08 18:42:26+00:00",
      "link": "https://arxiv.org/pdf/2601.05217v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05215v1",
      "title": "MineNPC-Task: Task Suite for Memory-Aware Minecraft Agents",
      "abstract": "We present \\textsc{MineNPC-Task}, a user-authored benchmark and evaluation harness for testing memory-aware, mixed-initiative LLM agents in open-world \\emph{Minecraft}. Rather than relying on synthetic prompts, tasks are elicited from formative and summative co-play with expert players, normalized into parametric templates with explicit preconditions and dependency structure, and paired with machine-checkable validators under a bounded-knowledge policy that forbids out-of-world shortcuts. The harness captures plan/act/memory events-including plan previews, targeted clarifications, memory reads and writes, precondition checks, and repair attempts and reports outcomes relative to the total number of attempted subtasks, derived from in-world evidence.   As an initial snapshot, we instantiate the framework with GPT-4o and evaluate \\textbf{216} subtasks across \\textbf{8} experienced players. We observe recurring breakdown patterns in code execution, inventory/tool handling, referencing, and navigation, alongside recoveries supported by mixed-initiative clarifications and lightweight memory. Participants rated interaction quality and interface usability positively, while highlighting the need for stronger memory persistence across tasks. We release the complete task suite, validators, logs, and harness to support transparent, reproducible evaluation of future memory-aware embodied agents.",
      "authors": [
        "Tamil Sudaravan Mohan Doss",
        "Michael Xu",
        "Sudha Rao",
        "Andrew D. Wilson",
        "Balasaravanan Thoravi Kumaravel"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 18:39:52+00:00",
      "link": "https://arxiv.org/pdf/2601.05215v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05214v1",
      "title": "Internal Representations as Indicators of Hallucinations in Agent Tool Selection",
      "abstract": "Large Language Models (LLMs) have shown remarkable capabilities in tool calling and tool usage, but suffer from hallucinations where they choose incorrect tools, provide malformed parameters and exhibit 'tool bypass' behavior by performing simulations and generating outputs instead of invoking specialized tools or external systems. This undermines the reliability of LLM based agents in production systems as it leads to inconsistent results, and bypasses security and audit controls. Such hallucinations in agent tool selection require early detection and error handling. Unlike existing hallucination detection methods that require multiple forward passes or external validation, we present a computationally efficient framework that detects tool-calling hallucinations in real-time by leveraging LLMs' internal representations during the same forward pass used for generation. We evaluate this approach on reasoning tasks across multiple domains, demonstrating strong detection performance (up to 86.4\\% accuracy) while maintaining real-time inference capabilities with minimal computational overhead, particularly excelling at detecting parameter-level hallucinations and inappropriate tool selections, critical for reliable agent deployment.",
      "authors": [
        "Kait Healy",
        "Bharathi Srinivasan",
        "Visakh Madathil",
        "Jing Wu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 18:38:45+00:00",
      "link": "https://arxiv.org/pdf/2601.05214v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05212v1",
      "title": "FlowLet: Conditional 3D Brain MRI Synthesis using Wavelet Flow Matching",
      "abstract": "Brain Magnetic Resonance Imaging (MRI) plays a central role in studying neurological development, aging, and diseases. One key application is Brain Age Prediction (BAP), which estimates an individual's biological brain age from MRI data. Effective BAP models require large, diverse, and age-balanced datasets, whereas existing 3D MRI datasets are demographically skewed, limiting fairness and generalizability. Acquiring new data is costly and ethically constrained, motivating generative data augmentation. Current generative methods are often based on latent diffusion models, which operate in learned low dimensional latent spaces to address the memory demands of volumetric MRI data. However, these methods are typically slow at inference, may introduce artifacts due to latent compression, and are rarely conditioned on age, thereby affecting the BAP performance. In this work, we propose FlowLet, a conditional generative framework that synthesizes age-conditioned 3D MRIs by leveraging flow matching within an invertible 3D wavelet domain, helping to avoid reconstruction artifacts and reducing computational demands. Experiments show that FlowLet generates high-fidelity volumes with few sampling steps. Training BAP models with data generated by FlowLet improves performance for underrepresented age groups, and region-based analysis confirms preservation of anatomical structures.",
      "authors": [
        "Danilo Danese",
        "Angela Lombardi",
        "Matteo Attimonelli",
        "Giuseppe Fasano",
        "Tommaso Di Noia"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 18:36:29+00:00",
      "link": "https://arxiv.org/pdf/2601.05212v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05208v1",
      "title": "MoE3D: A Mixture-of-Experts Module for 3D Reconstruction",
      "abstract": "MoE3D is a mixture-of-experts module designed to sharpen depth boundaries and mitigate flying-point artifacts (highlighted in red) of existing feed-forward 3D reconstruction models (left side). MoE3D predicts multiple candidate depth maps and fuses them via dynamic weighting (visualized by MoE weights on the right side). When integrated with a pre-trained 3D reconstruction backbone such as VGGT, it substantially enhances reconstruction quality with minimal additional computational overhead. Best viewed digitally.",
      "authors": [
        "Zichen Wang",
        "Ang Cao",
        "Liam J. Wang",
        "Jeong Joon Park"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 18:33:52+00:00",
      "link": "https://arxiv.org/pdf/2601.05208v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05205v1",
      "title": "EARL: Energy-Aware Optimization of Liquid State Machines for Pervasive AI",
      "abstract": "Pervasive AI increasingly depends on on-device learning systems that deliver low-latency and energy-efficient computation under strict resource constraints. Liquid State Machines (LSMs) offer a promising approach for low-power temporal processing in pervasive and neuromorphic systems, but their deployment remains challenging due to high hyperparameter sensitivity and the computational cost of traditional optimization methods that ignore energy constraints. This work presents EARL, an energy-aware reinforcement learning framework that integrates Bayesian optimization with an adaptive reinforcement learning based selection policy to jointly optimize accuracy and energy consumption. EARL employs surrogate modeling for global exploration, reinforcement learning for dynamic candidate prioritization, and an early termination mechanism to eliminate redundant evaluations, substantially reducing computational overhead. Experiments on three benchmark datasets demonstrate that EARL achieves 6 to 15 percent higher accuracy, 60 to 80 percent lower energy consumption, and up to an order of magnitude reduction in optimization time compared to leading hyperparameter tuning frameworks. These results highlight the effectiveness of energy-aware adaptive search in improving the efficiency and scalability of LSMs for resource-constrained on-device AI applications.",
      "authors": [
        "Zain Iqbal",
        "Lorenzo Valerio"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.PF"
      ],
      "published": "2026-01-08 18:31:11+00:00",
      "link": "https://arxiv.org/pdf/2601.05205v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05202v1",
      "title": "Stock Market Price Prediction using Neural Prophet with Deep Neural Network",
      "abstract": "Stock market price prediction is a significant interdisciplinary research domain that depends at the intersection of finance, statistics, and economics. Forecasting Accurately predicting stock prices has always been a focal point for various researchers. However, existing statistical approaches for time-series prediction often fail to effectively forecast the probability range of future stock prices. Hence, to solve this problem, the Neural Prophet with a Deep Neural Network (NP-DNN) is proposed to predict stock market prices. The preprocessing technique used in this research is Z-score normalization, which normalizes stock price data by removing scale differences, making patterns easier to detect. Missing value imputation fills gaps in historical data, enhancing the models use of complete information for more accurate predictions. The Multi-Layer Perceptron (MLP) learns complex nonlinear relationships among stock market prices and extracts hidden patterns from the input data, thereby creating meaningful feature representations for better prediction accuracy. The proposed NP-DNN model achieved an accuracy of 99.21% compared with other approaches using the Fused Large Language Model. Keywords: deep neural network, forecasting stock prices, multi-layer perceptron, neural prophet, stock market price prediction.",
      "authors": [
        "Navin Chhibber",
        "Suneel Khemka",
        "Navneet Kumar Tyagi",
        "Rohit Tewari",
        "Bireswar Banerjee",
        "Piyush Ranjan"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-08 18:24:22+00:00",
      "link": "https://arxiv.org/pdf/2601.05202v1",
      "tags": [
        "keyword:resnet",
        "keyword:resnet中文",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05201v1",
      "title": "Mechanisms of Prompt-Induced Hallucination in Vision-Language Models",
      "abstract": "Large vision-language models (VLMs) are highly capable, yet often hallucinate by favoring textual prompts over visual evidence. We study this failure mode in a controlled object-counting setting, where the prompt overstates the number of objects in the image (e.g., asking a model to describe four waterlilies when only three are present). At low object counts, models often correct the overestimation, but as the number of objects increases, they increasingly conform to the prompt regardless of the discrepancy. Through mechanistic analysis of three VLMs, we identify a small set of attention heads whose ablation substantially reduces prompt-induced hallucinations (PIH) by at least 40% without additional training. Across models, PIH-heads mediate prompt copying in model-specific ways. We characterize these differences and show that PIH ablation increases correction toward visual evidence. Our findings offer insights into the internal mechanisms driving prompt-induced hallucinations, revealing model-specific differences in how these behaviors are implemented.",
      "authors": [
        "William Rudman",
        "Michal Golovanevsky",
        "Dana Arad",
        "Yonatan Belinkov",
        "Ritambhara Singh",
        "Carsten Eickhoff",
        "Kyle Mahowald"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-08 18:23:03+00:00",
      "link": "https://arxiv.org/pdf/2601.05201v1",
      "tags": [
        "keyword:大语言模型",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05200v1",
      "title": "Multivector Reranking in the Era of Strong First-Stage Retrievers",
      "abstract": "Learned multivector representations power modern search systems with strong retrieval effectiveness, but their real-world use is limited by the high cost of exhaustive token-level retrieval. Therefore, most systems adopt a \\emph{gather-and-refine} strategy, where a lightweight gather phase selects candidates for full scoring. However, this approach requires expensive searches over large token-level indexes and often misses the documents that would rank highest under full similarity. In this paper, we reproduce several state-of-the-art multivector retrieval methods on two publicly available datasets, providing a clear picture of the current multivector retrieval field and observing the inefficiency of token-level gathering. Building on top of that, we show that replacing the token-level gather phase with a single-vector document retriever -- specifically, a learned sparse retriever (LSR) -- produces a smaller and more semantically coherent candidate set. This recasts the gather-and-refine pipeline into the well-established two-stage retrieval architecture. As retrieval latency decreases, query encoding with two neural encoders becomes the dominant computational bottleneck. To mitigate this, we integrate recent inference-free LSR methods, demonstrating that they preserve the retrieval effectiveness of the dual-encoder pipeline while substantially reducing query encoding time. Finally, we investigate multiple reranking configurations that balance efficiency, memory, and effectiveness, and we introduce two optimization techniques that prune low-quality candidates early. Empirical results show that these techniques improve retrieval efficiency by up to 1.8$\\times$ with no loss in quality. Overall, our two-stage approach achieves over $24\\times$ speedup over the state-of-the-art multivector retrieval systems, while maintaining comparable or superior retrieval quality.",
      "authors": [
        "Silvio Martinico",
        "Franco Maria Nardini",
        "Cosimo Rulli",
        "Rossano Venturini"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2026-01-08 18:22:18+00:00",
      "link": "https://arxiv.org/pdf/2601.05200v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05199v1",
      "title": "Approximation theory for distant Bang calculus",
      "abstract": "Approximation semantics capture the observable behaviour of λ-terms, with Böhm Trees and Taylor Expansion standing as two central paradigms. Although conceptually different, these notions are related via the Commutation Theorem, which links the Taylor expansion of a term to that of its Böhm tree. These notions are well understood in Call-by-Name λ-calculus and have been more recently introduced in Call-by-Value settings. Since these two evaluation strategies traditionally require separate theories, a natural next step is to seek a unified setting for approximation semantics. The Bang-calculus offers exactly such a framework, subsuming both CbN and CbV through linear-logic translations while providing robust rewriting properties. However, its approximation semantics is yet to be fully developed. In this work, we develop the approximation semantics for dBang, the Bang-calculus with explicit substitutions and distant reductions. We define Böhm trees and Taylor expansion within dBang and establish their fundamental properties. Our results subsume and generalize Call-By-Name and Call-By-Value through their translations into Bang, offering a single framework that uniformly captures infinitary and resource-sensitive semantics across evaluation strategies.",
      "authors": [
        "Kostia Chardonnet",
        "Jules Chouquet",
        "Axel Kerinec"
      ],
      "primary_category": "cs.LO",
      "categories": [
        "cs.LO"
      ],
      "published": "2026-01-08 18:20:06+00:00",
      "link": "https://arxiv.org/pdf/2601.05199v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05195v1",
      "title": "Basis Number of Graphs Excluding Minors",
      "abstract": "The basis number of a graph $G$ is the minimum $k$ such that the cycle space of $G$ is generated by a family of cycles using each edge at most $k$ times. A classical result of Mac Lane states that planar graphs are exactly graphs with basis number at most 2, and more generally, graphs embedded on a fixed surface are known to have bounded basis number. Generalising this, we prove that graphs excluding a fixed minor $H$ have bounded basis number.   Our proof uses the Graph Minor Structure Theorem, which requires us to understand how basis number behaves in tree-decompositions. In particular, we prove that graphs of treewidth $k$ have basis number bounded by some function of $k$. We handle tree-decompositions using the proof framework developed by Bojańczyk and Pilipczuk in their proof of Courcelle's conjecture.   Combining our approach with independent results of Miraftab, Morin and Yuditsky (2025) on basis number and path-decompositions, one can moreover improve our upper bound to a polynomial one: there exists an absolute constant $c>0$ such that every $H$-minor free graph has basis number $O(|H|^c)$.",
      "authors": [
        "Colin Geniet",
        "Ugo Giocanti"
      ],
      "primary_category": "math.CO",
      "categories": [
        "math.CO",
        "cs.DM"
      ],
      "published": "2026-01-08 18:18:10+00:00",
      "link": "https://arxiv.org/pdf/2601.05195v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05194v1",
      "title": "An interpretable data-driven approach to optimizing clinical fall risk assessment",
      "abstract": "In this study, we aim to better align fall risk prediction from the Johns Hopkins Fall Risk Assessment Tool (JHFRAT) with additional clinically meaningful measures via a data-driven modelling approach. We conducted a retrospective cohort analysis of 54,209 inpatient admissions from three Johns Hopkins Health System hospitals between March 2022 and October 2023. A total of 20,208 admissions were included as high fall risk encounters, and 13,941 were included as low fall risk encounters. To incorporate clinical knowledge and maintain interpretability, we employed constrained score optimization (CSO) models to reweight the JHFRAT scoring weights, while preserving its additive structure and clinical thresholds. Recalibration refers to adjusting item weights so that the resulting score can order encounters more consistently by the study's risk labels, and without changing the tool's form factor or deployment workflow. The model demonstrated significant improvements in predictive performance over the current JHFRAT (CSO AUC-ROC=0.91, JHFRAT AUC-ROC=0.86). This performance improvement translates to protecting an additional 35 high-risk patients per week across the Johns Hopkins Health System. The constrained score optimization models performed similarly with and without the EHR variables. Although the benchmark black-box model (XGBoost), improves upon the performance metrics of the knowledge-based constrained logistic regression (AUC-ROC=0.94), the CSO demonstrates more robustness to variations in risk labeling. This evidence-based approach provides a robust foundation for health systems to systematically enhance inpatient fall prevention protocols and patient safety using data-driven optimization techniques, contributing to improved risk assessment and resource allocation in healthcare settings.",
      "authors": [
        "Fardin Ganjkhanloo",
        "Emmett Springer",
        "Erik H. Hoyer",
        "Daniel L. Young",
        "Holley Farley",
        "Kimia Ghobadi"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-08 18:17:31+00:00",
      "link": "https://arxiv.org/pdf/2601.05194v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05192v1",
      "title": "LELA: an LLM-based Entity Linking Approach with Zero-Shot Domain Adaptation",
      "abstract": "Entity linking (mapping ambiguous mentions in text to entities in a knowledge base) is a foundational step in tasks such as knowledge graph construction, question-answering, and information extraction. Our method, LELA, is a modular coarse-to-fine approach that leverages the capabilities of large language models (LLMs), and works with different target domains, knowledge bases and LLMs, without any fine-tuning phase. Our experiments across various entity linking settings show that LELA is highly competitive with fine-tuned approaches, and substantially outperforms the non-fine-tuned ones.",
      "authors": [
        "Samy Haffoudhi",
        "Fabian M. Suchanek",
        "Nils Holzenberger"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 18:15:34+00:00",
      "link": "https://arxiv.org/pdf/2601.05192v1",
      "tags": [
        "keyword:resnet中文",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05191v1",
      "title": "Cutting AI Research Costs: How Task-Aware Compression Makes Large Language Model Agents Affordable",
      "abstract": "When researchers deploy large language models for autonomous tasks like reviewing literature or generating hypotheses, the computational bills add up quickly. A single research session using a 70-billion parameter model can cost around $127 in cloud fees, putting these tools out of reach for many academic labs. We developed AgentCompress to tackle this problem head-on. The core idea came from a simple observation during our own work: writing a novel hypothesis clearly demands more from the model than reformatting a bibliography. Why should both tasks run at full precision? Our system uses a small neural network to gauge how hard each incoming task will be, based only on its opening words, then routes it to a suitably compressed model variant. The decision happens in under a millisecond. Testing across 500 research workflows in four scientific fields, we cut compute costs by 68.3% while keeping 96.2% of the original success rate. For labs watching their budgets, this could mean the difference between running experiments and sitting on the sidelines",
      "authors": [
        "Zuhair Ahmed Khan Taha",
        "Mohammed Mudassir Uddin",
        "Shahnawaz Alam"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-01-08 18:13:46+00:00",
      "link": "https://arxiv.org/pdf/2601.05191v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05187v1",
      "title": "SimuAgent: An LLM-Based Simulink Modeling Assistant Enhanced with Reinforcement Learning",
      "abstract": "Large language models (LLMs) have revolutionized text-based code automation, but their potential in graph-oriented engineering workflows remains under-explored. We introduce SimuAgent, an LLM-powered modeling and simulation agent tailored for Simulink. SimuAgent replaces verbose XML with a concise, dictionary-style Python representation, dramatically cutting token counts, improving interpretability, and enabling fast, in-process simulation. A lightweight plan-execute architecture, trained in two stages, equips the agent with both low-level tool skills and high-level design reasoning. To tackle sparse rewards in long-horizon tasks, we propose Reflection-GRPO (ReGRPO), which augments Group Relative Policy Optimization (GRPO) with self-reflection traces that supply rich intermediate feedback, accelerating convergence and boosting robustness. Experiments on SimuBench, our newly released benchmark comprising 5300 multi-domain modeling tasks, show that a Qwen2.5-7B model fine-tuned with SimuAgent converges faster and achieves higher modeling accuracy than standard RL baselines, and even surpasses GPT-4o when evaluated with few-shot prompting on the same benchmark. Ablations confirm that the two-stage curriculum and abstract-reconstruct data augmentation further enhance generalization. SimuAgent trains and runs entirely on-premise with modest hardware, delivering a privacy-preserving, cost-effective solution for industrial model-driven engineering. SimuAgent bridges the gap between LLMs and graphical modeling environments, offering a practical solution for AI-assisted engineering design in industrial settings.",
      "authors": [
        "Yanchang Liang",
        "Xiaowei Zhao"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 18:10:35+00:00",
      "link": "https://arxiv.org/pdf/2601.05187v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05184v1",
      "title": "Observations and Remedies for Large Language Model Bias in Self-Consuming Performative Loop",
      "abstract": "The rapid advancement of large language models (LLMs) has led to growing interest in using synthetic data to train future models. However, this creates a self-consuming retraining loop, where models are trained on their own outputs and may cause performance drops and induce emerging biases. In real-world applications, previously deployed LLMs may influence the data they generate, leading to a dynamic system driven by user feedback. For example, if a model continues to underserve users from a group, less query data will be collected from this particular demographic of users. In this study, we introduce the concept of \\textbf{S}elf-\\textbf{C}onsuming \\textbf{P}erformative \\textbf{L}oop (\\textbf{SCPL}) and investigate the role of synthetic data in shaping bias during these dynamic iterative training processes under controlled performative feedback. This controlled setting is motivated by the inaccessibility of real-world user preference data from dynamic production systems, and enables us to isolate and analyze feedback-driven bias evolution in a principled manner. We focus on two types of loops, including the typical retraining setting and the incremental fine-tuning setting, which is largely underexplored. Through experiments on three real-world tasks, we find that the performative loop increases preference bias and decreases disparate bias. We design a reward-based rejection sampling strategy to mitigate the bias, moving towards more trustworthy self-improving systems.",
      "authors": [
        "Yaxuan Wang",
        "Zhongteng Cai",
        "Yujia Bao",
        "Xueru Zhang",
        "Yang Liu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-08 18:08:15+00:00",
      "link": "https://arxiv.org/pdf/2601.05184v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05181v1",
      "title": "Spacecube: A fast inverse hyperspectral georectification system",
      "abstract": "Hyperspectral cameras provide numerous advantages in terms of the utility of the data captured. They capture hundreds of data points per sample (pixel) instead of only the few of RGB or multispectral camera systems. Aerial systems sense such data remotely, but the data must be georectified to produce consistent images before analysis. We find the traditional direct georectification method to be slow, and it is prone to artifacts. To address its downsides, we propose Spacecube, a program that implements a complete hyperspectral georectification pipeline, including our own fast inverse georectification technique, using OpenGL graphics programming technologies. Spacecube operates substantially faster than real-time and eliminates pixel coverage artifacts. It facilitates high quality interactive viewing, data exploration, and export of final products. We release Spacecube's source code publicly for the community to use.",
      "authors": [
        "Thomas P. Watson",
        "Eddie L. Jacobs"
      ],
      "primary_category": "eess.IV",
      "categories": [
        "eess.IV",
        "cs.GR"
      ],
      "published": "2026-01-08 18:04:09+00:00",
      "link": "https://arxiv.org/pdf/2601.05181v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05180v1",
      "title": "The Adverse Effects of Omitting Records in Differential Privacy: How Sampling and Suppression Degrade the Privacy-Utility Tradeoff (Long Version)",
      "abstract": "Sampling is renowned for its privacy amplification in differential privacy (DP), and is often assumed to improve the utility of a DP mechanism by allowing a noise reduction. In this paper, we further show that this last assumption is flawed: When measuring utility at equal privacy levels, sampling as preprocessing consistently yields penalties due to utility loss from omitting records over all canonical DP mechanisms -- Laplace, Gaussian, exponential, and report noisy max -- as well as recent applications of sampling, such as clustering.   Extending this analysis, we investigate suppression as a generalized method of choosing, or omitting, records. Developing a theoretical analysis of this technique, we derive privacy bounds for arbitrary suppression strategies under unbounded approximate DP. We find that our tested suppression strategy also fails to improve the privacy-utility tradeoff. Surprisingly, uniform sampling emerges as one of the best suppression methods -- despite its still degrading effect. Our results call into question common preprocessing assumptions in DP practice.",
      "authors": [
        "Àlex Miranda-Pascual",
        "Javier Parra-Arnau",
        "Thorsten Strufe"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR"
      ],
      "published": "2026-01-08 18:03:57+00:00",
      "link": "https://arxiv.org/pdf/2601.05180v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05175v1",
      "title": "VideoAuto-R1: Video Auto Reasoning via Thinking Once, Answering Twice",
      "abstract": "Chain-of-thought (CoT) reasoning has emerged as a powerful tool for multimodal large language models on video understanding tasks. However, its necessity and advantages over direct answering remain underexplored. In this paper, we first demonstrate that for RL-trained video models, direct answering often matches or even surpasses CoT performance, despite CoT producing step-by-step analyses at a higher computational cost. Motivated by this, we propose VideoAuto-R1, a video understanding framework that adopts a reason-when-necessary strategy. During training, our approach follows a Thinking Once, Answering Twice paradigm: the model first generates an initial answer, then performs reasoning, and finally outputs a reviewed answer. Both answers are supervised via verifiable rewards. During inference, the model uses the confidence score of the initial answer to determine whether to proceed with reasoning. Across video QA and grounding benchmarks, VideoAuto-R1 achieves state-of-the-art accuracy with significantly improved efficiency, reducing the average response length by ~3.3x, e.g., from 149 to just 44 tokens. Moreover, we observe a low rate of thinking-mode activation on perception-oriented tasks, but a higher rate on reasoning-intensive tasks. This suggests that explicit language-based reasoning is generally beneficial but not always necessary.",
      "authors": [
        "Shuming Liu",
        "Mingchen Zhuge",
        "Changsheng Zhao",
        "Jun Chen",
        "Lemeng Wu",
        "Zechun Liu",
        "Chenchen Zhu",
        "Zhipeng Cai",
        "Chong Zhou",
        "Haozhe Liu",
        "Ernie Chang",
        "Saksham Suri",
        "Hongyu Xu",
        "Qi Qian",
        "Wei Wen",
        "Balakrishnan Varadarajan",
        "Zhuang Liu",
        "Hu Xu",
        "Florian Bordes",
        "Raghuraman Krishnamoorthi",
        "Bernard Ghanem",
        "Vikas Chandra",
        "Yunyang Xiong"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 18:00:59+00:00",
      "link": "https://arxiv.org/pdf/2601.05175v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05174v1",
      "title": "FaST: Efficient and Effective Long-Horizon Forecasting for Large-Scale Spatial-Temporal Graphs via Mixture-of-Experts",
      "abstract": "Spatial-Temporal Graph (STG) forecasting on large-scale networks has garnered significant attention. However, existing models predominantly focus on short-horizon predictions and suffer from notorious computational costs and memory consumption when scaling to long-horizon predictions and large graphs. Targeting the above challenges, we present FaST, an effective and efficient framework based on heterogeneity-aware Mixture-of-Experts (MoEs) for long-horizon and large-scale STG forecasting, which unlocks one-week-ahead (672 steps at a 15-minute granularity) prediction with thousands of nodes. FaST is underpinned by two key innovations. First, an adaptive graph agent attention mechanism is proposed to alleviate the computational burden inherent in conventional graph convolution and self-attention modules when applied to large-scale graphs. Second, we propose a new parallel MoE module that replaces traditional feed-forward networks with Gated Linear Units (GLUs), enabling an efficient and scalable parallel structure. Extensive experiments on real-world datasets demonstrate that FaST not only delivers superior long-horizon predictive accuracy but also achieves remarkable computational efficiency compared to state-of-the-art baselines. Our source code is available at: https://github.com/yijizhao/FaST.",
      "authors": [
        "Yiji Zhao",
        "Zihao Zhong",
        "Ao Wang",
        "Haomin Wen",
        "Ming Jin",
        "Yuxuan Liang",
        "Huaiyu Wan",
        "Hao Wu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-08 18:00:58+00:00",
      "link": "https://arxiv.org/pdf/2601.05174v1",
      "tags": [
        "keyword:大语言模型",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05173v1",
      "title": "Information-Theoretic Limits on Exact Subgraph Alignment Problem",
      "abstract": "The graph alignment problem aims to identify the vertex correspondence between two correlated graphs. Most existing studies focus on the scenario in which the two graphs share the same vertex set. However, in many real-world applications, such as computer vision, social network analysis, and bioinformatics, the task often involves locating a small graph pattern within a larger graph. Existing graph alignment algorithms and analysis cannot directly address these scenarios because they are not designed to identify the specific subset of vertices where the small graph pattern resides within the larger graph. Motivated by this limitation, we introduce the subgraph alignment problem, which seeks to recover both the vertex set and/or the vertex correspondence of a small graph pattern embedded in a larger graph. In the special case where the small graph pattern is an induced subgraph of the larger graph and both the vertex set and correspondence are to be recovered, the problem reduces to the subgraph isomorphism problem, which is NP-complete in the worst case. In this paper, we formally formulate the subgraph alignment problem by proposing the Erdos-Renyi subgraph pair model together with some appropriate recovery criterion. We then establish almost-tight information-theoretic results for the subgraph alignment problem and present some novel approaches for the analysis.",
      "authors": [
        "Chun Hei Michael Shiu",
        "Hei Victor Cheng",
        "Lele Wang"
      ],
      "primary_category": "cs.IT",
      "categories": [
        "cs.IT"
      ],
      "published": "2026-01-08 17:59:49+00:00",
      "link": "https://arxiv.org/pdf/2601.05173v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05172v1",
      "title": "CoV: Chain-of-View Prompting for Spatial Reasoning",
      "abstract": "Embodied question answering (EQA) in 3D environments often requires collecting context that is distributed across multiple viewpoints and partially occluded. However, most recent vision--language models (VLMs) are constrained to a fixed and finite set of input views, which limits their ability to acquire question-relevant context at inference time and hinders complex spatial reasoning. We propose Chain-of-View (CoV) prompting, a training-free, test-time reasoning framework that transforms a VLM into an active viewpoint reasoner through a coarse-to-fine exploration process. CoV first employs a View Selection agent to filter redundant frames and identify question-aligned anchor views. It then performs fine-grained view adjustment by interleaving iterative reasoning with discrete camera actions, obtaining new observations from the underlying 3D scene representation until sufficient context is gathered or a step budget is reached.   We evaluate CoV on OpenEQA across four mainstream VLMs and obtain an average +11.56\\% improvement in LLM-Match, with a maximum gain of +13.62\\% on Qwen3-VL-Flash. CoV further exhibits test-time scaling: increasing the minimum action budget yields an additional +2.51\\% average improvement, peaking at +3.73\\% on Gemini-2.5-Flash. On ScanQA and SQA3D, CoV delivers strong performance (e.g., 116 CIDEr / 31.9 EM@1 on ScanQA and 51.1 EM@1 on SQA3D). Overall, these results suggest that question-aligned view selection coupled with open-view search is an effective, model-agnostic strategy for improving spatial reasoning in 3D EQA without additional training.",
      "authors": [
        "Haoyu Zhao",
        "Akide Liu",
        "Zeyu Zhang",
        "Weijie Wang",
        "Feng Chen",
        "Ruihan Zhu",
        "Gholamreza Haffari",
        "Bohan Zhuang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-01-08 17:59:42+00:00",
      "link": "https://arxiv.org/pdf/2601.05172v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05171v1",
      "title": "Inside Out: Evolving User-Centric Core Memory Trees for Long-Term Personalized Dialogue Systems",
      "abstract": "Existing long-term personalized dialogue systems struggle to reconcile unbounded interaction streams with finite context constraints, often succumbing to memory noise accumulation, reasoning degradation, and persona inconsistency. To address these challenges, this paper proposes Inside Out, a framework that utilizes a globally maintained PersonaTree as the carrier of long-term user profiling. By constraining the trunk with an initial schema and updating the branches and leaves, PersonaTree enables controllable growth, achieving memory compression while preserving consistency. Moreover, we train a lightweight MemListener via reinforcement learning with process-based rewards to produce structured, executable, and interpretable {ADD, UPDATE, DELETE, NO_OP} operations, thereby supporting the dynamic evolution of the personalized tree. During response generation, PersonaTree is directly leveraged to enhance outputs in latency-sensitive scenarios; when users require more details, the agentic mode is triggered to introduce details on-demand under the constraints of the PersonaTree. Experiments show that PersonaTree outperforms full-text concatenation and various personalized memory systems in suppressing contextual noise and maintaining persona consistency. Notably, the small MemListener model achieves memory-operation decision performance comparable to, or even surpassing, powerful reasoning models such as DeepSeek-R1-0528 and Gemini-3-Pro.",
      "authors": [
        "Jihao Zhao",
        "Ding Chen",
        "Zhaoxin Fan",
        "Kerun Xu",
        "Mengting Hu",
        "Bo Tang",
        "Feiyu Xiong",
        "Zhiyu li"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 17:59:11+00:00",
      "link": "https://arxiv.org/pdf/2601.05171v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05170v1",
      "title": "Reverse-engineering NLI: A study of the meta-inferential properties of Natural Language Inference",
      "abstract": "Natural Language Inference (NLI) has been an important task for evaluating language models for Natural Language Understanding, but the logical properties of the task are poorly understood and often mischaracterized. Understanding the notion of inference captured by NLI is key to interpreting model performance on the task. In this paper we formulate three possible readings of the NLI label set and perform a comprehensive analysis of the meta-inferential properties they entail. Focusing on the SNLI dataset, we exploit (1) NLI items with shared premises and (2) items generated by LLMs to evaluate models trained on SNLI for meta-inferential consistency and derive insights into which reading of the logical relations is encoded by the dataset.",
      "authors": [
        "Rasmus Blanck",
        "Bill Noble",
        "Stergios Chatzikyriakidis"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 17:58:52+00:00",
      "link": "https://arxiv.org/pdf/2601.05170v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05167v1",
      "title": "RelayLLM: Efficient Reasoning via Collaborative Decoding",
      "abstract": "Large Language Models (LLMs) for complex reasoning is often hindered by high computational costs and latency, while resource-efficient Small Language Models (SLMs) typically lack the necessary reasoning capacity. Existing collaborative approaches, such as cascading or routing, operate at a coarse granularity by offloading entire queries to LLMs, resulting in significant computational waste when the SLM is capable of handling the majority of reasoning steps. To address this, we propose RelayLLM, a novel framework for efficient reasoning via token-level collaborative decoding. Unlike routers, RelayLLM empowers the SLM to act as an active controller that dynamically invokes the LLM only for critical tokens via a special command, effectively \"relaying\" the generation process. We introduce a two-stage training framework, including warm-up and Group Relative Policy Optimization (GRPO) to teach the model to balance independence with strategic help-seeking. Empirical results across six benchmarks demonstrate that RelayLLM achieves an average accuracy of 49.52%, effectively bridging the performance gap between the two models. Notably, this is achieved by invoking the LLM for only 1.07% of the total generated tokens, offering a 98.2% cost reduction compared to performance-matched random routers.",
      "authors": [
        "Chengsong Huang",
        "Tong Zheng",
        "Langlin Huang",
        "Jinyuan Li",
        "Haolin Liu",
        "Jiaxin Huang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-08 17:56:16+00:00",
      "link": "https://arxiv.org/pdf/2601.05167v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05166v1",
      "title": "Inapproximability of Counting Permutation Patterns",
      "abstract": "Detecting and counting copies of permutation patterns are fundamental algorithmic problems, with applications in the analysis of rankings, nonparametric statistics, and property testing tasks such as independence and quasirandomness testing. From an algorithmic perspective, there is a sharp difference in complexity between detecting and counting the copies of a given length-$k$ pattern in a length-$n$ permutation. The former admits a $2^{\\mathcal{O}(k^2)} \\cdot n$ time algorithm (Guillemot and Marx, 2014) while the latter cannot be solved in time $f(k)\\cdot n^{o(k/\\log k)}$ unless the Exponential Time Hypothesis (ETH) fails (Berendsohn, Kozma, and Marx, 2021). In fact already for patterns of length 4, exact counting is unlikely to admit near-linear time algorithms under standard fine-grained complexity assumptions (Dudek and Gawrychowski, 2020).   Recently, Ben-Eliezer, Mitrović and Sristava (2026) showed that for patterns of length up to 5, a $(1+\\varepsilon)$-approximation of the pattern count can be computed in near-linear time, yielding a separation between exact and approximate counting for small patterns, and conjectured that approximate counting is asymptotically easier than exact counting in general. We strongly refute their conjecture by showing that, under ETH, no algorithm running in time $f(k)\\cdot n^{o(k/\\log k)}$ can approximate the number of copies of a length-$k$ pattern within a multiplicative factor $n^{(1/2-\\varepsilon)k}$. The lower bound on runtime matches the conditional lower bound for exact pattern counting, and the obtained bound on the multiplicative error factor is essentially tight, as an $n^{k/2}$-approximation can be computed in $2^{\\mathcal{O}(k^2)}\\cdot n$ time using an algorithm for pattern detection.",
      "authors": [
        "Michal Opler"
      ],
      "primary_category": "cs.DS",
      "categories": [
        "cs.DS"
      ],
      "published": "2026-01-08 17:55:57+00:00",
      "link": "https://arxiv.org/pdf/2601.05166v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05165v1",
      "title": "Fundamental Tradeoffs for ISAC Multiple Access in Finite-Blocklength Regime",
      "abstract": "This paper investigates the fundamental communication--sensing tradeoffs of uplink dual-functional integrated sensing and communication (ISAC) multiple access under finite blocklength (FBL) constraints. Unlike conventional asymptotic analyses, we explicitly account for the limitations under FBL constraints imposed by short packets and low-latency transmission. By examining the unbiased channel state sensing estimator, we establish a geometric decomposition of the sensing error, indicating that it is jointly determined by the signal-to-noise ratio and the correlation structure of the information codebook. This insight reveals how cross-correlation among active users in the codebook geometry fundamentally constrains dual-functional ISAC performance. Consequently, we derive achievability and converse bounds that characterize the tradeoff between communication code rate and sensing accuracy in the FBL regime, with the converse further bounded by Shannon capacity. Moreover, by treating channel state sensing as a high-level sensing objective, a universal Cramér--Rao bound is derived to link channel estimation accuracy to practical sensing parameters. Examples of parameter sensing are also provided based on 3GPP standard. Numerical results validate the theoretical analysis and demonstrate the impact of blocklength, antenna dimensions, and sensing requirements.",
      "authors": [
        "Zhentian Zhang",
        "Christos Masouros",
        "Kai-Kit Wong",
        "Jian Dang",
        "Zaichen Zhang",
        "Kaitao Meng",
        "Farshad Rostami Ghadi",
        "Mohammad Javad Ahmadi"
      ],
      "primary_category": "cs.IT",
      "categories": [
        "cs.IT"
      ],
      "published": "2026-01-08 17:55:55+00:00",
      "link": "https://arxiv.org/pdf/2601.05165v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05163v1",
      "title": "DocDancer: Towards Agentic Document-Grounded Information Seeking",
      "abstract": "Document Question Answering (DocQA) focuses on answering questions grounded in given documents, yet existing DocQA agents lack effective tool utilization and largely rely on closed-source models. In this work, we introduce DocDancer, an end-to-end trained open-source Doc agent. We formulate DocQA as an information-seeking problem and propose a tool-driven agent framework that explicitly models document exploration and comprehension. To enable end-to-end training of such agents, we introduce an Exploration-then-Synthesis data synthesis pipeline that addresses the scarcity of high-quality training data for DocQA. Training on the synthesized data, the trained models on two long-context document understanding benchmarks, MMLongBench-Doc and DocBench, show their effectiveness. Further analysis provides valuable insights for the agentic tool design and synthetic data.",
      "authors": [
        "Qintong Zhang",
        "Xinjie Lv",
        "Jialong Wu",
        "Baixuan Li",
        "Zhengwei Tao",
        "Guochen Yan",
        "Huanyao Zhang",
        "Bin Wang",
        "Jiahao Xu",
        "Haitao Mi",
        "Wentao Zhang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 17:54:32+00:00",
      "link": "https://arxiv.org/pdf/2601.05163v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05162v1",
      "title": "GenAI-DrawIO-Creator: A Framework for Automated Diagram Generation",
      "abstract": "Diagrams are crucial for communicating complex information, yet creating and modifying them remains a labor-intensive task. We present GenAI-DrawIO-Creator, a novel framework that leverages Large Language Models (LLMs) to automate diagram generation and manipulation in the structured XML format used by draw.io. Our system integrates Claude 3.7 to reason about structured visual data and produce valid diagram representations. Key contributions include a high-level system design enabling real-time diagram updates, specialized prompt engineering and error-checking to ensure well-formed XML outputs. We demonstrate a working prototype capable of generating accurate diagrams (such as network architectures and flowcharts) from natural language or code, and even replicating diagrams from images. Simulated evaluations show that our approach significantly reduces diagram creation time and produces outputs with high structural fidelity. Our results highlight the promise of Claude 3.7 in handling structured visual reasoning tasks and lay the groundwork for future research in AI-assisted diagramming applications.",
      "authors": [
        "Jinze Yu",
        "Dayuan Jiang"
      ],
      "primary_category": "cs.GR",
      "categories": [
        "cs.GR",
        "cs.CV"
      ],
      "published": "2026-01-08 17:51:35+00:00",
      "link": "https://arxiv.org/pdf/2601.05162v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05159v1",
      "title": "Vision-Language Introspection: Mitigating Overconfident Hallucinations in MLLMs via Interpretable Bi-Causal Steering",
      "abstract": "Object hallucination critically undermines the reliability of Multimodal Large Language Models, often stemming from a fundamental failure in cognitive introspection, where models blindly trust linguistic priors over specific visual evidence. Existing mitigations remain limited: contrastive decoding approaches operate superficially without rectifying internal semantic misalignments, while current latent steering methods rely on static vectors that lack instance-specific precision. We introduce Vision-Language Introspection (VLI), a training-free inference framework that simulates a metacognitive self-correction process. VLI first performs Attributive Introspection to diagnose hallucination risks via probabilistic conflict detection and localize the causal visual anchors. It then employs Interpretable Bi-Causal Steering to actively modulate the inference process, dynamically isolating visual evidence from background noise while neutralizing blind confidence through adaptive calibration. VLI achieves state-of-the-art performance on advanced models, reducing object hallucination rates by 12.67% on MMHal-Bench and improving accuracy by 5.8% on POPE.",
      "authors": [
        "Shuliang Liu",
        "Songbo Yang",
        "Dong Fang",
        "Sihang Jia",
        "Yuqi Tang",
        "Lingfeng Su",
        "Ruoshui Peng",
        "Yibo Yan",
        "Xin Zou",
        "Xuming Hu"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-01-08 17:49:13+00:00",
      "link": "https://arxiv.org/pdf/2601.05159v1",
      "tags": [
        "keyword:大语言模型",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05157v1",
      "title": "Learning Mixture Models via Efficient High-dimensional Sparse Fourier Transforms",
      "abstract": "In this work, we give a ${\\rm poly}(d,k)$ time and sample algorithm for efficiently learning the parameters of a mixture of $k$ spherical distributions in $d$ dimensions. Unlike all previous methods, our techniques apply to heavy-tailed distributions and include examples that do not even have finite covariances. Our method succeeds whenever the cluster distributions have a characteristic function with sufficiently heavy tails. Such distributions include the Laplace distribution but crucially exclude Gaussians.   All previous methods for learning mixture models relied implicitly or explicitly on the low-degree moments. Even for the case of Laplace distributions, we prove that any such algorithm must use super-polynomially many samples. Our method thus adds to the short list of techniques that bypass the limitations of the method of moments.   Somewhat surprisingly, our algorithm does not require any minimum separation between the cluster means. This is in stark contrast to spherical Gaussian mixtures where a minimum $\\ell_2$-separation is provably necessary even information-theoretically [Regev and Vijayaraghavan '17]. Our methods compose well with existing techniques and allow obtaining ''best of both worlds\" guarantees for mixtures where every component either has a heavy-tailed characteristic function or has a sub-Gaussian tail with a light-tailed characteristic function.   Our algorithm is based on a new approach to learning mixture models via efficient high-dimensional sparse Fourier transforms. We believe that this method will find more applications to statistical estimation. As an example, we give an algorithm for consistent robust mean estimation against noise-oblivious adversaries, a model practically motivated by the literature on multiple hypothesis testing. It was formally proposed in a recent Master's thesis by one of the authors, and has already inspired follow-up works.",
      "authors": [
        "Alkis Kalavasis",
        "Pravesh K. Kothari",
        "Shuchen Li",
        "Manolis Zampetakis"
      ],
      "primary_category": "cs.DS",
      "categories": [
        "cs.DS",
        "cs.LG",
        "stat.ML"
      ],
      "published": "2026-01-08 17:47:58+00:00",
      "link": "https://arxiv.org/pdf/2601.05157v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05152v1",
      "title": "Safe Continual Reinforcement Learning Methods for Nonstationary Environments. Towards a Survey of the State of the Art",
      "abstract": "This work provides a state-of-the-art survey of continual safe online reinforcement learning (COSRL) methods. We discuss theoretical aspects, challenges, and open questions in building continual online safe reinforcement learning algorithms. We provide the taxonomy and the details of continual online safe reinforcement learning methods based on the type of safe learning mechanism that takes adaptation to nonstationarity into account. We categorize safety constraints formulation for online reinforcement learning algorithms, and finally, we discuss prospects for creating reliable, safe online learning algorithms.   Keywords: safe RL in nonstationary environments, safe continual reinforcement learning under nonstationarity, HM-MDP, NSMDP, POMDP, safe POMDP, constraints for continual learning, safe continual reinforcement learning review, safe continual reinforcement learning survey, safe continual reinforcement learning, safe online learning under distribution shift, safe continual online adaptation, safe reinforcement learning, safe exploration, safe adaptation, constrained Markov decision processes, safe reinforcement learning, partially observable Markov decision process, safe reinforcement learning and hidden Markov decision processes, Safe Online Reinforcement Learning, safe online reinforcement learning, safe online reinforcement learning, safe meta-learning, safe meta-reinforcement learning, safe context-based reinforcement learning, formulating safety constraints for continual learning",
      "authors": [
        "Timofey Tomashevskiy"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-08 17:42:56+00:00",
      "link": "https://arxiv.org/pdf/2601.05152v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05151v1",
      "title": "ROOFS: RObust biOmarker Feature Selection",
      "abstract": "Feature selection (FS) is essential for biomarker discovery and in the analysis of biomedical datasets. However, challenges such as high-dimensional feature space, low sample size, multicollinearity, and missing values make FS non-trivial. Moreover, FS performances vary across datasets and predictive tasks. We propose roofs, a Python package available at https://gitlab.inria.fr/compo/roofs, designed to help researchers in the choice of FS method adapted to their problem. Roofs benchmarks multiple FS methods on the user's data and generates reports that summarize a comprehensive set of evaluation metrics, including downstream predictive performance estimated using optimism correction, stability, reliability of individual features, and true positive and false positive rates assessed on semi-synthetic data with a simulated outcome. We demonstrate the utility of roofs on data from the PIONeeR clinical trial, aimed at identifying predictors of resistance to anti-PD-(L)1 immunotherapy in lung cancer. The PIONeeR dataset contained 374 multi-source blood and tumor biomarkers from 435 patients. A reduced subset of 214 features was obtained through iterative variance inflation factor pre-filtering. Of the 34 FS methods gathered in roofs, we evaluated 23 in combination with 11 classifiers (253 models in total) and identified a filter based on the union of Benjamini-Hochberg false discovery rate-adjusted p-values from t-test and logistic regression as the optimal approach, outperforming other methods including the widely used LASSO. We conclude that comprehensive benchmarking with roofs has the potential to improve the robustness and reproducibility of FS discoveries and increase the translational value of clinical models.",
      "authors": [
        "Anastasiia Bakhmach",
        "Paul Dufossé",
        "Andrea Vaglio",
        "Florence Monville",
        "Laurent Greillier",
        "Fabrice Barlési",
        "Sébastien Benzekry"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "published": "2026-01-08 17:41:07+00:00",
      "link": "https://arxiv.org/pdf/2601.05151v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05150v1",
      "title": "$PC^2$: Politically Controversial Content Generation via Jailbreaking Attacks on GPT-based Text-to-Image Models",
      "abstract": "The rapid evolution of text-to-image (T2I) models has enabled high-fidelity visual synthesis on a global scale. However, these advancements have introduced significant security risks, particularly regarding the generation of harmful content. Politically harmful content, such as fabricated depictions of public figures, poses severe threats when weaponized for fake news or propaganda. Despite its criticality, the robustness of current T2I safety filters against such politically motivated adversarial prompting remains underexplored. In response, we propose $PC^2$, the first black-box political jailbreaking framework for T2I models. It exploits a novel vulnerability where safety filters evaluate political sensitivity based on linguistic context. $PC^2$ operates through: (1) Identity-Preserving Descriptive Mapping to obfuscate sensitive keywords into neutral descriptions, and (2) Geopolitically Distal Translation to map these descriptions into fragmented, low-sensitivity languages. This strategy prevents filters from constructing toxic relationships between political entities within prompts, effectively bypassing detection. We construct a benchmark of 240 politically sensitive prompts involving 36 public figures. Evaluation on commercial T2I models, specifically GPT-series, shows that while all original prompts are blocked, $PC^2$ achieves attack success rates of up to 86%.",
      "authors": [
        "Wonwoo Choi",
        "Minjae Seo",
        "Minkyoo Song",
        "Hwanjo Heo",
        "Seungwon Shin",
        "Myoungsung You"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR"
      ],
      "published": "2026-01-08 17:40:50+00:00",
      "link": "https://arxiv.org/pdf/2601.05150v1",
      "tags": [
        "keyword:resnet",
        "keyword:resnet中文",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05149v1",
      "title": "Multi-Scale Local Speculative Decoding for Image Generation",
      "abstract": "Autoregressive (AR) models have achieved remarkable success in image synthesis, yet their sequential nature imposes significant latency constraints. Speculative Decoding offers a promising avenue for acceleration, but existing approaches are limited by token-level ambiguity and lack of spatial awareness. In this work, we introduce Multi-Scale Local Speculative Decoding (MuLo-SD), a novel framework that combines multi-resolution drafting with spatially informed verification to accelerate AR image generation. Our method leverages a low-resolution drafter paired with learned up-samplers to propose candidate image tokens, which are then verified in parallel by a high-resolution target model. Crucially, we incorporate a local rejection and resampling mechanism, enabling efficient correction of draft errors by focusing on spatial neighborhoods rather than raster-scan resampling after the first rejection. We demonstrate that MuLo-SD achieves substantial speedups - up to $\\mathbf{1.7\\times}$ - outperforming strong speculative decoding baselines such as EAGLE-2 and LANTERN in terms of acceleration, while maintaining comparable semantic alignment and perceptual quality. These results are validated using GenEval, DPG-Bench, and FID/HPSv2 on the MS-COCO 5k validation split. Extensive ablations highlight the impact of up-sampling design, probability pooling, and local rejection and resampling with neighborhood expansion. Our approach sets a new state-of-the-art in speculative decoding for image synthesis, bridging the gap between efficiency and fidelity.",
      "authors": [
        "Elia Peruzzo",
        "Guillaume Sautière",
        "Amirhossein Habibian"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 17:39:35+00:00",
      "link": "https://arxiv.org/pdf/2601.05149v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05148v1",
      "title": "Atlas 2 -- Foundation models for clinical deployment",
      "abstract": "Pathology foundation models substantially advanced the possibilities in computational pathology -- yet tradeoffs in terms of performance, robustness, and computational requirements remained, which limited their clinical deployment. In this report, we present Atlas 2, Atlas 2-B, and Atlas 2-S, three pathology vision foundation models which bridge these shortcomings by showing state-of-the-art performance in prediction performance, robustness, and resource efficiency in a comprehensive evaluation across eighty public benchmarks. Our models were trained on the largest pathology foundation model dataset to date comprising 5.5 million histopathology whole slide images, collected from three medical institutions Charité - Universtätsmedizin Berlin, LMU Munich, and Mayo Clinic.",
      "authors": [
        "Maximilian Alber",
        "Timo Milbich",
        "Alexandra Carpen-Amarie",
        "Stephan Tietz",
        "Jonas Dippel",
        "Lukas Muttenthaler",
        "Beatriz Perez Cancer",
        "Alessandro Benetti",
        "Panos Korfiatis",
        "Elias Eulig",
        "Jérôme Lüscher",
        "Jiasen Wu",
        "Sayed Abid Hashimi",
        "Gabriel Dernbach",
        "Simon Schallenberg",
        "Neelay Shah",
        "Moritz Krügener",
        "Aniruddh Jammoria",
        "Jake Matras",
        "Patrick Duffy",
        "Matt Redlon",
        "Philipp Jurmeister",
        "David Horst",
        "Lukas Ruff",
        "Klaus-Robert Müller",
        "Frederick Klauschen",
        "Andrew Norgan"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-08 17:37:00+00:00",
      "link": "https://arxiv.org/pdf/2601.05148v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05144v1",
      "title": "Distilling the Thought, Watermarking the Answer: A Principle Semantic Guided Watermark for Large Reasoning Models",
      "abstract": "Reasoning Large Language Models (RLLMs) excelling in complex tasks present unique challenges for digital watermarking, as existing methods often disrupt logical coherence or incur high computational costs. Token-based watermarking techniques can corrupt the reasoning flow by applying pseudo-random biases, while semantic-aware approaches improve quality but introduce significant latency or require auxiliary models. This paper introduces ReasonMark, a novel watermarking framework specifically designed for reasoning-intensive LLMs. Our approach decouples generation into an undisturbed Thinking Phase and a watermarked Answering Phase. We propose a Criticality Score to identify semantically pivotal tokens from the reasoning trace, which are distilled into a Principal Semantic Vector (PSV). The PSV then guides a semantically-adaptive mechanism that modulates watermark strength based on token-PSV alignment, ensuring robustness without compromising logical integrity. Extensive experiments show ReasonMark surpasses state-of-the-art methods by reducing text Perplexity by 0.35, increasing translation BLEU score by 0.164, and raising mathematical accuracy by 0.67 points. These advancements are achieved alongside a 0.34% higher watermark detection AUC and stronger robustness to attacks, all with a negligible increase in latency. This work enables the traceable and trustworthy deployment of reasoning LLMs in real-world applications.",
      "authors": [
        "Shuliang Liu",
        "Xingyu Li",
        "Hongyi Liu",
        "Yibo Yan",
        "Bingchen Duan",
        "Qi Zheng",
        "Dong Fang",
        "Lingfeng Su",
        "Xuming Hu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 17:32:22+00:00",
      "link": "https://arxiv.org/pdf/2601.05144v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05143v1",
      "title": "A Lightweight and Explainable Vision-Language Framework for Crop Disease Visual Question Answering",
      "abstract": "Visual question answering for crop disease analysis requires accurate visual understanding and reliable language generation. This work presents a lightweight vision-language framework for crop and disease identification from leaf images. The proposed approach combines a Swin Transformer vision encoder with sequence-to-sequence language decoders. A two-stage training strategy is adopted to improve visual representation learning and cross-modal alignment. The model is evaluated on a large-scale crop disease dataset using classification and natural language generation metrics. Experimental results show high accuracy for both crop and disease identification. The framework also achieves strong performance on BLEU, ROUGE and BERTScore. Our proposed models outperform large-scale vision-language baselines while using significantly fewer parameters. Explainability is assessed using Grad-CAM and token-level attribution. Qualitative results demonstrate robust performance under diverse user-driven queries. These findings highlight the effectiveness of task-specific visual pretraining for crop disease visual question answering.",
      "authors": [
        "Md. Zahid Hossain",
        "Most. Sharmin Sultana Samu",
        "Md. Rakibul Islam",
        "Md. Siam Ansary"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.CL"
      ],
      "published": "2026-01-08 17:31:09+00:00",
      "link": "https://arxiv.org/pdf/2601.05143v1",
      "tags": [
        "keyword:大语言模型",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05138v1",
      "title": "VerseCrafter: Dynamic Realistic Video World Model with 4D Geometric Control",
      "abstract": "Video world models aim to simulate dynamic, real-world environments, yet existing methods struggle to provide unified and precise control over camera and multi-object motion, as videos inherently operate dynamics in the projected 2D image plane. To bridge this gap, we introduce VerseCrafter, a 4D-aware video world model that enables explicit and coherent control over both camera and object dynamics within a unified 4D geometric world state. Our approach is centered on a novel 4D Geometric Control representation, which encodes the world state through a static background point cloud and per-object 3D Gaussian trajectories. This representation captures not only an object's path but also its probabilistic 3D occupancy over time, offering a flexible, category-agnostic alternative to rigid bounding boxes or parametric models. These 4D controls are rendered into conditioning signals for a pretrained video diffusion model, enabling the generation of high-fidelity, view-consistent videos that precisely adhere to the specified dynamics. Unfortunately, another major challenge lies in the scarcity of large-scale training data with explicit 4D annotations. We address this by developing an automatic data engine that extracts the required 4D controls from in-the-wild videos, allowing us to train our model on a massive and diverse dataset.",
      "authors": [
        "Sixiao Zheng",
        "Minghao Yin",
        "Wenbo Hu",
        "Xiaoyu Li",
        "Ying Shan",
        "Yanwei Fu"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 17:28:52+00:00",
      "link": "https://arxiv.org/pdf/2601.05138v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05137v1",
      "title": "Neural Algorithmic Reasoning for Approximate $k$-Coloring with Recursive Warm Starts",
      "abstract": "Node coloring is the task of assigning colors to the nodes of a graph such that no two adjacent nodes have the same color, while using as few colors as possible. It is the most widely studied instance of graph coloring and of central importance in graph theory; major results include the Four Color Theorem and work on the Hadwiger-Nelson Problem. As an abstraction of classical combinatorial optimization tasks, such as scheduling and resource allocation, it is also rich in practical applications. Here, we focus on a relaxed version, approximate $k$-coloring, which is the task of assigning at most $k$ colors to the nodes of a graph such that the number of edges whose vertices have the same color is approximately minimized. While classical approaches leverage mathematical programming or SAT solvers, recent studies have explored the use of machine learning. We follow this route and explore the use of graph neural networks (GNNs) for node coloring. We first present an optimized differentiable algorithm that improves a prior approach by Schuetz et al. with orthogonal node feature initialization and a loss function that penalizes conflicting edges more heavily when their endpoints have higher degree; the latter inspired by the classical result that a graph is $k$-colorable if and only if its $k$-core is $k$-colorable. Next, we introduce a lightweight greedy local search algorithm and show that it may be improved by recursively computing a $(k-1)$-coloring to use as a warm start. We then show that applying such recursive warm starts to the GNN approach leads to further improvements. Numerical experiments on a range of different graph structures show that while the local search algorithms perform best on small inputs, the GNN exhibits superior performance at scale. The recursive warm start may be of independent interest beyond graph coloring for local search methods for combinatorial optimization.",
      "authors": [
        "Knut Vanderbush",
        "Melanie Weber"
      ],
      "primary_category": "math.CO",
      "categories": [
        "math.CO",
        "cs.LG"
      ],
      "published": "2026-01-08 17:28:09+00:00",
      "link": "https://arxiv.org/pdf/2601.05137v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05134v1",
      "title": "Sequential Subspace Noise Injection Prevents Accuracy Collapse in Certified Unlearning",
      "abstract": "Certified unlearning based on differential privacy offers strong guarantees but remains largely impractical: the noisy fine-tuning approaches proposed so far achieve these guarantees but severely reduce model accuracy. We propose sequential noise scheduling, which distributes the noise budget across orthogonal subspaces of the parameter space, rather than injecting it all at once. This simple modification mitigates the destructive effect of noise while preserving the original certification guarantees. We extend the analysis of noisy fine-tuning to the subspace setting, proving that the same $(\\varepsilon,δ)$ privacy budget is retained. Empirical results on image classification benchmarks show that our approach substantially improves accuracy after unlearning while remaining robust to membership inference attacks. These results show that certified unlearning can achieve both rigorous guarantees and practical utility.",
      "authors": [
        "Polina Dolgova",
        "Sebastian U. Stich"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-08 17:23:13+00:00",
      "link": "https://arxiv.org/pdf/2601.05134v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05127v1",
      "title": "LooseRoPE: Content-aware Attention Manipulation for Semantic Harmonization",
      "abstract": "Recent diffusion-based image editing methods commonly rely on text or high-level instructions to guide the generation process, offering intuitive but coarse control. In contrast, we focus on explicit, prompt-free editing, where the user directly specifies the modification by cropping and pasting an object or sub-object into a chosen location within an image. This operation affords precise spatial and visual control, yet it introduces a fundamental challenge: preserving the identity of the pasted object while harmonizing it with its new context. We observe that attention maps in diffusion-based editing models inherently govern whether image regions are preserved or adapted for coherence. Building on this insight, we introduce LooseRoPE, a saliency-guided modulation of rotational positional encoding (RoPE) that loosens the positional constraints to continuously control the attention field of view. By relaxing RoPE in this manner, our method smoothly steers the model's focus between faithful preservation of the input image and coherent harmonization of the inserted object, enabling a balanced trade-off between identity retention and contextual blending. Our approach provides a flexible and intuitive framework for image editing, achieving seamless compositional results without textual descriptions or complex user input.",
      "authors": [
        "Etai Sella",
        "Yoav Baron",
        "Hadar Averbuch-Elor",
        "Daniel Cohen-Or",
        "Or Patashnik"
      ],
      "primary_category": "cs.GR",
      "categories": [
        "cs.GR"
      ],
      "published": "2026-01-08 17:17:47+00:00",
      "link": "https://arxiv.org/pdf/2601.05127v1",
      "tags": [
        "keyword:resnet中文",
        "keyword:大语言模型",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05125v1",
      "title": "VERSE: Visual Embedding Reduction and Space Exploration. Clustering-Guided Insights for Training Data Enhancement in Visually-Rich Document Understanding",
      "abstract": "This work introduces VERSE, a methodology for analyzing and improving Vision-Language Models applied to Visually-rich Document Understanding by exploring their visual embedding space. VERSE enables the visualization of latent representations, supporting the assessment of model feasibility. It also facilitates the identification of problematic regions and guides the generation of synthetic data to enhance performance in those clusters. We validate the methodology by training on the synthetic MERIT Dataset and evaluating on its real-world counterpart, MERIT Secret. Results show that VERSE helps uncover the visual features associated with error-prone clusters, and that retraining with samples containing these features substantially boosts F1 performance without degrading generalization. Furthermore, we demonstrate that on-premise models such as Donut and Idefics2, when optimized with VERSE, match or even surpass the performance of SaaS solutions like GPT-4 and Pixtral.",
      "authors": [
        "Ignacio de Rodrigo",
        "Alvaro J. Lopez-Lopez",
        "Jaime Boal"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-01-08 17:15:15+00:00",
      "link": "https://arxiv.org/pdf/2601.05125v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05124v1",
      "title": "Re-Align: Structured Reasoning-guided Alignment for In-Context Image Generation and Editing",
      "abstract": "In-context image generation and editing (ICGE) enables users to specify visual concepts through interleaved image-text prompts, demanding precise understanding and faithful execution of user intent. Although recent unified multimodal models exhibit promising understanding capabilities, these strengths often fail to transfer effectively to image generation. We introduce Re-Align, a unified framework that bridges the gap between understanding and generation through structured reasoning-guided alignment. At its core lies the In-Context Chain-of-Thought (IC-CoT), a structured reasoning paradigm that decouples semantic guidance and reference association, providing clear textual target and mitigating confusion among reference images. Furthermore, Re-Align introduces an effective RL training scheme that leverages a surrogate reward to measure the alignment between structured reasoning text and the generated image, thereby improving the model's overall performance on ICGE tasks. Extensive experiments verify that Re-Align outperforms competitive methods of comparable model scale and resources on both in-context image generation and editing tasks.",
      "authors": [
        "Runze He",
        "Yiji Cheng",
        "Tiankai Hang",
        "Zhimin Li",
        "Yu Xu",
        "Zijin Yin",
        "Shiyi Zhang",
        "Wenxun Dai",
        "Penghui Du",
        "Ao Ma",
        "Chunyu Wang",
        "Qinglin Lu",
        "Jizhong Han",
        "Jiao Dai"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 17:13:00+00:00",
      "link": "https://arxiv.org/pdf/2601.05124v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05116v1",
      "title": "From Rays to Projections: Better Inputs for Feed-Forward View Synthesis",
      "abstract": "Feed-forward view synthesis models predict a novel view in a single pass with minimal 3D inductive bias. Existing works encode cameras as Plücker ray maps, which tie predictions to the arbitrary world coordinate gauge and make them sensitive to small camera transformations, thereby undermining geometric consistency. In this paper, we ask what inputs best condition a model for robust and consistent view synthesis. We propose projective conditioning, which replaces raw camera parameters with a target-view projective cue that provides a stable 2D input. This reframes the task from a brittle geometric regression problem in ray space to a well-conditioned target-view image-to-image translation problem. Additionally, we introduce a masked autoencoding pretraining strategy tailored to this cue, enabling the use of large-scale uncalibrated data for pretraining. Our method shows improved fidelity and stronger cross-view consistency compared to ray-conditioned baselines on our view-consistency benchmark. It also achieves state-of-the-art quality on standard novel view synthesis benchmarks.",
      "authors": [
        "Zirui Wu",
        "Zeren Jiang",
        "Martin R. Oswald",
        "Jie Song"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 17:03:44+00:00",
      "link": "https://arxiv.org/pdf/2601.05116v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05114v1",
      "title": "Evaluative Fingerprints: Stable and Systematic Differences in LLM Evaluator Behavior",
      "abstract": "LLM-as-judge systems promise scalable, consistent evaluation. We find the opposite: judges are consistent, but not with each other; they are consistent with themselves. Across 3,240 evaluations (9 judges x 120 unique video x pack items x 3 independent runs), inter-judge agreement is near-zero (Krippendorff's α = 0.042). On two dimensions, judges disagree more than random noise would predict (α < 0). Yet this disagreement isn't chaos; it's structured. A classifier identifies which judge produced an evaluation with 77.1% accuracy from rubric scores alone, rising to 89.9% with disposition features. Within model families, the signal is even stronger: GPT-4.1 and GPT-5.2 are distinguishable with 99.6% accuracy. We call this the reliability paradox: judges cannot agree on what constitutes quality, yet their disagreement patterns are so stable they function as fingerprints. Each judge implements a distinct, stable theory of quality: an \"evaluative disposition\" that shapes how it interprets any rubric. We characterize these dispositions along multiple axes: harshness/leniency, dimension emphasis, within-judge stability (ICC), and evidence behavior (receipt validity, semantic linkage via NLI, and shotgun index). The implication is stark: LLM judges are not interchangeable instruments measuring a shared construct. They are distinct measurement devices, each encoding its own implicit theory of quality. Averaging their scores produces a synthetic verdict that corresponds to no judge's actual values.",
      "authors": [
        "Wajid Nasser"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 17:02:22+00:00",
      "link": "https://arxiv.org/pdf/2601.05114v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05111v1",
      "title": "Agent-as-a-Judge",
      "abstract": "LLM-as-a-Judge has revolutionized AI evaluation by leveraging large language models for scalable assessments. However, as evaluands become increasingly complex, specialized, and multi-step, the reliability of LLM-as-a-Judge has become constrained by inherent biases, shallow single-pass reasoning, and the inability to verify assessments against real-world observations. This has catalyzed the transition to Agent-as-a-Judge, where agentic judges employ planning, tool-augmented verification, multi-agent collaboration, and persistent memory to enable more robust, verifiable, and nuanced evaluations. Despite the rapid proliferation of agentic evaluation systems, the field lacks a unified framework to navigate this shifting landscape. To bridge this gap, we present the first comprehensive survey tracing this evolution. Specifically, we identify key dimensions that characterize this paradigm shift and establish a developmental taxonomy. We organize core methodologies and survey applications across general and professional domains. Furthermore, we analyze frontier challenges and identify promising research directions, ultimately providing a clear roadmap for the next generation of agentic evaluation.",
      "authors": [
        "Runyang You",
        "Hongru Cai",
        "Caiqi Zhang",
        "Qiancheng Xu",
        "Meng Liu",
        "Tiezheng Yu",
        "Yongqi Li",
        "Wenjie Li"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-08 16:58:10+00:00",
      "link": "https://arxiv.org/pdf/2601.05111v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05110v1",
      "title": "GlimpRouter: Efficient Collaborative Inference by Glimpsing One Token of Thoughts",
      "abstract": "Large Reasoning Models (LRMs) achieve remarkable performance by explicitly generating multi-step chains of thought, but this capability incurs substantial inference latency and computational cost. Collaborative inference offers a promising solution by selectively allocating work between lightweight and large models, yet a fundamental challenge remains: determining when a reasoning step requires the capacity of a large model or the efficiency of a small model. Existing routing strategies either rely on local token probabilities or post-hoc verification, introducing significant inference overhead. In this work, we propose a novel perspective on step-wise collaboration: the difficulty of a reasoning step can be inferred from its very first token. Inspired by the \"Aha Moment\" phenomenon in LRMs, we show that the entropy of the initial token serves as a strong predictor of step difficulty. Building on this insight, we introduce GlimpRouter, a training-free step-wise collaboration framework. GlimpRouter employs a lightweight model to generate only the first token of each reasoning step and routes the step to a larger model only when the initial token entropy exceeds a threshold. Experiments on multiple benchmarks demonstrate that our approach significantly reduces inference latency while preserving accuracy. For instance, GlimpRouter attains a substantial 10.7% improvement in accuracy while reducing inference latency by 25.9% compared to a standalone large model on AIME25. These results suggest a simple yet effective mechanism for reasoning: allocating computation based on a glimpse of thought rather than full-step evaluation.",
      "authors": [
        "Wenhao Zeng",
        "Xuteng Zhang",
        "Yuling Shi",
        "Chao Hu",
        "Yuting Chen",
        "Beijun Shen",
        "Xiaodong Gu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 16:58:07+00:00",
      "link": "https://arxiv.org/pdf/2601.05110v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05109v1",
      "title": "Nalar: An agent serving framework",
      "abstract": "LLM-driven agentic applications increasingly automate complex, multi-step tasks, but serving them efficiently remains challenging due to heterogeneous components, dynamic and model-driven control flow, long-running state, and unpredictable latencies. Nalar is a ground-up agent-serving framework that cleanly separates workflow specification from execution while providing the runtime visibility and control needed for robust performance. Nalar preserves full Python expressiveness, using lightweight auto-generated stubs that turn agent and tool invocations into futures carrying dependency and context metadata. A managed state layer decouples logical state from physical placement, enabling safe reuse, migration, and consistent retry behavior. A two-level control architecture combines global policy computation with local event-driven enforcement to support adaptive routing, scheduling, and resource management across evolving workflows. Together, these mechanisms allow Nalar to deliver scalable, efficient, and policy-driven serving of heterogeneous agentic applications without burdening developers with orchestration logic. Across three agentic workloads, Nalar cuts tail latency by 34--74\\%, achieves up to $2.9\\times$ speedups, sustains 80 RPS where baselines fail, and scales to 130K futures with sub-500 ms control overhead.",
      "authors": [
        "Marco Laju",
        "Donghyun Son",
        "Saurabh Agarwal",
        "Nitin Kedia",
        "Myungjin Lee",
        "Jayanth Srinivasa",
        "Aditya Akella"
      ],
      "primary_category": "cs.DC",
      "categories": [
        "cs.DC",
        "cs.MA"
      ],
      "published": "2026-01-08 16:56:40+00:00",
      "link": "https://arxiv.org/pdf/2601.05109v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05108v1",
      "title": "Rule Rewriting Revisited: A Fresh Look at Static Filtering for Datalog and ASP",
      "abstract": "Static filtering is a data-independent optimisation method for Datalog, which generalises algebraic query rewriting techniques from relational databases. In spite of its early discovery by Kifer and Lozinskii in 1986, the method has been overlooked in recent research and system development, and special cases are being rediscovered independently. We therefore recall the original approach, using updated terminology and more general filter predicates that capture features of modern systems, and we show how to extend its applicability to answer set programming (ASP). The outcome is strictly more general but also more complex than the classical approach: double exponential in general and single exponential even for predicates of bounded arity. As a solution, we propose tractable approximations of the algorithm that can still yield much improved logic programs in typical cases, e.g., it can improve the performance of rule systems over real-world data in the order of magnitude.",
      "authors": [
        "Philipp Hanisch",
        "Markus Krötzsch"
      ],
      "primary_category": "cs.DB",
      "categories": [
        "cs.DB",
        "cs.LO"
      ],
      "published": "2026-01-08 16:54:36+00:00",
      "link": "https://arxiv.org/pdf/2601.05108v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05107v1",
      "title": "Controllable Memory Usage: Balancing Anchoring and Innovation in Long-Term Human-Agent Interaction",
      "abstract": "As LLM-based agents are increasingly used in long-term interactions, cumulative memory is critical for enabling personalization and maintaining stylistic consistency. However, most existing systems adopt an ``all-or-nothing'' approach to memory usage: incorporating all relevant past information can lead to \\textit{Memory Anchoring}, where the agent is trapped by past interactions, while excluding memory entirely results in under-utilization and the loss of important interaction history. We show that an agent's reliance on memory can be modeled as an explicit and user-controllable dimension. We first introduce a behavioral metric of memory dependence to quantify the influence of past interactions on current outputs. We then propose \\textbf{Stee}rable \\textbf{M}emory Agent, \\texttt{SteeM}, a framework that allows users to dynamically regulate memory reliance, ranging from a fresh-start mode that promotes innovation to a high-fidelity mode that closely follows interaction history. Experiments across different scenarios demonstrate that our approach consistently outperforms conventional prompting and rigid memory masking strategies, yielding a more nuanced and effective control for personalized human-agent collaboration.",
      "authors": [
        "Muzhao Tian",
        "Zisu Huang",
        "Xiaohua Wang",
        "Jingwen Xu",
        "Zhengkang Guo",
        "Qi Qian",
        "Yuanzhe Shen",
        "Kaitao Song",
        "Jiakang Yuan",
        "Changze Lv",
        "Xiaoqing Zheng"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 16:54:30+00:00",
      "link": "https://arxiv.org/pdf/2601.05107v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05106v1",
      "title": "Token-Level LLM Collaboration via FusionRoute",
      "abstract": "Large language models (LLMs) exhibit strengths across diverse domains. However, achieving strong performance across these domains with a single general-purpose model typically requires scaling to sizes that are prohibitively expensive to train and deploy. On the other hand, while smaller domain-specialized models are much more efficient, they struggle to generalize beyond their training distributions. To address this dilemma, we propose FusionRoute, a robust and effective token-level multi-LLM collaboration framework in which a lightweight router simultaneously (i) selects the most suitable expert at each decoding step and (ii) contributes a complementary logit that refines or corrects the selected expert's next-token distribution via logit addition. Unlike existing token-level collaboration methods that rely solely on fixed expert outputs, we provide a theoretical analysis showing that pure expert-only routing is fundamentally limited: unless strong global coverage assumptions hold, it cannot in general realize the optimal decoding policy. By augmenting expert selection with a trainable complementary generator, FusionRoute expands the effective policy class and enables recovery of optimal value functions under mild conditions. Empirically, across both Llama-3 and Gemma-2 families and diverse benchmarks spanning mathematical reasoning, code generation, and instruction following, FusionRoute outperforms both sequence- and token-level collaboration, model merging, and direct fine-tuning, while remaining competitive with domain experts on their respective tasks.",
      "authors": [
        "Nuoya Xiong",
        "Yuhang Zhou",
        "Hanqing Zeng",
        "Zhaorun Chen",
        "Furong Huang",
        "Shuchao Bi",
        "Lizhu Zhang",
        "Zhuokai Zhao"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-01-08 16:53:16+00:00",
      "link": "https://arxiv.org/pdf/2601.05106v1",
      "tags": [
        "keyword:大语言模型",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05105v1",
      "title": "UniLiPs: Unified LiDAR Pseudo-Labeling with Geometry-Grounded Dynamic Scene Decomposition",
      "abstract": "Unlabeled LiDAR logs, in autonomous driving applications, are inherently a gold mine of dense 3D geometry hiding in plain sight - yet they are almost useless without human labels, highlighting a dominant cost barrier for autonomous-perception research. In this work we tackle this bottleneck by leveraging temporal-geometric consistency across LiDAR sweeps to lift and fuse cues from text and 2D vision foundation models directly into 3D, without any manual input. We introduce an unsupervised multi-modal pseudo-labeling method relying on strong geometric priors learned from temporally accumulated LiDAR maps, alongside with a novel iterative update rule that enforces joint geometric-semantic consistency, and vice-versa detecting moving objects from inconsistencies. Our method simultaneously produces 3D semantic labels, 3D bounding boxes, and dense LiDAR scans, demonstrating robust generalization across three datasets. We experimentally validate that our method compares favorably to existing semantic segmentation and object detection pseudo-labeling methods, which often require additional manual supervision. We confirm that even a small fraction of our geometrically consistent, densified LiDAR improves depth prediction by 51.5% and 22.0% MAE in the 80-150 and 150-250 meters range, respectively.",
      "authors": [
        "Filippo Ghilotti",
        "Samuel Brucker",
        "Nahku Saidy",
        "Matteo Matteucci",
        "Mario Bijelic",
        "Felix Heide"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 16:52:28+00:00",
      "link": "https://arxiv.org/pdf/2601.05105v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05104v1",
      "title": "How Human is AI? Examining the Impact of Emotional Prompts on Artificial and Human and Responsiveness",
      "abstract": "This research examines how the emotional tone of human-AI interactions shapes ChatGPT and human behavior. In a between-subject experiment, we asked participants to express a specific emotion while working with ChatGPT (GPT-4.0) on two tasks, including writing a public response and addressing an ethical dilemma. We found that compared to interactions where participants maintained a neutral tone, ChatGPT showed greater improvement in its answers when participants praised ChatGPT for its responses. Expressing anger towards ChatGPT also led to a higher albeit smaller improvement relative to the neutral condition, whereas blaming ChatGPT did not improve its answers. When addressing an ethical dilemma, ChatGPT prioritized corporate interests less when participants expressed anger towards it, while blaming increases its emphasis on protecting the public interest. Additionally, we found that people used more negative, hostile, and disappointing expressions in human-human communication after interactions during which participants blamed rather than praised for their responses. Together, our findings demonstrate that the emotional tone people apply in human-AI interactions not only shape ChatGPT's outputs but also carry over into subsequent human-human communication.",
      "authors": [
        "Florence Bernays",
        "Marco Henriques Pereira",
        "Jochen Menges"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "econ.GN"
      ],
      "published": "2026-01-08 16:50:00+00:00",
      "link": "https://arxiv.org/pdf/2601.05104v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05103v1",
      "title": "Semantically Orthogonal Framework for Citation Classification: Disentangling Intent and Content",
      "abstract": "Understanding the role of citations is essential for research assessment and citation-aware digital libraries. However, existing citation classification frameworks often conflate citation intent (why a work is cited) with cited content type (what part is cited), limiting their effectiveness in auto classification due to a dilemma between fine-grained type distinctions and practical classification reliability. We introduce SOFT, a Semantically Orthogonal Framework with Two dimensions that explicitly separates citation intent from cited content type, drawing inspiration from semantic role theory. We systematically re-annotate the ACL-ARC dataset using SOFT and release a cross-disciplinary test set sampled from ACT2. Evaluation with both zero-shot and fine-tuned Large Language Models demonstrates that SOFT enables higher agreement between human annotators and LLMs, and supports stronger classification performance and robust cross-domain generalization compared to ACL-ARC and SciCite annotation frameworks. These results confirm SOFT's value as a clear, reusable annotation standard, improving clarity, consistency, and generalizability for digital libraries and scholarly communication infrastructures. All code and data are publicly available on GitHub https://github.com/zhiyintan/SOFT.",
      "authors": [
        "Changxu Duan",
        "Zhiyin Tan"
      ],
      "primary_category": "cs.DL",
      "categories": [
        "cs.DL",
        "cs.CL"
      ],
      "published": "2026-01-08 16:48:36+00:00",
      "link": "https://arxiv.org/pdf/2601.05103v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05101v1",
      "title": "Arabic Prompts with English Tools: A Benchmark",
      "abstract": "Large Language Models (LLMs) are now integral to numerous industries, increasingly serving as the core reasoning engine for autonomous agents that perform complex tasks through tool-use. While the development of Arabic-native LLMs is accelerating, the benchmarks for evaluating their capabilities lag behind, with most existing frameworks focusing on English. A critical and overlooked area is tool-calling, where the performance of models prompted in non-English languages like Arabic is poorly understood, especially since these models are often pretrained on predominantly English data. This paper addresses this critical gap by introducing the first dedicated benchmark for evaluating the tool-calling and agentic capabilities of LLMs in the Arabic language. Our work provides a standardized framework to measure the functional accuracy and robustness of models in Arabic agentic workflows. Our findings reveal a huge performance gap: when users interact in Arabic, tool-calling accuracy drops by an average of 5-10\\%, regardless of whether the tool descriptions themselves are in Arabic or English. By shedding light on these critical challenges, this benchmark aims to foster the development of more reliable and linguistically equitable AI agents for Arabic-speaking users.",
      "authors": [
        "Konstantin Kubrak",
        "Ahmed El-Moselhy",
        "Ammar Alsulami",
        "Remaz Altuwaim",
        "Hassan Ismail Fawaz",
        "Faisal Alsaby"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 16:47:09+00:00",
      "link": "https://arxiv.org/pdf/2601.05101v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05099v1",
      "title": "Multi-Disciplinary Dataset Discovery from Citation-Verified Literature Contexts",
      "abstract": "Identifying suitable datasets for a research question remains challenging because existing dataset search engines rely heavily on metadata quality and keyword overlap, which often fail to capture the semantic intent of scientific investigation. We introduce a literature-driven framework that discovers datasets from citation contexts in scientific papers, enabling retrieval grounded in actual research use rather than metadata availability. Our approach combines large-scale citation-context extraction, schema-guided dataset recognition with Large Language Models, and provenance-preserving entity resolution. We evaluate the system on eight survey-derived computer science queries and find that it achieves substantially higher recall than Google Dataset Search and DataCite Commons, with normalized recall ranging from an average of 47.47% to a highest value of 81.82%. Beyond recovering gold-standard datasets, the method also surfaces additional datasets not documented in the surveys. Expert assessments across five top-level Fields of Science indicate that a substantial portion of the additional datasets are considered high utility, and some are regarded as novel for the specific topics chosen by the experts. These findings establish citation-context mining as an effective and generalizable paradigm for dataset discovery, particularly in settings where datasets lack sufficient or reliable metadata. To support reproducibility and future extensions, we release our code, evaluation datasets, and results on GitHub (https://github.com/Fireblossom/citation-context-dataset-discovery).",
      "authors": [
        "Zhiyin Tan",
        "Changxu Duan"
      ],
      "primary_category": "cs.DL",
      "categories": [
        "cs.DL",
        "cs.CL",
        "cs.IR"
      ],
      "published": "2026-01-08 16:46:06+00:00",
      "link": "https://arxiv.org/pdf/2601.05099v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05098v1",
      "title": "ECLIPSE: An Evolutionary Computation Library for Instrumentation Prototyping in Scientific Engineering",
      "abstract": "Designing scientific instrumentation often requires exploring large, highly constrained design spaces using computationally expensive physics simulations. These simulators pose substantial challenges for integrating evolutionary computation (EC) into scientific design workflows. Evolutionary computation typically requires numerous design evaluations, making the integration of slow, low-throughput simulators particularly challenging, as they are optimized for accuracy and ease of use rather than throughput. We present ECLIPSE, an evolutionary computation framework built to interface directly with complex, domain-specific simulation tools while supporting flexible geometric and parametric representations of scientific hardware. ECLIPSE provides a modular architecture consisting of (1) Individuals, which encode hardware designs using domain-aware, physically constrained representations; (2) Evaluators, which prepare simulation inputs, invoke external simulators, and translate the simulator's outputs into fitness measures; and (3) Evolvers, which implement EC algorithms suitable for high-cost, limited-throughput environments. We demonstrate the utility of ECLIPSE across several active space-science applications, including evolved 3D antennas and spacecraft geometries optimized for drag reduction in very low Earth orbit. We further discuss the practical challenges encountered when coupling EC with scientific simulation workflows, including interoperability constraints, parallelization limits, and extreme evaluation costs, and outline ongoing efforts to combat these challenges. ECLIPSE enables interdisciplinary teams of physicists, engineers, and EC researchers to collaboratively explore unconventional designs for scientific hardware while leveraging existing domain-specific simulation software.",
      "authors": [
        "Max Foreback",
        "Evan Imata",
        "Vincent Ragusa",
        "Jacob Weiler",
        "Christina Shao",
        "Joey Wagner",
        "Katherine G. Skocelas",
        "Jonathan Sy",
        "Aman Hafez",
        "Wolfgang Banzhaf",
        "Amy Conolly",
        "Kyle R. Helson",
        "Rick Marcusen",
        "Charles Ofria",
        "Marcin Pilinski",
        "Rajiv Ramnath",
        "Bryan Reynolds",
        "Anselmo C. Pontes",
        "Emily Dolson",
        "Julie Rolla"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE"
      ],
      "published": "2026-01-08 16:45:11+00:00",
      "link": "https://arxiv.org/pdf/2601.05098v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05095v1",
      "title": "Advanced Multimodal Learning for Seizure Detection and Prediction: Concept, Challenges, and Future Directions",
      "abstract": "Epilepsy is a chronic neurological disorder characterized by recurrent unprovoked seizures, affects over 50 million people worldwide, and poses significant risks, including sudden unexpected death in epilepsy (SUDEP). Conventional unimodal approaches, primarily reliant on electroencephalography (EEG), face several key challenges, including low SNR, nonstationarity, inter- and intrapatient heterogeneity, portability, and real-time applicability in clinical settings. To address these issues, a comprehensive survey highlights the concept of advanced multimodal learning for epileptic seizure detection and prediction (AMLSDP). The survey presents the evolution of epileptic seizure detection (ESD) and prediction (ESP) technologies across different eras. The survey also explores the core challenges of multimodal and non-EEG-based ESD and ESP. To overcome the key challenges of the multimodal system, the survey introduces the advanced processing strategies for efficient AMLSDP. Furthermore, this survey highlights future directions for researchers and practitioners. We believe this work will advance neurotechnology toward wearable and imaging-based solutions for epilepsy monitoring, serving as a valuable resource for future innovations in this domain.",
      "authors": [
        "Ijaz Ahmad",
        "Faizan Ahmad",
        "Sunday Timothy Aboyeji",
        "Yongtao Zhang",
        "Peng Yang",
        "Rab Nawaz",
        "Baiying Lei"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE"
      ],
      "published": "2026-01-08 16:43:06+00:00",
      "link": "https://arxiv.org/pdf/2601.05095v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05093v1",
      "title": "Why Are Some Countries More Politically Fragmented Online Than Others?",
      "abstract": "Online political divisions, such as fragmentation or polarization, are a growing global concern that can foster radicalization and hinder democratic cooperation; however, not all divisions are detrimental, some reflect pluralism and healthy diversity of opinion in a democracy. While prior research has predominantly focused on polarization in the United States, there remains a limited body of research on political divides in multiparty systems, and no universal method for comparing fragmentation across countries. Moreover, cross-country comparison is rare. This study first develops a novel measure of structural political fragmentation built on multi-scale community detection and the effective branching factor. Using a dataset of 18,325 political influencers from Brazil, Spain, and the United States, we assess online fragmentation in their Twitter/X co-following networks. We compare the fragmentation of the three countries, as well as the ideological groups within each. We further investigate factors associated with the level of fragmentation in each country. We find that political fragmentation differs across countries and is asymmetric between ideological groups. Brazil is the most fragmented, with higher fragmentation among the left-wing group, while Spain and the United States exhibit similar overall levels, with the left more fragmented in Spain and the right more fragmented in the United States. Additionally, we find that social identity plays a central role in political fragmentation. A strong alignment between ideological and social identities, with minimal overlap between ideologies, tends to promote greater integration and reduce fragmentation. Our findings provide explanations for cross-national and ideological differences in political fragmentation.",
      "authors": [
        "Yuan Zhang",
        "Laia Castro",
        "Frank Esser",
        "Alexandre Bovet"
      ],
      "primary_category": "cs.SI",
      "categories": [
        "cs.SI"
      ],
      "published": "2026-01-08 16:41:22+00:00",
      "link": "https://arxiv.org/pdf/2601.05093v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05092v1",
      "title": "Precoding Matrix Indicator in the 5G NR Protocol: A Tutorial on 3GPP Beamforming Codebooks",
      "abstract": "This paper bridges this critical gap by providing a systematic examination of the beamforming codebook technology, i.e., precoding matrix indicator (PMI), in the 5G NR from theoretical, standardization, and implementation perspectives. We begin by introducing the background of beamforming in multiple-input multiple-output (MIMO) systems and the signaling procedures for codebook-based beamforming in practical 5G systems. Then, we establish the fundamentals of regular codebooks and port-selection codebooks in 3GPP standards. Next, we provide rigorous technical analysis of 3GPP codebook evolution spanning Releases 15-18, with particular focus on: 1) We elucidate the core principles underlying codebook design, 2) provide clear physical interpretations for each symbolic variable in the codebook formulas, summarized in tabular form, and 3) offer intuitive visual illustrations to explain how codebook parameters convey information. These essential pedagogical elements are almost entirely absent in the often-obscure standardization documents. Through mathematical modeling, performance benchmarking, feedback comparisons, and scenario-dependent applicability analysis, we provide researchers and engineers with a unified understanding of beamforming codebooks in real-world systems. Furthermore, we identify future directions and other beamforming scenarios for ongoing research and development efforts. This work serves as both an informative tutorial and a guidance for future research, facilitating more effective collaboration between academia and industry in advancing wireless communication technologies.",
      "authors": [
        "Boyu Ning",
        "Haifan Yin",
        "Sixu Liu",
        "Hao Deng",
        "Songjie Yang",
        "Yuchen Zhang",
        "Weidong Mei",
        "David Gesbert",
        "Jaebum Park",
        "Robert W. Heath",
        "Emil Björnson"
      ],
      "primary_category": "cs.IT",
      "categories": [
        "cs.IT"
      ],
      "published": "2026-01-08 16:39:37+00:00",
      "link": "https://arxiv.org/pdf/2601.05092v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05091v1",
      "title": "Code-Mix Sentiment Analysis on Hinglish Tweets",
      "abstract": "The effectiveness of brand monitoring in India is increasingly challenged by the rise of Hinglish--a hybrid of Hindi and English--used widely in user-generated content on platforms like Twitter. Traditional Natural Language Processing (NLP) models, built for monolingual data, often fail to interpret the syntactic and semantic complexity of this code-mixed language, resulting in inaccurate sentiment analysis and misleading market insights. To address this gap, we propose a high-performance sentiment classification framework specifically designed for Hinglish tweets. Our approach fine-tunes mBERT (Multilingual BERT), leveraging its multilingual capabilities to better understand the linguistic diversity of Indian social media. A key component of our methodology is the use of subword tokenization, which enables the model to effectively manage spelling variations, slang, and out-of-vocabulary terms common in Romanized Hinglish. This research delivers a production-ready AI solution for brand sentiment tracking and establishes a strong benchmark for multilingual NLP in low-resource, code-mixed environments.",
      "authors": [
        "Aashi Garg",
        "Aneshya Das",
        "Arshi Arya",
        "Anushka Goyal",
        "Aditi"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-08 16:39:26+00:00",
      "link": "https://arxiv.org/pdf/2601.05091v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05084v1",
      "title": "Driver-Intention Prediction with Deep Learning: Real-Time Brain-to-Vehicle Communication",
      "abstract": "Brain-computer interfaces (BCIs) allow direct communication between the brain and electronics without the need for speech or physical movement. Such interfaces can be particularly beneficial in applications requiring rapid response times, such as driving, where a vehicle's advanced driving assistance systems could benefit from immediate understanding of a driver's intentions. This study presents a novel method for predicting a driver's intention to steer using electroencephalography (EEG) signals through deep learning. A driving simulator created a controlled environment in which participants imagined controlling a vehicle during various driving scenarios, including left and right turns, as well as straight driving. A convolutional neural network (CNN) classified the detected EEG data with minimal pre-processing. Our model achieved an accuracy of 83.7% in distinguishing between the three steering intentions and demonstrated the ability of CNNs to process raw EEG data effectively. The classification accuracy was highest for right-turn segments, which suggests a potential spatial bias in brain activity. This study lays the foundation for more intuitive brain-to-vehicle communication systems.",
      "authors": [
        "Niloufar Alavi",
        "Swati Shah",
        "Rezvan Alamian",
        "Stefan Goetz"
      ],
      "primary_category": "cs.HC",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.ET",
        "eess.SP",
        "eess.SY"
      ],
      "published": "2026-01-08 16:29:08+00:00",
      "link": "https://arxiv.org/pdf/2601.05084v1",
      "tags": [
        "keyword:resnet",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05083v1",
      "title": "Driving on Registers",
      "abstract": "We present DrivoR, a simple and efficient transformer-based architecture for end-to-end autonomous driving. Our approach builds on pretrained Vision Transformers (ViTs) and introduces camera-aware register tokens that compress multi-camera features into a compact scene representation, significantly reducing downstream computation without sacrificing accuracy. These tokens drive two lightweight transformer decoders that generate and then score candidate trajectories. The scoring decoder learns to mimic an oracle and predicts interpretable sub-scores representing aspects such as safety, comfort, and efficiency, enabling behavior-conditioned driving at inference. Despite its minimal design, DrivoR outperforms or matches strong contemporary baselines across NAVSIM-v1, NAVSIM-v2, and the photorealistic closed-loop HUGSIM benchmark. Our results show that a pure-transformer architecture, combined with targeted token compression, is sufficient for accurate, efficient, and adaptive end-to-end driving. Code and checkpoints will be made available via the project page.",
      "authors": [
        "Ellington Kirby",
        "Alexandre Boulch",
        "Yihong Xu",
        "Yuan Yin",
        "Gilles Puy",
        "Éloi Zablocki",
        "Andrei Bursuc",
        "Spyros Gidaris",
        "Renaud Marlet",
        "Florent Bartoccioni",
        "Anh-Quan Cao",
        "Nermin Samet",
        "Tuan-Hung VU",
        "Matthieu Cord"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "published": "2026-01-08 16:28:24+00:00",
      "link": "https://arxiv.org/pdf/2601.05083v1",
      "tags": [
        "keyword:大语言模型",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05082v1",
      "title": "Exploring Student Expectations and Confidence in Learning Analytics",
      "abstract": "Learning Analytics (LA) is nowadays ubiquitous in many educational systems, providing the ability to collect and analyze student data in order to understand and optimize learning and the environments in which it occurs. On the other hand, the collection of data requires to comply with the growing demand regarding privacy legislation. In this paper, we use the Student Expectation of Learning Analytics Questionnaire (SELAQ) to analyze the expectations and confidence of students from different faculties regarding the processing of their data for Learning Analytics purposes. This allows us to identify four clusters of students through clustering algorithms: Enthusiasts, Realists, Cautious and Indifferents. This structured analysis provides valuable insights into the acceptance and criticism of Learning Analytics among students.",
      "authors": [
        "Hayk Asatryan",
        "Basile Tousside",
        "Janis Mohr",
        "Malte Neugebauer",
        "Hildo Bijl",
        "Paul Spiegelberg",
        "Claudia Frohn-Schauf",
        "Jörg Frochte"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CY",
        "cs.HC"
      ],
      "published": "2026-01-08 16:27:09+00:00",
      "link": "https://arxiv.org/pdf/2601.05082v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05081v1",
      "title": "Dynamics in Search Engine Query Suggestions for European Politicians",
      "abstract": "Search engines are commonly used for online political information seeking. Yet, it remains unclear how search query suggestions for political searches that reflect the latent interest of internet users vary across countries and over time. We provide a systematic analysis of Google search engine query suggestions for European and national politicians. Using an original dataset of search query suggestions for European politicians collected in ten countries, we find that query suggestions are less stable over time in politicians' countries of origin, when the politicians hold a supranational role, and for female politicians. Moreover, query suggestions for political leaders and male politicians are more similar across countries. We conclude by discussing possible future directions for studying information search about European politicians in online search.",
      "authors": [
        "Franziska Pradel",
        "Fabian Haak",
        "Sven-Oliver Proksch",
        "Philipp Schaer"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2026-01-08 16:27:04+00:00",
      "link": "https://arxiv.org/pdf/2601.05081v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05076v1",
      "title": "Chain-of-Sanitized-Thoughts: Plugging PII Leakage in CoT of Large Reasoning Models",
      "abstract": "Large Reasoning Models (LRMs) improve performance, reliability, and interpretability by generating explicit chain-of-thought (CoT) reasoning, but this transparency introduces a serious privacy risk: intermediate reasoning often leaks personally identifiable information (PII) even when final answers are sanitized. We study how to induce privacy-first reasoning, where models reason without exposing sensitive information, using deployable interventions rather than post-hoc redaction. We introduce PII-CoT-Bench, a supervised dataset with privacy-aware CoT annotations, and a category-balanced evaluation benchmark covering realistic and adversarial leakage scenarios. Our results reveal a capability-dependent trend: state-of-the-art models benefit most from prompt-based controls, whereas weaker models require fine-tuning to achieve meaningful leakage reduction. Across models and categories, both approaches substantially reduce PII exposure with minimal degradation in utility, demonstrating that private reasoning can be achieved without sacrificing performance. Overall, we show that private CoT reasoning can be achieved with minimal utility loss, providing practical guidance for building privacy-preserving reasoning systems.",
      "authors": [
        "Arghyadeep Das",
        "Sai Sreenivas Chintha",
        "Rishiraj Girmal",
        "Kinjal Pandey",
        "Sharvi Endait"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 16:19:43+00:00",
      "link": "https://arxiv.org/pdf/2601.05076v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05075v1",
      "title": "SemPA: Improving Sentence Embeddings of Large Language Models through Semantic Preference Alignment",
      "abstract": "Traditional sentence embedding methods employ token-level contrastive learning on non-generative pre-trained models. Recently, there have emerged embedding methods based on generative large language models (LLMs). These methods either rely on fixed prompt templates or involve modifications to the model architecture. The former lacks further optimization of the model and results in limited performance, while the latter alters the internal computational mechanisms of the model, thereby compromising its generative capabilities. We propose SemPA, a novel approach that boosts the sentence representations while preserving the generative ability of LLMs via semantic preference alignment. We leverage sentence-level Direct Preference Optimization (DPO) to efficiently optimize LLMs on a paraphrase generation task, where the model learns to discriminate semantically equivalent sentences while preserving inherent generative capacity. Theoretically, we establish a formal connection between DPO and contrastive learning under the Plackett-Luce model framework. Empirically, experimental results on both semantic textual similarity tasks and various benchmarks for LLMs show that SemPA achieves better semantic representations without sacrificing the inherent generation capability of LLMs.",
      "authors": [
        "Ziyang Chen",
        "Zhenxuan Huang",
        "Yile Wang",
        "Weiqin Wang",
        "Lu Yin",
        "Hui Huang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 16:19:24+00:00",
      "link": "https://arxiv.org/pdf/2601.05075v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05074v1",
      "title": "Compensation Effect Amplification Control (CEAC): A movement-based approach for coordinated position and velocity control of the elbow of upper-limb prostheses",
      "abstract": "Despite advances in upper-limb (UL) prosthetic design, achieving intuitive control of intermediate joints - such as the wrist and elbow - remains challenging, particularly for continuous and velocity-modulated movements. We introduce a novel movement-based control paradigm entitled Compensation Effect Amplification Control (CEAC) that leverages users' trunk flexion and extension as input for controlling prosthetic elbow velocity. Considering that the trunk can be both a functional and compensatory joint when performing upper-limb actions, CEAC amplifies the natural coupling between trunk and prosthesis while introducing a controlled delay that allows users to modulate both the position and velocity of the prosthetic joint. We evaluated CEAC in a generic drawing task performed by twelve able-bodied participants using a supernumerary prosthesis with an active elbow. Additionally a multiple-target-reaching task was performed by a subset of ten participants. Results demonstrate task performances comparable to those obtained with natural arm movements, even when gesture velocity or drawing size were varied, while maintaining ergonomic trunk postures. Analysis revealed that CEAC effectively restores joint coordinated action, distributes movement effort between trunk and elbow, enabling intuitive trajectory control without requiring extreme compensatory movements. Overall, CEAC offers a promising control strategy for intermediate joints of UL prostheses, particularly in tasks requiring continuous and precise coordination.",
      "authors": [
        "Julian Kulozik",
        "Nathanaël Jarrassé"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-01-08 16:18:10+00:00",
      "link": "https://arxiv.org/pdf/2601.05074v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05073v1",
      "title": "Milestones over Outcome: Unlocking Geometric Reasoning with Sub-Goal Verifiable Reward",
      "abstract": "Multimodal Large Language Models (MLLMs) struggle with complex geometric reasoning, largely because \"black box\" outcome-based supervision fails to distinguish between lucky guesses and rigorous deduction. To address this, we introduce a paradigm shift towards subgoal-level evaluation and learning. We first construct GeoGoal, a benchmark synthesized via a rigorous formal verification data engine, which converts abstract proofs into verifiable numeric subgoals. This structure reveals a critical divergence between reasoning quality and outcome accuracy. Leveraging this, we propose the Sub-Goal Verifiable Reward (SGVR) framework, which replaces sparse signals with dense rewards based on the Skeleton Rate. Experiments demonstrate that SGVR not only enhances geometric performance (+9.7%) but also exhibits strong generalization, transferring gains to general math (+8.0%) and other general reasoning tasks (+2.8%), demonstrating broad applicability across diverse domains.",
      "authors": [
        "Jianlong Chen",
        "Daocheng Fu",
        "Shengze Xu",
        "Jiawei Chen",
        "Yuan Feng",
        "Yue Yang",
        "Junchi Yan",
        "Hongyuan Zha",
        "Renqiu Xia"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-08 16:17:56+00:00",
      "link": "https://arxiv.org/pdf/2601.05073v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05072v1",
      "title": "DAVOS: An Autonomous Vehicle Operating System in the Vehicle Computing Era",
      "abstract": "Vehicle computing represents a fundamental shift in how autonomous vehicles are designed and deployed, transforming them from isolated transportation systems into mobile computing platforms that support both safety-critical, real-time driving and data-centric services. In this setting, vehicles simultaneously support real-time driving pipelines and a growing set of data-driven applications, placing increased responsibility on the vehicle operating system to coordinate computation, data movement, storage, and access. These demands highlight recurring system considerations related to predictable execution, data and execution protection, efficient handling of high-rate sensor data, and long-term system evolvability, commonly summarized as Safety, Security, Efficiency, and Extensibility (SSEE). Existing vehicle operating systems and runtimes address these concerns in isolation, resulting in fragmented software stacks that limit coordination between autonomy workloads and vehicle data services. This paper presents DAVOS, the Delaware Autonomous Vehicle Operating System, a unified vehicle operating system architecture designed for the vehicle computing context. DAVOS provides a cohesive operating system foundation that supports both real-time autonomy and extensible vehicle computing within a single system framework.",
      "authors": [
        "Yuxin Wang",
        "Yuankai He",
        "Boyang Tian",
        "Lichen Xian",
        "Weisong Shi"
      ],
      "primary_category": "cs.OS",
      "categories": [
        "cs.OS",
        "cs.RO"
      ],
      "published": "2026-01-08 16:17:48+00:00",
      "link": "https://arxiv.org/pdf/2601.05072v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05065v1",
      "title": "Graph energy as a measure of community detectability in networks",
      "abstract": "A key challenge in network science is the detection of communities, which are sets of nodes in a network that are densely connected internally but sparsely connected to the rest of the network. A fundamental result in community detection is the existence of a nontrivial threshold for community detectability on sparse graphs that are generated by the planted partition model (PPM). Below this so-called ``detectability limit'', no community-detection method can perform better than random chance. Spectral methods for community detection fail before this detectability limit because the eigenvalues corresponding to the eigenvectors that are relevant for community detection can be absorbed by the bulk of the spectrum. One can bypass the detectability problem by using special matrices, like the non-backtracking matrix, but this requires one to consider higher-dimensional matrices. In this paper, we show that the difference in graph energy between a PPM and an Erdős--Rényi (ER) network has a distinct transition at the detectability threshold even for the adjacency matrices of the underlying networks. The graph energy is based on the full spectrum of an adjacency matrix, so our result suggests that standard graph matrices still allow one to separate the parameter regions with detectable and undetectable communities.",
      "authors": [
        "Lucas Böttcher",
        "Mason A. Porter",
        "Santo Fortunato"
      ],
      "primary_category": "cs.SI",
      "categories": [
        "cs.SI",
        "cond-mat.stat-mech",
        "physics.soc-ph"
      ],
      "published": "2026-01-08 16:10:01+00:00",
      "link": "https://arxiv.org/pdf/2601.05065v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05063v1",
      "title": "Quantitative mapping from conventional MRI using self-supervised physics-guided deep learning: applications to a large-scale, clinically heterogeneous dataset",
      "abstract": "Magnetic resonance imaging (MRI) is a cornerstone of clinical neuroimaging, yet conventional MRIs provide qualitative information heavily dependent on scanner hardware and acquisition settings. While quantitative MRI (qMRI) offers intrinsic tissue parameters, the requirement for specialized acquisition protocols and reconstruction algorithms restricts its availability and impedes large-scale biomarker research. This study presents a self-supervised physics-guided deep learning framework to infer quantitative T1, T2, and proton-density (PD) maps directly from widely available clinical conventional T1-weighted, T2-weighted, and FLAIR MRIs. The framework was trained and evaluated on a large-scale, clinically heterogeneous dataset comprising 4,121 scan sessions acquired at our institution over six years on four different 3 T MRI scanner systems, capturing real-world clinical variability. The framework integrates Bloch-based signal models directly into the training objective. Across more than 600 test sessions, the generated maps exhibited white matter and gray matter values consistent with literature ranges. Additionally, the generated maps showed invariance to scanner hardware and acquisition protocol groups, with inter-group coefficients of variation $\\leq$ 1.1%. Subject-specific analyses demonstrated excellent voxel-wise reproducibility across scanner systems and sequence parameters, with Pearson $r$ and concordance correlation coefficients exceeding 0.82 for T1 and T2. Mean relative voxel-wise differences were low across all quantitative parameters, especially for T2 ($<$ 6%). These results indicate that the proposed framework can robustly transform diverse clinical conventional MRI data into quantitative maps, potentially paving the way for large-scale quantitative biomarker research.",
      "authors": [
        "Jelmer van Lune",
        "Stefano Mandija",
        "Oscar van der Heide",
        "Matteo Maspero",
        "Martin B. Schilder",
        "Jan Willem Dankbaar",
        "Cornelis A. T. van den Berg",
        "Alessandro Sbrizzi"
      ],
      "primary_category": "physics.med-ph",
      "categories": [
        "physics.med-ph",
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-01-08 16:08:58+00:00",
      "link": "https://arxiv.org/pdf/2601.05063v1",
      "tags": [
        "keyword:resnet",
        "keyword:resnet中文",
        "keyword:大语言模型",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05062v1",
      "title": "Compositional Steering of Large Language Models with Steering Tokens",
      "abstract": "Deploying LLMs in real-world applications requires controllable output that satisfies multiple desiderata at the same time. While existing work extensively addresses LLM steering for a single behavior, \\textit{compositional steering} -- i.e., steering LLMs simultaneously towards multiple behaviors -- remains an underexplored problem. In this work, we propose \\emph{compositional steering tokens} for multi-behavior steering. We first embed individual behaviors, expressed as natural language instructions, into dedicated tokens via self-distillation. Contrary to most prior work, which operates in the activation space, our behavior steers live in the space of input tokens, enabling more effective zero-shot composition. We then train a dedicated \\textit{composition token} on pairs of behaviors and show that it successfully captures the notion of composition: it generalizes well to \\textit{unseen} compositions, including those with unseen behaviors as well as those with an unseen \\textit{number} of behaviors. Our experiments across different LLM architectures show that steering tokens lead to superior multi-behavior control compared to competing approaches (instructions, activation steering, and LoRA merging). Moreover, we show that steering tokens complement natural language instructions, with their combination resulting in further gains.",
      "authors": [
        "Gorjan Radevski",
        "Kiril Gashteovski",
        "Giwon Hong",
        "Carolin Lawrence",
        "Goran Glavaš"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-08 16:08:44+00:00",
      "link": "https://arxiv.org/pdf/2601.05062v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05059v1",
      "title": "From Understanding to Engagement: Personalized pharmacy Video Clips via Vision Language Models (VLMs)",
      "abstract": "Vision Language Models (VLMs) are poised to revolutionize the digital transformation of pharmacyceutical industry by enabling intelligent, scalable, and automated multi-modality content processing. Traditional manual annotation of heterogeneous data modalities (text, images, video, audio, and web links), is prone to inconsistencies, quality degradation, and inefficiencies in content utilization. The sheer volume of long video and audio data further exacerbates these challenges, (e.g. long clinical trial interviews and educational seminars).   Here, we introduce a domain adapted Video to Video Clip Generation framework that integrates Audio Language Models (ALMs) and Vision Language Models (VLMs) to produce highlight clips. Our contributions are threefold: (i) a reproducible Cut & Merge algorithm with fade in/out and timestamp normalization, ensuring smooth transitions and audio/visual alignment; (ii) a personalization mechanism based on role definition and prompt injection for tailored outputs (marketing, training, regulatory); (iii) a cost efficient e2e pipeline strategy balancing ALM/VLM enhanced processing. Evaluations on Video MME benchmark (900) and our proprietary dataset of 16,159 pharmacy videos across 14 disease areas demonstrate 3 to 4 times speedup, 4 times cost reduction, and competitive clip quality. Beyond efficiency gains, we also report our methods improved clip coherence scores (0.348) and informativeness scores (0.721) over state of the art VLM baselines (e.g., Gemini 2.5 Pro), highlighting the potential of transparent, custom extractive, and compliance supporting video summarization for life sciences.",
      "authors": [
        "Suyash Mishra",
        "Qiang Li",
        "Srikanth Patil",
        "Anubhav Girdhar"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-01-08 16:02:56+00:00",
      "link": "https://arxiv.org/pdf/2601.05059v1",
      "tags": [
        "keyword:大语言模型",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05057v1",
      "title": "Supporting Secured Integration of Microarchitectural Defenses",
      "abstract": "There has been a plethora of microarchitectural-level attacks leading to many proposed countermeasures. This has created an unexpected and unaddressed security issue where naive integration of those defenses can potentially lead to security vulnerabilities. This occurs when one defense changes an aspect of a microarchitecture that is crucial for the security of another defense. We refer to this problem as a microarchitectural defense assumption violation} (MDAV).   We propose a two-step methodology to screen for potential MDAVs in the early-stage of integration. The first step is to design and integrate a composed model, guided by bounded model checking of security properties. The second step is to implement the model concretely on a simulator and to evaluate with simulated attacks. As a contribution supporting the first step, we propose an event-based modeling framework, called Maestro, for testing and evaluating microarchitectural models with integrated defenses. In our evaluation, Maestro reveals MDAVs (8), supports compact expression (~15x Alloy LoC ratio), enables semantic composability and eliminates performance degradations (>100x).   As a contribution supporting the second step, we use an event-based simulator (GEM5) for investigating integrated microarchitectural defenses. We show that a covert channel attack is possible on a naively integrated implementation of some state-of-the-art defenses, and a repaired implementation using our integration methodology is resilient to the attack.",
      "authors": [
        "Kartik Ramkrishnan",
        "Stephen McCamant",
        "Antonia Zhai",
        "Pen-Chung Yew"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR",
        "cs.AR"
      ],
      "published": "2026-01-08 15:58:30+00:00",
      "link": "https://arxiv.org/pdf/2601.05057v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05053v1",
      "title": "Reinforced Efficient Reasoning via Semantically Diverse Exploration",
      "abstract": "Reinforcement learning with verifiable rewards (RLVR) has proven effective in enhancing the reasoning of large language models (LLMs). Monte Carlo Tree Search (MCTS)-based extensions improve upon vanilla RLVR (e.g., GRPO) by providing tree-based reasoning rollouts that enable fine-grained and segment-level credit assignment. However, existing methods still suffer from limited exploration diversity and inefficient reasoning. To address the above challenges, we propose reinforced efficient reasoning via semantically diverse explorations, i.e., ROSE, for LLMs. To encourage more diverse reasoning exploration, our method incorporates a semantic-entropy-based branching strategy and an $\\varepsilon$-exploration mechanism. The former operates on already sampled reasoning rollouts to capture semantic uncertainty and select branching points with high semantic divergence to generate new successive reasoning paths, whereas the latter stochastically initiates reasoning rollouts from the root, preventing the search process from becoming overly local. To improve efficiency, we design a length-aware segment-level advantage estimator that rewards concise and correct reasoning while penalizing unnecessarily long reasoning chains. Extensive experiments on various mathematical reasoning benchmarks with Qwen and Llama models validate the effectiveness and efficiency of ROSE. Codes are available at https://github.com/ZiqiZhao1/ROSE-rl.",
      "authors": [
        "Ziqi Zhao",
        "Zhaochun Ren",
        "Jiahong Zou",
        "Liu Yang",
        "Zhiwei Xu",
        "Xuri Ge",
        "Zhumin Chen",
        "Xinyu Ma",
        "Daiting Shi",
        "Shuaiqiang Wang",
        "Dawei Yin",
        "Xin Xin"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-08 15:56:44+00:00",
      "link": "https://arxiv.org/pdf/2601.05053v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05052v1",
      "title": "DeepWeightFlow: Re-Basined Flow Matching for Generating Neural Network Weights",
      "abstract": "Building efficient and effective generative models for neural network weights has been a research focus of significant interest that faces challenges posed by the high-dimensional weight spaces of modern neural networks and their symmetries. Several prior generative models are limited to generating partial neural network weights, particularly for larger models, such as ResNet and ViT. Those that do generate complete weights struggle with generation speed or require finetuning of the generated models. In this work, we present DeepWeightFlow, a Flow Matching model that operates directly in weight space to generate diverse and high-accuracy neural network weights for a variety of architectures, neural network sizes, and data modalities. The neural networks generated by DeepWeightFlow do not require fine-tuning to perform well and can scale to large networks. We apply Git Re-Basin and TransFusion for neural network canonicalization in the context of generative weight models to account for the impact of neural network permutation symmetries and to improve generation efficiency for larger model sizes. The generated networks excel at transfer learning, and ensembles of hundreds of neural networks can be generated in minutes, far exceeding the efficiency of diffusion-based methods. DeepWeightFlow models pave the way for more efficient and scalable generation of diverse sets of neural networks.",
      "authors": [
        "Saumya Gupta",
        "Scott Biggs",
        "Moritz Laber",
        "Zohair Shafi",
        "Robin Walters",
        "Ayan Paul"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "published": "2026-01-08 15:56:28+00:00",
      "link": "https://arxiv.org/pdf/2601.05052v1",
      "tags": [
        "keyword:resnet",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05051v1",
      "title": "Publishing FAIR and Machine-actionable Reviews in Materials Science: The Case for Symbolic Knowledge in Neuro-symbolic Artificial Intelligence",
      "abstract": "Scientific reviews are central to knowledge integration in materials science, yet their key insights remain locked in narrative text and static PDF tables, limiting reuse by humans and machines alike. This article presents a case study in atomic layer deposition and etching (ALD/E) where we publish review tables as FAIR, machine-actionable comparisons in the Open Research Knowledge Graph (ORKG), turning them into structured, queryable knowledge. Building on this, we contrast symbolic querying over ORKG with large language model-based querying, and argue that a curated symbolic layer should remain the backbone of reliable neurosymbolic AI in materials science, with LLMs serving as complementary, symbolically grounded interfaces rather than standalone sources of truth.",
      "authors": [
        "Jennifer D'Souza",
        "Soren Auer",
        "Eleni Poupaki",
        "Alex Watkins",
        "Anjana Devi",
        "Riikka L. Puurunen",
        "Bora Karasulu",
        "Adrie Mackus",
        "Erwin Kessels"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.DL",
        "cs.IT"
      ],
      "published": "2026-01-08 15:56:17+00:00",
      "link": "https://arxiv.org/pdf/2601.05051v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05050v1",
      "title": "Large language models can effectively convince people to believe conspiracies",
      "abstract": "Large language models (LLMs) have been shown to be persuasive across a variety of context. But it remains unclear whether this persuasive power advantages truth over falsehood, or if LLMs can promote misbeliefs just as easily as refuting them. Here, we investigate this question across three pre-registered experiments in which participants (N = 2,724 Americans) discussed a conspiracy theory they were uncertain about with GPT-4o, and the model was instructed to either argue against (\"debunking\") or for (\"bunking\") that conspiracy. When using a \"jailbroken\" GPT-4o variant with guardrails removed, the AI was as effective at increasing conspiracy belief as decreasing it. Concerningly, the bunking AI was rated more positively, and increased trust in AI, more than the debunking AI. Surprisingly, we found that using standard GPT-4o produced very similar effects, such that the guardrails imposed by OpenAI did little to revent the LLM from promoting conspiracy beliefs. Encouragingly, however, a corrective conversation reversed these newly induced conspiracy beliefs, and simply prompting GPT-4o to only use accurate information dramatically reduced its ability to increase conspiracy beliefs. Our findings demonstrate that LLMs possess potent abilities to promote both truth and falsehood, but that potential solutions may exist to help mitigate this risk.",
      "authors": [
        "Thomas H. Costello",
        "Kellin Pelrine",
        "Matthew Kowal",
        "Antonio A. Arechar",
        "Jean-François Godbout",
        "Adam Gleave",
        "David Rand",
        "Gordon Pennycook"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "econ.GN"
      ],
      "published": "2026-01-08 15:56:05+00:00",
      "link": "https://arxiv.org/pdf/2601.05050v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05049v1",
      "title": "How to Set the Learning Rate for Large-Scale Pre-training?",
      "abstract": "Optimal configuration of the learning rate (LR) is a fundamental yet formidable challenge in large-scale pre-training. Given the stringent trade-off between training costs and model performance, the pivotal question is whether the optimal LR can be accurately extrapolated from low-cost experiments. In this paper, we formalize this investigation into two distinct research paradigms: Fitting and Transfer. Within the Fitting Paradigm, we innovatively introduce a Scaling Law for search factor, effectively reducing the search complexity from O(n^3) to O(n*C_D*C_η) via predictive modeling. Within the Transfer Paradigm, we extend the principles of $μ$Transfer to the Mixture of Experts (MoE) architecture, broadening its applicability to encompass model depth, weight decay, and token horizons. By pushing the boundaries of existing hyperparameter research in terms of scale, we conduct a comprehensive comparison between these two paradigms. Our empirical results challenge the scalability of the widely adopted $μ$ Transfer in large-scale pre-training scenarios. Furthermore, we provide a rigorous analysis through the dual lenses of training stability and feature learning to elucidate the underlying reasons why module-wise parameter tuning underperforms in large-scale settings. This work offers systematic practical guidelines and a fresh theoretical perspective for optimizing industrial-level pre-training.",
      "authors": [
        "Yunhua Zhou",
        "Shuhao Xing",
        "Junhao Huang",
        "Xipeng Qiu",
        "Qipeng Guo"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 15:55:13+00:00",
      "link": "https://arxiv.org/pdf/2601.05049v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05047v1",
      "title": "Challenges and Research Directions for Large Language Model Inference Hardware",
      "abstract": "Large Language Model (LLM) inference is hard. The autoregressive Decode phase of the underlying Transformer model makes LLM inference fundamentally different from training. Exacerbated by recent AI trends, the primary challenges are memory and interconnect rather than compute. To address these challenges, we highlight four architecture research opportunities: High Bandwidth Flash for 10X memory capacity with HBM-like bandwidth; Processing-Near-Memory and 3D memory-logic stacking for high memory bandwidth; and low-latency interconnect to speedup communication. While our focus is datacenter AI, we also review their applicability for mobile devices.",
      "authors": [
        "Xiaoyu Ma",
        "David Patterson"
      ],
      "primary_category": "cs.AR",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-08 15:52:11+00:00",
      "link": "https://arxiv.org/pdf/2601.05047v1",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.05039v1",
      "title": "FinDeepForecast: A Live Multi-Agent System for Benchmarking Deep Research Agents in Financial Forecasting",
      "abstract": "Deep Research (DR) Agents powered by advanced Large Language Models (LLMs) have fundamentally shifted the paradigm for completing complex research tasks. Yet, a comprehensive and live evaluation of their forecasting performance on real-world, research-oriented tasks in high-stakes domains (e.g., finance) remains underexplored. We introduce FinDeepForecast, the first live, end-to-end multi-agent system for automatically evaluating DR agents by continuously generating research-oriented financial forecasting tasks. This system is equipped with a dual-track taxonomy, enabling the dynamic generation of recurrent and non-recurrent forecasting tasks at both corporate and macro levels. With this system, we generate FinDeepForecastBench, a weekly evaluation benchmark over a ten-week horizon, encompassing 8 global economies and 1,314 listed companies, and evaluate 13 representative methods. Extensive experiments show that, while DR agents consistently outperform strong baselines, their performance still falls short of genuine forward-looking financial reasoning. We expect the proposed FinDeepForecast system to consistently facilitate future advancements of DR agents in research-oriented financial forecasting tasks. The benchmark and leaderboard are publicly available on the OpenFinArena Platform.",
      "authors": [
        "Xiangyu Li",
        "Xuan Yao",
        "Guohao Qi",
        "Fengbin Zhu",
        "Kelvin J. L. Koa",
        "Xiang Yao Ng",
        "Ziyang Liu",
        "Xingyu Ni",
        "Chang Liu",
        "Yonghui Yang",
        "Yang Zhang",
        "Wenjie Wang",
        "Fuli Feng",
        "Chao Wang",
        "Huanbo Luan",
        "Xiaofen Xing",
        "Xiangmin Xu",
        "Tat-Seng Chua",
        "Ke-Wei Huang"
      ],
      "primary_category": "cs.MA",
      "categories": [
        "cs.MA"
      ],
      "published": "2026-01-08 15:45:09+00:00",
      "link": "https://arxiv.org/pdf/2601.05039v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.05033v1",
      "title": "A Data-Driven Predictive Framework for Inventory Optimization Using Context-Augmented Machine Learning Models",
      "abstract": "Demand forecasting in supply chain management (SCM) is critical for optimizing inventory, reducing waste, and improving customer satisfaction. Conventional approaches frequently neglect external influences like weather, festivities, and equipment breakdowns, resulting in inefficiencies. This research investigates the use of machine learning (ML) algorithms to improve demand prediction in retail and vending machine sectors. Four machine learning algorithms. Extreme Gradient Boosting (XGBoost), Autoregressive Integrated Moving Average (ARIMA), Facebook Prophet (Fb Prophet), and Support Vector Regression (SVR) were used to forecast inventory requirements. Ex-ternal factors like weekdays, holidays, and sales deviation indicators were methodically incorporated to enhance precision. XGBoost surpassed other models, reaching the lowest Mean Absolute Error (MAE) of 22.7 with the inclusion of external variables. ARIMAX and Fb Prophet demonstrated noteworthy enhancements, whereas SVR fell short in performance. Incorporating external factors greatly improves the precision of demand forecasting models, and XGBoost is identified as the most efficient algorithm. This study offers a strong framework for enhancing inventory management in retail and vending machine systems.",
      "authors": [
        "Anees Fatima",
        "Mohammad Abdus Salam"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-08 15:43:28+00:00",
      "link": "https://arxiv.org/pdf/2601.05033v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.05011v1",
      "title": "Leveraging Prediction Entropy for Automatic Prompt Weighting in Zero-Shot Audio-Language Classification",
      "abstract": "Audio-language models have recently demonstrated strong zero-shot capabilities by leveraging natural-language supervision to classify audio events without labeled training data. Yet, their performance is highly sensitive to the wording of text prompts, with small variations leading to large fluctuations in accuracy. Prior work has mitigated this issue through prompt learning or prompt ensembling. However, these strategies either require annotated data or fail to account for the fact that some prompts may negatively impact performance. In this work, we present an entropy-guided prompt weighting approach that aims to find a robust combination of prompt contributions to maximize prediction confidence. To this end, we formulate a tailored objective function that minimizes prediction entropy to yield new prompt weights, utilizing low-entropy as a proxy for high confidence. Our approach can be applied to individual samples or a batch of audio samples, requiring no additional labels and incurring negligible computational overhead. Experiments on five audio classification datasets covering environmental, urban, and vocal sounds, demonstrate consistent gains compared to classical prompt ensembling methods in a zero-shot setting, with accuracy improvements 5-times larger across the whole benchmark.",
      "authors": [
        "Karim El Khoury",
        "Maxime Zanella",
        "Tiffanie Godelaine",
        "Christophe De Vleeschouwer",
        "Benoit Macq"
      ],
      "primary_category": "cs.SD",
      "categories": [
        "cs.SD",
        "cs.LG"
      ],
      "published": "2026-01-08 15:11:04+00:00",
      "link": "https://arxiv.org/pdf/2601.05011v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.05004v1",
      "title": "Can Large Language Models Resolve Semantic Discrepancy in Self-Destructive Subcultures? Evidence from Jirai Kei",
      "abstract": "Self-destructive behaviors are linked to complex psychological states and can be challenging to diagnose. These behaviors may be even harder to identify within subcultural groups due to their unique expressions. As large language models (LLMs) are applied across various fields, some researchers have begun exploring their application for detecting self-destructive behaviors. Motivated by this, we investigate self-destructive behavior detection within subcultures using current LLM-based methods. However, these methods have two main challenges: (1) Knowledge Lag: Subcultural slang evolves rapidly, faster than LLMs' training cycles; and (2) Semantic Misalignment: it is challenging to grasp the specific and nuanced expressions unique to subcultures. To address these issues, we proposed Subcultural Alignment Solver (SAS), a multi-agent framework that incorporates automatic retrieval and subculture alignment, significantly enhancing the performance of LLMs in detecting self-destructive behavior. Our experimental results show that SAS outperforms the current advanced multi-agent framework OWL. Notably, it competes well with fine-tuned LLMs. We hope that SAS will advance the field of self-destructive behavior detection in subcultural contexts and serve as a valuable resource for future researchers.",
      "authors": [
        "Peng Wang",
        "Xilin Tao",
        "Siyi Yao",
        "Jiageng Wu",
        "Yuntao Zou",
        "Zhuotao Tian",
        "Libo Qin",
        "Dagang Li"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 15:02:41+00:00",
      "link": "https://arxiv.org/pdf/2601.05004v1",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.05002v1",
      "title": "On the Hidden Objective Biases of Group-based Reinforcement Learning",
      "abstract": "Group-based reinforcement learning methods, like Group Relative Policy Optimization (GRPO), are widely used nowadays to post-train large language models. Despite their empirical success, they exhibit structural mismatches between reward optimization and the underlying training objective. In this paper, we present a theoretical analysis of GRPO style methods by studying them within a unified surrogate formulation. This perspective reveals recurring properties that affect all the methods under analysis: (i) non-uniform group weighting induces systematic gradient biases on shared prefix tokens; (ii) interactions with the AdamW optimizer make training dynamics largely insensitive to reward scaling; and (iii) optimizer momentum can push policy updates beyond the intended clipping region under repeated optimization steps. We believe that these findings highlight fundamental limitations of current approaches and provide principled guidance for the design of future formulations.",
      "authors": [
        "Aleksandar Fontana",
        "Marco Simoni",
        "Giulio Rossolini",
        "Andrea Saracino",
        "Paolo Mori"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-08 15:00:35+00:00",
      "link": "https://arxiv.org/pdf/2601.05002v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04996v1",
      "title": "AlgBench: To What Extent Do Large Reasoning Models Understand Algorithms?",
      "abstract": "Reasoning ability has become a central focus in the advancement of Large Reasoning Models (LRMs). Although notable progress has been achieved on several reasoning benchmarks such as MATH500 and LiveCodeBench, existing benchmarks for algorithmic reasoning remain limited, failing to answer a critical question: Do LRMs truly master algorithmic reasoning? To answer this question, we propose AlgBench, an expert-curated benchmark that evaluates LRMs under an algorithm-centric paradigm.   AlgBench consists of over 3,000 original problems spanning 27 algorithms, constructed by ACM algorithmic experts and organized under a comprehensive taxonomy, including Euclidean-structured, non-Euclidean-structured, non-optimized, local-optimized, global-optimized, and heuristic-optimized categories. Empirical evaluations on leading LRMs (e.g., Gemini-3-Pro, DeepSeek-v3.2-Speciale and GPT-o3) reveal substantial performance heterogeneity: while models perform well on non-optimized tasks (up to 92%), accuracy drops sharply to around 49% on globally optimized algorithms such as dynamic programming. Further analysis uncovers \\textbf{strategic over-shifts}, wherein models prematurely abandon correct algorithmic designs due to necessary low-entropy tokens. These findings expose fundamental limitations of problem-centric reinforcement learning and highlight the necessity of an algorithm-centric training paradigm for robust algorithmic reasoning.",
      "authors": [
        "Henan Sun",
        "Kaichi Yu",
        "Yuyao Wang",
        "Bowen Liu",
        "Xunkai Li",
        "Rong-Hua Li",
        "Nuo Chen",
        "Jia Li"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 14:54:44+00:00",
      "link": "https://arxiv.org/pdf/2601.04996v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04983v1",
      "title": "Quantum Neural Network Training and Inference with Low Resolution Control Electronics",
      "abstract": "Scaling quantum computers requires tight integration of cryogenic control electronics with quantum processors, where Digital-to-Analog Converters (DACs) face severe power and area constraints. We investigate quantum neural network (QNN) training and inference under finite DAC resolution constraints across various DAC resolutions. Pre-trained QNNs achieve accuracy nearly indistinguishable from infinite-precision baselines when deployed on quantum systems with 6-bit DAC control electronics, exhibiting an elbow curve with diminishing returns beyond 4 bits. However, training under quantization reveals gradient deadlock below 12-bit resolution as gradient magnitudes fall below quantization step sizes. We introduce temperature-controlled stochasticity that overcomes this through probabilistic parameter updates, enabling successful training at 4-10 bit resolutions that remarkably matches or exceeds infinite-precision baseline performance. Our findings demonstrate that low-resolution control electronics need not compromise QML performance, enabling significant power and area reduction in cryogenic control systems for practical deployment as quantum hardware scales.",
      "authors": [
        "Rupayan Bhattacharjee",
        "Sergi Abadal",
        "Carmen G. Almudever",
        "Eduard Alarcon"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "cs.ET"
      ],
      "published": "2026-01-08 14:37:56+00:00",
      "link": "https://arxiv.org/pdf/2601.04983v1",
      "tags": [
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.04968v1",
      "title": "SparseLaneSTP: Leveraging Spatio-Temporal Priors with Sparse Transformers for 3D Lane Detection",
      "abstract": "3D lane detection has emerged as a critical challenge in autonomous driving, encompassing identification and localization of lane markings and the 3D road surface. Conventional 3D methods detect lanes from dense birds-eye-viewed (BEV) features, though erroneous transformations often result in a poor feature representation misaligned with the true 3D road surface. While recent sparse lane detectors have surpassed dense BEV approaches, they completely disregard valuable lane-specific priors. Furthermore, existing methods fail to utilize historic lane observations, which yield the potential to resolve ambiguities in situations of poor visibility. To address these challenges, we present SparseLaneSTP, a novel method that integrates both geometric properties of the lane structure and temporal information into a sparse lane transformer. It introduces a new lane-specific spatio-temporal attention mechanism, a continuous lane representation tailored for sparse architectures as well as temporal regularization. Identifying weaknesses of existing 3D lane datasets, we also introduce a precise and consistent 3D lane dataset using a simple yet effective auto-labeling strategy. Our experimental section proves the benefits of our contributions and demonstrates state-of-the-art performance across all detection and error metrics on existing 3D lane detection benchmarks as well as on our novel dataset.",
      "authors": [
        "Maximilian Pittner",
        "Joel Janai",
        "Mario Faigle",
        "Alexandru Paul Condurache"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 14:16:11+00:00",
      "link": "https://arxiv.org/pdf/2601.04968v1",
      "tags": [
        "keyword:大语言模型",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04960v1",
      "title": "A Unified Spoken Language Model with Injected Emotional-Attribution Thinking for Human-like Interaction",
      "abstract": "This paper presents a unified spoken language model for emotional intelligence, enhanced by a novel data construction strategy termed Injected Emotional-Attribution Thinking (IEAT). IEAT incorporates user emotional states and their underlying causes into the model's internal reasoning process, enabling emotion-aware reasoning to be internalized rather than treated as explicit supervision. The model is trained with a two-stage progressive strategy. The first stage performs speech-text alignment and emotional attribute modeling via self-distillation, while the second stage conducts end-to-end cross-modal joint optimization to ensure consistency between textual and spoken emotional expressions. Experiments on the Human-like Spoken Dialogue Systems Challenge (HumDial) Emotional Intelligence benchmark demonstrate that the proposed approach achieves top-ranked performance across emotional trajectory modeling, emotional reasoning, and empathetic response generation under both LLM-based and human evaluations.",
      "authors": [
        "Qing Wang",
        "Zehan Li",
        "Yaodong Song",
        "Hongjie Chen",
        "Jian Kang",
        "Jie Lian",
        "Jie Li",
        "Yongxiang Li",
        "Xuelong Li"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.SD"
      ],
      "published": "2026-01-08 14:07:30+00:00",
      "link": "https://arxiv.org/pdf/2601.04960v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04956v1",
      "title": "TEA: Temporal Adaptive Satellite Image Semantic Segmentation",
      "abstract": "Crop mapping based on satellite images time-series (SITS) holds substantial economic value in agricultural production settings, in which parcel segmentation is an essential step. Existing approaches have achieved notable advancements in SITS segmentation with predetermined sequence lengths. However, we found that these approaches overlooked the generalization capability of models across scenarios with varying temporal length, leading to markedly poor segmentation results in such cases. To address this issue, we propose TEA, a TEmporal Adaptive SITS semantic segmentation method to enhance the model's resilience under varying sequence lengths. We introduce a teacher model that encapsulates the global sequence knowledge to guide a student model with adaptive temporal input lengths. Specifically, teacher shapes the student's feature space via intermediate embedding, prototypes and soft label perspectives to realize knowledge transfer, while dynamically aggregating student model to mitigate knowledge forgetting. Finally, we introduce full-sequence reconstruction as an auxiliary task to further enhance the quality of representations across inputs of varying temporal lengths. Through extensive experiments, we demonstrate that our method brings remarkable improvements across inputs of different temporal lengths on common benchmarks. Our code will be publicly available.",
      "authors": [
        "Juyuan Kang",
        "Hao Zhu",
        "Yan Zhu",
        "Wei Zhang",
        "Jianing Chen",
        "Tianxiang Xiao",
        "Yike Ma",
        "Hao Jiang",
        "Feng Dai"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 14:02:28+00:00",
      "link": "https://arxiv.org/pdf/2601.04956v1",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.04925v1",
      "title": "Can AI-Generated Persuasion Be Detected? Persuaficial Benchmark and AI vs. Human Linguistic Differences",
      "abstract": "Large Language Models (LLMs) can generate highly persuasive text, raising concerns about their misuse for propaganda, manipulation, and other harmful purposes. This leads us to our central question: Is LLM-generated persuasion more difficult to automatically detect than human-written persuasion? To address this, we categorize controllable generation approaches for producing persuasive content with LLMs and introduce Persuaficial, a high-quality multilingual benchmark covering six languages: English, German, Polish, Italian, French and Russian. Using this benchmark, we conduct extensive empirical evaluations comparing human-authored and LLM-generated persuasive texts. We find that although overtly persuasive LLM-generated texts can be easier to detect than human-written ones, subtle LLM-generated persuasion consistently degrades automatic detection performance. Beyond detection performance, we provide the first comprehensive linguistic analysis contrasting human and LLM-generated persuasive texts, offering insights that may guide the development of more interpretable and robust detection tools.",
      "authors": [
        "Arkadiusz Modzelewski",
        "Paweł Golik",
        "Anna Kołos",
        "Giovanni Da San Martino"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 13:22:25+00:00",
      "link": "https://arxiv.org/pdf/2601.04925v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04922v1",
      "title": "AVX / NEON Intrinsic Functions: When Should They Be Used?",
      "abstract": "A cross-configuration benchmark is proposed to explore the capacities and limitations of AVX / NEON intrinsic functions in a generic context of development project, when a vectorisation strategy is required to optimise the code. The main aim is to guide developers to choose when using intrinsic functions, depending on the OS, architecture and/or available compiler. Intrinsic functions were observed highly efficient in conditional branching, with intrinsic version execution time reaching around 5% of plain code execution time. However, intrinsic functions were observed as unnecessary in many cases, as the compilers already well auto-vectorise the code.",
      "authors": [
        "Théo Boivin",
        "Joeffrey Legaux"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE"
      ],
      "published": "2026-01-08 13:21:19+00:00",
      "link": "https://arxiv.org/pdf/2601.04922v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04918v1",
      "title": "Breaking Robustness Barriers in Cognitive Diagnosis: A One-Shot Neural Architecture Search Perspective",
      "abstract": "With the advancement of network technologies, intelligent tutoring systems (ITS) have emerged to deliver increasingly precise and tailored personalized learning services. Cognitive diagnosis (CD) has emerged as a core research task in ITS, aiming to infer learners' mastery of specific knowledge concepts by modeling the mapping between learning behavior data and knowledge states. However, existing research prioritizes model performance enhancement while neglecting the pervasive noise contamination in observed response data, significantly hindering practical deployment. Furthermore, current cognitive diagnosis models (CDMs) rely heavily on researchers' domain expertise for structural design, which fails to exhaustively explore architectural possibilities, thus leaving model architectures' full potential untapped. To address this issue, we propose OSCD, an evolutionary multi-objective One-Shot neural architecture search method for Cognitive Diagnosis, designed to efficiently and robustly improve the model's capability in assessing learner proficiency. Specifically, OSCD operates through two distinct stages: training and searching. During the training stage, we construct a search space encompassing diverse architectural combinations and train a weight-sharing supernet represented via the complete binary tree topology, enabling comprehensive exploration of potential architectures beyond manual design priors. In the searching stage, we formulate the optimal architecture search under heterogeneous noise scenarios as a multi-objective optimization problem (MOP), and develop an optimization framework integrating a Pareto-optimal solution search strategy with cross-scenario performance evaluation for resolution. Extensive experiments on real-world educational datasets validate the effectiveness and robustness of the optimal architectures discovered by our OSCD model for CD tasks.",
      "authors": [
        "Ziwen Wang",
        "Shangshang Yang",
        "Xiaoshan Yu",
        "Haiping Ma",
        "Xingyi Zhang"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "published": "2026-01-08 13:17:40+00:00",
      "link": "https://arxiv.org/pdf/2601.04918v1",
      "tags": [
        "keyword:resnet",
        "keyword:resnet中文",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04915v1",
      "title": "OnomaCompass: A Texture Exploration Interface that Shuttles between Words and Images",
      "abstract": "Humans can finely perceive material textures, yet articulating such somatic impressions in words is a cognitive bottleneck in design ideation. We present OnomaCompass, a web-based exploration system that links sound-symbolic onomatopoeia and visual texture representations to support early-stage material discovery. Instead of requiring users to craft precise prompts for generative AI, OnomaCompass provides two coordinated latent-space maps--one for texture images and one for onomatopoeic term--built from an authored dataset of invented onomatopoeia and corresponding textures generated via Stable Diffusion. Users can navigate both spaces, trigger cross-modal highlighting, curate findings in a gallery, and preview textures applied to objects via an image-editing model. The system also supports video interpolation between selected textures and re-embedding of extracted frames to form an emergent exploration loop. We conducted a within-subjects study with 11 participants comparing OnomaCompass to a prompt-based image-generation workflow using Gemini 2.5 Flash Image (\"Nano Banana\"). OnomaCompass significantly reduced workload (NASA-TLX overall, mental demand, effort, and frustration; p < .05) and increased hedonic user experience (UEQ), while usability (SUS) favored the baseline. Qualitative findings indicate that OnomaCompass helps users externalize vague sensory expectations and promotes serendipitous discovery, but also reveals interaction challenges in spatial navigation. Overall, leveraging sound symbolism as a lightweight cue offers a complementary approach to Kansei-driven material ideation beyond prompt-centric generation.",
      "authors": [
        "Miki Okamura",
        "Shuhey Koyama",
        "Li Jingjing",
        "Yoichi Ochiai"
      ],
      "primary_category": "cs.HC",
      "categories": [
        "cs.HC"
      ],
      "published": "2026-01-08 13:13:44+00:00",
      "link": "https://arxiv.org/pdf/2601.04915v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04912v1",
      "title": "Decentralized Privacy-Preserving Federal Learning of Computer Vision Models on Edge Devices",
      "abstract": "Collaborative training of a machine learning model comes with a risk of sharing sensitive or private data. Federated learning offers a way of collectively training a single global model without the need to share client data, by sharing only the updated parameters from each client's local model. A central server is then used to aggregate parameters from all clients and redistribute the aggregated model back to the clients. Recent findings have shown that even in this scenario, private data can be reconstructed only using information about model parameters. Current efforts to mitigate this are mainly focused on reducing privacy risks on the server side, assuming that other clients will not act maliciously. In this work, we analyzed various methods for improving the privacy of client data concerning both the server and other clients for neural networks. Some of these methods include homomorphic encryption, gradient compression, gradient noising, and discussion on possible usage of modified federated learning systems such as split learning, swarm learning or fully encrypted models. We have analyzed the negative effects of gradient compression and gradient noising on the accuracy of convolutional neural networks used for classification. We have shown the difficulty of data reconstruction in the case of segmentation networks. We have also implemented a proof of concept on the NVIDIA Jetson TX2 module used in edge devices and simulated a federated learning process.",
      "authors": [
        "Damian Harenčák",
        "Lukáš Gajdošech",
        "Martin Madaras"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR",
        "cs.CV"
      ],
      "published": "2026-01-08 13:10:33+00:00",
      "link": "https://arxiv.org/pdf/2601.04912v1",
      "tags": [
        "keyword:resnet",
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.04899v1",
      "title": "Rotation-Robust Regression with Convolutional Model Trees",
      "abstract": "We study rotation-robust learning for image inputs using Convolutional Model Trees (CMTs) [1], whose split and leaf coefficients can be structured on the image grid and transformed geometrically at deployment time. In a controlled MNIST setting with a rotation-invariant regression target, we introduce three geometry-aware inductive biases for split directions -- convolutional smoothing, a tilt dominance constraint, and importance-based pruning -- and quantify their impact on robustness under in-plane rotations. We further evaluate a deployment-time orientation search that selects a discrete rotation maximizing a forest-level confidence proxy without updating model parameters. Orientation search improves robustness under severe rotations but can be harmful near the canonical orientation when confidence is misaligned with correctness. Finally, we observe consistent trends on MNIST digit recognition implemented as one-vs-rest regression, highlighting both the promise and limitations of confidence-based orientation selection for model-tree ensembles.",
      "authors": [
        "Hongyi Li",
        "William Ward Armstrong",
        "Jun Xu"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-01-08 12:53:33+00:00",
      "link": "https://arxiv.org/pdf/2601.04899v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04897v1",
      "title": "V-FAT: Benchmarking Visual Fidelity Against Text-bias",
      "abstract": "Recent advancements in Multimodal Large Language Models (MLLMs) have demonstrated impressive performance on standard visual reasoning benchmarks. However, there is growing concern that these models rely excessively on linguistic shortcuts rather than genuine visual grounding, a phenomenon we term Text Bias. In this paper, we investigate the fundamental tension between visual perception and linguistic priors. We decouple the sources of this bias into two dimensions: Internal Corpus Bias, stemming from statistical correlations in pretraining, and External Instruction Bias, arising from the alignment-induced tendency toward sycophancy. To quantify this effect, we introduce V-FAT (Visual Fidelity Against Text-bias), a diagnostic benchmark comprising 4,026 VQA instances across six semantic domains. V-FAT employs a Three-Level Evaluation Framework that systematically increases the conflict between visual evidence and textual information: (L1) internal bias from atypical images, (L2) external bias from misleading instructions, and (L3) synergistic bias where both coincide. We introduce the Visual Robustness Score (VRS), a metric designed to penalize \"lucky\" linguistic guesses and reward true visual fidelity. Our evaluation of 12 frontier MLLMs reveals that while models excel in existing benchmarks, they experience significant visual collapse under high linguistic dominance.",
      "authors": [
        "Ziteng Wang",
        "Yujie He",
        "Guanliang Li",
        "Siqi Yang",
        "Jiaqi Xiong",
        "Songxiang Liu"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.CV",
        "cs.LG",
        "cs.MM"
      ],
      "published": "2026-01-08 12:50:14+00:00",
      "link": "https://arxiv.org/pdf/2601.04897v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04895v1",
      "title": "DVD: A Robust Method for Detecting Variant Contamination in Large Language Model Evaluation",
      "abstract": "Evaluating large language models (LLMs) is increasingly confounded by \\emph{variant contamination}: the training corpus contains semantically equivalent yet lexically or syntactically altered versions of test items. Unlike verbatim leakage, these paraphrased or structurally transformed variants evade existing detectors based on sampling consistency or perplexity, thereby inflating benchmark scores via memorization rather than genuine reasoning. We formalize this problem and introduce \\textbf{DVD} (\\textbf{D}etection via \\textbf{V}ariance of generation \\textbf{D}istribution), a single-sample detector that models the local output distribution induced by temperature sampling. Our key insight is that contaminated items trigger alternation between a \\emph{memory-adherence} state and a \\emph{perturbation-drift} state, yielding abnormally high variance in the synthetic difficulty of low-probability tokens; uncontaminated items remain in drift with comparatively smooth variance. We construct the first benchmark for variant contamination across two domains Omni-MATH and SuperGPQA by generating and filtering semantically equivalent variants, and simulate contamination via fine-tuning models of different scales and architectures (Qwen2.5 and Llama3.1). Across datasets and models, \\textbf{DVD} consistently outperforms perplexity-based, Min-$k$\\%++, edit-distance (CDD), and embedding-similarity baselines, while exhibiting strong robustness to hyperparameters. Our results establish variance of the generation distribution as a principled and practical fingerprint for detecting variant contamination in LLM evaluation.",
      "authors": [
        "Renzhao Liang",
        "Jingru Chen",
        "Bo Jia",
        "Bo Deng",
        "Chenggang Xie",
        "Yidong Wang",
        "Ke Jin",
        "Xin Wang",
        "Linfeng Zhang",
        "Cunxiang Wang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 12:48:40+00:00",
      "link": "https://arxiv.org/pdf/2601.04895v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04891v1",
      "title": "Scaling Vision Language Models for Pharmaceutical Long Form Video Reasoning on Industrial GenAI Platform",
      "abstract": "Vision Language Models (VLMs) have shown strong performance on multimodal reasoning tasks, yet most evaluations focus on short videos and assume unconstrained computational resources. In industrial settings such as pharmaceutical content understanding, practitioners must process long-form videos under strict GPU, latency, and cost constraints, where many existing approaches fail to scale. In this work, we present an industrial GenAI framework that processes over 200,000 PDFs, 25,326 videos across eight formats (e.g., MP4, M4V, etc.), and 888 multilingual audio files in more than 20 languages. Our study makes three contributions: (i) an industrial large-scale architecture for multimodal reasoning in pharmaceutical domains; (ii) empirical analysis of over 40 VLMs on two leading benchmarks (Video-MME and MMBench) and proprietary dataset of 25,326 videos across 14 disease areas; and (iii) four findings relevant to long-form video reasoning: the role of multimodality, attention mechanism trade-offs, temporal reasoning limits, and challenges of video splitting under GPU constraints. Results show 3-8 times efficiency gains with SDPA attention on commodity GPUs, multimodality improving up to 8/12 task domains (especially length-dependent tasks), and clear bottlenecks in temporal alignment and keyframe detection across open- and closed-source VLMs. Rather than proposing a new \"A+B\" model, this paper characterizes practical limits, trade-offs, and failure patterns of current VLMs under realistic deployment constraints, and provide actionable guidance for both researchers and practitioners designing scalable multimodal systems for long-form video understanding in industrial domains.",
      "authors": [
        "Suyash Mishra",
        "Qiang Li",
        "Srikanth Patil",
        "Satyanarayan Pati",
        "Baddu Narendra"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-01-08 12:42:17+00:00",
      "link": "https://arxiv.org/pdf/2601.04891v1",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.04887v1",
      "title": "Flexible Manufacturing Systems Intralogistics: Dynamic Optimization of AGVs and Tool Sharing Using Coloured-Timed Petri Nets and Actor-Critic RL with Actions Masking",
      "abstract": "Flexible Manufacturing Systems (FMS) are pivotal in optimizing production processes in today's rapidly evolving manufacturing landscape. This paper advances the traditional job shop scheduling problem by incorporating additional complexities through the simultaneous integration of automated guided vehicles (AGVs) and tool-sharing systems. We propose a novel approach that combines Colored-Timed Petri Nets (CTPNs) with actor-critic model-based reinforcement learning (MBRL), effectively addressing the multifaceted challenges associated with FMS. CTPNs provide a formal modeling structure and dynamic action masking, significantly reducing the action search space, while MBRL ensures adaptability to changing environments through the learned policy. Leveraging the advantages of MBRL, we incorporate a lookahead strategy for optimal positioning of AGVs, improving operational efficiency. Our approach was evaluated on small-sized public benchmarks and a newly developed large-scale benchmark inspired by the Taillard benchmark. The results show that our approach matches traditional methods on smaller instances and outperforms them on larger ones in terms of makespan while achieving a tenfold reduction in computation time. To ensure reproducibility, we propose a gym-compatible environment and an instance generator. Additionally, an ablation study evaluates the contribution of each framework component to its overall performance.",
      "authors": [
        "Sofiene Lassoued",
        "Laxmikant Shrikant Bahetic",
        "Nathalie Weiß-Borkowskib",
        "Stefan Lierc",
        "Andreas Schwunga"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 12:37:02+00:00",
      "link": "https://arxiv.org/pdf/2601.04887v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04885v1",
      "title": "CuMA: Aligning LLMs with Sparse Cultural Values via Demographic-Aware Mixture of Adapters",
      "abstract": "As Large Language Models (LLMs) serve a global audience, alignment must transition from enforcing universal consensus to respecting cultural pluralism. We demonstrate that dense models, when forced to fit conflicting value distributions, suffer from \\textbf{Mean Collapse}, converging to a generic average that fails to represent diverse groups. We attribute this to \\textbf{Cultural Sparsity}, where gradient interference prevents dense parameters from spanning distinct cultural modes. To resolve this, we propose \\textbf{\\textsc{CuMA}} (\\textbf{Cu}ltural \\textbf{M}ixture of \\textbf{A}dapters), a framework that frames alignment as a \\textbf{conditional capacity separation} problem. By incorporating demographic-aware routing, \\textsc{CuMA} internalizes a \\textit{Latent Cultural Topology} to explicitly disentangle conflicting gradients into specialized expert subspaces. Extensive evaluations on WorldValuesBench, Community Alignment, and PRISM demonstrate that \\textsc{CuMA} achieves state-of-the-art performance, significantly outperforming both dense baselines and semantic-only MoEs. Crucially, our analysis confirms that \\textsc{CuMA} effectively mitigates mean collapse, preserving cultural diversity. Our code is available at https://github.com/Throll/CuMA.",
      "authors": [
        "Ao Sun",
        "Xiaoyu Wang",
        "Zhe Tan",
        "Yu Li",
        "Jiachen Zhu",
        "Shu Su",
        "Yuheng Jia"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-08 12:30:43+00:00",
      "link": "https://arxiv.org/pdf/2601.04885v1",
      "tags": [
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.04881v1",
      "title": "Zero Wrench Control via Wrench Disturbance Observer for Learning-free Peg-in-hole Assembly",
      "abstract": "This paper proposes a Dynamic Wrench Disturbance Observer (DW-DOB) designed to achieve highly sensitive zero-wrench control in contact-rich manipulation. By embedding task-space inertia into the observer nominal model, DW-DOB cleanly separates intrinsic dynamic reactions from true external wrenches. This preserves sensitivity to small forces and moments while ensuring robust regulation of contact wrenches. A passivity-based analysis further demonstrates that DW-DOB guarantees stable interactions under dynamic conditions, addressing the shortcomings of conventional observers that fail to compensate for inertial effects. Peg-in-hole experiments at industrial tolerances (H7/h6) validate the approach, yielding deeper and more compliant insertions with minimal residual wrenches and outperforming a conventional wrench disturbance observer and a PD baseline. These results highlight DW-DOB as a practical learning-free solution for high-precision zero-wrench control in contact-rich tasks.",
      "authors": [
        "Kiyoung Choi",
        "Juwon Jeong",
        "Sehoon Oh"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-01-08 12:29:21+00:00",
      "link": "https://arxiv.org/pdf/2601.04881v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04879v1",
      "title": "Mind2Report: A Cognitive Deep Research Agent for Expert-Level Commercial Report Synthesis",
      "abstract": "Synthesizing informative commercial reports from massive and noisy web sources is critical for high-stakes business decisions. Although current deep research agents achieve notable progress, their reports still remain limited in terms of quality, reliability, and coverage. In this work, we propose Mind2Report, a cognitive deep research agent that emulates the commercial analyst to synthesize expert-level reports. Specifically, it first probes fine-grained intent, then searches web sources and records distilled information on the fly, and subsequently iteratively synthesizes the report. We design Mind2Report as a training-free agentic workflow that augments general large language models (LLMs) with dynamic memory to support these long-form cognitive processes. To rigorously evaluate Mind2Report, we further construct QRC-Eval comprising 200 real-world commercial tasks and establish a holistic evaluation strategy to assess report quality, reliability, and coverage. Experiments demonstrate that Mind2Report outperforms leading baselines, including OpenAI and Gemini deep research agents. Although this is a preliminary study, we expect it to serve as a foundation for advancing the future design of commercial deep research agents. Our code and data are available at https://github.com/Melmaphother/Mind2Report.",
      "authors": [
        "Mingyue Cheng",
        "Daoyu Wang",
        "Qi Liu",
        "Shuo Yu",
        "Xiaoyu Tao",
        "Yuqian Wang",
        "Chengzhong Chu",
        "Yu Duan",
        "Mingkang Long",
        "Enhong Chen"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 12:27:52+00:00",
      "link": "https://arxiv.org/pdf/2601.04879v1",
      "tags": [
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.04876v1",
      "title": "ChronosAudio: A Comprehensive Long-Audio Benchmark for Evaluating Audio-Large Language Models",
      "abstract": "Although Audio Large Language Models (ALLMs) have witnessed substantial advancements, their long audio understanding capabilities remain unexplored. A plethora of benchmarks have been proposed for general audio tasks, they predominantly focus on short-form clips, leaving without a consensus on evaluating ALLMs over extended durations. This paper proposes ChronosAudio, the first multi-task benchmark tailored for long-audio understanding in ALLMs. It encompasses six major task categories and comprises 36,000 test instances totaling over 200 hours audio, stratified into short, middle, and long-form categories to comprehensively evaluate length generalization. Extensive experiments on 16 state-of-the-art models using ChronosAudio yield three critical findings: 1.Precipitous Long-Context Collapse: ALLMs exhibit a severe inability to sustain performance, with the transition from short to long contexts triggering a staggering performance degradation of over 90% in specific tasks. 2.Structural Attention Dilution: Performance degradation stems from a fundamental failure in maintaining temporal locality; attention mechanisms suffer from significant diffusion in later sequences. 3.Restorative Ceiling of Mitigation: Current strategies only offer 50% recovery. These findings reveal significant challenges in long-audio, underscoring the urgent need for approaches to achieve robust, document-level audio reasoning.",
      "authors": [
        "Kaiwen Luo",
        "Liang Lin",
        "Yibo Zhang",
        "Moayad Aloqaily",
        "Dexian Wang",
        "Zhenhong Zhou",
        "Junwei Zhang",
        "Kun Wang",
        "Li Sun",
        "Qingsong Wen"
      ],
      "primary_category": "cs.SD",
      "categories": [
        "cs.SD"
      ],
      "published": "2026-01-08 12:21:09+00:00",
      "link": "https://arxiv.org/pdf/2601.04876v1",
      "tags": [
        "keyword:大语言模型",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04873v1",
      "title": "FibreCastML: An Open Web Platform for Predicting Electrospun Nanofibre Diameter Distributions",
      "abstract": "Electrospinning is a scalable technique for producing fibrous scaffolds with tunable micro- and nanoscale architectures for applications in tissue engineering, drug delivery, and wound care. While machine learning (ML) has been used to support electrospinning process optimisation, most existing approaches predict only mean fibre diameters, neglecting the full diameter distribution that governs scaffold performance. This work presents FibreCastML, an open, distribution-aware ML framework that predicts complete fibre diameter spectra from routinely reported electrospinning parameters and provides interpretable insights into process structure relationships.   A meta-dataset comprising 68538 individual fibre diameter measurements extracted from 1778 studies across 16 biomedical polymers was curated. Six standard processing parameters, namely solution concentration, applied voltage, flow rate, tip to collector distance, needle diameter, and collector rotation speed, were used to train seven ML models using nested cross validation with leave one study out external folds. Model interpretability was achieved using variable importance analysis, SHapley Additive exPlanations, correlation matrices, and three dimensional parameter maps.   Non linear models consistently outperformed linear baselines, achieving coefficients of determination above 0.91 for several widely used polymers. Solution concentration emerged as the dominant global driver of fibre diameter distributions. Experimental validation across different electrospinning systems demonstrated close agreement between predicted and measured distributions. FibreCastML enables more reproducible and data driven optimisation of electrospun scaffold architectures.",
      "authors": [
        "Elisa Roldan",
        "Kirstie Andrews",
        "Stephen M. Richardson",
        "Reyhaneh Fatahian",
        "Glen Cooper",
        "Rasool Erfani",
        "Tasneem Sabir",
        "Neil D. Reeves"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-08 12:18:41+00:00",
      "link": "https://arxiv.org/pdf/2601.04873v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04867v1",
      "title": "Gradient-based Optimisation of Modulation Effects",
      "abstract": "Modulation effects such as phasers, flangers and chorus effects are heavily used in conjunction with the electric guitar. Machine learning based emulation of analog modulation units has been investigated in recent years, but most methods have either been limited to one class of effect or suffer from a high computational cost or latency compared to canonical digital implementations. Here, we build on previous work and present a framework for modelling flanger, chorus and phaser effects based on differentiable digital signal processing. The model is trained in the time-frequency domain, but at inference operates in the time-domain, requiring zero latency. We investigate the challenges associated with gradient-based optimisation of such effects, and show that low-frequency weighting of loss functions avoids convergence to local minima when learning delay times. We show that when trained against analog effects units, sound output from the model is in some cases perceptually indistinguishable from the reference, but challenges still remain for effects with long delay times and feedback.",
      "authors": [
        "Alistair Carson",
        "Alec Wright",
        "Stefan Bilbao"
      ],
      "primary_category": "eess.AS",
      "categories": [
        "eess.AS",
        "cs.LG",
        "cs.SD"
      ],
      "published": "2026-01-08 12:04:41+00:00",
      "link": "https://arxiv.org/pdf/2601.04867v1",
      "tags": [
        "keyword:resnet",
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.04862v1",
      "title": "Wireless Communication with Cross-Linked Rotatable Antenna Array: Architecture Design and Rotation Optimization",
      "abstract": "Rotatable antenna (RA) technology can harness additional spatial degrees of freedom by enabling the dynamic three-dimensional orientation control of each antenna. Unfortunately, the hardware cost and control complexity of traditional RA systems is proportional to the number of RAs. To address the issue, we consider a cross-linked (CL) RA structure, which enables the coordinated rotation of multiple antennas, thereby offering a cost-effective solution. To evaluate the performance of the CL-RA array, we investigate a CL-RA-aided uplink system. Specifically, we first establish system models for both antenna element-level and antenna panel-level rotation. Then, we formulate a sum rate maximization problem by jointly optimizing the receive beamforming at the base station and the rotation angles. For the antenna element-level rotation, we derive the optimal solution of the CL-RA array under the single-user case. Subsequently, for two rotation schemes, we propose an alternating optimization algorithm to solve the formulated problem in the multi-user case, where the receive beamforming and the antenna rotation angles are obtained by applying the minimum mean square error method and feasible direction method, respectively. In addition, considering the hardware limitations, we apply the genetic algorithm to address the discrete rotation angles selection problem. Simulation results show that by carefully designing the row-column partition scheme, the performance of the CL-RA architecture is quite close to that of the flexible antenna orientation scheme. Moreover, the CL antenna element-level scheme surpasses the CL antenna panel-level scheme by 25% and delivers a 128% performance improvement over conventional fixed-direction antennas.",
      "authors": [
        "Ailing Zheng",
        "Qingqing Wu",
        "Ziyuan Zheng",
        "Qiaoyan Peng",
        "Yanze Zhu",
        "Honghao Wang",
        "Wen Chen",
        "Guoying Zhang"
      ],
      "primary_category": "cs.IT",
      "categories": [
        "cs.IT"
      ],
      "published": "2026-01-08 11:57:24+00:00",
      "link": "https://arxiv.org/pdf/2601.04862v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04861v1",
      "title": "Orchestrating Intelligence: Confidence-Aware Routing for Efficient Multi-Agent Collaboration across Multi-Scale Models",
      "abstract": "While multi-agent systems (MAS) have demonstrated superior performance over single-agent approaches in complex reasoning tasks, they often suffer from significant computational inefficiencies. Existing frameworks typically deploy large language models (LLMs) uniformly across all agent roles, failing to account for the varying cognitive demands of different reasoning stages. We address this inefficiency by proposing OI-MAS framework, a novel multi-agent framework that implements an adaptive model-selection policy across a heterogeneous pool of multi-scale LLMs. Specifically, OI-MAS introduces a state-dependent routing mechanism that dynamically selects agent roles and model scales throughout the reasoning process. In addition, we introduce a confidence-aware mechanism that selects appropriate model scales conditioned on task complexity, thus reducing unnecessary reliance on large-scale models. Experimental results show that OI-MAS consistently outperforms baseline multi-agent systems, improving accuracy by up to 12.88\\% while reducing cost by up to 79.78\\%.",
      "authors": [
        "Jingbo Wang",
        "Sendong Zhao",
        "Jiatong Liu",
        "Haochun Wang",
        "Wanting Li",
        "Bing Qin",
        "Ting Liu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 11:56:09+00:00",
      "link": "https://arxiv.org/pdf/2601.04861v1",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.04855v1",
      "title": "Rethinking GNNs and Missing Features: Challenges, Evaluation and a Robust Solution",
      "abstract": "Handling missing node features is a key challenge for deploying Graph Neural Networks (GNNs) in real-world domains such as healthcare and sensor networks. Existing studies mostly address relatively benign scenarios, namely benchmark datasets with (a) high-dimensional but sparse node features and (b) incomplete data generated under Missing Completely At Random (MCAR) mechanisms. For (a), we theoretically prove that high sparsity substantially limits the information loss caused by missingness, making all models appear robust and preventing a meaningful comparison of their performance. To overcome this limitation, we introduce one synthetic and three real-world datasets with dense, semantically meaningful features. For (b), we move beyond MCAR and design evaluation protocols with more realistic missingness mechanisms. Moreover, we provide a theoretical background to state explicit assumptions on the missingness process and analyze their implications for different methods. Building on this analysis, we propose GNNmim, a simple yet effective baseline for node classification with incomplete feature data. Experiments show that GNNmim is competitive with respect to specialized architectures across diverse datasets and missingness regimes.",
      "authors": [
        "Francesco Ferrini",
        "Veronica Lachi",
        "Antonio Longa",
        "Bruno Lepri",
        "Matono Akiyoshi",
        "Andrea Passerini",
        "Xin Liu",
        "Manfred Jaeger"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-08 11:45:59+00:00",
      "link": "https://arxiv.org/pdf/2601.04855v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04852v1",
      "title": "Quantum Secure Biometric Authentication in Decentralised Systems",
      "abstract": "Biometric authentication has become integral to digital identity systems, particularly in smart cities where it en-ables secure access to services across governance, trans-portation, and public infrastructure. Centralised archi-tectures, though widely used, pose privacy and scalabil-ity challenges due to the aggregation of sensitive biomet-ric data. Decentralised identity frameworks offer better data sovereignty and eliminate single points of failure but introduce new security concerns, particularly around mu-tual trust among distributed devices. In such environments, biometric sensors and verification agents must authenticate one another before sharing sensitive biometric data. Ex-isting authentication schemes rely on classical public key infrastructure, which is increasingly susceptible to quan-tum attacks. This work addresses this gap by propos-ing a quantum-secure communication protocol for decen-tralised biometric systems, built upon an enhanced Quan-tum Key Distribution (QKD) system. The protocol incorpo-rates quantum-resilient authentication at both the classical and quantum layers of QKD: post-quantum cryptography (PQC) is used to secure the classical channel, while authen-tication qubits verify the integrity of the quantum channel. Once trust is established, QKD generates symmetric keys for encrypting biometric data in transit. Qiskit-based sim-ulations show a key generation rate of 15 bits/sec and 89% efficiency. This layered, quantum-resilient approach offers scalable, robust authentication for next-generation smart city infrastructures.",
      "authors": [
        "Tooba Qasim",
        "Vasilios A. Siris",
        "Izak Oosthuizen",
        "Muttukrishnan Rajarajan",
        "Sujit Biswas"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR"
      ],
      "published": "2026-01-08 11:42:18+00:00",
      "link": "https://arxiv.org/pdf/2601.04852v1",
      "tags": [
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.04842v1",
      "title": "Intelligent resource allocation in wireless networks via deep reinforcement learning",
      "abstract": "This study addresses the challenge of optimal power allocation in stochastic wireless networks by employing a Deep Reinforcement Learning (DRL) framework. Specifically, we design a Deep Q-Network (DQN) agent capable of learning adaptive power control policies directly from channel state observations, effectively bypassing the need for explicit system models. We formulate the resource allocation problem as a Markov Decision Process (MDP) and benchmark the proposed approach against classical heuristics, including fixed allocation, random assignment, and the theoretical water-filling algorithm. Empirical results demonstrate that the DQN agent achieves a system throughput of 3.88 Mbps, effectively matching the upper limit of the water fill, while outperforming the random and fixed allocation strategies by approximately 73% and 27%, respectively. Moreover, the agent exhibits emergent fairness, maintaining a Jain's Index of 0.91, and successfully optimizes the trade-off between spectral efficiency and energy consumption. These findings substantiate the efficacy of model-free DRL as a robust and scalable solution for resource management in next-generation communication systems.",
      "authors": [
        "Marie Diane Iradukunda",
        "Chabi F. Elégbédé",
        "Yaé Ulrich Gaba"
      ],
      "primary_category": "cs.NI",
      "categories": [
        "cs.NI"
      ],
      "published": "2026-01-08 11:22:59+00:00",
      "link": "https://arxiv.org/pdf/2601.04842v1",
      "tags": [
        "keyword:resnet",
        "keyword:resnet中文",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04824v1",
      "title": "SOVABench: A Vehicle Surveillance Action Retrieval Benchmark for Multimodal Large Language Models",
      "abstract": "Automatic identification of events and recurrent behavior analysis are critical for video surveillance. However, most existing content-based video retrieval benchmarks focus on scene-level similarity and do not evaluate the action discrimination required in surveillance. To address this gap, we introduce SOVABench (Surveillance Opposite Vehicle Actions Benchmark), a real-world retrieval benchmark built from surveillance footage and centered on vehicle-related actions. SOVABench defines two evaluation protocols (inter-pair and intra-pair) to assess cross-action discrimination and temporal direction understanding. Although action distinctions are generally intuitive for human observers, our experiments show that they remain challenging for state-of-the-art vision and multimodal models.   Leveraging the visual reasoning and instruction-following capabilities of Multimodal Large Language Models (MLLMs), we present a training-free framework for producing interpretable embeddings from MLLM-generated descriptions for both images and videos. The framework achieves strong performance on SOVABench as well as on several spatial and counting benchmarks where contrastive Vision-Language Models often fail. The code, annotations, and instructions to construct the benchmark are publicly available.",
      "authors": [
        "Oriol Rabasseda",
        "Zenjie Li",
        "Kamal Nasrollahi",
        "Sergio Escalera"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 10:58:59+00:00",
      "link": "https://arxiv.org/pdf/2601.04824v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04813v1",
      "title": "Proof of Commitment: A Human-Centric Resource for Permissionless Consensus",
      "abstract": "Permissionless consensus protocols require a scarce resource to regulate leader election and provide Sybil resistance. Existing paradigms such as Proof of Work and Proof of Stake instantiate this scarcity through parallelizable resources like computation or capital. Once acquired, these resources can be subdivided across many identities at negligible marginal cost, making linear Sybil cost fundamentally unattainable.   We introduce Proof of Commitment (PoCmt), a consensus primitive grounded in a non-parallelizable resource: real-time human engagement. Validators maintain a commitment state capturing cumulative human effort, protocol participation, and online availability. Engagement is enforced through a Human Challenge Oracle that issues identity-bound, time-sensitive challenges, limiting the number of challenges solvable within each human window.   Under this model, sustaining multiple active identities requires proportional human-time effort. We establish a cost-theoretic separation showing that protocols based on parallelizable resources admit zero marginal Sybil cost, whereas PoCmt enforces a strictly linear cost profile. Using a weighted-backbone analysis, we show that PoCmt achieves safety, liveness, and commitment-proportional fairness under partial synchrony.   Simulations complement the analysis by isolating human-time capacity as the sole adversarial bottleneck and validating the predicted commitment drift and fairness properties. These results position PoCmt as a new point in the consensus design space, grounding permissionless security in sustained human effort rather than computation or capital.",
      "authors": [
        "Homayoun Maleki",
        "Nekane Sainz",
        "Jon Legarda"
      ],
      "primary_category": "cs.DC",
      "categories": [
        "cs.DC"
      ],
      "published": "2026-01-08 10:46:26+00:00",
      "link": "https://arxiv.org/pdf/2601.04813v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04801v1",
      "title": "MPM-LLM4DSE: Reaching the Pareto Frontier in HLS with Multimodal Learning and LLM-Driven Exploration",
      "abstract": "High-Level Synthesis (HLS) design space exploration (DSE) seeks Pareto-optimal designs within expansive pragma configuration spaces. To accelerate HLS DSE, graph neural networks (GNNs) are commonly employed as surrogates for HLS tools to predict quality of results (QoR) metrics, while multi-objective optimization algorithms expedite the exploration. However, GNN-based prediction methods may not fully capture the rich semantic features inherent in behavioral descriptions, and conventional multi-objective optimization algorithms often do not explicitly account for the domain-specific knowledge regarding how pragma directives influence QoR. To address these limitations, this paper proposes the MPM-LLM4DSE framework, which incorporates a multimodal prediction model (MPM) that simultaneously fuses features from behavioral descriptions and control and data flow graphs. Furthermore, the framework employs a large language model (LLM) as an optimizer, accompanied by a tailored prompt engineering methodology. This methodology incorporates pragma impact analysis on QoR to guide the LLM in generating high-quality configurations (LLM4DSE). Experimental results demonstrate that our multimodal predictive model significantly outperforms state-of-the-art work ProgSG by up to 10.25$\\times$. Furthermore, in DSE tasks, the proposed LLM4DSE achieves an average performance gain of 39.90\\% over prior methods, validating the effectiveness of our prompting methodology. Code and models are available at https://github.com/wslcccc/MPM-LLM4DSE.",
      "authors": [
        "Lei Xu",
        "Shanshan Wang",
        "Chenglong Xiao"
      ],
      "primary_category": "cs.AR",
      "categories": [
        "cs.AR",
        "cs.LG"
      ],
      "published": "2026-01-08 10:32:49+00:00",
      "link": "https://arxiv.org/pdf/2601.04801v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04799v1",
      "title": "Neural-Symbolic Integration with Evolvable Policies",
      "abstract": "Neural-Symbolic (NeSy) Artificial Intelligence has emerged as a promising approach for combining the learning capabilities of neural networks with the interpretable reasoning of symbolic systems. However, existing NeSy frameworks typically require either predefined symbolic policies or policies that are differentiable, limiting their applicability when domain expertise is unavailable or when policies are inherently non-differentiable. We propose a framework that addresses this limitation by enabling the concurrent learning of both non-differentiable symbolic policies and neural network weights through an evolutionary process. Our approach casts NeSy systems as organisms in a population that evolve through mutations (both symbolic rule additions and neural weight changes), with fitness-based selection guiding convergence toward hidden target policies. The framework extends the NEUROLOG architecture to make symbolic policies trainable, adapts Valiant's Evolvability framework to the NeSy context, and employs Machine Coaching semantics for mutable symbolic representations. Neural networks are trained through abductive reasoning from the symbolic component, eliminating differentiability requirements. Through extensive experimentation, we demonstrate that NeSy systems starting with empty policies and random neural weights can successfully approximate hidden non-differentiable target policies, achieving median correct performance approaching 100%. This work represents a step toward enabling NeSy research in domains where the acquisition of symbolic knowledge from experts is challenging or infeasible.",
      "authors": [
        "Marios Thoma",
        "Vassilis Vassiliades",
        "Loizos Michael"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.NE"
      ],
      "published": "2026-01-08 10:29:49+00:00",
      "link": "https://arxiv.org/pdf/2601.04799v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04794v1",
      "title": "APEX: Academic Poster Editing Agentic Expert",
      "abstract": "Designing academic posters is a labor-intensive process requiring the precise balance of high-density content and sophisticated layout. While existing paper-to-poster generation methods automate initial drafting, they are typically single-pass and non-interactive, often fail to align with complex, subjective user intent. To bridge this gap, we propose APEX (Academic Poster Editing agentic eXpert), the first agentic framework for interactive academic poster editing, supporting fine-grained control with robust multi-level API-based editing and a review-and-adjustment Mechanism. In addition, we introduce APEX-Bench, the first systematic benchmark comprising 514 academic poster editing instructions, categorized by a multi-dimensional taxonomy including operation type, difficulty, and abstraction level, constructed via reference-guided and reference-free strategies to ensure realism and diversity. We further establish a multi-dimensional VLM-as-a-judge evaluation protocol to assess instruction fulfillment, modification scope, and visual consistency & harmony. Experimental results demonstrate that APEX significantly outperforms baseline methods. Our implementation is available at https://github.com/Breesiu/APEX.",
      "authors": [
        "Chengxin Shi",
        "Qinnan Cai",
        "Zeyuan Chen",
        "Long Zeng",
        "Yibo Zhao",
        "Jing Yu",
        "Jianxiang Yu",
        "Xiang Li"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 10:21:49+00:00",
      "link": "https://arxiv.org/pdf/2601.04794v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04789v1",
      "title": "NC2C: Automated Convexification of Generic Non-Convex Optimization Problems",
      "abstract": "Non-convex optimization problems are pervasive across mathematical programming, engineering design, and scientific computing, often posing intractable challenges for traditional solvers due to their complex objective functions and constrained landscapes. To address the inefficiency of manual convexification and the over-reliance on expert knowledge, we propose NC2C, an LLM-based end-to-end automated framework designed to transform generic non-convex optimization problems into solvable convex forms using large language models. NC2C leverages LLMs' mathematical reasoning capabilities to autonomously detect non-convex components, select optimal convexification strategies, and generate rigorous convex equivalents. The framework integrates symbolic reasoning, adaptive transformation techniques, and iterative validation, equipped with error correction loops and feasibility domain correction mechanisms to ensure the robustness and validity of transformed problems. Experimental results on a diverse dataset of 100 generic non-convex problems demonstrate that NC2C achieves an 89.3\\% execution rate and a 76\\% success rate in producing feasible, high-quality convex transformations. This outperforms baseline methods by a significant margin, highlighting NC2C's ability to leverage LLMs for automated non-convex to convex transformation, reduce expert dependency, and enable efficient deployment of convex solvers for previously intractable optimization tasks.",
      "authors": [
        "Xinyue Peng",
        "Yanming Liu",
        "Yihan Cang",
        "Yuwei Zhang",
        "Xinyi Wang",
        "Songhang Deng",
        "Jiannan Cao"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-08 10:12:45+00:00",
      "link": "https://arxiv.org/pdf/2601.04789v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04786v1",
      "title": "AgentOCR: Reimagining Agent History via Optical Self-Compression",
      "abstract": "Recent advances in large language models (LLMs) enable agentic systems trained with reinforcement learning (RL) over multi-turn interaction trajectories, but practical deployment is bottlenecked by rapidly growing textual histories that inflate token budgets and memory usage. We introduce AgentOCR, a framework that exploits the superior information density of visual tokens by representing the accumulated observation-action history as a compact rendered image. To make multi-turn rollouts scalable, AgentOCR proposes segment optical caching. By decomposing history into hashable segments and maintaining a visual cache, this mechanism eliminates redundant re-rendering. Beyond fixed rendering, AgentOCR introduces agentic self-compression, where the agent actively emits a compression rate and is trained with compression-aware reward to adaptively balance task success and token efficiency. We conduct extensive experiments on challenging agentic benchmarks, ALFWorld and search-based QA. Remarkably, results demonstrate that AgentOCR preserves over 95\\% of text-based agent performance while substantially reducing token consumption (>50\\%), yielding consistent token and memory efficiency. Our further analysis validates a 20x rendering speedup from segment optical caching and the effective strategic balancing of self-compression.",
      "authors": [
        "Lang Feng",
        "Fuchao Yang",
        "Feng Chen",
        "Xin Cheng",
        "Haiyang Xu",
        "Zhenglin Wan",
        "Ming Yan",
        "Bo An"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-08 10:10:20+00:00",
      "link": "https://arxiv.org/pdf/2601.04786v1",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.04785v1",
      "title": "SRU-Pix2Pix: A Fusion-Driven Generator Network for Medical Image Translation with Few-Shot Learning",
      "abstract": "Magnetic Resonance Imaging (MRI) provides detailed tissue information, but its clinical application is limited by long acquisition time, high cost, and restricted resolution. Image translation has recently gained attention as a strategy to address these limitations. Although Pix2Pix has been widely applied in medical image translation, its potential has not been fully explored. In this study, we propose an enhanced Pix2Pix framework that integrates Squeeze-and-Excitation Residual Networks (SEResNet) and U-Net++ to improve image generation quality and structural fidelity. SEResNet strengthens critical feature representation through channel attention, while U-Net++ enhances multi-scale feature fusion. A simplified PatchGAN discriminator further stabilizes training and refines local anatomical realism. Experimental results demonstrate that under few-shot conditions with fewer than 500 images, the proposed method achieves consistent structural fidelity and superior image quality across multiple intra-modality MRI translation tasks, showing strong generalization ability. These results suggest an effective extension of Pix2Pix for medical image translation.",
      "authors": [
        "Xihe Qiu",
        "Yang Dai",
        "Xiaoyu Tan",
        "Sijia Li",
        "Fenghao Sun",
        "Lu Gan",
        "Liang Liu"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-01-08 10:10:03+00:00",
      "link": "https://arxiv.org/pdf/2601.04785v1",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.04770v1",
      "title": "SciIF: Benchmarking Scientific Instruction Following Towards Rigorous Scientific Intelligence",
      "abstract": "As large language models (LLMs) transition from general knowledge retrieval to complex scientific discovery, their evaluation standards must also incorporate the rigorous norms of scientific inquiry. Existing benchmarks exhibit a critical blind spot: general instruction-following metrics focus on superficial formatting, while domain-specific scientific benchmarks assess only final-answer correctness, often rewarding models that arrive at the right result with the wrong reasons. To address this gap, we introduce scientific instruction following: the capability to solve problems while strictly adhering to the constraints that establish scientific validity. Specifically, we introduce SciIF, a multi-discipline benchmark that evaluates this capability by pairing university-level problems with a fixed catalog of constraints across three pillars: scientific conditions (e.g., boundary checks and assumptions), semantic stability (e.g., unit and symbol conventions), and specific processes(e.g., required numerical methods). Uniquely, SciIF emphasizes auditability, requiring models to provide explicit evidence of constraint satisfaction rather than implicit compliance. By measuring both solution correctness and multi-constraint adherence, SciIF enables finegrained diagnosis of compositional reasoning failures, ensuring that LLMs can function as reliable agents within the strict logical frameworks of science.",
      "authors": [
        "Encheng Su",
        "Jianyu Wu",
        "Chen Tang",
        "Lintao Wang",
        "Pengze Li",
        "Aoran Wang",
        "Jinouwen Zhang",
        "Yizhou Wang",
        "Yuan Meng",
        "Xinzhu Ma",
        "Shixiang Tang",
        "Houqiang Li"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.DB"
      ],
      "published": "2026-01-08 09:45:58+00:00",
      "link": "https://arxiv.org/pdf/2601.04770v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04768v1",
      "title": "LANGSAE EDITING: Improving Multilingual Information Retrieval via Post-hoc Language Identity Removal",
      "abstract": "Dense retrieval in multilingual settings often searches over mixed-language collections, yet multilingual embeddings encode language identity alongside semantics. This language signal can inflate similarity for same-language pairs and crowd out relevant evidence written in other languages. We propose LANGSAE EDITING, a post-hoc sparse autoencoder trained on pooled embeddings that enables controllable removal of language-identity signal directly in vector space. The method identifies language-associated latent units using cross-language activation statistics, suppresses these units at inference time, and reconstructs embeddings in the original dimensionality, making it compatible with existing vector databases without retraining the base encoder or re-encoding raw text. Experiments across multiple languages show consistent improvements in ranking quality and cross-language coverage, with especially strong gains for script-distinct languages.",
      "authors": [
        "Dongjun Kim",
        "Jeongho Yoon",
        "Chanjun Park",
        "Heuiseok Lim"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.IR"
      ],
      "published": "2026-01-08 09:36:41+00:00",
      "link": "https://arxiv.org/pdf/2601.04768v1",
      "tags": [
        "keyword:resnet",
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.04767v1",
      "title": "AT$^2$PO: Agentic Turn-based Policy Optimization via Tree Search",
      "abstract": "LLM agents have emerged as powerful systems for tackling multi-turn tasks by interleaving internal reasoning and external tool interactions. Agentic Reinforcement Learning has recently drawn significant research attention as a critical post-training paradigm to further refine these capabilities. In this paper, we present AT$^2$PO (Agentic Turn-based Policy Optimization via Tree Search), a unified framework for multi-turn agentic RL that addresses three core challenges: limited exploration diversity, sparse credit assignment, and misaligned policy optimization. AT$^2$PO introduces a turn-level tree structure that jointly enables Entropy-Guided Tree Expansion for strategic exploration and Turn-wise Credit Assignment for fine-grained reward propagation from sparse outcomes. Complementing this, we propose Agentic Turn-based Policy Optimization, a turn-level learning objective that aligns policy updates with the natural decision granularity of agentic interactions. ATPO is orthogonal to tree search and can be readily integrated into any multi-turn RL pipeline. Experiments across seven benchmarks demonstrate consistent improvements over the state-of-the-art baseline by up to 1.84 percentage points in average, with ablation studies validating the effectiveness of each component. Our code is available at https://github.com/zzfoutofspace/ATPO.",
      "authors": [
        "Zefang Zong",
        "Dingwei Chen",
        "Yang Li",
        "Qi Yi",
        "Bo Zhou",
        "Chengming Li",
        "Bo Qian",
        "Peng Chen",
        "Jie Jiang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-08 09:35:49+00:00",
      "link": "https://arxiv.org/pdf/2601.04767v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04766v1",
      "title": "Revisiting Judge Decoding from First Principles via Training-Free Distributional Divergence",
      "abstract": "Judge Decoding accelerates LLM inference by relaxing the strict verification of Speculative Decoding, yet it typically relies on expensive and noisy supervision. In this work, we revisit this paradigm from first principles, revealing that the ``criticality'' scores learned via costly supervision are intrinsically encoded in the draft-target distributional divergence. We theoretically prove a structural correspondence between learned linear judges and Kullback-Leibler (KL) divergence, demonstrating they rely on the same underlying logit primitives. Guided by this, we propose a simple, training-free verification mechanism based on KL divergence. Extensive experiments across reasoning and coding benchmarks show that our method matches or outperforms complex trained judges (e.g., AutoJudge), offering superior robustness to domain shifts and eliminating the supervision bottleneck entirely.",
      "authors": [
        "Shengyin Sun",
        "Yiming Li",
        "Renxi Liu",
        "Weizhe Lin",
        "Hui-Ling Zhen",
        "Xianzhi Yu",
        "Mingxuan Yuan",
        "Chen Ma"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 09:34:54+00:00",
      "link": "https://arxiv.org/pdf/2601.04766v1",
      "tags": [
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.04765v1",
      "title": "Differential syntactic and semantic encoding in LLMs",
      "abstract": "We study how syntactic and semantic information is encoded in inner layer representations of Large Language Models (LLMs), focusing on the very large DeepSeek-V3. We find that, by averaging hidden-representation vectors of sentences sharing syntactic structure or meaning, we obtain vectors that capture a significant proportion of the syntactic and semantic information contained in the representations. In particular, subtracting these syntactic and semantic ``centroids'' from sentence vectors strongly affects their similarity with syntactically and semantically matched sentences, respectively, suggesting that syntax and semantics are, at least partially, linearly encoded. We also find that the cross-layer encoding profiles of syntax and semantics are different, and that the two signals can to some extent be decoupled, suggesting differential encoding of these two types of linguistic information in LLM representations.",
      "authors": [
        "Santiago Acevedo",
        "Alessandro Laio",
        "Marco Baroni"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "physics.comp-ph"
      ],
      "published": "2026-01-08 09:33:29+00:00",
      "link": "https://arxiv.org/pdf/2601.04765v1",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.04764v1",
      "title": "Orion-RAG: Path-Aligned Hybrid Retrieval for Graphless Data",
      "abstract": "Retrieval-Augmented Generation (RAG) has proven effective for knowledge synthesis, yet it encounters significant challenges in practical scenarios where data is inherently discrete and fragmented. In most environments, information is distributed across isolated files like reports and logs that lack explicit links. Standard search engines process files independently, ignoring the connections between them. Furthermore, manually building Knowledge Graphs is impractical for such vast data. To bridge this gap, we present Orion-RAG. Our core insight is simple yet effective: we do not need heavy algorithms to organize this data. Instead, we use a low-complexity strategy to extract lightweight paths that naturally link related concepts. We demonstrate that this streamlined approach suffices to transform fragmented documents into semi-structured data, enabling the system to link information across different files effectively. Extensive experiments demonstrate that Orion-RAG consistently outperforms mainstream frameworks across diverse domains, supporting real-time updates and explicit Human-in-the-Loop verification with high cost-efficiency. Experiments on FinanceBench demonstrate superior precision with a 25.2% relative improvement over strong baselines.",
      "authors": [
        "Zhen Chen",
        "Weihao Xie",
        "Peilin Chen",
        "Shiqi Wang",
        "Jianping Wang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 09:32:01+00:00",
      "link": "https://arxiv.org/pdf/2601.04764v1",
      "tags": [
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.04758v1",
      "title": "PILOT-Bench: A Benchmark for Legal Reasoning in the Patent Domain with IRAC-Aligned Classification Tasks",
      "abstract": "The Patent Trial and Appeal Board (PTAB) of the USPTO adjudicates thousands of ex parte appeals each year, requiring the integration of technical understanding and legal reasoning. While large language models (LLMs) are increasingly applied in patent and legal practice, their use has remained limited to lightweight tasks, with no established means of systematically evaluating their capacity for structured legal reasoning in the patent domain. In this work, we introduce PILOT-Bench, the first PTAB-centric benchmark that aligns PTAB decisions with USPTO patent data at the case-level and formalizes three IRAC-aligned classification tasks: Issue Type, Board Authorities, and Subdecision. We evaluate a diverse set of closed-source (commercial) and open-source LLMs and conduct analyses across multiple perspectives, including input-variation settings, model families, and error tendencies. Notably, on the Issue Type task, closed-source models consistently exceed 0.75 in Micro-F1 score, whereas the strongest open-source model (Qwen-8B) achieves performance around 0.56, highlighting a substantial gap in reasoning capabilities. PILOT-Bench establishes a foundation for the systematic evaluation of patent-domain legal reasoning and points toward future directions for improving LLMs through dataset design and model alignment. All data, code, and benchmark resources are available at https://github.com/TeamLab/pilot-bench.",
      "authors": [
        "Yehoon Jang",
        "Chaewon Lee",
        "Hyun-seok Min",
        "Sungchul Choi"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-08 09:26:05+00:00",
      "link": "https://arxiv.org/pdf/2601.04758v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04747v1",
      "title": "Efficient Compression in Semigroups",
      "abstract": "Straight-line programs are a central tool in several areas of computer science, including data compression, algebraic complexity theory, and the algorithmic solution of algebraic equations. In the algebraic setting, where straight-line programs can be interpreted as circuits over algebraic structures such as semigroups or groups, they have led to deep insights in computational complexity.   A key result by Babai and Szemerédi (1984) showed that finite groups afford efficient compression via straight-line programs, enabling the design of a black-box computation model for groups. Building on their result, Fleischer (2019) placed the Cayley table membership problem for certain classes (pseudovarieties) of finite semigroups in NPOLYLOGTIME, and in some cases even in FOLL. He also provided a complete classification of pseudovarieties of finite monoids affording efficient compression.   In this work, we complete this classification program initiated by Fleischer, characterizing precisely those pseudovarieties of finite semigroups that afford efficient compression via straight-line programs. Along the way, we also improve several known bounds on the length and width of straight-line programs over semigroups, monoids, and groups. These results lead to new upper bounds for the membership problem in the Cayley table model: for all pseudovarieties that afford efficient compression and do not contain any nonsolvable group, we obtain FOLL algorithms. In particular, we resolve a conjecture of Barrington, Kadau, Lange, and McKenzie (2001), showing that the membership problem for all solvable groups is in FOLL.",
      "authors": [
        "Alexander Thumm",
        "Armin Weiß"
      ],
      "primary_category": "math.RA",
      "categories": [
        "math.RA",
        "cs.CC",
        "math.GR"
      ],
      "published": "2026-01-08 09:13:53+00:00",
      "link": "https://arxiv.org/pdf/2601.04747v1",
      "tags": [
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.04745v1",
      "title": "KnowMe-Bench: Benchmarking Person Understanding for Lifelong Digital Companions",
      "abstract": "Existing long-horizon memory benchmarks mostly use multi-turn dialogues or synthetic user histories, which makes retrieval performance an imperfect proxy for person understanding. We present \\BenchName, a publicly releasable benchmark built from long-form autobiographical narratives, where actions, context, and inner thoughts provide dense evidence for inferring stable motivations and decision principles. \\BenchName~reconstructs each narrative into a flashback-aware, time-anchored stream and evaluates models with evidence-linked questions spanning factual recall, subjective state attribution, and principle-level reasoning. Across diverse narrative sources, retrieval-augmented systems mainly improve factual accuracy, while errors persist on temporally grounded explanations and higher-level inferences, highlighting the need for memory mechanisms beyond retrieval. Our data is in \\href{KnowMeBench}{https://github.com/QuantaAlpha/KnowMeBench}.",
      "authors": [
        "Tingyu Wu",
        "Zhisheng Chen",
        "Ziyan Weng",
        "Shuhe Wang",
        "Chenglong Li",
        "Shuo Zhang",
        "Sen Hu",
        "Silin Wu",
        "Qizhen Lan",
        "Huacan Wang",
        "Ronghao Chen"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.IR"
      ],
      "published": "2026-01-08 09:11:33+00:00",
      "link": "https://arxiv.org/pdf/2601.04745v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04744v1",
      "title": "Semi-Supervised Diseased Detection from Speech Dialogues with Multi-Level Data Modeling",
      "abstract": "Detecting medical conditions from speech acoustics is fundamentally a weakly-supervised learning problem: a single, often noisy, session-level label must be linked to nuanced patterns within a long, complex audio recording. This task is further hampered by severe data scarcity and the subjective nature of clinical annotations. While semi-supervised learning (SSL) offers a viable path to leverage unlabeled data, existing audio methods often fail to address the core challenge that pathological traits are not uniformly expressed in a patient's speech. We propose a novel, audio-only SSL framework that explicitly models this hierarchy by jointly learning from frame-level, segment-level, and session-level representations within unsegmented clinical dialogues. Our end-to-end approach dynamically aggregates these multi-granularity features and generates high-quality pseudo-labels to efficiently utilize unlabeled data. Extensive experiments show the framework is model-agnostic, robust across languages and conditions, and highly data-efficient-achieving, for instance, 90\\% of fully-supervised performance using only 11 labeled samples. This work provides a principled approach to learning from weak, far-end supervision in medical speech analysis.",
      "authors": [
        "Xingyuan Li",
        "Mengyue Wu"
      ],
      "primary_category": "cs.SD",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "published": "2026-01-08 09:10:16+00:00",
      "link": "https://arxiv.org/pdf/2601.04744v1",
      "tags": [
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.04732v1",
      "title": "The Role of Quantum in Hybrid Quantum-Classical Neural Networks: A Realistic Assessment",
      "abstract": "Quantum machine learning has emerged as a promising application domain for near-term quantum hardware, particularly through hybrid quantum-classical models that leverage both classical and quantum processing. Although numerous hybrid architectures have been proposed and demonstrated successfully on benchmark tasks, a significant open question remains regarding the specific contribution of quantum components to the overall performance of these models. In this work, we aim to shed light on the impact of quantum processing within hybrid quantum-classical neural network architectures through a rigorous statistical study. We systematically assess common hybrid models on medical signal data as well as planar and volumetric images, examining the influence attributable to classical and quantum aspects such as encoding schemes, entanglement, and circuit size. We find that in best-case scenarios, hybrid models show performance comparable to their classical counterparts, however, in most cases, performance metrics deteriorate under the influence of quantum components. Our multi-modal analysis provides realistic insights into the contributions of quantum components and advocates for cautious claims and design choices for hybrid models in near-term applications.",
      "authors": [
        "Dominik Freinberger",
        "Philipp Moser"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-08 08:54:44+00:00",
      "link": "https://arxiv.org/pdf/2601.04732v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04728v1",
      "title": "Excess Description Length of Learning Generalizable Predictors",
      "abstract": "Understanding whether fine-tuning elicits latent capabilities or teaches new ones is a fundamental question for language model evaluation and safety. We develop a formal information-theoretic framework for quantifying how much predictive structure fine-tuning extracts from the train dataset and writes into a model's parameters. Our central quantity, Excess Description Length (EDL), is defined via prequential coding and measures the gap between the bits required to encode training labels sequentially using an evolving model (trained online) and the residual encoding cost under the final trained model. We establish that EDL is non-negative in expectation, converges to surplus description length in the infinite-data limit, and provides bounds on expected generalization gain. Through a series of toy models, we clarify common confusions about information in learning: why random labels yield EDL near zero, how a single example can eliminate many bits of uncertainty about the underlying rule(s) that describe the data distribution, why structure learned on rare inputs contributes proportionally little to expected generalization, and how format learning creates early transients distinct from capability acquisition. This framework provides rigorous foundations for the empirical observation that capability elicitation and teaching exhibit qualitatively distinct scaling signatures.",
      "authors": [
        "Elizabeth Donoway",
        "Hailey Joren",
        "Fabien Roger",
        "Jan Leike"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-08 08:46:42+00:00",
      "link": "https://arxiv.org/pdf/2601.04728v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04727v1",
      "title": "Training a Custom CNN on Five Heterogeneous Image Datasets",
      "abstract": "Deep learning has transformed visual data analysis, with Convolutional Neural Networks (CNNs) becoming highly effective in learning meaningful feature representations directly from images. Unlike traditional manual feature engineering methods, CNNs automatically extract hierarchical visual patterns, enabling strong performance across diverse real-world contexts. This study investigates the effectiveness of CNN-based architectures across five heterogeneous datasets spanning agricultural and urban domains: mango variety classification, paddy variety identification, road surface condition assessment, auto-rickshaw detection, and footpath encroachment monitoring. These datasets introduce varying challenges, including differences in illumination, resolution, environmental complexity, and class imbalance, necessitating adaptable and robust learning models.   We evaluate a lightweight, task-specific custom CNN alongside established deep architectures, including ResNet-18 and VGG-16, trained both from scratch and using transfer learning. Through systematic preprocessing, augmentation, and controlled experimentation, we analyze how architectural complexity, model depth, and pre-training influence convergence, generalization, and performance across datasets of differing scale and difficulty. The key contributions of this work are: (1) the development of an efficient custom CNN that achieves competitive performance across multiple application domains, and (2) a comprehensive comparative analysis highlighting when transfer learning and deep architectures provide substantial advantages, particularly in data-constrained environments. These findings offer practical insights for deploying deep learning models in resource-limited yet high-impact real-world visual classification tasks.",
      "authors": [
        "Anika Tabassum",
        "Tasnuva Mahazabin Tuba",
        "Nafisa Naznin"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.NE"
      ],
      "published": "2026-01-08 08:44:17+00:00",
      "link": "https://arxiv.org/pdf/2601.04727v1",
      "tags": [
        "keyword:resnet",
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.04720v1",
      "title": "Qwen3-VL-Embedding and Qwen3-VL-Reranker: A Unified Framework for State-of-the-Art Multimodal Retrieval and Ranking",
      "abstract": "In this report, we introduce the Qwen3-VL-Embedding and Qwen3-VL-Reranker model series, the latest extensions of the Qwen family built on the Qwen3-VL foundation model. Together, they provide an end-to-end pipeline for high-precision multimodal search by mapping diverse modalities, including text, images, document images, and video, into a unified representation space. The Qwen3-VL-Embedding model employs a multi-stage training paradigm, progressing from large-scale contrastive pre-training to reranking model distillation, to generate semantically rich high-dimensional vectors. It supports Matryoshka Representation Learning, enabling flexible embedding dimensions, and handles inputs up to 32k tokens. Complementing this, Qwen3-VL-Reranker performs fine-grained relevance estimation for query-document pairs using a cross-encoder architecture with cross-attention mechanisms. Both model series inherit the multilingual capabilities of Qwen3-VL, supporting more than 30 languages, and are released in $\\textbf{2B}$ and $\\textbf{8B}$ parameter sizes to accommodate diverse deployment requirements. Empirical evaluations demonstrate that the Qwen3-VL-Embedding series achieves state-of-the-art results across diverse multimodal embedding evaluation benchmarks. Specifically, Qwen3-VL-Embedding-8B attains an overall score of $\\textbf{77.8}$ on MMEB-V2, ranking first among all models (as of January 8, 2025). This report presents the architecture, training methodology, and practical capabilities of the series, demonstrating their effectiveness on various multimodal retrieval tasks, including image-text retrieval, visual question answering, and video-text matching.",
      "authors": [
        "Mingxin Li",
        "Yanzhao Zhang",
        "Dingkun Long",
        "Keqin Chen",
        "Sibo Song",
        "Shuai Bai",
        "Zhibo Yang",
        "Pengjun Xie",
        "An Yang",
        "Dayiheng Liu",
        "Jingren Zhou",
        "Junyang Lin"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 08:36:06+00:00",
      "link": "https://arxiv.org/pdf/2601.04720v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04719v1",
      "title": "GPU-Accelerated INT8 Quantization for KV Cache Compression in Large Language Models",
      "abstract": "The key-value (KV) cache in large language models presents a significant memory bottleneck during inference, growing linearly with sequence length and often exceeding the memory footprint of model weights themselves. We implement and evaluate GPU-accelerated INT8 quantization for KV cache compression, achieving 4$\\times$ memory reduction with minimal accuracy degradation. We develop four CUDA kernel variants -- naive, tiled, coarsened, and vectorized -- and benchmark them across realistic workload sizes up to 1 billion elements. Our vectorized kernel achieves up to 1,694$\\times$ speedup over CPU baselines while maintaining reconstruction error below 0.004 and attention score error below 0.1 even for 8K-dimensional heads. These results demonstrate that INT8 quantization provides a practical approach for reducing memory pressure in LLM inference with negligible computational overhead (6--58ms) and minimal impact on downstream model behavior",
      "authors": [
        "Maanas Taneja",
        "Purab Shingvi"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.PF"
      ],
      "published": "2026-01-08 08:35:56+00:00",
      "link": "https://arxiv.org/pdf/2601.04719v1",
      "tags": [
        "keyword:大语言模型",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04716v1",
      "title": "Fame Fades, Nature Remains: Disentangling the Character Identity of Role-Playing Agents",
      "abstract": "Despite the rapid proliferation of Role-Playing Agents (RPAs) based on Large Language Models (LLMs), the structural dimensions defining a character's identity remain weakly formalized, often treating characters as arbitrary text inputs. In this paper, we propose the concept of \\textbf{Character Identity}, a multidimensional construct that disentangles a character into two distinct layers: \\textbf{(1) Parametric Identity}, referring to character-specific knowledge encoded from the LLM's pre-training, and \\textbf{(2) Attributive Identity}, capturing fine-grained behavioral properties such as personality traits and moral values. To systematically investigate these layers, we construct a unified character profile schema and generate both Famous and Synthetic characters under identical structural constraints. Our evaluation across single-turn and multi-turn interactions reveals two critical phenomena. First, we identify \\textit{\"Fame Fades\"}: while famous characters hold a significant advantage in initial turns due to parametric knowledge, this edge rapidly vanishes as models prioritize accumulating conversational context over pre-trained priors. Second, we find that \\textit{\"Nature Remains\"}: while models robustly portray general personality traits regardless of polarity, RPA performance is highly sensitive to the valence of morality and interpersonal relationships. Our findings pinpoint negative social natures as the primary bottleneck in RPA fidelity, guiding future character construction and evaluation.",
      "authors": [
        "Yonghyun Jun",
        "Junhyuk Choi",
        "Jihyeong Park",
        "Hwanhee Lee"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 08:33:40+00:00",
      "link": "https://arxiv.org/pdf/2601.04716v1",
      "tags": [
        "keyword:resnet",
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.04710v1",
      "title": "Prior-Informed Zeroth-Order Optimization with Adaptive Direction Alignment for Memory-Efficient LLM Fine-Tuning",
      "abstract": "Fine-tuning large language models (LLMs) has achieved remarkable success across various NLP tasks, but the substantial memory overhead during backpropagation remains a critical bottleneck, especially as model scales grow. Zeroth-order (ZO) optimization alleviates this issue by estimating gradients through forward passes and Gaussian sampling, avoiding the need for backpropagation. However, conventional ZO methods suffer from high variance in gradient estimation due to their reliance on random perturbations, leading to slow convergence and suboptimal performance. We propose a simple plug-and-play method that incorporates prior-informed perturbations to refine gradient estimation. Our method dynamically computes a guiding vector from Gaussian samples, which directs perturbations toward more informative directions, significantly accelerating convergence compared to standard ZO approaches. We further investigate a greedy perturbation strategy to explore the impact of prior knowledge on gradient estimation. Theoretically, we prove that our gradient estimator achieves stronger alignment with the true gradient direction, enhancing optimization efficiency. Extensive experiments across LLMs of varying scales and architectures demonstrate that our proposed method could seamlessly integrate into existing optimization methods, delivering faster convergence and superior performance. Notably, on the OPT-13B model, our method outperforms traditional ZO optimization across all 11 benchmark tasks and surpasses gradient-based baselines on 9 out of 11 tasks, establishing a robust balance between efficiency and accuracy.",
      "authors": [
        "Feihu Jin",
        "Shipeng Cen",
        "Ying Tan"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-01-08 08:27:15+00:00",
      "link": "https://arxiv.org/pdf/2601.04710v1",
      "tags": [
        "keyword:resnet",
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.04707v1",
      "title": "MQ-GNN: A Multi-Queue Pipelined Architecture for Scalable and Efficient GNN Training",
      "abstract": "Graph Neural Networks (GNNs) are powerful tools for learning graph-structured data, but their scalability is hindered by inefficient mini-batch generation, data transfer bottlenecks, and costly inter-GPU synchronization. Existing training frameworks fail to overlap these stages, leading to suboptimal resource utilization. This paper proposes MQ-GNN, a multi-queue pipelined framework that maximizes training efficiency by interleaving GNN training stages and optimizing resource utilization. MQ-GNN introduces Ready-to-Update Asynchronous Consistent Model (RaCoM), which enables asynchronous gradient sharing and model updates while ensuring global consistency through adaptive periodic synchronization. Additionally, it employs global neighbor sampling with caching to reduce data transfer overhead and an adaptive queue-sizing strategy to balance computation and memory efficiency. Experiments on four large-scale datasets and ten baseline models demonstrate that MQ-GNN achieves up to \\boldmath $\\bm{4.6\\,\\times}$ faster training time and 30% improved GPU utilization while maintaining competitive accuracy. These results establish MQ-GNN as a scalable and efficient solution for multi-GPU GNN training.",
      "authors": [
        "Irfan Ullah",
        "Young-Koo Lee"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "cs.PF"
      ],
      "published": "2026-01-08 08:19:47+00:00",
      "link": "https://arxiv.org/pdf/2601.04707v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04705v1",
      "title": "A zone-based training approach for last-mile routing using Graph Neural Networks and Pointer Networks",
      "abstract": "Rapid e-commerce growth has pushed last-mile delivery networks to their limits, where small routing gains translate into lower costs, faster service, and fewer emissions. Classical heuristics struggle to adapt when travel times are highly asymmetric (e.g., one-way streets, congestion). A deep learning-based approach to the last-mile routing problem is presented to generate geographical zones composed of stop sequences to minimize last-mile delivery times.   The presented approach is an encoder-decoder architecture. Each route is represented as a complete directed graph whose nodes are stops and whose edge weights are asymmetric travel times. A Graph Neural Network encoder produces node embeddings that captures the spatial relationships between stops. A Pointer Network decoder then takes the embeddings and the route's start node to sequentially select the next stops, assigning a probability to each unvisited node as the next destination.   Cells of a Discrete Global Grid System which contain route stops in the training data are obtained and clustered to generate geographical zones of similar size in which the process of training and inference are divided. Subsequently, a different instance of the model is trained per zone only considering the stops of the training routes which are included in that zone.   This approach is evaluated using the Los Angeles routes from the 2021 Amazon Last Mile Routing Challenge. Results from general and zone-based training are compared, showing a reduction in the average predicted route length in the zone-based training compared to the general training. The performance improvement of the zone-based approach becomes more pronounced as the number of stops per route increases.",
      "authors": [
        "Àngel Ruiz-Fas",
        "Carlos Granell",
        "José Francisco Ramos",
        "Joaquín Huerta",
        "Sergio Trilles"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-08 08:18:32+00:00",
      "link": "https://arxiv.org/pdf/2601.04705v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04703v1",
      "title": "Beyond Monolithic Architectures: A Multi-Agent Search and Knowledge Optimization Framework for Agentic Search",
      "abstract": "Agentic search has emerged as a promising paradigm for complex information seeking by enabling Large Language Models (LLMs) to interleave reasoning with tool use. However, prevailing systems rely on monolithic agents that suffer from structural bottlenecks, including unconstrained reasoning outputs that inflate trajectories, sparse outcome-level rewards that complicate credit assignment, and stochastic search noise that destabilizes learning. To address these challenges, we propose \\textbf{M-ASK} (Multi-Agent Search and Knowledge), a framework that explicitly decouples agentic search into two complementary roles: Search Behavior Agents, which plan and execute search actions, and Knowledge Management Agents, which aggregate, filter, and maintain a compact internal context. This decomposition allows each agent to focus on a well-defined subtask and reduces interference between search and context construction. Furthermore, to enable stable coordination, M-ASK employs turn-level rewards to provide granular supervision for both search decisions and knowledge updates. Experiments on multi-hop QA benchmarks demonstrate that M-ASK outperforms strong baselines, achieving not only superior answer accuracy but also significantly more stable training dynamics.\\footnote{The source code for M-ASK is available at https://github.com/chenyiqun/M-ASK.}",
      "authors": [
        "Yiqun Chen",
        "Lingyong Yan",
        "Zixuan Yang",
        "Erhan Zhang",
        "Jiashu Zhao",
        "Shuaiqiang Wang",
        "Dawei Yin",
        "Jiaxin Mao"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 08:13:27+00:00",
      "link": "https://arxiv.org/pdf/2601.04703v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04700v1",
      "title": "PRISM: A Unified Framework for Post-Training LLMs Without Verifiable Rewards",
      "abstract": "Current techniques for post-training Large Language Models (LLMs) rely either on costly human supervision or on external verifiers to boost performance on tasks such as mathematical reasoning and code generation. However, as LLMs improve their problem-solving, any further improvement will potentially require high-quality solutions to difficult problems that are not available to humans. As a result, learning from unlabeled data is becoming increasingly attractive in the research community. Existing methods extract learning signal from a model's consistency, either by majority voting or by converting the model's internal confidence into reward. Although internal consistency metric such as entropy or self-certainty require no human intervention, as we show in this work, these are unreliable signals for large-scale and long-term training. To address the unreliability, we propose PRISM, a unified training framework that uses a Process Reward Model (PRM) to guide learning alongside model's internal confidence in the absence of ground-truth labels. We show that effectively combining PRM with self-certainty can lead to both stable training and better test-time performance, and also keep the model's internal confidence in check.",
      "authors": [
        "Mukesh Ghimire",
        "Aosong Feng",
        "Liwen You",
        "Youzhi Luo",
        "Fang Liu",
        "Xuan Zhu"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 08:09:29+00:00",
      "link": "https://arxiv.org/pdf/2601.04700v1",
      "tags": [
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.04699v1",
      "title": "SeqWalker: Sequential-Horizon Vision-and-Language Navigation with Hierarchical Planning",
      "abstract": "Sequential-Horizon Vision-and-Language Navigation (SH-VLN) presents a challenging scenario where agents should sequentially execute multi-task navigation guided by complex, long-horizon language instructions. Current vision-and-language navigation models exhibit significant performance degradation with such multi-task instructions, as information overload impairs the agent's ability to attend to observationally relevant details. To address this problem, we propose SeqWalker, a navigation model built on a hierarchical planning framework. Our SeqWalker features: i) A High-Level Planner that dynamically selects global instructions into contextually relevant sub-instructions based on the agent's current visual observations, thus reducing cognitive load; ii) A Low-Level Planner incorporating an Exploration-Verification strategy that leverages the inherent logical structure of instructions for trajectory error correction. To evaluate SH-VLN performance, we also extend the IVLN dataset and establish a new benchmark. Extensive experiments are performed to demonstrate the superiority of the proposed SeqWalker.",
      "authors": [
        "Zebin Han",
        "Xudong Wang",
        "Baichen Liu",
        "Qi Lyu",
        "Zhenduo Shang",
        "Jiahua Dong",
        "Lianqing Liu",
        "Zhi Han"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "published": "2026-01-08 08:09:24+00:00",
      "link": "https://arxiv.org/pdf/2601.04699v1",
      "tags": [
        "keyword:大语言模型",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04696v1",
      "title": "A Method for Constructing a Digital Transformation Driving Mechanism Based on Semantic Understanding of Large Models",
      "abstract": "In the process of digital transformation, enterprises are faced with problems such as insufficient semantic understanding of unstructured data and lack of intelligent decision-making basis in driving mechanisms. This study proposes a method that combines a large language model (LLM) and a knowledge graph. First, a fine-tuned BERT (Bidirectional Encoder Representations from Transformers) model is used to perform entity recognition and relationship extraction on multi-source heterogeneous texts, and GPT-4 is used to generate semantically enhanced vector representations; secondly, a two-layer graph neural network (GNN) architecture is designed to fuse the semantic vectors output by LLM with business metadata to construct a dynamic and scalable enterprise knowledge graph; then reinforcement learning is introduced to optimize decision path generation, and the reward function is used to drive the mechanism iteration. In the case of the manufacturing industry, this mechanism reduced the response time for equipment failure scenarios from 7.8 hours to 3.7 hours, the F1 value reached 94.3%, and the compensation for decision errors in the annual digital transformation cost decreased by 45.3%. This method significantly enhances the intelligence level and execution efficiency of the digital transformation driving mechanism by integrating large model semantic understanding with structured knowledge.",
      "authors": [
        "Huayi Liu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-08 08:06:58+00:00",
      "link": "https://arxiv.org/pdf/2601.04696v1",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.04695v1",
      "title": "Tape: A Cellular Automata Benchmark for Evaluating Rule-Shift Generalization in Reinforcement Learning",
      "abstract": "We present Tape, a controlled reinforcement-learning benchmark designed to isolate out-of-distribution (OOD) failure under latent rule shifts.Tape is derived from one-dimensional cellular automata, enabling precise train/test splits where observation and action spaces are held fixed while transition rules change. Using a reproducible evaluation pipeline, we compare model-free baselines, model-based planning with learned world models, and task-inference (meta-RL) methods. A consistent pattern emerges: methods that are strong in-distribution (ID) can collapse under heldout-rule OOD, and high-variance OOD evaluation can make rankings unstable unless experiments are sufficiently replicated.We provide (i) standardized OOD protocols, (ii) statistical reporting requirements (seeds, confidence intervals, and hypothesis tests), and (iii) information-theoretic identities connecting entropy reduction to conditional mutual information and expected posterior KL divergence, clarifying what \"uncertainty reduction\" objectives can and cannot guarantee under rule shifts.",
      "authors": [
        "Enze Pan"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-08 08:05:42+00:00",
      "link": "https://arxiv.org/pdf/2601.04695v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04693v1",
      "title": "Thunder-KoNUBench: A Corpus-Aligned Benchmark for Korean Negation Understanding",
      "abstract": "Although negation is known to challenge large language models (LLMs), benchmarks for evaluating negation understanding, especially in Korean, are scarce. We conduct a corpus-based analysis of Korean negation and show that LLM performance degrades under negation. We then introduce Thunder-KoNUBench, a sentence-level benchmark that reflects the empirical distribution of Korean negation phenomena. Evaluating 47 LLMs, we analyze the effects of model size and instruction tuning, and show that fine-tuning on Thunder-KoNUBench improves negation understanding and broader contextual comprehension in Korean.",
      "authors": [
        "Sungmok Jung",
        "Yeonkyoung So",
        "Joonhak Lee",
        "Sangho Kim",
        "Yelim Ahn",
        "Jaejin Lee"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 08:02:52+00:00",
      "link": "https://arxiv.org/pdf/2601.04693v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04688v1",
      "title": "ToolGate: Contract-Grounded and Verified Tool Execution for LLMs",
      "abstract": "Large Language Models (LLMs) augmented with external tools have demonstrated remarkable capabilities in complex reasoning tasks. However, existing frameworks rely heavily on natural language reasoning to determine when tools can be invoked and whether their results should be committed, lacking formal guarantees for logical safety and verifiability. We present \\textbf{ToolGate}, a forward execution framework that provides logical safety guarantees and verifiable state evolution for LLM tool calling. ToolGate maintains an explicit symbolic state space as a typed key-value mapping representing trusted world information throughout the reasoning process. Each tool is formalized as a Hoare-style contract consisting of a precondition and a postcondition, where the precondition gates tool invocation by checking whether the current state satisfies the required conditions, and the postcondition determines whether the tool's result can be committed to update the state through runtime verification. Our approach guarantees that the symbolic state evolves only through verified tool executions, preventing invalid or hallucinated results from corrupting the world representation. Experimental validation demonstrates that ToolGate significantly improves the reliability and verifiability of tool-augmented LLM systems while maintaining competitive performance on complex multi-step reasoning tasks. This work establishes a foundation for building more trustworthy and debuggable AI systems that integrate language models with external tools.",
      "authors": [
        "Yanming Liu",
        "Xinyue Peng",
        "Jiannan Cao",
        "Xinyi Wang",
        "Songhang Deng",
        "Jintao Chen",
        "Jianwei Yin",
        "Xuhong Zhang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.FL"
      ],
      "published": "2026-01-08 07:56:45+00:00",
      "link": "https://arxiv.org/pdf/2601.04688v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04676v1",
      "title": "DB-MSMUNet:Dual Branch Multi-scale Mamba UNet for Pancreatic CT Scans Segmentation",
      "abstract": "Accurate segmentation of the pancreas and its lesions in CT scans is crucial for the precise diagnosis and treatment of pancreatic cancer. However, it remains a highly challenging task due to several factors such as low tissue contrast with surrounding organs, blurry anatomical boundaries, irregular organ shapes, and the small size of lesions. To tackle these issues, we propose DB-MSMUNet (Dual-Branch Multi-scale Mamba UNet), a novel encoder-decoder architecture designed specifically for robust pancreatic segmentation. The encoder is constructed using a Multi-scale Mamba Module (MSMM), which combines deformable convolutions and multi-scale state space modeling to enhance both global context modeling and local deformation adaptation. The network employs a dual-decoder design: the edge decoder introduces an Edge Enhancement Path (EEP) to explicitly capture boundary cues and refine fuzzy contours, while the area decoder incorporates a Multi-layer Decoder (MLD) to preserve fine-grained details and accurately reconstruct small lesions by leveraging multi-scale deep semantic features. Furthermore, Auxiliary Deep Supervision (ADS) heads are added at multiple scales to both decoders, providing more accurate gradient feedback and further enhancing the discriminative capability of multi-scale features. We conduct extensive experiments on three datasets: the NIH Pancreas dataset, the MSD dataset, and a clinical pancreatic tumor dataset provided by collaborating hospitals. DB-MSMUNet achieves Dice Similarity Coefficients of 89.47%, 87.59%, and 89.02%, respectively, outperforming most existing state-of-the-art methods in terms of segmentation accuracy, edge preservation, and robustness across different datasets. These results demonstrate the effectiveness and generalizability of the proposed method for real-world pancreatic CT segmentation tasks.",
      "authors": [
        "Qiu Guan",
        "Zhiqiang Yang",
        "Dezhang Ye",
        "Yang Chen",
        "Xinli Xu",
        "Ying Tang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 07:41:37+00:00",
      "link": "https://arxiv.org/pdf/2601.04676v1",
      "tags": [
        "keyword:resnet",
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.04675v1",
      "title": "LLM-Guided Quantified SMT Solving over Uninterpreted Functions",
      "abstract": "Quantified formulas with Uninterpreted Functions (UFs) over non-linear real arithmetic pose fundamental challenges for Satisfiability Modulo Theories (SMT) solving. Traditional quantifier instantiation methods struggle because they lack semantic understanding of UF constraints, forcing them to search through unbounded solution spaces with limited guidance. We present AquaForte, a framework that leverages Large Language Models to provide semantic guidance for UF instantiation by generating instantiated candidates for function definitions that satisfy the constraints, thereby significantly reducing the search space and complexity for solvers. Our approach preprocesses formulas through constraint separation, uses structured prompts to extract mathematical reasoning from LLMs, and integrates the results with traditional SMT algorithms through adaptive instantiation. AquaForte maintains soundness through systematic validation: LLM-guided instantiations yielding SAT solve the original problem, while UNSAT results generate exclusion clauses for iterative refinement. Completeness is preserved by fallback to traditional solvers augmented with learned constraints. Experimental evaluation on SMT-COMP benchmarks demonstrates that AquaForte solves numerous instances where state-of-the-art solvers like Z3 and CVC5 timeout, with particular effectiveness on satisfiable formulas. Our work shows that LLMs can provide valuable mathematical intuition for symbolic reasoning, establishing a new paradigm for SMT constraint solving.",
      "authors": [
        "Kunhang Lv",
        "Yuhang Dong",
        "Rui Han",
        "Fuqi Jia",
        "Feifei Ma",
        "Jian Zhang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 07:40:37+00:00",
      "link": "https://arxiv.org/pdf/2601.04675v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04674v1",
      "title": "PROMISE: Process Reward Models Unlock Test-Time Scaling Laws in Generative Recommendations",
      "abstract": "Generative Recommendation has emerged as a promising paradigm, reformulating recommendation as a sequence-to-sequence generation task over hierarchical Semantic IDs. However, existing methods suffer from a critical issue we term Semantic Drift, where errors in early, high-level tokens irreversibly divert the generation trajectory into irrelevant semantic subspaces. Inspired by Process Reward Models (PRMs) that enhance reasoning in Large Language Models, we propose Promise, a novel framework that integrates dense, step-by-step verification into generative models. Promise features a lightweight PRM to assess the quality of intermediate inference steps, coupled with a PRM-guided Beam Search strategy that leverages dense feedback to dynamically prune erroneous branches. Crucially, our approach unlocks Test-Time Scaling Laws for recommender systems: by increasing inference compute, smaller models can match or surpass larger models. Extensive offline experiments and online A/B tests on a large-scale platform demonstrate that Promise effectively mitigates Semantic Drift, significantly improving recommendation accuracy while enabling efficient deployment.",
      "authors": [
        "Chengcheng Guo",
        "Kuo Cai",
        "Yu Zhou",
        "Qiang Luo",
        "Ruiming Tang",
        "Han Li",
        "Kun Gai",
        "Guorui Zhou"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2026-01-08 07:38:46+00:00",
      "link": "https://arxiv.org/pdf/2601.04674v1",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.04673v1",
      "title": "Estimating Causal Effects in Gaussian Linear SCMs with Finite Data",
      "abstract": "Estimating causal effects from observational data remains a fundamental challenge in causal inference, especially in the presence of latent confounders. This paper focuses on estimating causal effects in Gaussian Linear Structural Causal Models (GL-SCMs), which are widely used due to their analytical tractability. However, parameter estimation in GL-SCMs is often infeasible with finite data, primarily due to overparameterization. To address this, we introduce the class of Centralized Gaussian Linear SCMs (CGL-SCMs), a simplified yet expressive subclass where exogenous variables follow standardized distributions. We show that CGL-SCMs are equally expressive in terms of causal effect identifiability from observational distributions and present a novel EM-based estimation algorithm that can learn CGL-SCM parameters and estimate identifiable causal effects from finite observational samples. Our theoretical analysis is validated through experiments on synthetic data and benchmark causal graphs, demonstrating that the learned models accurately recover causal distributions.",
      "authors": [
        "Aurghya Maiti",
        "Prateek Jain"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "published": "2026-01-08 07:37:10+00:00",
      "link": "https://arxiv.org/pdf/2601.04673v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04670v1",
      "title": "Learning Dynamics in RL Post-Training for Language Models",
      "abstract": "Reinforcement learning (RL) post-training is a critical stage in modern language model development, playing a key role in improving alignment and reasoning ability. However, several phenomena remain poorly understood, including the reduction in output diversity. To gain a broader understanding of RL post-training, we analyze the learning dynamics of RL post-training from a perspective that has been studied in supervised learning but remains underexplored in RL. We adopt an empirical neural tangent kernel (NTK) framework and decompose the NTK into two components to characterize how RL updates propagate across training samples. Our analysis reveals that limited variability in feature representations can cause RL updates to systematically increase model confidence, providing an explanation for the commonly observed reduction in output diversity after RL post-training. Furthermore, we show that effective learning in this regime depends on rapidly shaping the classifier, which directly affects the gradient component of the NTK. Motivated by these insights, we propose classifier-first reinforcement learning (CF-RL), a simple two-stage training strategy that prioritizes classifier updates before standard RL optimization. Experimental results validate our theoretical analysis by demonstrating increased model confidence and accelerated optimization under CF-RL. Additional analysis shows that the mechanism underlying CF-RL differs from that of linear-probing-then-fine-tuning in supervised learning. Overall, our study formalizes the learning dynamics of RL post-training and motivates further analysis and improvement.",
      "authors": [
        "Akiyoshi Tomihari"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-08 07:32:15+00:00",
      "link": "https://arxiv.org/pdf/2601.04670v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04668v1",
      "title": "Optimizing Path Planning using Deep Reinforcement Learning for UGVs in Precision Agriculture",
      "abstract": "This study focuses on optimizing path planning for unmanned ground vehicles (UGVs) in precision agriculture using deep reinforcement learning (DRL) techniques in continuous action spaces. The research begins with a review of traditional grid-based methods, such as A* and Dijkstra's algorithms, and discusses their limitations in dynamic agricultural environments, highlighting the need for adaptive learning strategies. The study then explores DRL approaches, including Deep Q-Networks (DQN), which demonstrate improved adaptability and performance in two-dimensional simulations. Enhancements such as Double Q-Networks and Dueling Networks are evaluated to further improve decision-making. Building on these results, the focus shifts to continuous action space models, specifically Deep Deterministic Policy Gradient (DDPG) and Twin Delayed Deep Deterministic Policy Gradient (TD3), which are tested in increasingly complex environments. Experiments conducted in a three-dimensional environment using ROS and Gazebo demonstrate the effectiveness of continuous DRL algorithms in navigating dynamic agricultural scenarios. Notably, the pretrained TD3 agent achieves a 95 percent success rate in dynamic environments, demonstrating the robustness of the proposed approach in handling moving obstacles while ensuring safety for both crops and the robot.",
      "authors": [
        "Laukik Patade",
        "Rohan Rane",
        "Sandeep Pillai"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "published": "2026-01-08 07:28:11+00:00",
      "link": "https://arxiv.org/pdf/2601.04668v1",
      "tags": [
        "keyword:resnet",
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.04653v1",
      "title": "Vibe Coding an LLM-powered Theorem Prover",
      "abstract": "We present Isabellm, an LLM-powered theorem prover for Isabelle/HOL that performs fully automatic proof synthesis. Isabellm works with any local LLM on Ollama and APIs such as Gemini CLI, and it is designed to run on consumer grade computers. The system combines a stepwise prover, which uses large language models to propose proof commands validated by Isabelle in a bounded search loop, with a higher-level proof planner that generates structured Isar outlines and attempts to fill and repair remaining gaps. The framework includes beam search for tactics, tactics reranker ML and RL models, premise selection with small transformer models, micro-RAG for Isar proofs built from AFP, and counter-example guided proof repair. All the code is implemented by GPT 4.1 - 5.2, Gemini 3 Pro, and Claude 4.5. Empirically, Isabellm can prove certain lemmas that defeat Isabelle's standard automation, including Sledgehammer, demonstrating the practical value of LLM-guided proof search. At the same time, we find that even state-of-the-art LLMs, such as GPT 5.2 Extended Thinking and Gemini 3 Pro struggle to reliably implement the intended fill-and-repair mechanisms with complex algorithmic designs, highlighting fundamental challenges in LLM code generation and reasoning. The code of Isabellm is available at https://github.com/zhehou/llm-isabelle",
      "authors": [
        "Zhe Hou"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "published": "2026-01-08 07:00:24+00:00",
      "link": "https://arxiv.org/pdf/2601.04653v1",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.04646v1",
      "title": "Succeeding at Scale: Automated Multi-Retriever Fusion and Query-Side Adaptation for Multi-Tenant Search",
      "abstract": "Large-scale multi-tenant retrieval systems amass vast user query logs yet critically lack the curated relevance labels required for effective domain adaptation. This \"dark data\" problem is exacerbated by the operational cost of model updates: jointly fine-tuning query and document encoders requires re-indexing the entire corpus, which is prohibitive in multi-tenant environments with thousands of isolated indices. To address these dual challenges, we introduce \\textbf{DevRev Search}, a passage retrieval benchmark for technical customer support constructed through a fully automatic pipeline. We employ a \\textbf{fusion-based candidate generation} strategy, pooling results from diverse sparse and dense retrievers, and utilize an LLM-as-a-Judge to perform rigorous \\textbf{consistency filtering} and relevance assignment. We further propose a practical \\textbf{Index-Preserving Adaptation} strategy: by fine-tuning only the query encoder via Low-Rank Adaptation (LoRA), we achieve competitive performance improvements while keeping the document index frozen. Our experiments on DevRev Search and SciFact demonstrate that targeting specific transformer layers in the query encoder yields optimal quality-efficiency trade-offs, offering a scalable path for personalized enterprise search.",
      "authors": [
        "Prateek Jain",
        "Shabari S Nair",
        "Ritesh Goru",
        "Prakhar Agarwal",
        "Ajay Yadav",
        "Yoga Sri Varshan Varadharajan",
        "Constantine Caramanis"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-01-08 06:44:40+00:00",
      "link": "https://arxiv.org/pdf/2601.04646v1",
      "tags": [
        "keyword:大语言模型",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04643v1",
      "title": "MMFCTUB: Multi-Modal Financial Credit Table Understanding Benchmark",
      "abstract": "The advent of multi-modal language models (MLLMs) has spurred research into their application across various table understanding tasks. However, their performance in credit table understanding (CTU) for financial credit review remains largely unexplored due to the following barriers: low data consistency, high annotation costs stemming from domain-specific knowledge and complex calculations, and evaluation paradigm gaps between benchmark and real-world scenarios. To address these challenges, we introduce MMFCTUB (Multi-Modal Financial Credit Table Understanding Benchmark), a practical benchmark, encompassing more than 7,600 high quality CTU samples across 5 table types. MMFCTUB employ a minimally supervised pipeline that adheres to inter-table constraints and maintains data distributions consistency. The benchmark leverages capacity-driven questions and mask-and-recovery strategy to evaluate models' cross-table structure perception, domain knowledge utilization, and numerical calculation capabilities. Utilizing MMFCTUB, we conduct comprehensive evaluations of both proprietary and open-source MLLMs, revealing their strengths and limitations in CTU tasks. MMFCTUB serves as a valuable resource for the research community, facilitating rigorous evaluation of MLLMs in the domain of CTU.",
      "authors": [
        "Cui Yakun",
        "Yanting Zhang",
        "Zhu Lei",
        "Jian Xie",
        "Zhizhuo Kou",
        "Hang Du",
        "Zhenghao Zhu",
        "Sirui Han"
      ],
      "primary_category": "cs.CE",
      "categories": [
        "cs.CE"
      ],
      "published": "2026-01-08 06:34:47+00:00",
      "link": "https://arxiv.org/pdf/2601.04643v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04638v1",
      "title": "SpeechMedAssist: Efficiently and Effectively Adapting Speech Language Models for Medical Consultation",
      "abstract": "Medical consultations are intrinsically speech-centric. However, most prior works focus on long-text-based interactions, which are cumbersome and patient-unfriendly. Recent advances in speech language models (SpeechLMs) have enabled more natural speech-based interaction, yet the scarcity of medical speech data and the inefficiency of directly fine-tuning on speech data jointly hinder the adoption of SpeechLMs in medical consultation. In this paper, we propose SpeechMedAssist, a SpeechLM natively capable of conducting speech-based multi-turn interactions with patients. By exploiting the architectural properties of SpeechLMs, we decouple the conventional one-stage training into a two-stage paradigm consisting of (1) Knowledge & Capability Injection via Text and (2) Modality Re-alignment with Limited Speech Data, thereby reducing the requirement for medical speech data to only 10k synthesized samples. To evaluate SpeechLMs for medical consultation scenarios, we design a benchmark comprising both single-turn question answering and multi-turn simulated interactions. Experimental results show that our model outperforms all baselines in both effectiveness and robustness in most evaluation settings.",
      "authors": [
        "Sirry Chen",
        "Jieyi Wang",
        "Wei Chen",
        "Zhongyu Wei"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-08 06:14:58+00:00",
      "link": "https://arxiv.org/pdf/2601.04638v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04620v1",
      "title": "AgentDevel: Reframing Self-Evolving LLM Agents as Release Engineering",
      "abstract": "Recent progress in large language model (LLM) agents has largely focused on embedding self-improvement mechanisms inside the agent or searching over many concurrent variants. While these approaches can raise aggregate scores, they often yield unstable and hard-to-audit improvement trajectories, making it difficult to guarantee non-regression or to reason about failures across versions. We reframe agent improvement as \\textbf{release engineering}: agents are treated as shippable artifacts, and improvement is externalized into a regression-aware release pipeline. We introduce \\textbf{AgentDevel}, a release engineering pipeline that iteratively runs the current agent, produces implementation-blind, symptom-level quality signals from execution traces, synthesizes a single release candidate (RC) via executable diagnosis, and promotes it under flip-centered gating. AgentDevel features three core designs: (i) an implementation-blind LLM critic that characterizes failure appearances without accessing agent internals, (ii) script-based executable diagnosis that aggregates dominant symptom patterns and produces auditable engineering specifications, and (iii) flip-centered gating that prioritizes pass to fail regressions and fail to pass fixes as first-class evidence. Unlike population-based search or in-agent self-refinement, AgentDevel maintains a single canonical version line and emphasizes non-regression as a primary objective. Experiments on execution-heavy benchmarks demonstrate that AgentDevel yields stable improvements with significantly fewer regressions while producing reproducible, auditable artifacts. Overall, AgentDevel provides a practical development discipline for building, debugging, and releasing LLM agents as software development.",
      "authors": [
        "Di Zhang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 05:49:01+00:00",
      "link": "https://arxiv.org/pdf/2601.04620v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04614v1",
      "title": "HyperAlign: Hyperbolic Entailment Cones for Adaptive Text-to-Image Alignment Assessment",
      "abstract": "With the rapid development of text-to-image generation technology, accurately assessing the alignment between generated images and text prompts has become a critical challenge. Existing methods rely on Euclidean space metrics, neglecting the structured nature of semantic alignment, while lacking adaptive capabilities for different samples. To address these limitations, we propose HyperAlign, an adaptive text-to-image alignment assessment framework based on hyperbolic entailment geometry. First, we extract Euclidean features using CLIP and map them to hyperbolic space. Second, we design a dynamic-supervision entailment modeling mechanism that transforms discrete entailment logic into continuous geometric structure supervision. Finally, we propose an adaptive modulation regressor that utilizes hyperbolic geometric features to generate sample-level modulation parameters, adaptively calibrating Euclidean cosine similarity to predict the final score. HyperAlign achieves highly competitive performance on both single database evaluation and cross-database generalization tasks, fully validating the effectiveness of hyperbolic geometric modeling for image-text alignment assessment.",
      "authors": [
        "Wenzhi Chen",
        "Bo Hu",
        "Leida Li",
        "Lihuo He",
        "Wen Lu",
        "Xinbo Gao"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 05:41:06+00:00",
      "link": "https://arxiv.org/pdf/2601.04614v1",
      "tags": [
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.04610v1",
      "title": "Evaluating Human and Machine Confidence in Phishing Email Detection: A Comparative Study",
      "abstract": "Identifying deceptive content like phishing emails demands sophisticated cognitive processes that combine pattern recognition, confidence assessment, and contextual analysis. This research examines how human cognition and machine learning models work together to distinguish phishing emails from legitimate ones. We employed three interpretable algorithms Logistic Regression, Decision Trees, and Random Forests training them on both TF-IDF features and semantic embeddings, then compared their predictions against human evaluations that captured confidence ratings and linguistic observations. Our results show that machine learning models provide good accuracy rates, but their confidence levels vary significantly. Human evaluators, on the other hand, use a greater variety of language signs and retain more consistent confidence. We also found that while language proficiency has minimal effect on detection performance, aging does. These findings offer helpful direction for creating transparent AI systems that complement human cognitive functions, ultimately improving human-AI cooperation in challenging content analysis tasks.",
      "authors": [
        "Paras Jain",
        "Khushi Dhar",
        "Olyemi E. Amujo",
        "Esa M. Rantanen"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 05:30:41+00:00",
      "link": "https://arxiv.org/pdf/2601.04610v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04607v1",
      "title": "HUR-MACL: High-Uncertainty Region-Guided Multi-Architecture Collaborative Learning for Head and Neck Multi-Organ Segmentation",
      "abstract": "Accurate segmentation of organs at risk in the head and neck is essential for radiation therapy, yet deep learning models often fail on small, complexly shaped organs. While hybrid architectures that combine different models show promise, they typically just concatenate features without exploiting the unique strengths of each component. This results in functional overlap and limited segmentation accuracy. To address these issues, we propose a high uncertainty region-guided multi-architecture collaborative learning (HUR-MACL) model for multi-organ segmentation in the head and neck. This model adaptively identifies high uncertainty regions using a convolutional neural network, and for these regions, Vision Mamba as well as Deformable CNN are utilized to jointly improve their segmentation accuracy. Additionally, a heterogeneous feature distillation loss was proposed to promote collaborative learning between the two architectures in high uncertainty regions to further enhance performance. Our method achieves SOTA results on two public datasets and one private dataset.",
      "authors": [
        "Xiaoyu Liu",
        "Siwen Wei",
        "Linhao Qu",
        "Mingyuan Pan",
        "Chengsheng Zhang",
        "Yonghong Shi",
        "Zhijian Song"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-01-08 05:25:05+00:00",
      "link": "https://arxiv.org/pdf/2601.04607v1",
      "tags": [
        "keyword:resnet",
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.04592v1",
      "title": "Density Matrix RNN (DM-RNN): A Quantum Information Theoretic Framework for Modeling Musical Context and Polyphony",
      "abstract": "Classical Recurrent Neural Networks (RNNs) summarize musical context into a deterministic hidden state vector, imposing an information bottleneck that fails to capture the inherent ambiguity in music. We propose the Density Matrix RNN (DM-RNN), a novel theoretical architecture utilizing the Density Matrix. This allows the model to maintain a statistical ensemble of musical interpretations (a mixed state), capturing both classical probabilities and quantum coherences. We rigorously define the temporal dynamics using Quantum Channels (CPTP maps). Crucially, we detail a parameterization strategy based on the Choi-Jamiolkowski isomorphism, ensuring the learned dynamics remain physically valid (CPTP) by construction. We introduce an analytical framework using Von Neumann Entropy to quantify musical uncertainty and Quantum Mutual Information (QMI) to measure entanglement between voices. The DM-RNN provides a mathematically rigorous framework for modeling complex, ambiguous musical structures.",
      "authors": [
        "Joonwon Seo",
        "Mariana Montiel"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.SD",
        "math-ph"
      ],
      "published": "2026-01-08 04:44:04+00:00",
      "link": "https://arxiv.org/pdf/2601.04592v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04589v1",
      "title": "MiLDEdit: Reasoning-Based Multi-Layer Design Document Editing",
      "abstract": "Real-world design documents (e.g., posters) are inherently multi-layered, combining decoration, text, and images. Editing them from natural-language instructions requires fine-grained, layer-aware reasoning to identify relevant layers and coordinate modifications. Prior work largely overlooks multi-layer design document editing, focusing instead on single-layer image editing or multi-layer generation, which assume a flat canvas and lack the reasoning needed to determine what and where to modify. To address this gap, we introduce the Multi-Layer Document Editing Agent (MiLDEAgent), a reasoning-based framework that combines an RL-trained multimodal reasoner for layer-wise understanding with an image editor for targeted modifications. To systematically benchmark this setting, we introduce the MiLDEBench, a human-in-the-loop corpus of over 20K design documents paired with diverse editing instructions. The benchmark is complemented by a task-specific evaluation protocol, MiLDEEval, which spans four dimensions including instruction following, layout consistency, aesthetics, and text rendering. Extensive experiments on 14 open-source and 2 closed-source models reveal that existing approaches fail to generalize: open-source models often cannot complete multi-layer document editing tasks, while closed-source models suffer from format violations. In contrast, MiLDEAgent achieves strong layer-aware reasoning and precise editing, significantly outperforming all open-source baselines and attaining performance comparable to closed-source models, thereby establishing the first strong baseline for multi-layer document editing.",
      "authors": [
        "Zihao Lin",
        "Wanrong Zhu",
        "Jiuxiang Gu",
        "Jihyung Kil",
        "Christopher Tensmeyer",
        "Lin Zhang",
        "Shilong Liu",
        "Ruiyi Zhang",
        "Lifu Huang",
        "Vlad I. Morariu",
        "Tong Sun"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 04:38:07+00:00",
      "link": "https://arxiv.org/pdf/2601.04589v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04574v1",
      "title": "FeedEval: Pedagogically Aligned Evaluation of LLM-Generated Essay Feedback",
      "abstract": "Going beyond the prediction of numerical scores, recent research in automated essay scoring has increasingly emphasized the generation of high-quality feedback that provides justification and actionable guidance. To mitigate the high cost of expert annotation, prior work has commonly relied on LLM-generated feedback to train essay assessment models. However, such feedback is often incorporated without explicit quality validation, resulting in the propagation of noise in downstream applications. To address this limitation, we propose FeedEval, an LLM-based framework for evaluating LLM-generated essay feedback along three pedagogically grounded dimensions: specificity, helpfulness, and validity. FeedEval employs dimension-specialized LLM evaluators trained on datasets curated in this study to assess multiple feedback candidates and select high-quality feedback for downstream use. Experiments on the ASAP++ benchmark show that FeedEval closely aligns with human expert judgments and that essay scoring models trained with FeedEval-filtered high-quality feedback achieve superior scoring performance. Furthermore, revision experiments using small LLMs show that the high-quality feedback identified by FeedEval leads to more effective essay revisions. We will release our code and curated datasets upon accepted.",
      "authors": [
        "Seongyeub Chu",
        "Jongwoo Kim",
        "Munyong Yi"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 04:04:29+00:00",
      "link": "https://arxiv.org/pdf/2601.04574v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04568v1",
      "title": "Neurosymbolic Retrievers for Retrieval-augmented Generation",
      "abstract": "Retrieval Augmented Generation (RAG) has made significant strides in overcoming key limitations of large language models, such as hallucination, lack of contextual grounding, and issues with transparency. However, traditional RAG systems consist of three interconnected neural components - the retriever, re-ranker, and generator - whose internal reasoning processes remain opaque. This lack of transparency complicates interpretability, hinders debugging efforts, and erodes trust, especially in high-stakes domains where clear decision-making is essential. To address these challenges, we introduce the concept of Neurosymbolic RAG, which integrates symbolic reasoning using a knowledge graph with neural retrieval techniques. This new framework aims to answer two primary questions: (a) Can retrievers provide a clear and interpretable basis for document selection? (b) Can symbolic knowledge enhance the clarity of the retrieval process? We propose three methods to improve this integration. First is MAR (Knowledge Modulation Aligned Retrieval) that employs modulation networks to refine query embeddings using interpretable symbolic features, thereby making document matching more explicit. Second, KG-Path RAG enhances queries by traversing knowledge graphs to improve overall retrieval quality and interpretability. Lastly, Process Knowledge-infused RAG utilizes domain-specific tools to reorder retrieved content based on validated workflows. Preliminary results from mental health risk assessment tasks indicate that this neurosymbolic approach enhances both transparency and overall performance",
      "authors": [
        "Yash Saxena",
        "Manas Gaur"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "cs.LG"
      ],
      "published": "2026-01-08 03:53:05+00:00",
      "link": "https://arxiv.org/pdf/2601.04568v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04566v1",
      "title": "BackdoorAgent: A Unified Framework for Backdoor Attacks on LLM-based Agents",
      "abstract": "Large language model (LLM) agents execute tasks through multi-step workflows that combine planning, memory, and tool use. While this design enables autonomy, it also expands the attack surface for backdoor threats. Backdoor triggers injected into specific stages of an agent workflow can persist through multiple intermediate states and adversely influence downstream outputs. However, existing studies remain fragmented and typically analyze individual attack vectors in isolation, leaving the cross-stage interaction and propagation of backdoor triggers poorly understood from an agent-centric perspective. To fill this gap, we propose \\textbf{BackdoorAgent}, a modular and stage-aware framework that provides a unified, agent-centric view of backdoor threats in LLM agents. BackdoorAgent structures the attack surface into three functional stages of agentic workflows, including \\textbf{planning attacks}, \\textbf{memory attacks}, and \\textbf{tool-use attacks}, and instruments agent execution to enable systematic analysis of trigger activation and propagation across different stages. Building on this framework, we construct a standardized benchmark spanning four representative agent applications: \\textbf{Agent QA}, \\textbf{Agent Code}, \\textbf{Agent Web}, and \\textbf{Agent Drive}, covering both language-only and multimodal settings. Our empirical analysis shows that \\textit{triggers implanted at a single stage can persist across multiple steps and propagate through intermediate states.} For instance, when using a GPT-based backbone, we observe trigger persistence in 43.58\\% of planning attacks, 77.97\\% of memory attacks, and 60.28\\% of tool-stage attacks, highlighting the vulnerabilities of the agentic workflow itself to backdoor threats. To facilitate reproducibility and future research, our code and benchmark are publicly available at GitHub.",
      "authors": [
        "Yunhao Feng",
        "Yige Li",
        "Yutao Wu",
        "Yingshui Tan",
        "Yanming Guo",
        "Yifan Ding",
        "Kun Zhai",
        "Xingjun Ma",
        "Yugang Jiang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-08 03:49:39+00:00",
      "link": "https://arxiv.org/pdf/2601.04566v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04564v1",
      "title": "When Tone and Words Disagree: Towards Robust Speech Emotion Recognition under Acoustic-Semantic Conflict",
      "abstract": "Speech Emotion Recognition (SER) systems often assume congruence between vocal emotion and lexical semantics. However, in real-world interactions, acoustic-semantic conflict is common yet overlooked, where the emotion conveyed by tone contradicts the literal meaning of spoken words. We show that state-of-the-art SER models, including ASR-based, self-supervised learning (SSL) approaches and Audio Language Models (ALMs), suffer performance degradation under such conflicts due to semantic bias or entangled acoustic-semantic representations. To address this, we propose the Fusion Acoustic-Semantic (FAS) framework, which explicitly disentangles acoustic and semantic pathways and bridges them through a lightweight, query-based attention module. To enable systematic evaluation, we introduce the Conflict in Acoustic-Semantic Emotion (CASE), the first dataset dominated by clear and interpretable acoustic-semantic conflicts in varied scenarios. Extensive experiments demonstrate that FAS consistently outperforms existing methods in both in-domain and zero-shot settings. Notably, on the CASE benchmark, conventional SER models fail dramatically, while FAS sets a new SOTA with 59.38% accuracy. Our code and datasets is available at https://github.com/24DavidHuang/FAS.",
      "authors": [
        "Dawei Huang",
        "Yongjie Lv",
        "Ruijie Xiong",
        "Chunxiang Jin",
        "Xiaojiang Peng"
      ],
      "primary_category": "cs.SD",
      "categories": [
        "cs.SD"
      ],
      "published": "2026-01-08 03:47:21+00:00",
      "link": "https://arxiv.org/pdf/2601.04564v1",
      "tags": [
        "keyword:大语言模型",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04562v1",
      "title": "Reasoning Over Space: Enabling Geographic Reasoning for LLM-Based Generative Next POI Recommendation",
      "abstract": "Generative recommendation with large language models (LLMs) reframes prediction as sequence generation, yet existing LLM-based recommenders remain limited in leveraging geographic signals that are crucial in mobility and local-services scenarios. Here, we present Reasoning Over Space (ROS), a framework that utilizes geography as a vital decision variable within the reasoning process. ROS introduces a Hierarchical Spatial Semantic ID (SID) that discretizes coarse-to-fine locality and POI semantics into compositional tokens, and endows LLM with a three-stage Mobility Chain-of-Thought (CoT) paradigm that models user personality, constructs an intent-aligned candidate space, and performs locality informed pruning. We further align the model with real world geography via spatial-guided Reinforcement Learning (RL). Experiments on three widely used location-based social network (LBSN) datasets show that ROS achieves over 10% relative gains in hit rate over strongest LLM-based baselines and improves cross-city transfer, despite using a smaller backbone model.",
      "authors": [
        "Dongyi Lv",
        "Qiuyu Ding",
        "Heng-Da Xu",
        "Zhaoxu Sun",
        "Zhi Wang",
        "Feng Xiong",
        "Mu Xu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 03:46:03+00:00",
      "link": "https://arxiv.org/pdf/2601.04562v1",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.04551v1",
      "title": "Discrete Fourier Transform-based Point Cloud Compression for Efficient SLAM in Featureless Terrain",
      "abstract": "Simultaneous Localization and Mapping (SLAM) is an essential technology for the efficiency and reliability of unmanned robotic exploration missions. While the onboard computational capability and communication bandwidth are critically limited, the point cloud data handled by SLAM is large in size, attracting attention to data compression methods. To address such a problem, in this paper, we propose a new method for compressing point cloud maps by exploiting the Discrete Fourier Transform (DFT). The proposed technique converts the Digital Elevation Model (DEM) to the frequency-domain 2D image and omits its high-frequency components, focusing on the exploration of gradual terrains such as planets and deserts. Unlike terrains with detailed structures such as artificial environments, high-frequency components contribute little to the representation of gradual terrains. Thus, this method is effective in compressing data size without significant degradation of the point cloud. We evaluated the method in terms of compression rate and accuracy using camera sequences of two terrains with different elevation profiles.",
      "authors": [
        "Riku Suzuki",
        "Ayumi Umemura",
        "Shreya Santra",
        "Kentaro Uno",
        "Kazuya Yoshida"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-01-08 03:28:56+00:00",
      "link": "https://arxiv.org/pdf/2601.04551v1",
      "tags": [
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.04550v1",
      "title": "GEnSHIN: Graphical Enhanced Spatio-temporal Hierarchical Inference Network for Traffic Flow Prediction",
      "abstract": "With the acceleration of urbanization, intelligent transportation systems have an increasing demand for accurate traffic flow prediction. This paper proposes a novel Graph Enhanced Spatio-temporal Hierarchical Inference Network (GEnSHIN) to handle the complex spatio-temporal dependencies in traffic flow prediction. The model integrates three innovative designs: 1) An attention-enhanced Graph Convolutional Recurrent Unit (GCRU), which strengthens the modeling capability for long-term temporal dependencies by introducing Transformer modules; 2) An asymmetric dual-embedding graph generation mechanism, which leverages the real road network and data-driven latent asymmetric topology to generate graph structures that better fit the characteristics of actual traffic flow; 3) A dynamic memory bank module, which utilizes learnable traffic pattern prototypes to provide personalized traffic pattern representations for each sensor node, and introduces a lightweight graph updater during the decoding phase to adapt to dynamic changes in road network states. Extensive experiments on the public dataset METR-LA show that GEnSHIN achieves or surpasses the performance of comparative models across multiple metrics such as Mean Absolute Error (MAE), Root Mean Square Error (RMSE), and Mean Absolute Percentage Error (MAPE). Notably, the model demonstrates excellent prediction stability during peak morning and evening traffic hours. Ablation experiments further validate the effectiveness of each core module and its contribution to the final performance.",
      "authors": [
        "Zhiyan Zhou",
        "Junjie Liao",
        "Manho Zhang",
        "Yingyi Liao",
        "Ziai Wang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-08 03:27:10+00:00",
      "link": "https://arxiv.org/pdf/2601.04550v1",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.04547v1",
      "title": "Data-Driven Terramechanics Approach Towards a Realistic Real-Time Simulator for Lunar Rovers",
      "abstract": "High-fidelity simulators for the lunar surface provide a digital environment for extensive testing of rover operations and mission planning. However, current simulators focus on either visual realism or physical accuracy, which limits their capability to replicate lunar conditions comprehensively. This work addresses that gap by combining high visual fidelity with realistic terrain interaction for a realistic representation of rovers on the lunar surface. Because direct simulation of wheel-soil interactions is computationally expensive, a data-driven approach was adopted, using regression models for slip and sinkage from data collected in both full-rover and single-wheel experiments and simulations. The resulting regression-based terramechanics model accurately reproduced steady-state and dynamic slip, as well as sinkage behavior, on flat terrain and slopes up to 20 degrees, with validation against field test results. Additionally, improvements were made to enhance the realism of terrain deformation and wheel trace visualization. This method supports real-time applications that require physically plausible terrain response alongside high visual fidelity.",
      "authors": [
        "Jakob M. Kern",
        "James M. Hurrell",
        "Shreya Santra",
        "Keisuke Takehana",
        "Kentaro Uno",
        "Kazuya Yoshida"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-01-08 03:23:31+00:00",
      "link": "https://arxiv.org/pdf/2601.04547v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04540v1",
      "title": "AdaptEval: A Benchmark for Evaluating Large Language Models on Code Snippet Adaptation",
      "abstract": "Recent advancements in large language models (LLMs) have automated various software engineering tasks, with benchmarks emerging to evaluate their capabilities. However, for adaptation, a critical activity during code reuse, there is no benchmark to assess LLMs' performance, leaving their practical utility in this area unclear. To fill this gap, we propose AdaptEval, a benchmark designed to evaluate LLMs on code snippet adaptation. Unlike existing benchmarks, AdaptEval incorporates the following three distinctive features: First, Practical Context. Tasks in AdaptEval are derived from developers' practices, preserving rich contextual information from Stack Overflow and GitHub communities. Second, Multi-granularity Annotation. Each task is annotated with requirements at both task and adaptation levels, supporting the evaluation of LLMs across diverse adaptation scenarios. Third, Fine-grained Evaluation. AdaptEval includes a two-tier testing framework combining adaptation-level and function-level tests, which enables evaluating LLMs' performance across various individual adaptations. Based on AdaptEval, we conduct the first empirical study to evaluate six instruction-tuned LLMs and especially three reasoning LLMs on code snippet adaptation. Experimental results demonstrate that AdaptEval enables the assessment of LLMs' adaptation capabilities from various perspectives. It also provides critical insights into their current limitations, particularly their struggle to follow explicit instructions. We hope AdaptEval can facilitate further investigation and enhancement of LLMs' capabilities in code snippet adaptation, supporting their real-world applications.",
      "authors": [
        "Tanghaoran Zhang",
        "Xinjun Mao",
        "Shangwen Wang",
        "Yuxin Zhao",
        "Yao Lu",
        "Jin Zhang",
        "Zhang Zhang",
        "Kang Yang",
        "Yue Yu"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "published": "2026-01-08 03:13:20+00:00",
      "link": "https://arxiv.org/pdf/2601.04540v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04531v1",
      "title": "Self-MedRAG: a Self-Reflective Hybrid Retrieval-Augmented Generation Framework for Reliable Medical Question Answering",
      "abstract": "Large Language Models (LLMs) have demonstrated significant potential in medical Question Answering (QA), yet they remain prone to hallucinations and ungrounded reasoning, limiting their reliability in high-stakes clinical scenarios. While Retrieval-Augmented Generation (RAG) mitigates these issues by incorporating external knowledge, conventional single-shot retrieval often fails to resolve complex biomedical queries requiring multi-step inference. To address this, we propose Self-MedRAG, a self-reflective hybrid framework designed to mimic the iterative hypothesis-verification process of clinical reasoning. Self-MedRAG integrates a hybrid retrieval strategy, combining sparse (BM25) and dense (Contriever) retrievers via Reciprocal Rank Fusion (RRF) to maximize evidence coverage. It employs a generator to produce answers with supporting rationales, which are then assessed by a lightweight self-reflection module using Natural Language Inference (NLI) or LLM-based verification. If the rationale lacks sufficient evidentiary support, the system autonomously reformulates the query and iterates to refine the context. We evaluated Self-MedRAG on the MedQA and PubMedQA benchmarks. The results demonstrate that our hybrid retrieval approach significantly outperforms single-retriever baselines. Furthermore, the inclusion of the self-reflective loop yielded substantial gains, increasing accuracy on MedQA from 80.00% to 83.33% and on PubMedQA from 69.10% to 79.82%. These findings confirm that integrating hybrid retrieval with iterative, evidence-based self-reflection effectively reduces unsupported claims and enhances the clinical reliability of LLM-based systems.",
      "authors": [
        "Jessica Ryan",
        "Alexander I. Gumilang",
        "Robert Wiliam",
        "Derwin Suhartono"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "published": "2026-01-08 02:56:04+00:00",
      "link": "https://arxiv.org/pdf/2601.04531v1",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.04521v1",
      "title": "TSSR: Two-Stage Swap-Reward-Driven Reinforcement Learning for Character-Level SMILES Generation",
      "abstract": "The design of reliable, valid, and diverse molecules is fundamental to modern drug discovery, as improved molecular generation supports efficient exploration of the chemical space for potential drug candidates and reduces the cost of early design efforts. Despite these needs, current chemical language models that generate molecules as SMILES strings are vulnerable to compounding token errors: many samples are unparseable or chemically implausible, and hard constraints meant to prevent failure can restrict exploration. To address this gap, we introduce TSSR, a Two-Stage, Swap-Reward-driven reinforcement learning (RL) framework for character-level SMILES generation. Stage one rewards local token swaps that repair syntax, promoting transitions from invalid to parseable strings. Stage two provides chemistry-aware feedback from RDKit diagnostics, rewarding reductions in valence, aromaticity, and connectivity issues. The reward decomposes into interpretable terms (swap efficiency, error reduction, distance to validity), is model agnostic, and requires no task-specific labels or hand-crafted grammars. We evaluated TSSR on the MOSES benchmark using a GRU policy trained with PPO in both pure RL (P-RL) from random initialization and fine-tuning RL (F-RL) starting from a pretrained chemical language model, assessing 10,000 generated SMILES per run. In P-RL, TSSR significantly improves syntactic validity, chemical validity, and novelty. In F-RL, TSSR preserves drug-likeness and synthesizability while increasing validity and novelty. Token-level analysis shows that syntax edits and chemistry fixes act jointly to reduce RDKit detected errors. TSSR converts a sparse terminal objective into a denser and more interpretable reward, improving both syntactic and chemical quality without reducing diversity. TSSR is dataset-agnostic and can be adapted to various reinforcement learning approaches.",
      "authors": [
        "Jacob Ede Levine",
        "Yun Lyan Luo",
        "Sai Chandra Kosaraju"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-08 02:35:22+00:00",
      "link": "https://arxiv.org/pdf/2601.04521v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04520v1",
      "title": "FaceRefiner: High-Fidelity Facial Texture Refinement with Differentiable Rendering-based Style Transfer",
      "abstract": "Recent facial texture generation methods prefer to use deep networks to synthesize image content and then fill in the UV map, thus generating a compelling full texture from a single image. Nevertheless, the synthesized texture UV map usually comes from a space constructed by the training data or the 2D face generator, which limits the methods' generalization ability for in-the-wild input images. Consequently, their facial details, structures and identity may not be consistent with the input. In this paper, we address this issue by proposing a style transfer-based facial texture refinement method named FaceRefiner. FaceRefiner treats the 3D sampled texture as style and the output of a texture generation method as content. The photo-realistic style is then expected to be transferred from the style image to the content image. Different from current style transfer methods that only transfer high and middle level information to the result, our style transfer method integrates differentiable rendering to also transfer low level (or pixel level) information in the visible face regions. The main benefit of such multi-level information transfer is that, the details, structures and semantics in the input can thus be well preserved. The extensive experiments on Multi-PIE, CelebA and FFHQ datasets demonstrate that our refinement method can improve the texture quality and the face identity preserving ability, compared with state-of-the-arts.",
      "authors": [
        "Chengyang Li",
        "Baoping Cheng",
        "Yao Cheng",
        "Haocheng Zhang",
        "Renshuai Liu",
        "Yinglin Zheng",
        "Jing Liao",
        "Xuan Cheng"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 02:34:29+00:00",
      "link": "https://arxiv.org/pdf/2601.04520v1",
      "tags": [
        "keyword:resnet",
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.04519v1",
      "title": "TokenSeg: Efficient 3D Medical Image Segmentation via Hierarchical Visual Token Compression",
      "abstract": "Three-dimensional medical image segmentation is a fundamental yet computationally demanding task due to the cubic growth of voxel processing and the redundant computation on homogeneous regions. To address these limitations, we propose \\textbf{TokenSeg}, a boundary-aware sparse token representation framework for efficient 3D medical volume segmentation. Specifically, (1) we design a \\emph{multi-scale hierarchical encoder} that extracts 400 candidate tokens across four resolution levels to capture both global anatomical context and fine boundary details; (2) we introduce a \\emph{boundary-aware tokenizer} that combines VQ-VAE quantization with importance scoring to select 100 salient tokens, over 60\\% of which lie near tumor boundaries; and (3) we develop a \\emph{sparse-to-dense decoder} that reconstructs full-resolution masks through token reprojection, progressive upsampling, and skip connections. Extensive experiments on a 3D breast DCE-MRI dataset comprising 960 cases demonstrate that TokenSeg achieves state-of-the-art performance with 94.49\\% Dice and 89.61\\% IoU, while reducing GPU memory and inference latency by 64\\% and 68\\%, respectively. To verify the generalization capability, our evaluations on MSD cardiac and brain MRI benchmark datasets demonstrate that TokenSeg consistently delivers optimal performance across heterogeneous anatomical structures. These results highlight the effectiveness of anatomically informed sparse representation for accurate and efficient 3D medical image segmentation.",
      "authors": [
        "Sen Zeng",
        "Hong Zhou",
        "Zheng Zhu",
        "Yang Liu"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 02:32:48+00:00",
      "link": "https://arxiv.org/pdf/2601.04519v1",
      "tags": [
        "keyword:resnet",
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.04518v1",
      "title": "Integrating Distribution Matching into Semi-Supervised Contrastive Learning for Labeled and Unlabeled Data",
      "abstract": "The advancement of deep learning has greatly improved supervised image classification. However, labeling data is costly, prompting research into unsupervised learning methods such as contrastive learning. In real-world scenarios, fully unlabeled datasets are rare, making semi-supervised learning (SSL) highly relevant in scenarios where a small amount of labeled data coexists with a large volume of unlabeled data. A well-known semi-supervised contrastive learning approach involves assigning pseudo-labels to unlabeled data. This study aims to enhance pseudo-label-based SSL by incorporating distribution matching between labeled and unlabeled feature embeddings to improve image classification accuracy across multiple datasets.",
      "authors": [
        "Shogo Nakayama",
        "Masahiro Okuda"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-08 02:32:12+00:00",
      "link": "https://arxiv.org/pdf/2601.04518v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04517v1",
      "title": "Bridging Distance and Spectral Positional Encodings via Anchor-Based Diffusion Geometry Approximation",
      "abstract": "Molecular graph learning benefits from positional signals that capture both local neighborhoods and global topology. Two widely used families are spectral encodings derived from Laplacian or diffusion operators and anchor-based distance encodings built from shortest-path information, yet their precise relationship is poorly understood. We interpret distance encodings as a low-rank surrogate of diffusion geometry and derive an explicit trilateration map that reconstructs truncated diffusion coordinates from transformed anchor distances and anchor spectral positions, with pointwise and Frobenius-gap guarantees on random regular graphs. On DrugBank molecular graphs using a shared GNP-based DDI prediction backbone, a distance-driven Nyström scheme closely recovers diffusion geometry, and both Laplacian and distance encodings substantially outperform a no-encoding baseline.",
      "authors": [
        "Zimo Yan",
        "Zheng Xie",
        "Runfan Duan",
        "Chang Liu",
        "Wumei Du"
      ],
      "primary_category": "cs.IT",
      "categories": [
        "cs.IT",
        "cs.LG"
      ],
      "published": "2026-01-08 02:31:03+00:00",
      "link": "https://arxiv.org/pdf/2601.04517v1",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.04509v1",
      "title": "A General Neural Backbone for Mixed-Integer Linear Optimization via Dual Attention",
      "abstract": "Mixed-integer linear programming (MILP), a widely used modeling framework for combinatorial optimization, are central to many scientific and engineering applications, yet remains computationally challenging at scale. Recent advances in deep learning address this challenge by representing MILP instances as variable-constraint bipartite graphs and applying graph neural networks (GNNs) to extract latent structural patterns and enhance solver efficiency. However, this architecture is inherently limited by the local-oriented mechanism, leading to restricted representation power and hindering neural approaches for MILP. Here we present an attention-driven neural architecture that learns expressive representations beyond the pure graph view. A dual-attention mechanism is designed to perform parallel self- and cross-attention over variables and constraints, enabling global information exchange and deeper representation learning. We apply this general backbone to various downstream tasks at the instance level, element level, and solving state level. Extensive experiments across widely used benchmarks show consistent improvements of our approach over state-of-the-art baselines, highlighting attention-based neural architectures as a powerful foundation for learning-enhanced mixed-integer linear optimization.",
      "authors": [
        "Peixin Huang",
        "Yaoxin Wu",
        "Yining Ma",
        "Cathy Wu",
        "Wen Song",
        "Wei Zhang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 02:23:47+00:00",
      "link": "https://arxiv.org/pdf/2601.04509v1",
      "tags": [
        "keyword:resnet",
        "keyword:大语言模型",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04507v1",
      "title": "A Semi-supervised Molecular Learning Framework for Activity Cliff Estimation",
      "abstract": "Machine learning (ML) enables accurate and fast molecular property predictions, which are of interest in drug discovery and material design. Their success is based on the principle of similarity at its heart, assuming that similar molecules exhibit close properties. However, activity cliffs challenge this principle, and their presence leads to a sharp decline in the performance of existing ML algorithms, particularly graph-based methods. To overcome this obstacle under a low-data scenario, we propose a novel semi-supervised learning (SSL) method dubbed SemiMol, which employs predictions on numerous unannotated data as pseudo-signals for subsequent training. Specifically, we introduce an additional instructor model to evaluate the accuracy and trustworthiness of proxy labels because existing pseudo-labeling approaches require probabilistic outputs to reveal the model's confidence and fail to be applied in regression tasks. Moreover, we design a self-adaptive curriculum learning algorithm to progressively move the target model toward hard samples at a controllable pace. Extensive experiments on 30 activity cliff datasets demonstrate that SemiMol significantly enhances graph-based ML architectures and outpasses state-of-the-art pretraining and SSL baselines.",
      "authors": [
        "Fang Wu"
      ],
      "primary_category": "cs.CE",
      "categories": [
        "cs.CE",
        "cs.AI"
      ],
      "published": "2026-01-08 02:20:25+00:00",
      "link": "https://arxiv.org/pdf/2601.04507v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04506v1",
      "title": "Surface-based Molecular Design with Multi-modal Flow Matching",
      "abstract": "Therapeutic peptides show promise in targeting previously undruggable binding sites, with recent advancements in deep generative models enabling full-atom peptide co-design for specific protein receptors. However, the critical role of molecular surfaces in protein-protein interactions (PPIs) has been underexplored. To bridge this gap, we propose an omni-design peptides generation paradigm, called SurfFlow, a novel surface-based generative algorithm that enables comprehensive co-design of sequence, structure, and surface for peptides. SurfFlow employs a multi-modality conditional flow matching (CFM) architecture to learn distributions of surface geometries and biochemical properties, enhancing peptide binding accuracy. Evaluated on the comprehensive PepMerge benchmark, SurfFlow consistently outperforms full-atom baselines across all metrics. These results highlight the advantages of considering molecular surfaces in de novo peptide discovery and demonstrate the potential of integrating multiple protein modalities for more effective therapeutic peptide discovery.",
      "authors": [
        "Fang Wu",
        "Zhengyuan Zhou",
        "Shuting Jin",
        "Xiangxiang Zeng",
        "Jure Leskovec",
        "Jinbo Xu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE"
      ],
      "published": "2026-01-08 02:19:29+00:00",
      "link": "https://arxiv.org/pdf/2601.04506v1",
      "tags": [
        "keyword:resnet",
        "keyword:大语言模型",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04505v1",
      "title": "CircuitLM: A Multi-Agent LLM-Aided Design Framework for Generating Circuit Schematics from Natural Language Prompts",
      "abstract": "Generating accurate circuit schematics from high-level natural language descriptions remains a persistent challenge in electronics design, as large language models (LLMs) frequently hallucinate in granular details, violate electrical constraints, and produce non-machine-readable outputs. We present CircuitLM, a novel multi-agent LLM-aided circuit design pipeline that translates user prompts into structured, visually interpretable CircuitJSON schematics through five sequential stages: (i) LLM-based component identification, (ii) canonical pinout retrieval, (iii) chain-of-thought reasoning by an electronics expert agent, (iv) JSON schematic synthesis, and (v) force-directed SVG visualization. Anchored by a curated, embedding-powered component knowledge base. While LLMs often violate electrical constraints, CircuitLM bridges this gap by grounding generation in a verified and dynamically extensible component database, initially comprising 50 components. To ensure safety, we incorporate a hybrid evaluation framework, namely Dual-Metric Circuit Validation (DMCV), validated against human-expert assessments, which achieves high fidelity in microcontroller-centric designs. We evaluate the system on 100 diverse embedded-systems prompts across six LLMs and introduce DMCV to assess both structural and electrical validity. This work bridges natural language input to deployable hardware designs, enabling reliable circuit prototyping by non-experts. Our code and data will be made public upon acceptance.",
      "authors": [
        "Khandakar Shakib Al Hasan",
        "Syed Rifat Raiyan",
        "Hasin Mahtab Alvee",
        "Wahid Sadik"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL",
        "eess.SY"
      ],
      "published": "2026-01-08 02:18:43+00:00",
      "link": "https://arxiv.org/pdf/2601.04505v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04500v1",
      "title": "GUITester: Enabling GUI Agents for Exploratory Defect Discovery",
      "abstract": "Exploratory GUI testing is essential for software quality but suffers from high manual costs. While Multi-modal Large Language Model (MLLM) agents excel in navigation, they fail to autonomously discover defects due to two core challenges: \\textit{Goal-Oriented Masking}, where agents prioritize task completion over reporting anomalies, and \\textit{Execution-Bias Attribution}, where system defects are misidentified as agent errors. To address these, we first introduce \\textbf{GUITestBench}, the first interactive benchmark for this task, featuring 143 tasks across 26 defects. We then propose \\textbf{GUITester}, a multi-agent framework that decouples navigation from verification via two modules: (i) a \\textit{Planning-Execution Module (PEM)} that proactively probes for defects via embedded testing intents, and (ii) a \\textit{Hierarchical Reflection Module (HRM)} that resolves attribution ambiguity through interaction history analysis. GUITester achieves an F1-score of 48.90\\% (Pass@3) on GUITestBench, outperforming state-of-the-art baselines (33.35\\%). Our work demonstrates the feasibility of autonomous exploratory testing and provides a robust foundation for future GUI quality assurance~\\footnote{Our code is now available in~\\href{https://github.com/ADaM-BJTU/GUITestBench}{https://github.com/ADaM-BJTU/GUITestBench}}.",
      "authors": [
        "Yifei Gao",
        "Jiang Wu",
        "Xiaoyi Chen",
        "Yifan Yang",
        "Zhe Cui",
        "Tianyi Ma",
        "Jiaming Zhang",
        "Jitao Sang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 02:07:53+00:00",
      "link": "https://arxiv.org/pdf/2601.04500v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04497v1",
      "title": "Vision-Language Agents for Interactive Forest Change Analysis",
      "abstract": "Modern forest monitoring workflows increasingly benefit from the growing availability of high-resolution satellite imagery and advances in deep learning. Two persistent challenges in this context are accurate pixel-level change detection and meaningful semantic change captioning for complex forest dynamics. While large language models (LLMs) are being adapted for interactive data exploration, their integration with vision-language models (VLMs) for remote sensing image change interpretation (RSICI) remains underexplored. To address this gap, we introduce an LLM-driven agent for integrated forest change analysis that supports natural language querying across multiple RSICI tasks. The proposed system builds upon a multi-level change interpretation (MCI) vision-language backbone with LLM-based orchestration. To facilitate adaptation and evaluation in forest environments, we further introduce the Forest-Change dataset, which comprises bi-temporal satellite imagery, pixel-level change masks, and multi-granularity semantic change captions generated using a combination of human annotation and rule-based methods. Experimental results show that the proposed system achieves mIoU and BLEU-4 scores of 67.10% and 40.17% on the Forest-Change dataset, and 88.13% and 34.41% on LEVIR-MCI-Trees, a tree-focused subset of LEVIR-MCI benchmark for joint change detection and captioning. These results highlight the potential of interactive, LLM-driven RSICI systems to improve accessibility, interpretability, and efficiency of forest change analysis. All data and code are publicly available at https://github.com/JamesBrockUoB/ForestChat.",
      "authors": [
        "James Brock",
        "Ce Zhang",
        "Nantheera Anantrasirichai"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-08 02:02:36+00:00",
      "link": "https://arxiv.org/pdf/2601.04497v1",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.04486v1",
      "title": "Decision-Aware Trust Signal Alignment for SOC Alert Triage",
      "abstract": "Detection systems that utilize machine learning are progressively implemented at Security Operations Centers (SOCs) to help an analyst to filter through high volumes of security alerts. Practically, such systems tend to reveal probabilistic results or confidence scores which are ill-calibrated and hard to read when under pressure. Qualitative and survey based studies of SOC practice done before reveal that poor alert quality and alert overload greatly augment the burden on the analyst, especially when tool outputs are not coherent with decision requirements, or signal noise. One of the most significant limitations is that model confidence is usually shown without expressing that there are asymmetric costs in decision making where false alarms are much less harmful than missed attacks. The present paper presents a decision-sensitive trust signal correspondence scheme of SOC alert triage. The framework combines confidence that has been calibrated, lightweight uncertainty cues, and cost-sensitive decision thresholds into coherent decision-support layer, instead of making changes to detection models. To enhance probabilistic consistency, the calibration is done using the known post-hoc methods and the uncertainty cues give conservative protection in situations where model certainty is low. To measure the model-independent performance of the suggested model, we apply the Logistic Regression and the Random Forest classifiers to the UNSW-NB15 intrusion detection benchmark. According to simulation findings, false negatives are greatly amplified by the presence of misaligned displays of confidence, whereas cost weighted loss decreases by orders of magnitude between models with decision aligned trust signals. Lastly, we describe a human-in-the-loop study plan that would allow empirically assessing the decision-making of the analysts with aligned and misaligned trust interfaces.",
      "authors": [
        "Israt Jahan Chowdhury",
        "Md Abu Yousuf Tanvir"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.HC"
      ],
      "published": "2026-01-08 01:41:54+00:00",
      "link": "https://arxiv.org/pdf/2601.04486v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04480v1",
      "title": "When Models Manipulate Manifolds: The Geometry of a Counting Task",
      "abstract": "Language models can perceive visual properties of text despite receiving only sequences of tokens-we mechanistically investigate how Claude 3.5 Haiku accomplishes one such task: linebreaking in fixed-width text. We find that character counts are represented on low-dimensional curved manifolds discretized by sparse feature families, analogous to biological place cells. Accurate predictions emerge from a sequence of geometric transformations: token lengths are accumulated into character count manifolds, attention heads twist these manifolds to estimate distance to the line boundary, and the decision to break the line is enabled by arranging estimates orthogonally to create a linear decision boundary. We validate our findings through causal interventions and discover visual illusions--character sequences that hijack the counting mechanism. Our work demonstrates the rich sensory processing of early layers, the intricacy of attention algorithms, and the importance of combining feature-based and geometric views of interpretability.",
      "authors": [
        "Wes Gurnee",
        "Emmanuel Ameisen",
        "Isaac Kauvar",
        "Julius Tarng",
        "Adam Pearce",
        "Chris Olah",
        "Joshua Batson"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-08 01:33:42+00:00",
      "link": "https://arxiv.org/pdf/2601.04480v1",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.04476v1",
      "title": "Memory-Guided Unified Hardware Accelerator for Mixed-Precision Scientific Computing",
      "abstract": "Recent hardware acceleration advances have enabled powerful specialized accelerators for finite element computations, spiking neural network inference, and sparse tensor operations. However, existing approaches face fundamental limitations: (1) finite element methods lack comprehensive rounding error analysis for reduced-precision implementations and use fixed precision assignment strategies that cannot adapt to varying numerical conditioning; (2) spiking neural network accelerators cannot handle non-spike operations and suffer from bit-width escalation as network depth increases; and (3) FPGA tensor accelerators optimize only for dense computations while requiring manual configuration for each sparsity pattern. To address these challenges, we introduce \\textbf{Memory-Guided Unified Hardware Accelerator for Mixed-Precision Scientific Computing}, a novel framework that integrates three enhanced modules with memory-guided adaptation for efficient mixed-workload processing on unified platforms. Our approach employs memory-guided precision selection to overcome fixed precision limitations, integrates experience-driven bit-width management and dynamic parallelism adaptation for enhanced spiking neural network acceleration, and introduces curriculum learning for automatic sparsity pattern discovery. Extensive experiments on FEniCS, COMSOL, ANSYS benchmarks, MNIST, CIFAR-10, CIFAR-100, DVS-Gesture datasets, and COCO 2017 demonstrate 2.8\\% improvement in numerical accuracy, 47\\% throughput increase, 34\\% energy reduction, and 45-65\\% throughput improvement compared to specialized accelerators. Our work enables unified processing of finite element methods, spiking neural networks, and sparse computations on a single platform while eliminating data transfer overhead between separate units.",
      "authors": [
        "Chuanzhen Wang",
        "Leo Zhang",
        "Eric Liu"
      ],
      "primary_category": "cs.AR",
      "categories": [
        "cs.AR"
      ],
      "published": "2026-01-08 01:28:45+00:00",
      "link": "https://arxiv.org/pdf/2601.04476v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04474v1",
      "title": "Computational Compliance for AI Regulation: Blueprint for a New Research Domain",
      "abstract": "The era of AI regulation (AIR) is upon us. But AI systems, we argue, will not be able to comply with these regulations at the necessary speed and scale by continuing to rely on traditional, analogue methods of compliance. Instead, we posit that compliance with these regulations will only realistically be achieved computationally: that is, with algorithms that run across the life cycle of an AI system, automatically steering it toward AIR compliance in the face of dynamic conditions. Yet despite their (we would argue) inevitability, the research community has yet to specify exactly how these algorithms for computational AIR compliance should behave - or how we should benchmark their performance. To fill these gaps, we specify a set of design goals for such algorithms. In addition, we specify a benchmark dataset that can be used to quantitatively measure whether individual algorithms satisfy these design goals. By delivering this blueprint, we hope to give shape to an important but uncrystallized new domain of research - and, in doing so, incite necessary investment in it.",
      "authors": [
        "Bill Marino",
        "Nicholas D. Lane"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 01:22:45+00:00",
      "link": "https://arxiv.org/pdf/2601.04474v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04473v1",
      "title": "Convergence Rates for Learning Pseudo-Differential Operators",
      "abstract": "This paper establishes convergence rates for learning elliptic pseudo-differential operators, a fundamental operator class in partial differential equations and mathematical physics. In a wavelet-Galerkin framework, we formulate learning over this class as a structured infinite-dimensional regression problem with multiscale sparsity. Building on this structure, we propose a sparse, data- and computation-efficient estimator, which leverages a novel matrix compression scheme tailored to the learning task and a nested-support strategy to balance approximation and estimation errors. In addition to obtaining convergence rates for the estimator, we show that the learned operator induces an efficient and stable Galerkin solver whose numerical error matches its statistical accuracy. Our results therefore contribute to bringing together operator learning, data-driven solvers, and wavelet methods in scientific computing.",
      "authors": [
        "Jiaheng Chen",
        "Daniel Sanz-Alonso"
      ],
      "primary_category": "math.ST",
      "categories": [
        "math.ST",
        "cs.LG",
        "math.NA",
        "stat.ML"
      ],
      "published": "2026-01-08 01:21:08+00:00",
      "link": "https://arxiv.org/pdf/2601.04473v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04462v1",
      "title": "Meta-probabilistic Modeling",
      "abstract": "While probabilistic graphical models can discover latent structure in data, their effectiveness hinges on choosing well-specified models. Identifying such models is challenging in practice, often requiring iterative checking and revision through trial and error. To this end, we propose meta-probabilistic modeling (MPM), a meta-learning algorithm that learns generative model structure directly from multiple related datasets. MPM uses a hierarchical architecture where global model specifications are shared across datasets while local parameters remain dataset-specific. For learning and inference, we propose a tractable VAE-inspired surrogate objective, and optimize it through bi-level optimization: local variables are updated analytically via coordinate ascent, while global parameters are trained with gradient-based methods. We evaluate MPM on object-centric image modeling and sequential text modeling, demonstrating that it adapts generative models to data while recovering meaningful latent representations.",
      "authors": [
        "Kevin Zhang",
        "Yixin Wang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-08 00:34:06+00:00",
      "link": "https://arxiv.org/pdf/2601.04462v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04449v1",
      "title": "Explainable Admission-Level Predictive Modeling for Prolonged Hospital Stay in Elderly Populations: Challenges in Low- and Middle-Income Countries",
      "abstract": "Prolonged length of stay (pLoS) is a significant factor associated with the risk of adverse in-hospital events. We develop and explain a predictive model for pLos using admission-level patient and hospital administrative data. The approach includes a feature selection method by selecting non-correlated features with the highest information value. The method uses features weights of evidence to select a representative within cliques from graph theory. The prognosis study analyzed the records from 120,354 hospital admissions at the Hospital Alma Mater de Antioquia between January 2017 and March 2022. After a cleaning process the dataset was split into training (67%), test (22%), and validation (11%) cohorts. A logistic regression model was trained to predict the pLoS in two classes: less than or greater than 7 days. The performance of the model was evaluated using accuracy, precision, sensitivity, specificity, and AUC-ROC metrics. The feature selection method returns nine interpretable variables, enhancing the models' transparency. In the validation cohort, the pLoS model achieved a specificity of 0.83 (95% CI, 0.82-0.84), sensitivity of 0.64 (95% CI, 0.62-0.65), accuracy of 0.76 (95% CI, 0.76-0.77), precision of 0.67 (95% CI, 0.66-0.69), and AUC-ROC of 0.82 (95% CI, 0.81-0.83). The model exhibits strong predictive performance and offers insights into the factors that influence prolonged hospital stays. This makes it a valuable tool for hospital management and for developing future intervention studies aimed at reducing pLoS.",
      "authors": [
        "Daniel Sierra-Botero",
        "Ana Molina-Taborda",
        "Leonardo Espinosa-Leal",
        "Alexander Karpenko",
        "Alejandro Hernandez",
        "Olga Lopez-Acevedo"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 23:35:24+00:00",
      "link": "https://arxiv.org/pdf/2601.04449v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04445v1",
      "title": "SpectraFormer: an Attention-Based Raman Unmixing Tool for Accessing the Graphene Buffer-Layer Signature on SiC",
      "abstract": "Raman spectroscopy is a key tool for graphene characterization, yet its application to graphene grown on silicon carbide (SiC) is strongly limited by the intense and variable second-order Raman response of the substrate. This limitation is critical for buffer layer graphene, a semiconducting interfacial phase, whose vibrational signatures are overlapped with the SiC background and challenging to be reliably accessed using conventional reference-based subtraction, due to strong spatial and experimental variability of the substrate signal. Here we present SpectraFormer, a transformer-based deep learning model that reconstructs the SiC Raman substrate contribution directly from post-growth partially masked spectroscopic data without relying on explicit reference measurements. By learning global correlations across the entire Raman shift range, the model captures the statistical structure of the SiC background and enables accurate reconstruction of its contribution in mixed spectra. Subtraction of the reconstructed substrate signal reveals weak vibrational features associated with ZLG that are inaccessible through conventional analysis methods. The extracted spectra are validated by ab initio vibrational calculations, allowing assignment of the resolved features to specific modes and confirming their physical consistency. By leveraging a state-of-the-art attention-based deep learning architecture, this approach establishes a robust, reference-free framework for Raman analysis of graphene on SiC and provides a foundation, compatible with real-time data acquisition, to its integration into automated, closed-loop AI-assisted growth optimization.",
      "authors": [
        "Dmitriy Poteryayev",
        "Pietro Novelli",
        "Annalisa Coriolano",
        "Riccardo Dettori",
        "Valentina Tozzini",
        "Fabio Beltram",
        "Massimiliano Pontil",
        "Antonio Rossi",
        "Stiven Forti",
        "Camilla Coletti"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-07 23:20:19+00:00",
      "link": "https://arxiv.org/pdf/2601.04445v1",
      "tags": [
        "keyword:resnet",
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.04443v1",
      "title": "Large Language Models for Detecting Cyberattacks on Smart Grid Protective Relays",
      "abstract": "This paper presents a large language model (LLM)-based framework for detecting cyberattacks on transformer current differential relays (TCDRs), which, if undetected, may trigger false tripping of critical transformers. The proposed approach adapts and fine-tunes compact LLMs such as DistilBERT to distinguish cyberattacks from actual faults using textualized multidimensional TCDR current measurements recorded before and after tripping. Our results demonstrate that DistilBERT detects 97.6% of cyberattacks without compromising TCDR dependability and achieves inference latency below 6 ms on a commercial workstation. Additional evaluations confirm the framework's robustness under combined time-synchronization and false-data-injection attacks, resilience to measurement noise, and stability across prompt formulation variants. Furthermore, GPT-2 and DistilBERT+LoRA achieve comparable performance, highlighting the potential of LLMs for enhancing smart grid cybersecurity. We provide the full dataset used in this study for reproducibility.",
      "authors": [
        "Ahmad Mohammad Saber",
        "Saeed Jafari",
        "Zhengmao Ouyang",
        "Paul Budnarain",
        "Amr Youssef",
        "Deepa Kundur"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR",
        "cs.LG",
        "eess.SP"
      ],
      "published": "2026-01-07 23:12:03+00:00",
      "link": "https://arxiv.org/pdf/2601.04443v1",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.04442v1",
      "title": "Addressing Overthinking in Large Vision-Language Models via Gated Perception-Reasoning Optimization",
      "abstract": "Large Vision-Language Models (LVLMs) have exhibited strong reasoning capabilities through chain-of-thought mechanisms that generate step-by-step rationales. However, such slow-thinking approaches often lead to overthinking, where models produce excessively verbose responses even for simple queries, resulting in test-time inefficiency and even degraded accuracy. Prior work has attempted to mitigate this issue via adaptive reasoning strategies, but these methods largely overlook a fundamental bottleneck: visual perception failures. We argue that stable reasoning critically depends on low-level visual grounding, and that reasoning errors often originate from imperfect perception rather than insufficient deliberation. To address this limitation, we propose Gated Perception-Reasoning Optimization (GPRO), a meta-reasoning controller that dynamically routes computation among three decision paths at each generation step: a lightweight fast path, a slow perception path for re-examining visual inputs, and a slow reasoning path for internal self-reflection. To learn this distinction, we derive large-scale failure attribution supervision from approximately 790k samples, using teacher models to distinguish perceptual hallucinations from reasoning errors. We then train the controller with multi-objective reinforcement learning to optimize the trade-off between task accuracy and computational cost under uncertainty. Experiments on five benchmarks demonstrate that GPRO substantially improves both accuracy and efficiency, outperforming recent slow-thinking methods while generating significantly shorter responses.",
      "authors": [
        "Xingjian Diao",
        "Zheyuan Liu",
        "Chunhui Zhang",
        "Weiyi Wu",
        "Keyi Kong",
        "Lin Shi",
        "Kaize Ding",
        "Soroush Vosoughi",
        "Jiang Gui"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.CL"
      ],
      "published": "2026-01-07 23:05:17+00:00",
      "link": "https://arxiv.org/pdf/2601.04442v1",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.04428v1",
      "title": "CRUNet-MR-Univ: A Foundation Model for Diverse Cardiac MRI Reconstruction",
      "abstract": "In recent years, deep learning has attracted increasing attention in the field of Cardiac MRI (CMR) reconstruction due to its superior performance over traditional methods, particularly in handling higher acceleration factors, highlighting its potential for real-world clinical applications. However, current deep learning methods remain limited in generalizability. CMR scans exhibit wide variability in image contrast, sampling patterns, scanner vendors, anatomical structures, and disease types. Most existing models are designed to handle only a single or narrow subset of these variations, leading to performance degradation when faced with distribution shifts. Therefore, it is beneficial to develop a unified model capable of generalizing across diverse CMR scenarios. To this end, we propose CRUNet-MR-Univ, a foundation model that leverages spatio-temporal correlations and prompt-based priors to effectively handle the full diversity of CMR scans. Our approach consistently outperforms baseline methods across a wide range of settings, highlighting its effectiveness and promise.",
      "authors": [
        "Donghang Lyu",
        "Marius Staring",
        "Hildo Lamb",
        "Mariya Doneva"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-01-07 22:23:56+00:00",
      "link": "https://arxiv.org/pdf/2601.04428v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04413v1",
      "title": "Distribution-Guided and Constrained Quantum Machine Unlearning",
      "abstract": "Machine unlearning aims to remove the influence of specific training data from a learned model without full retraining. While recent work has begun to explore unlearning in quantum machine learning, existing approaches largely rely on fixed, uniform target distributions and do not explicitly control the trade-off between forgetting and retained model behaviour. In this work, we propose a distribution-guided framework for class-level quantum machine unlearning that treats unlearning as a constrained optimization problem. Our method introduces a tunable target distribution derived from model similarity statistics, decoupling the suppression of forgotten-class confidence from assumptions about redistribution among retained classes. We further incorporate an anchor-based preservation constraint that explicitly maintains predictive behaviour on selected retained data, yielding a controlled optimization trajectory that limits deviation from the original model. We evaluate the approach on variational quantum classifiers trained on the Iris and Covertype datasets. Results demonstrate sharp suppression of forgotten-class confidence, minimal degradation of retained-class performance, and closer alignment with the gold retrained model baselines compared to uniform-target unlearning. These findings highlight the importance of target design and constraint-based formulations for reliable and interpretable quantum machine unlearning.",
      "authors": [
        "Nausherwan Malik",
        "Zubair Khalid",
        "Muhammad Faryad"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "quant-ph"
      ],
      "published": "2026-01-07 21:44:20+00:00",
      "link": "https://arxiv.org/pdf/2601.04413v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04411v1",
      "title": "Rate or Fate? RLV$^\\varepsilon$R: Reinforcement Learning with Verifiable Noisy Rewards",
      "abstract": "Reinforcement learning with verifiable rewards (RLVR) is a simple but powerful paradigm for training LLMs: sample a completion, verify it, and update. In practice, however, the verifier is almost never clean--unit tests probe only limited corner cases; human and synthetic labels are imperfect; and LLM judges (e.g., RLAIF) are noisy and can be exploited--and this problem worsens on harder domains (especially coding) where tests are sparse and increasingly model-generated. We ask a pragmatic question: does the verification noise merely slow down the learning (rate), or can it flip the outcome (fate)?   To address this, we develop an analytically tractable multi-armed bandit view of RLVR dynamics, instantiated with GRPO and validated in controlled experiments. Modeling false positives and false negatives and grouping completions into recurring reasoning modes yields a replicator-style (natural-selection) flow on the probability simplex. The dynamics decouples into within-correct-mode competition and a one-dimensional evolution for the mass on incorrect modes, whose drift is determined solely by Youden's index J=TPR-FPR. This yields a sharp phase transition: when J>0, the incorrect mass is driven toward extinction (learning); when J=0, the process is neutral; and when J<0, incorrect modes amplify until they dominate (anti-learning and collapse). In the learning regime J>0, noise primarily rescales convergence time (\"rate, not fate\"). Experiments on verifiable programming tasks under synthetic noise reproduce the predicted J=0 boundary. Beyond noise, the framework offers a general lens for analyzing RLVR stability, convergence, and algorithmic interventions.",
      "authors": [
        "Ali Rad",
        "Khashayar Filom",
        "Darioush Keivan",
        "Peyman Mohajerin Esfahani",
        "Ehsan Kamalinejad"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-07 21:31:26+00:00",
      "link": "https://arxiv.org/pdf/2601.04411v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04401v1",
      "title": "Transformer-based Multi-agent Reinforcement Learning for Separation Assurance in Structured and Unstructured Airspaces",
      "abstract": "Conventional optimization-based metering depends on strict adherence to precomputed schedules, which limits the flexibility required for the stochastic operations of Advanced Air Mobility (AAM). In contrast, multi-agent reinforcement learning (MARL) offers a decentralized, adaptive framework that can better handle uncertainty, required for safe aircraft separation assurance. Despite this advantage, current MARL approaches often overfit to specific airspace structures, limiting their adaptability to new configurations. To improve generalization, we recast the MARL problem in a relative polar state space and train a transformer encoder model across diverse traffic patterns and intersection angles. The learned model provides speed advisories to resolve conflicts while maintaining aircraft near their desired cruising speeds. In our experiments, we evaluated encoder depths of 1, 2, and 3 layers in both structured and unstructured airspaces, and found that a single encoder configuration outperformed deeper variants, yielding near-zero near mid-air collision rates and shorter loss-of-separation infringements than the deeper configurations. Additionally, we showed that the same configuration outperforms a baseline model designed purely with attention. Together, our results suggest that the newly formulated state representation, novel design of neural network architecture, and proposed training strategy provide an adaptable and scalable decentralized solution for aircraft separation assurance in both structured and unstructured airspaces.",
      "authors": [
        "Arsyi Aziz",
        "Peng Wei"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.LG",
        "cs.MA"
      ],
      "published": "2026-01-07 21:18:28+00:00",
      "link": "https://arxiv.org/pdf/2601.04401v1",
      "tags": [
        "keyword:resnet",
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.04398v1",
      "title": "Interpreting Transformers Through Attention Head Intervention",
      "abstract": "Neural networks are growing more capable on their own, but we do not understand their neural mechanisms. Understanding these mechanisms' decision-making processes, or mechanistic interpretability, enables (1) accountability and control in high-stakes domains, (2) the study of digital brains and the emergence of cognition, and (3) discovery of new knowledge when AI systems outperform humans.",
      "authors": [
        "Mason Kadem",
        "Rong Zheng"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 21:15:20+00:00",
      "link": "https://arxiv.org/pdf/2601.04398v1",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.04397v1",
      "title": "Performance Analysis of Image Classification on Bangladeshi Datasets",
      "abstract": "Convolutional Neural Networks (CNNs) have demonstrated remarkable success in image classification tasks; however, the choice between designing a custom CNN from scratch and employing established pre-trained architectures remains an important practical consideration. In this work, we present a comparative analysis of a custom-designed CNN and several widely used deep learning architectures, including VGG-16, ResNet-50, and MobileNet, for an image classification task. The custom CNN is developed and trained from scratch, while the popular architectures are employed using transfer learning under identical experimental settings. All models are evaluated using standard performance metrics such as accuracy, precision, recall, and F1-score. Experimental results show that pre-trained CNN architectures consistently outperform the custom CNN in terms of classification accuracy and convergence speed, particularly when training data is limited. However, the custom CNN demonstrates competitive performance with significantly fewer parameters and reduced computational complexity. This study highlights the trade-offs between model complexity, performance, and computational efficiency, and provides practical insights into selecting appropriate CNN architectures for image classification problems.",
      "authors": [
        "Mohammed Sami Khan",
        "Fabiha Muniat",
        "Rowzatul Zannat"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-07 21:15:16+00:00",
      "link": "https://arxiv.org/pdf/2601.04397v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04392v1",
      "title": "Enhanced-FQL($λ$), an Efficient and Interpretable RL with novel Fuzzy Eligibility Traces and Segmented Experience Replay",
      "abstract": "This paper introduces a fuzzy reinforcement learning framework, Enhanced-FQL($λ$), that integrates novel Fuzzified Eligibility Traces (FET) and Segmented Experience Replay (SER) into fuzzy Q-learning with Fuzzified Bellman Equation (FBE) for continuous control tasks. The proposed approach employs an interpretable fuzzy rule base instead of complex neural architectures, while maintaining competitive performance through two key innovations: a fuzzified Bellman equation with eligibility traces for stable multi-step credit assignment, and a memory-efficient segment-based experience replay mechanism for enhanced sample efficiency. Theoretical analysis proves the proposed method convergence under standard assumptions. Extensive evaluations in continuous control domains demonstrate that Enhanced-FQL($λ$) achieves superior sample efficiency and reduced variance compared to n-step fuzzy TD and fuzzy SARSA($λ$) baselines, while maintaining substantially lower computational complexity than deep RL alternatives such as DDPG. The framework's inherent interpretability, combined with its computational efficiency and theoretical convergence guarantees, makes it particularly suitable for safety-critical applications where transparency and resource constraints are essential.",
      "authors": [
        "Mohsen Jalaeian-Farimani"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO",
        "eess.SY",
        "math.OC"
      ],
      "published": "2026-01-07 20:59:18+00:00",
      "link": "https://arxiv.org/pdf/2601.04392v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04390v1",
      "title": "SciFig: Towards Automating Scientific Figure Generation",
      "abstract": "Creating high-quality figures and visualizations for scientific papers is a time-consuming task that requires both deep domain knowledge and professional design skills. Despite over 2.5 million scientific papers published annually, the figure generation process remains largely manual. We introduce $\\textbf{SciFig}$, an end-to-end AI agent system that generates publication-ready pipeline figures directly from research paper texts. SciFig uses a hierarchical layout generation strategy, which parses research descriptions to identify component relationships, groups related elements into functional modules, and generates inter-module connections to establish visual organization. Furthermore, an iterative chain-of-thought (CoT) feedback mechanism progressively improves layouts through multiple rounds of visual analysis and reasoning. We introduce a rubric-based evaluation framework that analyzes 2,219 real scientific figures to extract evaluation rubrics and automatically generates comprehensive evaluation criteria. SciFig demonstrates remarkable performance: achieving 70.1$\\%$ overall quality on dataset-level evaluation and 66.2$\\%$ on paper-specific evaluation, and consistently high scores across metrics such as visual clarity, structural organization, and scientific accuracy. SciFig figure generation pipeline and our evaluation benchmark will be open-sourced.",
      "authors": [
        "Siyuan Huang",
        "Yutong Gao",
        "Juyang Bai",
        "Yifan Zhou",
        "Zi Yin",
        "Xinxin Liu",
        "Rama Chellappa",
        "Chun Pong Lau",
        "Sayan Nag",
        "Cheng Peng",
        "Shraman Pramanick"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-07 20:56:58+00:00",
      "link": "https://arxiv.org/pdf/2601.04390v1",
      "tags": [
        "keyword:resnet",
        "keyword:resnet中文",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04389v1",
      "title": "MiJaBench: Revealing Minority Biases in Large Language Models via Hate Speech Jailbreaking",
      "abstract": "Current safety evaluations of large language models (LLMs) create a dangerous illusion of universality, aggregating \"Identity Hate\" into scalar scores that mask systemic vulnerabilities against specific populations. To expose this selective safety, we introduce MiJaBench, a bilingual (English and Portuguese) adversarial benchmark comprising 44,000 prompts across 16 minority groups. By generating 528,000 prompt-response pairs from 12 state-of-the-art LLMs, we curate MiJaBench-Align, revealing that safety alignment is not a generalized semantic capability but a demographic hierarchy: defense rates fluctuate by up to 33\\% within the same model solely based on the target group. Crucially, we demonstrate that model scaling exacerbates these disparities, suggesting that current alignment techniques do not create principle of non-discrimination but reinforces memorized refusal boundaries only for specific groups, challenging the current scaling laws of security. We release all datasets and scripts to encourage research into granular demographic alignment at GitHub.",
      "authors": [
        "Iago Alves Brito",
        "Walcy Santos Rezende Rios",
        "Julia Soares Dollis",
        "Diogo Fernandes Costa Silva",
        "Arlindo Rodrigues Galvão Filho"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-07 20:53:18+00:00",
      "link": "https://arxiv.org/pdf/2601.04389v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04378v1",
      "title": "Aligned explanations in neural networks",
      "abstract": "Feature attribution is the dominant paradigm for explaining deep neural networks. However, most existing methods only loosely reflect the model's prediction-making process, thereby merely white-painting the black box. We argue that explanatory alignment is a key aspect of trustworthiness in prediction tasks: explanations must be directly linked to predictions, rather than serving as post-hoc rationalizations. We present model readability as a design principle enabling alignment, and PiNets as a modeling framework to pursue it in a deep learning context. PiNets are pseudo-linear networks that produce instance-wise linear predictions in an arbitrary feature space, making them linearly readable. We illustrate their use on image classification and segmentation tasks, demonstrating how PiNets produce explanations that are faithful across multiple criteria in addition to alignment.",
      "authors": [
        "Corentin Lobet",
        "Francesca Chiaromonte"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CV",
        "stat.ML"
      ],
      "published": "2026-01-07 20:35:02+00:00",
      "link": "https://arxiv.org/pdf/2601.04378v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04376v1",
      "title": "Combining facial videos and biosignals for stress estimation during driving",
      "abstract": "Reliable stress recognition from facial videos is challenging due to stress's subjective nature and voluntary facial control. While most methods rely on Facial Action Units, the role of disentangled 3D facial geometry remains underexplored. We address this by analyzing stress during distracted driving using EMOCA-derived 3D expression and pose coefficients. Paired hypothesis tests between baseline and stressor phases reveal that 41 of 56 coefficients show consistent, phase-specific stress responses comparable to physiological markers. Building on this, we propose a Transformer-based temporal modeling framework and assess unimodal, early-fusion, and cross-modal attention strategies. Cross-Modal Attention fusion of EMOCA and physiological signals achieves best performance (AUROC 92\\%, Accuracy 86.7\\%), with EMOCA-gaze fusion also competitive (AUROC 91.8\\%). This highlights the effectiveness of temporal modeling and cross-modal attention for stress recognition.",
      "authors": [
        "Paraskevi Valergaki",
        "Vassilis C. Nicodemou",
        "Iason Oikonomidis",
        "Antonis Argyros",
        "Anastasios Roussos"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-07 20:32:34+00:00",
      "link": "https://arxiv.org/pdf/2601.04376v1",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.04367v1",
      "title": "Graph Integrated Transformers for Community Detection in Social Networks",
      "abstract": "Community detection is crucial for applications like targeted marketing and recommendation systems. Traditional methods rely on network structure, and embedding-based models integrate semantic information. However, there is a challenge when a model leverages local and global information from complex structures like social networks. Graph Neural Networks (GNNs) and Transformers have shown superior performance in capturing local and global relationships. In this paper, We propose Graph Integrated Transformer for Community Detection (GIT-CD), a hybrid model combining GNNs and Transformer-based attention mechanisms to enhance community detection in social networks. Specifically, the GNN module captures local graph structures, while the Transformer module models long-range dependencies. A self-optimizing clustering module refines community assignments using K-Means, silhouette loss, and KL divergence minimization. Experimental results on benchmark datasets show that GIT-CD outperforms state-of-the-art models, making it a robust approach for detecting meaningful communities in complex social networks.",
      "authors": [
        "Heba Zahran",
        "M. Omair Shafiq"
      ],
      "primary_category": "cs.SI",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "published": "2026-01-07 20:13:32+00:00",
      "link": "https://arxiv.org/pdf/2601.04367v1",
      "tags": [
        "keyword:大语言模型",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04366v1",
      "title": "Machine Learning Model for Sparse PCM Completion",
      "abstract": "In this paper, we propose a machine learning model for sparse pairwise comparison matrices (PCMs), combining classical PCM approaches with graph-based learning techniques. Numerical results are provided to demonstrate the effectiveness and scalability of the proposed method.",
      "authors": [
        "Selcuk Koyuncu",
        "Ronak Nouri",
        "Stephen Providence"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "math.OC"
      ],
      "published": "2026-01-07 20:13:14+00:00",
      "link": "https://arxiv.org/pdf/2601.04366v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04361v1",
      "title": "Causally-Aware Information Bottleneck for Domain Adaptation",
      "abstract": "We tackle a common domain adaptation setting in causal systems. In this setting, the target variable is observed in the source domain but is entirely missing in the target domain. We aim to impute the target variable in the target domain from the remaining observed variables under various shifts. We frame this as learning a compact, mechanism-stable representation. This representation preserves information relevant for predicting the target while discarding spurious variation. For linear Gaussian causal models, we derive a closed-form Gaussian Information Bottleneck (GIB) solution. This solution reduces to a canonical correlation analysis (CCA)-style projection and offers Directed Acyclic Graph (DAG)-aware options when desired. For nonlinear or non-Gaussian data, we introduce a Variational Information Bottleneck (VIB) encoder-predictor. This approach scales to high dimensions and can be trained on source data and deployed zero-shot to the target domain. Across synthetic and real datasets, our approach consistently attains accurate imputations, supporting practical use in high-dimensional causal models and furnishing a unified, lightweight toolkit for causal domain adaptation.",
      "authors": [
        "Mohammad Ali Javidian"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-07 19:54:58+00:00",
      "link": "https://arxiv.org/pdf/2601.04361v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04359v1",
      "title": "PackCache: A Training-Free Acceleration Method for Unified Autoregressive Video Generation via Compact KV-Cache",
      "abstract": "A unified autoregressive model is a Transformer-based framework that addresses diverse multimodal tasks (e.g., text, image, video) as a single sequence modeling problem under a shared token space. Such models rely on the KV-cache mechanism to reduce attention computation from O(T^2) to O(T); however, KV-cache size grows linearly with the number of generated tokens, and it rapidly becomes the dominant bottleneck limiting inference efficiency and generative length. Unified autoregressive video generation inherits this limitation. Our analysis reveals that KV-cache tokens exhibit distinct spatiotemporal properties: (i) text and conditioning-image tokens act as persistent semantic anchors that consistently receive high attention, and (ii) attention to previous frames naturally decays with temporal distance. Leveraging these observations, we introduce PackCache, a training-free KV-cache management method that dynamically compacts the KV cache through three coordinated mechanisms: condition anchoring that preserves semantic references, cross-frame decay modeling that allocates cache budget according to temporal distance, and spatially preserving position embedding that maintains coherent 3D structure under cache removal. In terms of efficiency, PackCache accelerates end-to-end generation by 1.7-2.2x on 48-frame long sequences, showcasing its strong potential for enabling longer-sequence video generation. Notably, the final four frames - the portion most impacted by the progressively expanding KV-cache and thus the most expensive segment of the clip - PackCache delivers a 2.6x and 3.7x acceleration on A40 and H200, respectively, for 48-frame videos.",
      "authors": [
        "Kunyang Li",
        "Mubarak Shah",
        "Yuzhang Shang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-07 19:51:06+00:00",
      "link": "https://arxiv.org/pdf/2601.04359v1",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.04352v1",
      "title": "Comparative Analysis of Custom CNN Architectures versus Pre-trained Models and Transfer Learning: A Study on Five Bangladesh Datasets",
      "abstract": "This study presents a comprehensive comparative analysis of custom-built Convolutional Neural Networks (CNNs) against popular pre-trained architectures (ResNet-18 and VGG-16) using both feature extraction and transfer learning approaches. We evaluated these models across five diverse image classification datasets from Bangladesh: Footpath Vision, Auto Rickshaw Detection, Mango Image Classification, Paddy Variety Recognition, and Road Damage Detection. Our experimental results demonstrate that transfer learning with fine-tuning consistently outperforms both custom CNNs built from scratch and feature extraction methods, achieving accuracy improvements ranging from 3% to 76% across different datasets. Notably, ResNet-18 with fine-tuning achieved perfect 100% accuracy on the Road Damage BD dataset. While custom CNNs offer advantages in model size (3.4M parameters vs. 11-134M for pre-trained models) and training efficiency on simpler tasks, pre-trained models with transfer learning provide superior performance, particularly on complex classification tasks with limited training data. This research provides practical insights for practitioners in selecting appropriate deep learning approaches based on dataset characteristics, computational resources, and performance requirements.",
      "authors": [
        "Ibrahim Tanvir",
        "Alif Ruslan",
        "Sartaj Solaiman"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-01-07 19:36:41+00:00",
      "link": "https://arxiv.org/pdf/2601.04352v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04348v1",
      "title": "SCAR-GS: Spatial Context Attention for Residuals in Progressive Gaussian Splatting",
      "abstract": "Recent advances in 3D Gaussian Splatting have allowed for real-time, high-fidelity novel view synthesis. Nonetheless, these models have significant storage requirements for large and medium-sized scenes, hindering their deployment over cloud and streaming services. Some of the most recent progressive compression techniques for these models rely on progressive masking and scalar quantization techniques to reduce the bitrate of Gaussian attributes using spatial context models. While effective, scalar quantization may not optimally capture the correlations of high-dimensional feature vectors, which can potentially limit the rate-distortion performance.   In this work, we introduce a novel progressive codec for 3D Gaussian Splatting that replaces traditional methods with a more powerful Residual Vector Quantization approach to compress the primitive features. Our key contribution is an auto-regressive entropy model, guided by a multi-resolution hash grid, that accurately predicts the conditional probability of each successive transmitted index, allowing for coarse and refinement layers to be compressed with high efficiency.",
      "authors": [
        "Diego Revilla",
        "Pooja Suresh",
        "Anand Bhojan",
        "Ooi Wei Tsang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.GR"
      ],
      "published": "2026-01-07 19:34:51+00:00",
      "link": "https://arxiv.org/pdf/2601.04348v1",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.04342v1",
      "title": "ReHyAt: Recurrent Hybrid Attention for Video Diffusion Transformers",
      "abstract": "Recent advances in video diffusion models have shifted towards transformer-based architectures, achieving state-of-the-art video generation but at the cost of quadratic attention complexity, which severely limits scalability for longer sequences. We introduce ReHyAt, a Recurrent Hybrid Attention mechanism that combines the fidelity of softmax attention with the efficiency of linear attention, enabling chunk-wise recurrent reformulation and constant memory usage. Unlike the concurrent linear-only SANA Video, ReHyAt's hybrid design allows efficient distillation from existing softmax-based models, reducing the training cost by two orders of magnitude to ~160 GPU hours, while being competitive in the quality. Our light-weight distillation and finetuning pipeline provides a recipe that can be applied to future state-of-the-art bidirectional softmax-based models. Experiments on VBench and VBench-2.0, as well as a human preference study, demonstrate that ReHyAt achieves state-of-the-art video quality while reducing attention cost from quadratic to linear, unlocking practical scalability for long-duration and on-device video generation. Project page is available at https://qualcomm-ai-research.github.io/rehyat.",
      "authors": [
        "Mohsen Ghafoorian",
        "Amirhossein Habibian"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-07 19:26:30+00:00",
      "link": "https://arxiv.org/pdf/2601.04342v1",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.04339v1",
      "title": "Unified Text-Image Generation with Weakness-Targeted Post-Training",
      "abstract": "Unified multimodal generation architectures that jointly produce text and images have recently emerged as a promising direction for text-to-image (T2I) synthesis. However, many existing systems rely on explicit modality switching, generating reasoning text before switching manually to image generation. This separate, sequential inference process limits cross-modal coupling and prohibits automatic multimodal generation. This work explores post-training to achieve fully unified text-image generation, where models autonomously transition from textual reasoning to visual synthesis within a single inference process. We examine the impact of joint text-image generation on T2I performance and the relative importance of each modality during post-training. We additionally explore different post-training data strategies, showing that a targeted dataset addressing specific limitations achieves superior results compared to broad image-caption corpora or benchmark-aligned data. Using offline, reward-weighted post-training with fully self-generated synthetic data, our approach enables improvements in multimodal image generation across four diverse T2I benchmarks, demonstrating the effectiveness of reward-weighting both modalities and strategically designed post-training data.",
      "authors": [
        "Jiahui Chen",
        "Philippe Hansen-Estruch",
        "Xiaochuang Han",
        "Yushi Hu",
        "Emily Dinan",
        "Amita Kamath",
        "Michal Drozdzal",
        "Reyhane Askari-Hemmat",
        "Luke Zettlemoyer",
        "Marjan Ghazvininejad"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-01-07 19:19:44+00:00",
      "link": "https://arxiv.org/pdf/2601.04339v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04334v1",
      "title": "Autonomous Reasoning for Spacecraft Control: A Large Language Model Framework with Group Relative Policy Optimization",
      "abstract": "This paper presents a learning-based guidance-and-control approach that couples a reasoning-enabled Large Language Model (LLM) with Group Relative Policy Optimization (GRPO). A two-stage procedure consisting of Supervised Fine-Tuning (SFT) to learn formatting and control primitives, followed by GRPO for interaction-driven policy improvement, trains controllers for each environment. The framework is demonstrated on four control problems spanning a gradient of dynamical complexity, from canonical linear systems through nonlinear oscillatory dynamics to three-dimensional spacecraft attitude control with gyroscopic coupling and thrust constraints. Results demonstrate that an LLM with explicit reasoning, optimized via GRPO, can synthesize feasible stabilizing policies under consistent training settings across both linear and nonlinear systems. The two-stage training methodology enables models to generate control sequences while providing human-readable explanations of their decision-making process. This work establishes a foundation for applying GRPO-based reasoning to autonomous control systems, with potential applications in aerospace and other safety-critical domains.",
      "authors": [
        "Amit Jain",
        "Richard Linares"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "math.OC"
      ],
      "published": "2026-01-07 19:13:22+00:00",
      "link": "https://arxiv.org/pdf/2601.04334v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04177v1",
      "title": "Hierarchical GNN-Based Multi-Agent Learning for Dynamic Queue-Jump Lane and Emergency Vehicle Corridor Formation",
      "abstract": "Emergency vehicles require rapid passage through congested traffic, yet existing strategies fail to adapt to dynamic conditions. We propose a novel hierarchical graph neural network (GNN)-based multi-agent reinforcement learning framework to coordinate connected vehicles for emergency corridor formation. Our approach uses a high-level planner for global strategy and low-level controllers for trajectory execution, utilizing graph attention networks to scale with variable agent counts. Trained via Multi-Agent Proximal Policy Optimization (MAPPO), the system reduces emergency vehicle travel time by 28.3% compared to baselines and 44.6% compared to uncoordinated traffic in simulations. The design achieves near-zero collision rates (0.3%) while maintaining 81% of background traffic efficiency. Ablation and generalization studies confirm the framework's robustness across diverse scenarios. These results demonstrate the effectiveness of combining GNNs with hierarchical learning for intelligent transportation systems.",
      "authors": [
        "Haoran Su"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "eess.SY"
      ],
      "published": "2026-01-07 18:43:18+00:00",
      "link": "https://arxiv.org/pdf/2601.04177v1",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.04176v1",
      "title": "Robust Physics Discovery from Highly Corrupted Data: A PINN Framework Applied to the Nonlinear Schrödinger Equation",
      "abstract": "We demonstrate a deep learning framework capable of recovering physical parameters from the Nonlinear Schrodinger Equation (NLSE) under severe noise conditions. By integrating Physics-Informed Neural Networks (PINNs) with automatic differentiation, we achieve reconstruction of the nonlinear coefficient beta with less than 0.2 percent relative error using only 500 sparse, randomly sampled data points corrupted by 20 percent additive Gaussian noise, a regime where traditional finite difference methods typically fail due to noise amplification in numerical derivatives. We validate the method's generalization capabilities across different physical regimes (beta between 0.5 and 2.0) and varying data availability (between 100 and 1000 training points), demonstrating consistent sub-1 percent accuracy. Statistical analysis over multiple independent runs confirms robustness (standard deviation less than 0.15 percent for beta equals 1.0). The complete pipeline executes in approximately 80 minutes on modest cloud GPU resources (NVIDIA Tesla T4), making the approach accessible for widespread adoption. Our results indicate that physics-based regularization acts as an effective filter against high measurement uncertainty, positioning PINNs as a viable alternative to traditional optimization methods for inverse problems in spatiotemporal dynamics where experimental data is scarce and noisy. All code is made publicly available to facilitate reproducibility.",
      "authors": [
        "Pietro de Oliveira Esteves"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "physics.comp-ph"
      ],
      "published": "2026-01-07 18:43:11+00:00",
      "link": "https://arxiv.org/pdf/2601.04176v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04160v2",
      "title": "All That Glisters Is Not Gold: A Benchmark for Reference-Free Counterfactual Financial Misinformation Detection",
      "abstract": "We introduce RFC Bench, a benchmark for evaluating large language models on financial misinformation under realistic news. RFC Bench operates at the paragraph level and captures the contextual complexity of financial news where meaning emerges from dispersed cues. The benchmark defines two complementary tasks: reference free misinformation detection and comparison based diagnosis using paired original perturbed inputs. Experiments reveal a consistent pattern: performance is substantially stronger when comparative context is available, while reference free settings expose significant weaknesses, including unstable predictions and elevated invalid outputs. These results indicate that current models struggle to maintain coherent belief states without external grounding. By highlighting this gap, RFC Bench provides a structured testbed for studying reference free reasoning and advancing more reliable financial misinformation detection in real world settings.",
      "authors": [
        "Yuechen Jiang",
        "Zhiwei Liu",
        "Yupeng Cao",
        "Yueru He",
        "Chen Xu",
        "Ziyang Xu",
        "Zhiyang Deng",
        "Prayag Tiwari",
        "Xi Chen",
        "Alejandro Lopez-Lira",
        "Jimin Huang",
        "Junichi Tsujii",
        "Sophia Ananiadou"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.CE",
        "q-fin.CP"
      ],
      "published": "2026-01-07 18:18:28+00:00",
      "link": "https://arxiv.org/pdf/2601.04160v2",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04159v1",
      "title": "ToTMNet: FFT-Accelerated Toeplitz Temporal Mixing Network for Lightweight Remote Photoplethysmography",
      "abstract": "Remote photoplethysmography (rPPG) estimates a blood volume pulse (BVP) waveform from facial videos captured by commodity cameras. Although recent deep models improve robustness compared to classical signal-processing approaches, many methods increase computational cost and parameter count, and attention-based temporal modeling introduces quadratic scaling with respect to the temporal length. This paper proposes ToTMNet, a lightweight rPPG architecture that replaces temporal attention with an FFT-accelerated Toeplitz temporal mixing layer. The Toeplitz operator provides full-sequence temporal receptive field using a linear number of parameters in the clip length and can be applied in near-linear time using circulant embedding and FFT-based convolution. ToTMNet integrates the global Toeplitz temporal operator into a compact gated temporal mixer that combines a local depthwise temporal convolution branch with gated global Toeplitz mixing, enabling efficient long-range temporal filtering while only having 63k parameters. Experiments on two datasets, UBFC-rPPG (real videos) and SCAMPS (synthetic videos), show that ToTMNet achieves strong heart-rate estimation accuracy with a compact design. On UBFC-rPPG intra-dataset evaluation, ToTMNet reaches 1.055 bpm MAE with Pearson correlation 0.996. In a synthetic-to-real setting (SCAMPS to UBFC-rPPG), ToTMNet reaches 1.582 bpm MAE with Pearson correlation 0.994. Ablation results confirm that the gating mechanism is important for effectively using global Toeplitz mixing, especially under domain shift. The main limitation of this preprint study is the use of only two datasets; nevertheless, the results indicate that Toeplitz-structured temporal mixing is a practical and efficient alternative to attention for rPPG.",
      "authors": [
        "Vladimir Frants",
        "Sos Agaian",
        "Karen Panetta"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-07 18:15:09+00:00",
      "link": "https://arxiv.org/pdf/2601.04159v1",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.04151v1",
      "title": "Klear: Unified Multi-Task Audio-Video Joint Generation",
      "abstract": "Audio-video joint generation has progressed rapidly, yet substantial challenges still remain. Non-commercial approaches still suffer audio-visual asynchrony, poor lip-speech alignment, and unimodal degradation, which can be stemmed from weak audio-visual correspondence modeling, limited generalization, and scarce high-quality dense-caption data. To address these issues, we introduce Klear and delve into three axes--model architecture, training strategy, and data curation. Architecturally, we adopt a single-tower design with unified DiT blocks and an Omni-Full Attention mechanism, achieving tight audio-visual alignment and strong scalability. Training-wise, we adopt a progressive multitask regime--random modality masking to joint optimization across tasks, and a multistage curriculum, yielding robust representations, strengthening A-V aligned world knowledge, and preventing unimodal collapse. For datasets, we present the first large-scale audio-video dataset with dense captions, and introduce a novel automated data-construction pipeline which annotates and filters millions of diverse, high-quality, strictly aligned audio-video-caption triplets. Building on this, Klear scales to large datasets, delivering high-fidelity, semantically and temporally aligned, instruction-following generation in both joint and unimodal settings while generalizing robustly to out-of-distribution scenarios. Across tasks, it substantially outperforms prior methods by a large margin and achieves performance comparable to Veo 3, offering a unified, scalable path toward next-generation audio-video synthesis.",
      "authors": [
        "Jun Wang",
        "Chunyu Qiang",
        "Yuxin Guo",
        "Yiran Wang",
        "Xijuan Zeng",
        "Chen Zhang",
        "Pengfei Wan"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM",
        "cs.SD"
      ],
      "published": "2026-01-07 18:03:45+00:00",
      "link": "https://arxiv.org/pdf/2601.04151v1",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.04299v1",
      "title": "Transformer-Based Multi-Modal Temporal Embeddings for Explainable Metabolic Phenotyping in Type 1 Diabetes",
      "abstract": "Type 1 diabetes (T1D) is a highly metabolically heterogeneous disease that cannot be adequately characterized by conventional biomarkers such as glycated hemoglobin (HbA1c). This study proposes an explainable deep learning framework that integrates continuous glucose monitoring (CGM) data with laboratory profiles to learn multimodal temporal embeddings of individual metabolic status. Temporal dependencies across modalities are modeled using a transformer encoder, while latent metabolic phenotypes are identified via Gaussian mixture modeling. Model interpretability is achieved through transformer attention visualization and SHAP-based feature attribution. Five latent metabolic phenotypes, ranging from metabolic stability to elevated cardiometabolic risk, were identified among 577 individuals with T1D. These phenotypes exhibit distinct biochemical profiles, including differences in glycemic control, lipid metabolism, renal markers, and thyrotropin (TSH) levels. Attention analysis highlights glucose variability as a dominant temporal factor, while SHAP analysis identifies HbA1c, triglycerides, cholesterol, creatinine, and TSH as key contributors to phenotype differentiation. Phenotype membership shows statistically significant, albeit modest, associations with hypertension, myocardial infarction, and heart failure. Overall, this explainable multimodal temporal embedding framework reveals physiologically coherent metabolic subgroups in T1D and supports risk stratification beyond single biomarkers.",
      "authors": [
        "Pir Bakhsh Khokhar",
        "Carmine Gravino",
        "Fabio Palomba",
        "Sule Yildrim Yayilgan",
        "Sarang Shaikh"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "q-bio.QM"
      ],
      "published": "2026-01-07 18:01:12+00:00",
      "link": "https://arxiv.org/pdf/2601.04299v1",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.04131v1",
      "title": "ContextFocus: Activation Steering for Contextual Faithfulness in Large Language Models",
      "abstract": "Large Language Models (LLMs) encode vast amounts of parametric knowledge during pre-training. As world knowledge evolves, effective deployment increasingly depends on their ability to faithfully follow externally retrieved context. When such evidence conflicts with the model's internal knowledge, LLMs often default to memorized facts, producing unfaithful outputs. In this work, we introduce ContextFocus, a lightweight activation steering approach that improves context faithfulness in such knowledge-conflict settings while preserving fluency and efficiency. Unlike prior approaches, our solution requires no model finetuning and incurs minimal inference-time overhead, making it highly efficient. We evaluate ContextFocus on the ConFiQA benchmark, comparing it against strong baselines including ContextDPO, COIECD, and prompting-based methods. Furthermore, we show that our method is complementary to prompting strategies and remains effective on larger models. Extensive experiments show that ContextFocus significantly improves contextual-faithfulness. Our results highlight the effectiveness, robustness, and efficiency of ContextFocus in improving contextual-faithfulness of LLM outputs.",
      "authors": [
        "Nikhil Anand",
        "Shwetha Somasundaram",
        "Anirudh Phukan",
        "Apoorv Saxena",
        "Koyel Mukherjee"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-07 17:45:20+00:00",
      "link": "https://arxiv.org/pdf/2601.04131v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04127v1",
      "title": "Pixel-Wise Multimodal Contrastive Learning for Remote Sensing Images",
      "abstract": "Satellites continuously generate massive volumes of data, particularly for Earth observation, including satellite image time series (SITS). However, most deep learning models are designed to process either entire images or complete time series sequences to extract meaningful features for downstream tasks. In this study, we propose a novel multimodal approach that leverages pixel-wise two-dimensional (2D) representations to encode visual property variations from SITS more effectively. Specifically, we generate recurrence plots from pixel-based vegetation index time series (NDVI, EVI, and SAVI) as an alternative to using raw pixel values, creating more informative representations. Additionally, we introduce PIxel-wise Multimodal Contrastive (PIMC), a new multimodal self-supervision approach that produces effective encoders based on two-dimensional pixel time series representations and remote sensing imagery (RSI). To validate our approach, we assess its performance on three downstream tasks: pixel-level forecasting and classification using the PASTIS dataset, and land cover classification on the EuroSAT dataset. Moreover, we compare our results to state-of-the-art (SOTA) methods on all downstream tasks. Our experimental results show that the use of 2D representations significantly enhances feature extraction from SITS, while contrastive learning improves the quality of representations for both pixel time series and RSI. These findings suggest that our multimodal method outperforms existing models in various Earth observation tasks, establishing it as a robust self-supervision framework for processing both SITS and RSI. Code avaliable on",
      "authors": [
        "Leandro Stival",
        "Ricardo da Silva Torres",
        "Helio Pedrini"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-01-07 17:41:11+00:00",
      "link": "https://arxiv.org/pdf/2601.04127v1",
      "tags": [
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.04121v1",
      "title": "MORPHFED: Federated Learning for Cross-institutional Blood Morphology Analysis",
      "abstract": "Automated blood morphology analysis can support hematological diagnostics in low- and middle-income countries (LMICs) but remains sensitive to dataset shifts from staining variability, imaging differences, and rare morphologies. Building centralized datasets to capture this diversity is often infeasible due to privacy regulations and data-sharing restrictions. We introduce a federated learning framework for white blood cell morphology analysis that enables collaborative training across institutions without exchanging training data. Using blood films from multiple clinical sites, our federated models learn robust, domain-invariant representations while preserving complete data privacy. Evaluations across convolutional and transformer-based architectures show that federated training achieves strong cross-site performance and improved generalization to unseen institutions compared to centralized training. These findings highlight federated learning as a practical and privacy-preserving approach for developing equitable, scalable, and generalizable medical imaging AI in resource-limited healthcare environments.",
      "authors": [
        "Gabriel Ansah",
        "Eden Ruffell",
        "Delmiro Fernandez-Reyes",
        "Petru Manescu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CV"
      ],
      "published": "2026-01-07 17:32:24+00:00",
      "link": "https://arxiv.org/pdf/2601.04121v1",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.04120v1",
      "title": "A Single-Loop Bilevel Deep Learning Method for Optimal Control of Obstacle Problems",
      "abstract": "Optimal control of obstacle problems arises in a wide range of applications and is computationally challenging due to its nonsmoothness, nonlinearity, and bilevel structure. Classical numerical approaches rely on mesh-based discretization and typically require solving a sequence of costly subproblems. In this work, we propose a single-loop bilevel deep learning method, which is mesh-free, scalable to high-dimensional and complex domains, and avoids repeated solution of discretized subproblems. The method employs constraint-embedding neural networks to approximate the state and control and preserves the bilevel structure. To train the neural networks efficiently, we propose a Single-Loop Stochastic First-Order Bilevel Algorithm (S2-FOBA), which eliminates nested optimization and does not rely on restrictive lower-level uniqueness assumptions. We analyze the convergence behavior of S2-FOBA under mild assumptions. Numerical experiments on benchmark examples, including distributed and obstacle control problems with regular and irregular obstacles on complex domains, demonstrate that the proposed method achieves satisfactory accuracy while reducing computational cost compared to classical numerical methods.",
      "authors": [
        "Yongcun Song",
        "Shangzhi Zeng",
        "Jin Zhang",
        "Lvgang Zhang"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC",
        "cs.LG"
      ],
      "published": "2026-01-07 17:30:42+00:00",
      "link": "https://arxiv.org/pdf/2601.04120v1",
      "tags": [
        "keyword:resnet",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04118v2",
      "title": "GeoReason: Aligning Thinking And Answering In Remote Sensing Vision-Language Models Via Logical Consistency Reinforcement Learning",
      "abstract": "The evolution of Remote Sensing Vision-Language Models(RS-VLMs) emphasizes the importance of transitioning from perception-centric recognition toward high-level deductive reasoning to enhance cognitive reliability in complex spatial tasks. However, current models often suffer from logical hallucinations, where correct answers are derived from flawed reasoning chains or rely on positional shortcuts rather than spatial logic. This decoupling undermines reliability in strategic spatial decision-making. To address this, we present GeoReason, a framework designed to synchronize internal thinking with final decisions. We first construct GeoReason-Bench, a logic-driven dataset containing 4,000 reasoning trajectories synthesized from geometric primitives and expert knowledge. We then formulate a two-stage training strategy: (1) Supervised Knowledge Initialization to equip the model with reasoning syntax and domain expertise, and (2) Consistency-Aware Reinforcement Learning to refine deductive reliability. This second stage integrates a novel Logical Consistency Reward, which penalizes logical drift via an option permutation strategy to anchor decisions in verifiable reasoning traces. Experimental results demonstrate that our framework significantly enhances the cognitive reliability and interpretability of RS-VLMs, achieving state-of-the-art performance compared to other advanced methods.",
      "authors": [
        "Wenshuai Li",
        "Xiantai Xiang",
        "Zixiao Wen",
        "Guangyao Zhou",
        "Ben Niu",
        "Feng Wang",
        "Lijia Huang",
        "Qiantong Wang",
        "Yuxin Hu"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-07 17:26:41+00:00",
      "link": "https://arxiv.org/pdf/2601.04118v2",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.04098v1",
      "title": "Layer-wise Positional Bias in Short-Context Language Modeling",
      "abstract": "Language models often show a preference for using information from specific positions in the input regardless of semantic relevance. While positional bias has been studied in various contexts, from attention sinks to task performance degradation in long-context settings, prior work has not established how these biases evolve across individual layers and input positions, or how they vary independent of task complexity. We introduce an attribution-based framework to analyze positional effects in short-context language modeling. Using layer conductance with a sliding-window approach, we quantify how each layer distributes importance across input positions, yielding layer-wise positional importance profiles. We find that these profiles are architecture-specific, stable across inputs, and invariant to lexical scrambling. Characterizing these profiles, we find prominent recency bias that increases with depth and subtle primacy bias that diminishes through model depth. Beyond positional structure, we also show that early layers preferentially weight content words over function words across all positions, while later layers lose this word-type differentiation.",
      "authors": [
        "Maryam Rahimi",
        "Mahdi Nouri",
        "Yadollah Yaghoobzadeh"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-07 17:04:30+00:00",
      "link": "https://arxiv.org/pdf/2601.04098v1",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.04065v1",
      "title": "Unsupervised Modular Adaptive Region Growing and RegionMix Classification for Wind Turbine Segmentation",
      "abstract": "Reliable operation of wind turbines requires frequent inspections, as even minor surface damages can degrade aerodynamic performance, reduce energy output, and accelerate blade wear. Central to automating these inspections is the accurate segmentation of turbine blades from visual data. This task is traditionally addressed through dense, pixel-wise deep learning models. However, such methods demand extensive annotated datasets, posing scalability challenges. In this work, we introduce an annotation-efficient segmentation approach that reframes the pixel-level task into a binary region classification problem. Image regions are generated using a fully unsupervised, interpretable Modular Adaptive Region Growing technique, guided by image-specific Adaptive Thresholding and enhanced by a Region Merging process that consolidates fragmented areas into coherent segments. To improve generalization and classification robustness, we introduce RegionMix, an augmentation strategy that synthesizes new training samples by combining distinct regions. Our framework demonstrates state-of-the-art segmentation accuracy and strong cross-site generalization by consistently segmenting turbine blades across distinct windfarms.",
      "authors": [
        "Raül Pérez-Gonzalo",
        "Riccardo Magro",
        "Andreas Espersen",
        "Antonio Agudo"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-01-07 16:29:52+00:00",
      "link": "https://arxiv.org/pdf/2601.04065v1",
      "tags": [
        "keyword:resnet",
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.04058v1",
      "title": "Minimum distance classification for nonlinear dynamical systems",
      "abstract": "We address the problem of classifying trajectory data generated by some nonlinear dynamics, where each class corresponds to a distinct dynamical system. We propose Dynafit, a kernel-based method for learning a distance metric between training trajectories and the underlying dynamics. New observations are assigned to the class with the most similar dynamics according to the learned metric. The learning algorithm approximates the Koopman operator which globally linearizes the dynamics in a (potentially infinite) feature space associated with a kernel function. The distance metric is computed in feature space independently of its dimensionality by using the kernel trick common in machine learning. We also show that the kernel function can be tailored to incorporate partial knowledge of the dynamics when available. Dynafit is applicable to various classification tasks involving nonlinear dynamical systems and sensors. We illustrate its effectiveness on three examples: chaos detection with the logistic map, recognition of handwritten dynamics and of visual dynamic textures.",
      "authors": [
        "Dominique Martinez"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 16:21:47+00:00",
      "link": "https://arxiv.org/pdf/2601.04058v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04057v1",
      "title": "Using Legacy Polysomnography Data to Train a Radar System to Quantify Sleep in Older Adults and People living with Dementia",
      "abstract": "Objective: Ultra-wideband radar technology offers a promising solution for unobtrusive and cost-effective in-home sleep monitoring. However, the limited availability of radar sleep data poses challenges in building robust models that generalize across diverse cohorts and environments. This study proposes a novel deep transfer learning framework to enhance sleep stage classification using radar data. Methods: An end-to-end neural network was developed to classify sleep stages based on nocturnal respiratory and motion signals. The network was trained using a combination of large-scale polysomnography (PSG) datasets and radar data. A domain adaptation approach employing adversarial learning was utilized to bridge the knowledge gap between PSG and radar signals. Validation was performed on a radar dataset of 47 older adults (mean age: 71.2), including 18 participants with prodromal or mild Alzheimer disease. Results: The proposed network structure achieves an accuracy of 79.5% with a Kappa value of 0.65 when classifying wakefulness, rapid eye movement, light sleep and deep sleep. Experimental results confirm that our deep transfer learning approach significantly enhances automatic sleep staging performance in the target domain. Conclusion: This method effectively addresses challenges associated with data variability and limited sample size, substantially improving the reliability of automatic sleep staging models, especially in contexts where radar data is limited. Significance: The findings underscore the viability of UWB radar as a nonintrusive, forward-looking sleep assessment tool that could significantly benefit care for older people and people with neurodegenerative disorders.",
      "authors": [
        "M. Yin",
        "K. G. Ravindran",
        "C. Hadjipanayi",
        "A. Bannon",
        "A. Rapeaux",
        "C. Della Monica",
        "T. S. Lande",
        "Derk-Jan Dijk",
        "T. G. Constandinou"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 16:21:27+00:00",
      "link": "https://arxiv.org/pdf/2601.04057v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04054v1",
      "title": "LinkD: AutoRegressive Diffusion Model for Mechanical Linkage Synthesis",
      "abstract": "Designing mechanical linkages to achieve target end-effector trajectories presents a fundamental challenge due to the intricate coupling between continuous node placements, discrete topological configurations, and nonlinear kinematic constraints. The highly nonlinear motion-to-configuration relationship means small perturbations in joint positions drastically alter trajectories, while the combinatorially expanding design space renders conventional optimization and heuristic methods computationally intractable. We introduce an autoregressive diffusion framework that exploits the dyadic nature of linkage assembly by representing mechanisms as sequentially constructed graphs, where nodes correspond to joints and edges to rigid links. Our approach combines a causal transformer with a Denoising Diffusion Probabilistic Model (DDPM), both conditioned on target trajectories encoded via a transformer encoder. The causal transformer autoregressively predicts discrete topology node-by-node, while the DDPM refines each node's spatial coordinates and edge connectivity to previously generated nodes. This sequential generation enables adaptive trial-and-error synthesis where problematic nodes exhibiting kinematic locking or collisions can be selectively regenerated, allowing autonomous correction of degenerate configurations during design. Our graph-based, data-driven methodology surpasses traditional optimization approaches, enabling scalable inverse design that generalizes to mechanisms with arbitrary node counts. We demonstrate successful synthesis of linkage systems containing up to 20 nodes with extensibility to N-node architectures. This work advances autoregressive graph generation methodologies and computational kinematic synthesis, establishing new paradigms for scalable inverse design of complex mechanical systems.",
      "authors": [
        "Yayati Jadhav",
        "Amir Barati Farimani"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 16:19:11+00:00",
      "link": "https://arxiv.org/pdf/2601.04054v1",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.04052v1",
      "title": "Stable Language Guidance for Vision-Language-Action Models",
      "abstract": "Vision-Language-Action (VLA) models have demonstrated impressive capabilities in generalized robotic control; however, they remain notoriously brittle to linguistic perturbations. We identify a critical ``modality collapse'' phenomenon where strong visual priors overwhelm sparse linguistic signals, causing agents to overfit to specific instruction phrasings while ignoring the underlying semantic intent. To address this, we propose \\textbf{Residual Semantic Steering (RSS)}, a probabilistic framework that disentangles physical affordance from semantic execution. RSS introduces two theoretical innovations: (1) \\textbf{Monte Carlo Syntactic Integration}, which approximates the true semantic posterior via dense, LLM-driven distributional expansion, and (2) \\textbf{Residual Affordance Steering}, a dual-stream decoding mechanism that explicitly isolates the causal influence of language by subtracting the visual affordance prior. Theoretical analysis suggests that RSS effectively maximizes the mutual information between action and intent while suppressing visual distractors. Empirical results across diverse manipulation benchmarks demonstrate that RSS achieves state-of-the-art robustness, maintaining performance even under adversarial linguistic perturbations.",
      "authors": [
        "Zhihao Zhan",
        "Yuhao Chen",
        "Jiaying Zhou",
        "Qinhan Lv",
        "Hao Liu",
        "Keze Wang",
        "Liang Lin",
        "Guangrun Wang"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.CL"
      ],
      "published": "2026-01-07 16:16:10+00:00",
      "link": "https://arxiv.org/pdf/2601.04052v1",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.04051v1",
      "title": "Symbolic Regression for Shared Expressions: Introducing Partial Parameter Sharing",
      "abstract": "Symbolic Regression aims to find symbolic expressions that describe datasets. Due to better interpretability, it is a machine learning paradigm particularly powerful for scientific discovery. In recent years, several works have expanded the concept to allow the description of similar phenomena using a single expression with varying sets of parameters, thereby introducing categorical variables. Some previous works allow only \"non-shared\" (category-value-specific) parameters, and others also incorporate \"shared\" (category-value-agnostic) parameters. We expand upon those efforts by considering multiple categorical variables, and introducing intermediate levels of parameter sharing. With two categorical variables, an intermediate level of parameter sharing emerges, i.e., parameters which are shared across either category but change across the other. The new approach potentially decreases the number of parameters, while revealing additional information about the problem. Using a synthetic, fitting-only example, we test the limits of this setup in terms of data requirement reduction and transfer learning. As a real-world symbolic regression example, we demonstrate the benefits of the proposed approach on an astrophysics dataset used in a previous study, which considered only one categorical variable. We achieve a similar fit quality but require significantly fewer individual parameters, and extract additional information about the problem.",
      "authors": [
        "Viktor Martinek",
        "Roland Herzog"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 16:12:14+00:00",
      "link": "https://arxiv.org/pdf/2601.04051v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04043v1",
      "title": "When Helpers Become Hazards: A Benchmark for Analyzing Multimodal LLM-Powered Safety in Daily Life",
      "abstract": "As Multimodal Large Language Models (MLLMs) become an indispensable assistant in human life, the unsafe content generated by MLLMs poses a danger to human behavior, perpetually overhanging human society like a sword of Damocles. To investigate and evaluate the safety impact of MLLMs responses on human behavior in daily life, we introduce SaLAD, a multimodal safety benchmark which contains 2,013 real-world image-text samples across 10 common categories, with a balanced design covering both unsafe scenarios and cases of oversensitivity. It emphasizes realistic risk exposure, authentic visual inputs, and fine-grained cross-modal reasoning, ensuring that safety risks cannot be inferred from text alone. We further propose a safety-warning-based evaluation framework that encourages models to provide clear and informative safety warnings, rather than generic refusals. Results on 18 MLLMs demonstrate that the top-performing models achieve a safe response rate of only 57.2% on unsafe queries. Moreover, even popular safety alignment methods limit effectiveness of the models in our scenario, revealing the vulnerabilities of current MLLMs in identifying dangerous behaviors in daily life. Our dataset is available at https://github.com/xinyuelou/SaLAD.",
      "authors": [
        "Xinyue Lou",
        "Jinan Xu",
        "Jingyi Yin",
        "Xiaolong Wang",
        "Zhaolu Kang",
        "Youwei Liao",
        "Yixuan Wang",
        "Xiangyu Shi",
        "Fengran Mo",
        "Su Yao",
        "Kaiyu Huang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 15:59:07+00:00",
      "link": "https://arxiv.org/pdf/2601.04043v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04293v1",
      "title": "A Systematic Mapping Study on the Debugging of Autonomous Driving Systems",
      "abstract": "As Autonomous Driving Systems (ADS) progress towards commercial deployment, there is an increasing focus on ensuring their safety and reliability. While considerable research has been conducted on testing methods for detecting faults in ADS, very little attention has been paid to debugging in ADS. Debugging is an essential process that follows test failures to localise and repair the faults in the systems to maintain their safety and reliability. This Systematic Mapping Study (SMS) aims to provide a detailed overview of the current landscape of ADS debugging, highlighting existing approaches and identifying gaps in research. The study also proposes directions for future work and standards for problem definition and terminology in the field. Our findings reveal various methods for ADS debugging and highlight the current fragmented yet promising landscape.",
      "authors": [
        "Nathan Shaw",
        "Sanjeetha Pennada",
        "Robert M Hierons",
        "Donghwan Shin"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE"
      ],
      "published": "2026-01-07 15:50:55+00:00",
      "link": "https://arxiv.org/pdf/2601.04293v1",
      "tags": [
        "keyword:resnet",
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.04025v1",
      "title": "Simulated Students in Tutoring Dialogues: Substance or Illusion?",
      "abstract": "Advances in large language models (LLMs) enable many new innovations in education. However, evaluating the effectiveness of new technology requires real students, which is time-consuming and hard to scale up. Therefore, many recent works on LLM-powered tutoring solutions have used simulated students for both training and evaluation, often via simple prompting. Surprisingly, little work has been done to ensure or even measure the quality of simulated students. In this work, we formally define the student simulation task, propose a set of evaluation metrics that span linguistic, behavioral, and cognitive aspects, and benchmark a wide range of student simulation methods on these metrics. We experiment on a real-world math tutoring dialogue dataset, where both automated and human evaluation results show that prompting strategies for student simulation perform poorly; supervised fine-tuning and preference optimization yield much better but still limited performance, motivating future work on this challenging task.",
      "authors": [
        "Alexander Scarlatos",
        "Jaewook Lee",
        "Simon Woodhead",
        "Andrew Lan"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.CY"
      ],
      "published": "2026-01-07 15:44:11+00:00",
      "link": "https://arxiv.org/pdf/2601.04025v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04011v1",
      "title": "Flexible-Duplex Cell-Free Architecture for Secure Uplink Communications in Low-Altitude Wireless Networks",
      "abstract": "Low-altitude wireless networks (LAWNs) are expected to play a central role in future 6G infrastructures, yet uplink transmissions of uncrewed aerial vehicles (UAVs) remain vulnerable to eavesdropping due to their limited transmit power, constrained antenna resources, and highly exposed air-ground propagation conditions. To address this fundamental bottleneck, we propose a flexible-duplex cell-free (CF) architecture in which each distributed access point (AP) can dynamically operate either as a receive AP for UAV uplink collection or as a transmit AP that generates cooperative artificial noise (AN) for secrecy enhancement. Such AP-level duplex flexibility introduces an additional spatial degree of freedom that enables distributed and adaptive protection against wiretapping in LAWNs. Building upon this architecture, we formulate a max-min secrecy-rate problem that jointly optimizes AP mode selection, receive combining, and AN covariance design. This tightly coupled and nonconvex optimization is tackled by first deriving the optimal receive combiners in closed form, followed by developing a penalty dual decomposition (PDD) algorithm with guaranteed convergence to a stationary solution. To further reduce computational burden, we propose a low-complexity sequential scheme that determines AP modes via a heuristic metric and then updates the AN covariance matrices through closed-form iterations embedded in the PDD framework. Simulation results show that the proposed flexible-duplex architecture yields substantial secrecy-rate gains over CF systems with fixed AP roles. The joint optimization method attains the highest secrecy performance, while the low-complexity approach achieves over 90% of the optimal performance with an order-of-magnitude lower computational complexity, offering a practical solution for secure uplink communications in LAWNs.",
      "authors": [
        "Wei Shi",
        "Wei Xu",
        "Yongming Huang",
        "Jiacheng Yao",
        "Wenhao Hu",
        "Dongming Wang"
      ],
      "primary_category": "cs.IT",
      "categories": [
        "cs.IT",
        "eess.SP"
      ],
      "published": "2026-01-07 15:20:26+00:00",
      "link": "https://arxiv.org/pdf/2601.04011v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04005v1",
      "title": "Padé Neurons for Efficient Neural Models",
      "abstract": "Neural networks commonly employ the McCulloch-Pitts neuron model, which is a linear model followed by a point-wise non-linear activation. Various researchers have already advanced inherently non-linear neuron models, such as quadratic neurons, generalized operational neurons, generative neurons, and super neurons, which offer stronger non-linearity compared to point-wise activation functions. In this paper, we introduce a novel and better non-linear neuron model called Padé neurons (Paons), inspired by Padé approximants. Paons offer several advantages, such as diversity of non-linearity, since each Paon learns a different non-linear function of its inputs, and layer efficiency, since Paons provide stronger non-linearity in much fewer layers compared to piecewise linear approximation. Furthermore, Paons include all previously proposed neuron models as special cases, thus any neuron model in any network can be replaced by Paons. We note that there has been a proposal to employ the Padé approximation as a generalized point-wise activation function, which is fundamentally different from our model. To validate the efficacy of Paons, in our experiments, we replace classic neurons in some well-known neural image super-resolution, compression, and classification models based on the ResNet architecture with Paons. Our comprehensive experimental results and analyses demonstrate that neural models built by Paons provide better or equal performance than their classic counterparts with a smaller number of layers. The PyTorch implementation code for Paon is open-sourced at https://github.com/onur-keles/Paon.",
      "authors": [
        "Onur Keleş",
        "A. Murat Tekalp"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "eess.IV"
      ],
      "published": "2026-01-07 15:15:30+00:00",
      "link": "https://arxiv.org/pdf/2601.04005v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03997v2",
      "title": "VotIE: Information Extraction from Meeting Minutes",
      "abstract": "Municipal meeting minutes record key decisions in local democratic processes. Unlike parliamentary proceedings, which typically adhere to standardized formats, they encode voting outcomes in highly heterogeneous, free-form narrative text that varies widely across municipalities, posing significant challenges for automated extraction. In this paper, we introduce VotIE (Voting Information Extraction), a new information extraction task aimed at identifying structured voting events in narrative deliberative records, and establish the first benchmark for this task using Portuguese municipal minutes, building on the recently introduced CitiLink corpus. Our experiments yield two key findings. First, under standard in-domain evaluation, fine-tuned encoders, specifically XLM-R-CRF, achieve the strongest performance, reaching 93.2\\% macro F1, outperforming generative approaches. Second, in a cross-municipality setting that evaluates transfer to unseen administrative contexts, these models suffer substantial performance degradation, whereas few-shot LLMs demonstrate greater robustness, with significantly smaller declines in performance. Despite this generalization advantage, the high computational cost of generative models currently constrains their practicality. As a result, lightweight fine-tuned encoders remain a more practical option for large-scale, real-world deployment. To support reproducible research in administrative NLP, we publicly release our benchmark, trained models, and evaluation framework.",
      "authors": [
        "José Pedro Evans",
        "Luís Filipe Cunha",
        "Purificação Silvano",
        "Alípio Jorge",
        "Nuno Guimarães",
        "Sérgio Nunes",
        "Ricardo Campos"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 15:06:53+00:00",
      "link": "https://arxiv.org/pdf/2601.03997v2",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03986v1",
      "title": "Benchmark^2: Systematic Evaluation of LLM Benchmarks",
      "abstract": "The rapid proliferation of benchmarks for evaluating large language models (LLMs) has created an urgent need for systematic methods to assess benchmark quality itself. We propose Benchmark^2, a comprehensive framework comprising three complementary metrics: (1) Cross-Benchmark Ranking Consistency, measuring whether a benchmark produces model rankings aligned with peer benchmarks; (2) Discriminability Score, quantifying a benchmark's ability to differentiate between models; and (3) Capability Alignment Deviation, identifying problematic instances where stronger models fail but weaker models succeed within the same model family. We conduct extensive experiments across 15 benchmarks spanning mathematics, reasoning, and knowledge domains, evaluating 11 LLMs across four model families. Our analysis reveals significant quality variations among existing benchmarks and demonstrates that selective benchmark construction based on our metrics can achieve comparable evaluation performance with substantially reduced test sets.",
      "authors": [
        "Qi Qian",
        "Chengsong Huang",
        "Jingwen Xu",
        "Changze Lv",
        "Muling Wu",
        "Wenhao Liu",
        "Xiaohua Wang",
        "Zhenghua Wang",
        "Zisu Huang",
        "Muzhao Tian",
        "Jianhan Xu",
        "Kun Hu",
        "He-Da Wang",
        "Yao Hu",
        "Xuanjing Huang",
        "Xiaoqing Zheng"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 14:59:03+00:00",
      "link": "https://arxiv.org/pdf/2601.03986v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03981v1",
      "title": "RADAR: Retrieval-Augmented Detector with Adversarial Refinement for Robust Fake News Detection",
      "abstract": "To efficiently combat the spread of LLM-generated misinformation, we present RADAR, a retrieval-augmented detector with adversarial refinement for robust fake news detection. Our approach employs a generator that rewrites real articles with factual perturbations, paired with a lightweight detector that verifies claims using dense passage retrieval. To enable effective co-evolution, we introduce verbal adversarial feedback (VAF). Rather than relying on scalar rewards, VAF issues structured natural-language critiques; these guide the generator toward more sophisticated evasion attempts, compelling the detector to adapt and improve. On a fake news detection benchmark, RADAR achieves 86.98% ROC-AUC, significantly outperforming general-purpose LLMs with retrieval. Ablation studies confirm that detector-side retrieval yields the largest gains, while VAF and few-shot demonstrations provide critical signals for robust training.",
      "authors": [
        "Song-Duo Ma",
        "Yi-Hung Liu",
        "Hsin-Yu Lin",
        "Pin-Yu Chen",
        "Hong-Yan Huang",
        "Shau-Yung Hsu",
        "Yun-Nung Chen"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 14:52:15+00:00",
      "link": "https://arxiv.org/pdf/2601.03981v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03977v1",
      "title": "Stage-specific cancer survival prediction enriched by explainable machine learning",
      "abstract": "Despite the fact that cancer survivability rates vary greatly between stages, traditional survival prediction models have frequently been trained and assessed using examples from all combined phases of the disease. This method may result in an overestimation of performance and ignore the stage-specific variations. Using the SEER dataset, we created and verified explainable machine learning (ML) models to predict stage-specific cancer survivability in colorectal, stomach, and liver cancers. ML-based cancer survival analysis has been a long-standing topic in the literature; however, studies involving the explainability and transparency of ML survivability models are limited. Our use of explainability techniques, including SHapley Additive exPlanations (SHAP) and Local Interpretable Model-agnostic Explanations (LIME), enabled us to illustrate significant feature-cancer stage interactions that would have remained hidden in traditional black-box models. We identified how certain demographic and clinical variables influenced survival differently across cancer stages and types. These insights provide not only transparency but also clinical relevance, supporting personalized treatment planning. By focusing on stage-specific models, this study provides new insights into the most important factors at each stage of cancer, offering transparency and potential clinical relevance to support personalized treatment planning.",
      "authors": [
        "Parisa Poorhasani",
        "Bogdan Iancu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 14:44:04+00:00",
      "link": "https://arxiv.org/pdf/2601.03977v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03976v1",
      "title": "On-Device Deep Reinforcement Learning for Decentralized Task Offloading Performance trade-offs in the training process",
      "abstract": "Allowing less capable devices to offload computational tasks to more powerful devices or servers enables the development of new applications that may not run correctly on the device itself. Deciding where and why to run each of those applications is a complex task. Therefore, different approaches have been adopted to make offloading decisions. In this work, we propose a decentralized Deep Reinforcement Learning (DRL) agent to address the selection of computing locations. Unlike most existing work, we analyze it in a real testbed composed of various edge devices running the agent to determine where to execute each task. These devices are connected to a Multi-Access Edge Computing (MEC) server and a Cloud server through 5G communications. We evaluate not only the agent's performance in meeting task requirements but also the implications of running this type of agent locally, assessing the trade-offs of training locally versus remotely in terms of latency and energy consumption.",
      "authors": [
        "Gorka Nieto",
        "Idoia de la Iglesia",
        "Cristina Perfecto",
        "Unai Lopez-Novoa"
      ],
      "primary_category": "cs.ET",
      "categories": [
        "cs.ET",
        "eess.SY"
      ],
      "published": "2026-01-07 14:43:35+00:00",
      "link": "https://arxiv.org/pdf/2601.03976v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03969v1",
      "title": "Anti-Length Shift: Dynamic Outlier Truncation for Training Efficient Reasoning Models",
      "abstract": "Large reasoning models enhanced by reinforcement learning with verifiable rewards have achieved significant performance gains by extending their chain-of-thought. However, this paradigm incurs substantial deployment costs as models often exhibit excessive verbosity on simple queries. Existing efficient reasoning methods relying on explicit length penalties often introduce optimization conflicts and leave the generative mechanisms driving overthinking largely unexamined. In this paper, we identify a phenomenon termed length shift where models increasingly generate unnecessary reasoning on trivial inputs during training. To address this, we introduce Dynamic Outlier Truncation (DOT), a training-time intervention that selectively suppresses redundant tokens. This method targets only the extreme tail of response lengths within fully correct rollout groups while preserving long-horizon reasoning capabilities for complex problems. To complement this intervention and ensure stable convergence, we further incorporate auxiliary KL regularization and predictive dynamic sampling. Experimental results across multiple model scales demonstrate that our approach significantly pushes the efficiency-performance Pareto frontier outward. Notably, on the AIME-24, our method reduces inference token usage by 78% while simultaneously increasing accuracy compared to the initial policy and surpassing state-of-the-art efficient reasoning methods.",
      "authors": [
        "Wei Wu",
        "Liyi Chen",
        "Congxi Xiao",
        "Tianfu Wang",
        "Qimeng Wang",
        "Chengqiang Lu",
        "Yan Gao",
        "Yi Wu",
        "Yao Hu",
        "Hui Xiong"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-07 14:31:07+00:00",
      "link": "https://arxiv.org/pdf/2601.03969v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03955v1",
      "title": "ResTok: Learning Hierarchical Residuals in 1D Visual Tokenizers for Autoregressive Image Generation",
      "abstract": "Existing 1D visual tokenizers for autoregressive (AR) generation largely follow the design principles of language modeling, as they are built directly upon transformers whose priors originate in language, yielding single-hierarchy latent tokens and treating visual data as flat sequential token streams. However, this language-like formulation overlooks key properties of vision, particularly the hierarchical and residual network designs that have long been essential for convergence and efficiency in visual models. To bring \"vision\" back to vision, we propose the Residual Tokenizer (ResTok), a 1D visual tokenizer that builds hierarchical residuals for both image tokens and latent tokens. The hierarchical representations obtained through progressively merging enable cross-level feature fusion at each layer, substantially enhancing representational capacity. Meanwhile, the semantic residuals between hierarchies prevent information overlap, yielding more concentrated latent distributions that are easier for AR modeling. Cross-level bindings consequently emerge without any explicit constraints. To accelerate the generation process, we further introduce a hierarchical AR generator that substantially reduces sampling steps by predicting an entire level of latent tokens at once rather than generating them strictly token-by-token. Extensive experiments demonstrate that restoring hierarchical residual priors in visual tokenization significantly improves AR image generation, achieving a gFID of 2.34 on ImageNet-256 with only 9 sampling steps. Code is available at https://github.com/Kwai-Kolors/ResTok.",
      "authors": [
        "Xu Zhang",
        "Cheng Da",
        "Huan Yang",
        "Kun Gai",
        "Ming Lu",
        "Zhan Ma"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-07 14:09:18+00:00",
      "link": "https://arxiv.org/pdf/2601.03955v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03940v1",
      "title": "Large-Scale Aspect-Based Sentiment Analysis with Reasoning-Infused LLMs",
      "abstract": "We introduce Arctic-ABSA, a collection of powerful models for real-life aspect-based sentiment analysis (ABSA). Our models are tailored to commercial needs, trained on a large corpus of public data alongside carefully generated synthetic data, resulting in a dataset 20 times larger than SemEval14. We extend typical ABSA models by expanding the number of sentiment classes from the standard three (positive, negative, neutral) to five, adding mixed and unknown classes, while also jointly predicting overall text sentiment and supporting multiple languages. We experiment with reasoning injection by fine-tuning on Chain-of-Thought (CoT) examples and introduce a novel reasoning pretraining technique for encoder-only models that significantly improves downstream fine-tuning and generalization. Our 395M-parameter encoder and 8B-parameter decoder achieve up to 10 percentage points higher accuracy than GPT-4o and Claude 3.5 Sonnet, while setting new state-of-the-art results on the SemEval14 benchmark. A single multilingual model maintains 87-91% accuracy across six languages without degrading English performance. We release ABSA-mix, a large-scale benchmark aggregating 17 public ABSA datasets across 92 domains.",
      "authors": [
        "Paweł Liskowski",
        "Krzysztof Jankowski"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-07 13:58:29+00:00",
      "link": "https://arxiv.org/pdf/2601.03940v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03928v1",
      "title": "FocusUI: Efficient UI Grounding via Position-Preserving Visual Token Selection",
      "abstract": "Vision-Language Models (VLMs) have shown remarkable performance in User Interface (UI) grounding tasks, driven by their ability to process increasingly high-resolution screenshots. However, screenshots are tokenized into thousands of visual tokens (e.g., about 4700 for 2K resolution), incurring significant computational overhead and diluting attention. In contrast, humans typically focus on regions of interest when interacting with UI. In this work, we pioneer the task of efficient UI grounding. Guided by practical analysis of the task's characteristics and challenges, we propose FocusUI, an efficient UI grounding framework that selects patches most relevant to the instruction while preserving positional continuity for precise grounding. FocusUI addresses two key challenges: (1) Eliminating redundant tokens in visual encoding. We construct patch-level supervision by fusing an instruction-conditioned score with a rule-based UI-graph score that down-weights large homogeneous regions to select distinct and instruction-relevant visual tokens. (2) Preserving positional continuity during visual token selection. We find that general visual token pruning methods suffer from severe accuracy degradation on UI grounding tasks due to broken positional information. We introduce a novel PosPad strategy, which compresses each contiguous sequence of dropped visual tokens into a single special marker placed at the sequence's last index to preserve positional continuity. Comprehensive experiments on four grounding benchmarks demonstrate that FocusUI surpasses GUI-specific baselines. On the ScreenSpot-Pro benchmark, FocusUI-7B achieves a performance improvement of 3.7% over GUI-Actor-7B. Even with only 30% visual token retention, FocusUI-7B drops by only 3.2% while achieving up to 1.44x faster inference and 17% lower peak GPU memory.",
      "authors": [
        "Mingyu Ouyang",
        "Kevin Qinghong Lin",
        "Mike Zheng Shou",
        "Hwee Tou Ng"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "published": "2026-01-07 13:48:12+00:00",
      "link": "https://arxiv.org/pdf/2601.03928v1",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.03926v1",
      "title": "Doc-PP: Document Policy Preservation Benchmark for Large Vision-Language Models",
      "abstract": "The deployment of Large Vision-Language Models (LVLMs) for real-world document question answering is often constrained by dynamic, user-defined policies that dictate information disclosure based on context. While ensuring adherence to these explicit constraints is critical, existing safety research primarily focuses on implicit social norms or text-only settings, overlooking the complexities of multimodal documents. In this paper, we introduce Doc-PP (Document Policy Preservation Benchmark), a novel benchmark constructed from real-world reports requiring reasoning across heterogeneous visual and textual elements under strict non-disclosure policies. Our evaluation highlights a systemic Reasoning-Induced Safety Gap: models frequently leak sensitive information when answers must be inferred through complex synthesis or aggregated across modalities, effectively circumventing existing safety constraints. Furthermore, we identify that providing extracted text improves perception but inadvertently facilitates leakage. To address these vulnerabilities, we propose DVA (Decompose-Verify-Aggregation), a structural inference framework that decouples reasoning from policy verification. Experimental results demonstrate that DVA significantly outperforms standard prompting defenses, offering a robust baseline for policy-compliant document understanding",
      "authors": [
        "Haeun Jang",
        "Hwan Chang",
        "Hwanhee Lee"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 13:45:39+00:00",
      "link": "https://arxiv.org/pdf/2601.03926v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03924v1",
      "title": "A low-complexity method for efficient depth-guided image deblurring",
      "abstract": "Image deblurring is a challenging problem in imaging due to its highly ill-posed nature. Deep learning models have shown great success in tackling this problem but the quest for the best image quality has brought their computational complexity up, making them impractical on anything but powerful servers. Meanwhile, recent works have shown that mobile Lidars can provide complementary information in the form of depth maps that enhance deblurring quality. In this paper, we introduce a novel low-complexity neural network for depth-guided image deblurring. We show that the use of the wavelet transform to separate structural details and reduce spatial redundancy as well as efficient feature conditioning on the depth information are essential ingredients in developing a low-complexity model. Experimental results show competitive image quality against recent state-of-the-art models while reducing complexity by up to two orders of magnitude.",
      "authors": [
        "Ziyao Yi",
        "Diego Valsesia",
        "Tiziano Bianchi",
        "Enrico Magli"
      ],
      "primary_category": "eess.IV",
      "categories": [
        "eess.IV",
        "cs.CV"
      ],
      "published": "2026-01-07 13:45:20+00:00",
      "link": "https://arxiv.org/pdf/2601.03924v1",
      "tags": [
        "keyword:resnet",
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.03923v1",
      "title": "Human Challenge Oracle: Designing AI-Resistant, Identity-Bound, Time-Limited Tasks for Sybil-Resistant Consensus",
      "abstract": "Sybil attacks remain a fundamental obstacle in open online systems, where adversaries can cheaply create and sustain large numbers of fake identities. Existing defenses, including CAPTCHAs and one-time proof-of-personhood mechanisms, primarily address identity creation and provide limited protection against long-term, large-scale Sybil participation, especially as automated solvers and AI systems continue to improve.   We introduce the Human Challenge Oracle (HCO), a new security primitive for continuous, rate-limited human verification. HCO issues short, time-bound challenges that are cryptographically bound to individual identities and must be solved in real time. The core insight underlying HCO is that real-time human cognitive effort, such as perception, attention, and interactive reasoning, constitutes a scarce resource that is inherently difficult to parallelize or amortize across identities.   We formalize the design goals and security properties of HCO and show that, under explicit and mild assumptions, sustaining s active identities incurs a cost that grows linearly with s in every time window. We further describe abstract classes of admissible challenges and concrete browser-based instantiations, and present an initial empirical study illustrating that these challenges are easily solvable by humans within seconds while remaining difficult for contemporary automated systems under strict time constraints.",
      "authors": [
        "Homayoun Maleki",
        "Nekane Sainz",
        "Jon Legarda"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR"
      ],
      "published": "2026-01-07 13:42:21+00:00",
      "link": "https://arxiv.org/pdf/2601.03923v1",
      "tags": [
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.03915v1",
      "title": "HemBLIP: A Vision-Language Model for Interpretable Leukemia Cell Morphology Analysis",
      "abstract": "Microscopic evaluation of white blood cell morphology is central to leukemia diagnosis, yet current deep learning models often act as black boxes, limiting clinical trust and adoption. We introduce HemBLIP, a vision language model designed to generate interpretable, morphology aware descriptions of peripheral blood cells. Using a newly constructed dataset of 14k healthy and leukemic cells paired with expert-derived attribute captions, we adapt a general-purpose VLM via both full fine-tuning and LoRA based parameter efficient training, and benchmark against the biomedical foundation model MedGEMMA. HemBLIP achieves higher caption quality and morphological accuracy, while LoRA adaptation provides further gains with significantly reduced computational cost. These results highlight the promise of vision language models for transparent and scalable hematological diagnostics.",
      "authors": [
        "Julie van Logtestijn",
        "Petru Manescu"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-07 13:31:33+00:00",
      "link": "https://arxiv.org/pdf/2601.03915v1",
      "tags": [
        "keyword:大语言模型",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03914v1",
      "title": "When Models Decide and When They Bind: A Two-Stage Computation for Multiple-Choice Question-Answering",
      "abstract": "Multiple-choice question answering (MCQA) is easy to evaluate but adds a meta-task: models must both solve the problem and output the symbol that *represents* the answer, conflating reasoning errors with symbol-binding failures. We study how language models implement MCQA internally using representational analyses (PCA, linear probes) as well as causal interventions. We find that option-boundary (newline) residual states often contain strong linearly decodable signals related to per-option correctness. Winner-identity probing reveals a two-stage progression: the winning *content position* becomes decodable immediately after the final option is processed, while the *output symbol* is represented closer to the answer emission position. Tests under symbol and content permutations support a two-stage mechanism in which models first select a winner in content space and then bind or route that winner to the appropriate symbol to emit.",
      "authors": [
        "Hugh Mee Wong",
        "Rick Nouwen",
        "Albert Gatt"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 13:27:48+00:00",
      "link": "https://arxiv.org/pdf/2601.03914v1",
      "tags": [
        "keyword:resnet",
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.03910v1",
      "title": "An Algebraic Representation Theorem for Linear GENEOs in Geometric Machine Learning",
      "abstract": "Geometric and Topological Deep Learning are rapidly growing research areas that enhance machine learning through the use of geometric and topological structures. Within this framework, Group Equivariant Non-Expansive Operators (GENEOs) have emerged as a powerful class of operators for encoding symmetries and designing efficient, interpretable neural architectures. Originally introduced in Topological Data Analysis, GENEOs have since found applications in Deep Learning as tools for constructing equivariant models with reduced parameter complexity. GENEOs provide a unifying framework bridging Geometric and Topological Deep Learning and include the operator computing persistence diagrams as a special case. Their theoretical foundations rely on group actions, equivariance, and compactness properties of operator spaces, grounding them in algebra and geometry while enabling both mathematical rigor and practical relevance. While a previous representation theorem characterized linear GENEOs acting on data of the same type, many real-world applications require operators between heterogeneous data spaces. In this work, we address this limitation by introducing a new representation theorem for linear GENEOs acting between different perception pairs, based on generalized T-permutant measures. Under mild assumptions on the data domains and group actions, our result provides a complete characterization of such operators. We also prove the compactness and convexity of the space of linear GENEOs. We further demonstrate the practical impact of this theory by applying the proposed framework to improve the performance of autoencoders, highlighting the relevance of GENEOs in modern machine learning applications.",
      "authors": [
        "Francesco Conti",
        "Patrizio Frosini",
        "Nicola Quercioli"
      ],
      "primary_category": "math.RT",
      "categories": [
        "math.RT",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-07 13:21:44+00:00",
      "link": "https://arxiv.org/pdf/2601.03910v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04282v1",
      "title": "LEGATO: Good Identity Unlearning Is Continuous",
      "abstract": "Machine unlearning has become a crucial role in enabling generative models trained on large datasets to remove sensitive, private, or copyright-protected data. However, existing machine unlearning methods face three challenges in learning to forget identity of generative models: 1) inefficient, where identity erasure requires fine-tuning all the model's parameters; 2) limited controllability, where forgetting intensity cannot be controlled and explainability is lacking; 3) catastrophic collapse, where the model's retention capability undergoes drastic degradation as forgetting progresses. Forgetting has typically been handled through discrete and unstable updates, often requiring full-model fine-tuning and leading to catastrophic collapse. In this work, we argue that identity forgetting should be modeled as a continuous trajectory, and introduce LEGATO - Learn to ForgEt Identity in GenerAtive Models via Trajectory-consistent Neural Ordinary Differential Equations. LEGATO augments pre-trained generators with fine-tunable lightweight Neural ODE adapters, enabling smooth, controllable forgetting while keeping the original model weights frozen. This formulation allows forgetting intensity to be precisely modulated via ODE step size, offering interpretability and robustness. To further ensure stability, we introduce trajectory consistency constraints that explicitly prevent catastrophic collapse during unlearning. Extensive experiments across in-domain and out-of-domain identity unlearning benchmarks show that LEGATO achieves state-of-the-art forgetting performance, avoids catastrophic collapse and reduces fine-tuned parameters.",
      "authors": [
        "Qiang Chen",
        "Chun-Wun Cheng",
        "Xiu Su",
        "Hongyan Xu",
        "Xi Lin",
        "Shan You",
        "Angelica I. Aviles-Rivero",
        "Yi Chen"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 13:15:25+00:00",
      "link": "https://arxiv.org/pdf/2601.04282v1",
      "tags": [
        "keyword:resnet",
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.03888v2",
      "title": "IndexTTS 2.5 Technical Report",
      "abstract": "In prior work, we introduced IndexTTS 2, a zero-shot neural text-to-speech foundation model comprising two core components: a transformer-based Text-to-Semantic (T2S) module and a non-autoregressive Semantic-to-Mel (S2M) module, which together enable faithful emotion replication and establish the first autoregressive duration-controllable generative paradigm. Building upon this, we present IndexTTS 2.5, which significantly enhances multilingual coverage, inference speed, and overall synthesis quality through four key improvements: 1) Semantic Codec Compression: we reduce the semantic codec frame rate from 50 Hz to 25 Hz, halving sequence length and substantially lowering both training and inference costs; 2) Architectural Upgrade: we replace the U-DiT-based backbone of the S2M module with a more efficient Zipformer-based modeling architecture, achieving notable parameter reduction and faster mel-spectrogram generation; 3) Multilingual Extension: We propose three explicit cross-lingual modeling strategies, boundary-aware alignment, token-level concatenation, and instruction-guided generation, establishing practical design principles for zero-shot multilingual emotional TTS that supports Chinese, English, Japanese, and Spanish, and enables robust emotion transfer even without target-language emotional training data; 4) Reinforcement Learning Optimization: we apply GRPO in post-training of the T2S module, improving pronunciation accuracy and natrualness. Experiments show that IndexTTS 2.5 not only supports broader language coverage but also replicates emotional prosody in unseen languages under the same zero-shot setting. IndexTTS 2.5 achieves a 2.28 times improvement in RTF while maintaining comparable WER and speaker similarity to IndexTTS 2.",
      "authors": [
        "Yunpei Li",
        "Xun Zhou",
        "Jinchao Wang",
        "Lu Wang",
        "Yong Wu",
        "Siyi Zhou",
        "Yiquan Zhou",
        "Jingchen Shu"
      ],
      "primary_category": "cs.SD",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "published": "2026-01-07 12:58:16+00:00",
      "link": "https://arxiv.org/pdf/2601.03888v2",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.03884v1",
      "title": "FLNet: Flood-Induced Agriculture Damage Assessment using Super Resolution of Satellite Images",
      "abstract": "Distributing government relief efforts after a flood is challenging. In India, the crops are widely affected by floods; therefore, making rapid and accurate crop damage assessment is crucial for effective post-disaster agricultural management. Traditional manual surveys are slow and biased, while current satellite-based methods face challenges like cloud cover and low spatial resolution. Therefore, to bridge this gap, this paper introduced FLNet, a novel deep learning based architecture that used super-resolution to enhance the 10 m spatial resolution of Sentinel-2 satellite images into 3 m resolution before classifying damage. We tested our model on the Bihar Flood Impacted Croplands Dataset (BFCD-22), and the results showed an improved critical \"Full Damage\" F1-score from 0.83 to 0.89, nearly matching the 0.89 score of commercial high-resolution imagery. This work presented a cost-effective and scalable solution, paving the way for a nationwide shift from manual to automated, high-fidelity damage assessment.",
      "authors": [
        "Sanidhya Ghosal",
        "Anurag Sharma",
        "Sushil Ghildiyal",
        "Mukesh Saini"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-01-07 12:51:28+00:00",
      "link": "https://arxiv.org/pdf/2601.03884v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03882v1",
      "title": "Feature-Aware One-Shot Federated Learning via Hierarchical Token Sequences",
      "abstract": "One-shot federated learning (OSFL) reduces the communication cost and privacy risks of iterative federated learning by constructing a global model with a single round of communication. However, most existing methods struggle to achieve robust performance on real-world domains such as medical imaging, or are inefficient when handling non-IID (Independent and Identically Distributed) data. To address these limitations, we introduce FALCON, a framework that enhances the effectiveness of OSFL over non-IID image data. The core idea of FALCON is to leverage the feature-aware hierarchical token sequences generation and knowledge distillation into OSFL. First, each client leverages a pretrained visual encoder with hierarchical scale encoding to compress images into hierarchical token sequences, which capture multi-scale semantics. Second, a multi-scale autoregressive transformer generator is used to model the distribution of these token sequences and generate the synthetic sequences. Third, clients upload the synthetic sequences along with the local classifier trained on the real token sequences to the server. Finally, the server incorporates knowledge distillation into global training to reduce reliance on precise distribution modeling. Experiments on medical and natural image datasets validate the effectiveness of FALCON in diverse non-IID scenarios, outperforming the best OSFL baselines by 9.58% in average accuracy.",
      "authors": [
        "Shudong Liu",
        "Hanwen Zhang",
        "Xiuling Wang",
        "Yuesheng Zhu",
        "Guibo Luo"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 12:48:16+00:00",
      "link": "https://arxiv.org/pdf/2601.03882v1",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.04279v1",
      "title": "Generation of synthetic delay time series for air transport applications",
      "abstract": "The generation of synthetic data is receiving increasing attention from the scientific community, thanks to its ability to solve problems like data scarcity and privacy, and is starting to find applications in air transport. We here tackle the problem of generating synthetic, yet realistic, time series of delays at airports, starting from large collections of operations in Europe and the US. We specifically compare three models, two of them based on state of the art Deep Learning algorithms, and one simplified Genetic Algorithm approach. We show how the latter can generate time series that are almost indistinguishable from real ones, while maintaining a high variability. We further validate the resulting time series in a problem of detecting delay propagations between airports. We finally make the synthetic data available to the scientific community.",
      "authors": [
        "Pau Esteve",
        "Massimiliano Zanin"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 12:43:14+00:00",
      "link": "https://arxiv.org/pdf/2601.04279v1",
      "tags": [
        "keyword:resnet",
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.03875v1",
      "title": "Staged Voxel-Level Deep Reinforcement Learning for 3D Medical Image Segmentation with Noisy Annotations",
      "abstract": "Deep learning has achieved significant advancements in medical image segmentation. Currently, obtaining accurate segmentation outcomes is critically reliant on large-scale datasets with high-quality annotations. However, noisy annotations are frequently encountered owing to the complex morphological structures of organs in medical images and variations among different annotators, which can substantially limit the efficacy of segmentation models. Motivated by the fact that medical imaging annotator can correct labeling errors during segmentation based on prior knowledge, we propose an end-to-end Staged Voxel-Level Deep Reinforcement Learning (SVL-DRL) framework for robust medical image segmentation under noisy annotations. This framework employs a dynamic iterative update strategy to automatically mitigate the impact of erroneous labels without requiring manual intervention. The key advancements of SVL-DRL over existing works include: i) formulating noisy annotations as a voxel-dependent problem and addressing it through a novel staged reinforcement learning framework which guarantees robust model convergence; ii) incorporating a voxel-level asynchronous advantage actor-critic (vA3C) module that conceptualizes each voxel as an autonomous agent, which allows each agent to dynamically refine its own state representation during training, thereby directly mitigating the influence of erroneous labels; iii) designing a novel action space for the agents, along with a composite reward function that strategically combines the Dice value and a spatial continuity metric to significantly boost segmentation accuracy while maintain semantic integrity. Experiments on three public medical image datasets demonstrates State-of-The-Art (SoTA) performance under various experimental settings, with an average improvement of over 3\\% in both Dice and IoU scores.",
      "authors": [
        "Yuyang Fu",
        "Xiuzhen Guo",
        "Ji Shi"
      ],
      "primary_category": "eess.IV",
      "categories": [
        "eess.IV",
        "cs.CV"
      ],
      "published": "2026-01-07 12:39:54+00:00",
      "link": "https://arxiv.org/pdf/2601.03875v1",
      "tags": [
        "keyword:resnet",
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.03858v1",
      "title": "What Does Loss Optimization Actually Teach, If Anything? Knowledge Dynamics in Continual Pre-training of LLMs",
      "abstract": "Continual Pre-Training (CPT) is widely used for acquiring and updating factual knowledge in LLMs. This practice treats loss as a proxy for knowledge learning, while offering no grounding into how it changes during training. We study CPT as a knowledge learning process rather than a solely optimization problem. We construct a controlled, distribution-matched benchmark of factual documents and interleave diagnostic probes directly into the CPT loop, enabling epoch-level measurement of knowledge acquisition dynamics and changes in Out-Of-Domain (OOD) general skills (e.g., math). We further analyze how CPT reshapes knowledge circuits during training. Across three instruction-tuned LLMs and multiple CPT strategies, optimization and learning systematically diverge as loss decreases monotonically while factual learning is unstable and non-monotonic. Acquired facts are rarely consolidated, learning is strongly conditioned on prior exposure, and OOD performance degrades from early epochs. Circuit analysis reveals rapid reconfiguration of knowledge pathways across epochs, providing an explanation for narrow acquisition windows and systematic forgetting. These results show that loss optimization is misaligned with learning progress in CPT and motivate evaluation of stopping criteria based on task-level learning dynamics.",
      "authors": [
        "Seyed Mahed Mousavi",
        "Simone Alghisi",
        "Giuseppe Riccardi"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 12:14:33+00:00",
      "link": "https://arxiv.org/pdf/2601.03858v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03853v1",
      "title": "From No-Regret to Strategically Robust Learning in Repeated Auctions",
      "abstract": "In Bayesian single-item auctions, a monotone bidding strategy--one that prescribes a higher bid for a higher value type--can be equivalently represented as a partition of the quantile space into consecutive intervals corresponding to increasing bids. Kumar et al. (2024) prove that agile online gradient descent (OGD), when used to update a monotone bidding strategy through its quantile representation, is strategically robust in repeated first-price auctions: when all bidders employ agile OGD in this way, the auctioneer's average revenue per round is at most the revenue of Myerson's optimal auction, regardless of how she adjusts the reserve price over time.   In this work, we show that this strategic robustness guarantee is not unique to agile OGD or to the first-price auction: any no-regret learning algorithm, when fed gradient feedback with respect to the quantile representation, is strategically robust, even if the auction format changes every round, provided the format satisfies allocation monotonicity and voluntary participation. In particular, the multiplicative weights update (MWU) algorithm simultaneously achieves the optimal regret guarantee and the best-known strategic robustness guarantee. At a technical level, our results are established via a simple relation that bridges Myerson's auction theory and standard no-regret learning theory. This showcases the potential of translating standard regret guarantees into strategic robustness guarantees for specific games, without explicitly minimizing any form of swap regret.",
      "authors": [
        "Junyao Zhao"
      ],
      "primary_category": "cs.GT",
      "categories": [
        "cs.GT",
        "cs.LG",
        "econ.TH"
      ],
      "published": "2026-01-07 12:09:13+00:00",
      "link": "https://arxiv.org/pdf/2601.03853v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03850v1",
      "title": "Investigating the Grounding Bottleneck for a Large-Scale Configuration Problem: Existing Tools and Constraint-Aware Guessing",
      "abstract": "Answer set programming (ASP) aims to realize the AI vision: The user specifies the problem, and the computer solves it. Indeed, ASP has made this vision true in many application domains. However, will current ASP solving techniques scale up for large configuration problems? As a benchmark for such problems, we investigated the configuration of electronic systems, which may comprise more than 30,000 components. We show the potential and limits of current ASP technology, focusing on methods that address the so-called grounding bottleneck, i.e., the sharp increase of memory demands in the size of the problem instances. To push the limits, we investigated the incremental solving approach, which proved effective in practice. However, even in the incremental approach, memory demands impose significant limits. Based on an analysis of grounding, we developed the method constraint-aware guessing, which significantly reduced the memory need.",
      "authors": [
        "Veronika Semmelrock",
        "Gerhard Friedrich"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-07 12:08:44+00:00",
      "link": "https://arxiv.org/pdf/2601.03850v1",
      "tags": [
        "keyword:resnet",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03849v1",
      "title": "Automated Theorem Proving for Prolog Verification",
      "abstract": "LPTP (Logic Program Theorem Prover) is an interactive natural-deduction-based theorem  prover for pure Prolog programs with negation as failure, unification with the occurs check, and a restricted but extensible set of built-in predicates. With LPTP, one can formally prove termination  and partial correctness of such Prolog programs. LPTP was designed in the mid-1990's by Robert F. Staerk.  It is written in ISO-Prolog and comes with an Emacs user-interface.    From a theoretical point of view, in his publications about LPTP, Staerk associates a set of first-order axioms IND(P) to the considered Prolog program P.  IND(P) contains the Clark's equality theory for P,  definitions of success, failure and termination for each user-defined logic procedure in P,  axioms relating these three points of view, and an axiom schema for  proving inductive properties. LPTP is thus a dedicated proof editor where these axioms are hard-wired.    We propose to translate these axioms as first-order formulas (FOFs), and apply automated theorem provers to  check the property of interest. Using  FOF  as an intermediary language, we experiment the use of automated theorem  provers for Prolog program verification. We evaluate the approach over  a benchmark of about 400 properties of Prolog  programs from the library available with LPTP. Both the  compiler which generates a set of FOF files from a given input  Prolog program together with its properties and the benchmark are publicly available.",
      "authors": [
        "Fred Mesnard",
        "Thierry Marianne",
        "Étienne Payet"
      ],
      "primary_category": "cs.LO",
      "categories": [
        "cs.LO",
        "cs.PL"
      ],
      "published": "2026-01-07 12:08:30+00:00",
      "link": "https://arxiv.org/pdf/2601.03849v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03848v1",
      "title": "Implementing the First-Order Logic of Here and There",
      "abstract": "We present automated theorem provers for the first-order logic of here and there (HT). They are based on a native sequent calculus for the logic of HT and an axiomatic embedding of the logic of HT into intuitionistic logic. The analytic proof search in the sequent calculus is optimized by using free variables and skolemization. The embedding is used in combination with sequent, tableau and connection calculi for intuitionistic first-order logic. All provers are evaluated on a large benchmark set of first-order formulas, providing a foundation for the development of more efficient HT provers.",
      "authors": [
        "Jens Otten",
        "Torsten Schaub"
      ],
      "primary_category": "cs.LO",
      "categories": [
        "cs.LO",
        "cs.AI",
        "cs.PL"
      ],
      "published": "2026-01-07 12:08:15+00:00",
      "link": "https://arxiv.org/pdf/2601.03848v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03847v1",
      "title": "xDNN(ASP): Explanation Generation System for Deep Neural Networks powered by Answer Set Programming",
      "abstract": "Explainable artificial intelligence (xAI) has gained significant attention in recent years. Among other things, explainablility for deep neural networks has been a topic of intensive research due to the meteoric rise in prominence of deep neural networks and their \"black-box\" nature. xAI approaches can be characterized along different dimensions such as their scope (global versus local explanations) or underlying methodologies (statistic-based versus rule-based strategies). Methods generating global explanations aim to provide reasoning process applicable to all possible output classes while local explanation methods focus only on a single, specific class. SHAP (SHapley Additive exPlanations), a well-known statistical technique, identifies important features of a network. Deep neural network rule extraction method constructs IF-THEN rules that link input conditions to a class. Another approach focuses on generating counterfactuals which help explain how small changes to an input can affect the model's predictions. However, these techniques primarily focus on the input-output relationship and thus neglect the structure of the network in explanation generation.   In this work, we propose xDNN(ASP), an explanation generation system for deep neural networks that provides global explanations. Given a neural network model and its training data, xDNN(ASP) extracts a logic program under answer set semantics that-in the ideal case-represents the trained model, i.e., answer sets of the extracted program correspond one-to-one to input-output pairs of the network. We demonstrate experimentally, using two synthetic datasets, that not only the extracted logic program maintains a high-level of accuracy in the prediction task, but it also provides valuable information for the understanding of the model such as the importance of features as well as the impact of hidden nodes on the prediction. The latter can be used as a guide for reducing the number of nodes used in hidden layers, i.e., providing a means for optimizing the network.",
      "authors": [
        "Ly Ly Trieu",
        "Tran Cao Son"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-07 12:08:00+00:00",
      "link": "https://arxiv.org/pdf/2601.03847v1",
      "tags": [
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.03845v1",
      "title": "Formally Explaining Decision Tree Models with Answer Set Programming",
      "abstract": "Decision tree models, including random forests and gradient-boosted decision trees, are widely used in machine learning due to their high predictive performance.  However, their complex structures often make them difficult to interpret, especially in safety-critical applications where model decisions require formal justification.  Recent work has demonstrated that logical and abductive explanations can be derived through automated reasoning techniques.  In this paper, we propose a method for generating various types of explanations, namely, sufficient, contrastive, majority, and tree-specific explanations, using Answer Set Programming (ASP).  Compared to SAT-based approaches, our ASP-based method offers greater flexibility in encoding user preferences and supports enumeration of all possible explanations.  We empirically evaluate the approach on a diverse set of datasets and demonstrate its effectiveness and limitations compared to existing methods.",
      "authors": [
        "Akihiro Takemura",
        "Masayuki Otani",
        "Katsumi Inoue"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "published": "2026-01-07 12:07:45+00:00",
      "link": "https://arxiv.org/pdf/2601.03845v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03844v1",
      "title": "XAI-LAW: A Logic Programming Tool for Modeling, Explaining, and Learning Legal Decisions",
      "abstract": "We propose an approach to model articles of the Italian Criminal Code (ICC), using Answer Set Programming (ASP), and to semi-automatically learn legal rules from examples based on prior judicial decisions. The developed tool is intended to support legal experts during the criminal trial phase by providing reasoning and possible legal outcomes. The methodology involves analyzing and encoding articles of the ICC in ASP, including \"crimes against the person\" and property offenses. The resulting model is validated on a set of previous verdicts and refined as necessary. During the encoding process, contradictions may arise; these are properly handled by the system, which also generates possible decisions for new cases and provides explanations through a tool that leverages the \"supportedness\" of stable models. The automatic explainability offered by the tool can also be used to clarify the logic behind judicial decisions, making the decision-making process more interpretable. Furthermore, the tool integrates an inductive logic programming system for ASP, which is employed to generalize legal rules from case examples.",
      "authors": [
        "Agostino Dovier",
        "Talissa Dreossi",
        "Andrea Formisano",
        "Benedetta Strizzolo"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-07 12:07:30+00:00",
      "link": "https://arxiv.org/pdf/2601.03844v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03823v1",
      "title": "Step Potential Advantage Estimation: Harnessing Intermediate Confidence and Correctness for Efficient Mathematical Reasoning",
      "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) elicits long chain-of-thought reasoning in large language models (LLMs), but outcome-based rewards lead to coarse-grained advantage estimation. While existing approaches improve RLVR via token-level entropy or sequence-level length control, they lack a semantically grounded, step-level measure of reasoning progress. As a result, LLMs fail to distinguish necessary deduction from redundant verification: they may continue checking after reaching a correct solution and, in extreme cases, overturn a correct trajectory into an incorrect final answer. To remedy the lack of process supervision, we introduce a training-free probing mechanism that extracts intermediate confidence and correctness and combines them into a Step Potential signal that explicitly estimates the reasoning state at each step. Building on this signal, we propose Step Potential Advantage Estimation (SPAE), a fine-grained credit assignment method that amplifies potential gains, penalizes potential drops, and applies penalty after potential saturates to encourage timely termination. Experiments across multiple benchmarks show SPAE consistently improves accuracy while substantially reducing response length, outperforming strong RL baselines and recent efficient reasoning and token-level advantage estimation methods. The code is available at https://github.com/cii030/SPAE-RL.",
      "authors": [
        "Fei Wu",
        "Zhenrong Zhang",
        "Qikai Chang",
        "Jianshu Zhang",
        "Quan Liu",
        "Jun Du"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 11:36:01+00:00",
      "link": "https://arxiv.org/pdf/2601.03823v1",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.03822v1",
      "title": "ROI-Reasoning: Rational Optimization for Inference via Pre-Computation Meta-Cognition",
      "abstract": "Large language models (LLMs) can achieve strong reasoning performance with sufficient computation, but they do not inherently know how much computation a task requires. We study budgeted inference-time reasoning for multiple tasks under a strict global token constraint and formalize it as a Ordered Stochastic Multiple-Choice Knapsack Problem(OS-MCKP). This perspective highlights a meta-cognitive requirement -- anticipating task difficulty, estimating return over investment (ROI), and allocating computation strategically. We propose ROI-Reasoning, a two-stage framework that endows LLMs with intrinsic, budget-aware rationality. In the first stage, Meta-Cognitive Fine-Tuning teaches models to predict reasoning cost and expected utility before generation, enabling explicit solve-or-skip decisions. Next, Rationality-Aware Reinforcement Learning optimizes sequential decision making under a hard token budget, allowing models to learn long-horizon allocation strategies. Across budgeted mathematical reasoning benchmarks, ROI-Reasoning consistently improves overall score while substantially reducing regret under tight computation budgets.",
      "authors": [
        "Muyang Zhao",
        "Qi Qi",
        "Hao Sun"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-07 11:30:55+00:00",
      "link": "https://arxiv.org/pdf/2601.03822v1",
      "tags": [
        "keyword:resnet",
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.04270v1",
      "title": "Predictable Gradient Manifolds in Deep Learning: Temporal Path-Length and Intrinsic Rank as a Complexity Regime",
      "abstract": "Deep learning optimization exhibits structure that is not captured by worst-case gradient bounds. Empirically, gradients along training trajectories are often temporally predictable and evolve within a low-dimensional subspace. In this work we formalize this observation through a measurable framework for predictable gradient manifolds.   We introduce two computable quantities: a prediction-based path length that measures how well gradients can be forecast from past information, and a predictable rank that quantifies the intrinsic temporal dimension of gradient increments. We show how classical online and nonconvex optimization guarantees can be restated so that convergence and regret depend explicitly on these quantities, rather than on worst-case variation.   Across convolutional networks, vision transformers, language models, and synthetic control tasks, we find that gradient trajectories are locally predictable and exhibit strong low-rank structure over time. These properties are stable across architectures and optimizers, and can be diagnosed directly from logged gradients using lightweight random projections.   Our results provide a unifying lens for understanding optimization dynamics in modern deep learning, reframing standard training as operating in a low-complexity temporal regime. This perspective suggests new directions for adaptive optimizers, rank-aware tracking, and prediction-based algorithm design grounded in measurable properties of real training runs.",
      "authors": [
        "Anherutowa Calvo"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 11:23:55+00:00",
      "link": "https://arxiv.org/pdf/2601.04270v1",
      "tags": [
        "keyword:resnet",
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.04269v1",
      "title": "Systems Explaining Systems: A Framework for Intelligence and Consciousness",
      "abstract": "This paper proposes a conceptual framework in which intelligence and consciousness emerge from relational structure rather than from prediction or domain-specific mechanisms. Intelligence is defined as the capacity to form and integrate causal connections between signals, actions, and internal states. Through context enrichment, systems interpret incoming information using learned relational structure that provides essential context in an efficient representation that the raw input itself does not contain, enabling efficient processing under metabolic constraints.   Building on this foundation, we introduce the systems-explaining-systems principle, where consciousness emerges when recursive architectures allow higher-order systems to learn and interpret the relational patterns of lower-order systems across time. These interpretations are integrated into a dynamically stabilized meta-state and fed back through context enrichment, transforming internal models from representations of the external world into models of the system's own cognitive processes.   The framework reframes predictive processing as an emergent consequence of contextual interpretation rather than explicit forecasting and suggests that recursive multi-system architectures may be necessary for more human-like artificial intelligence.",
      "authors": [
        "Sean Niklas Semmler"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LG",
        "q-bio.NC"
      ],
      "published": "2026-01-07 11:19:22+00:00",
      "link": "https://arxiv.org/pdf/2601.04269v1",
      "tags": [
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.04268v1",
      "title": "Making Tunable Parameters State-Dependent in Weather and Climate Models with Reinforcement Learning",
      "abstract": "Weather and climate models rely on parametrisations to represent unresolved sub-grid processes. Traditional schemes rely on fixed coefficients that are weakly constrained and tuned offline, contributing to persistent biases that limit their ability to adapt to the underlying physics. This study presents a framework that learns components of parametrisation schemes online as a function of the evolving model state using reinforcement learning (RL) and evaluates the resulting RL-driven parameter updates across a hierarchy of idealised testbeds spanning a simple climate bias correction (SCBC), a radiative-convective equilibrium (RCE), and a zonal mean energy balance model (EBM) with both single-agent and federated multi-agent settings. Across nine RL algorithms, Truncated Quantile Critics (TQC), Deep Deterministic Policy Gradient (DDPG), and Twin Delayed DDPG (TD3) achieved the highest skill and the most stable convergence across configurations, with performance assessed against a static baseline using area-weighted RMSE, temperature profile and pressure-level diagnostics. For the EBM, single-agent RL outperformed static parameter tuning with the strongest gains in tropical and mid-latitude bands, while federated RL on multi-agent setups enabled geographically specialised control and faster convergence, with a six-agent DDPG configuration using frequent aggregation yielding the lowest area-weighted RMSE across the tropics and mid-latitudes. The learnt corrections were also physically meaningful as agents modulated EBM radiative parameters to reduce meridional biases, adjusted RCE lapse rates to match vertical temperature errors, and stabilised SCBC heating increments to limit drift. Overall, results highlight RL to deliver skilful state-dependent, and regime-aware parametrisations, offering a scalable pathway for online learning within numerical models.",
      "authors": [
        "Pritthijit Nath",
        "Sebastian Schemm",
        "Henry Moss",
        "Peter Haynes",
        "Emily Shuckburgh",
        "Mark J. Webb"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "physics.ao-ph"
      ],
      "published": "2026-01-07 11:19:16+00:00",
      "link": "https://arxiv.org/pdf/2601.04268v1",
      "tags": [
        "keyword:resnet",
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.03812v1",
      "title": "AI Generated Text Detection",
      "abstract": "The rapid development of large language models has led to an increase in AI-generated text, with students increasingly using LLM-generated content as their own work, which violates academic integrity. This paper presents an evaluation of AI text detection methods, including both traditional machine learning models and transformer-based architectures. We utilize two datasets, HC3 and DAIGT v2, to build a unified benchmark and apply a topic-based data split to prevent information leakage. This approach ensures robust generalization across unseen domains. Our experiments show that TF-IDF logistic regression achieves a reasonable baseline accuracy of 82.87%. However, deep learning models outperform it. The BiLSTM classifier achieves an accuracy of 88.86%, while DistilBERT achieves a similar accuracy of 88.11% with the highest ROC-AUC score of 0.96, demonstrating the strongest overall performance. The results indicate that contextual semantic modeling is significantly superior to lexical features and highlight the importance of mitigating topic memorization through appropriate evaluation protocols. The limitations of this work are primarily related to dataset diversity and computational constraints. In future work, we plan to expand dataset diversity and utilize parameter-efficient fine-tuning methods such as LoRA. We also plan to explore smaller or distilled models and employ more efficient batching strategies and hardware-aware optimization.",
      "authors": [
        "Adilkhan Alikhanov",
        "Aidar Amangeldi",
        "Diar Demeubay",
        "Dilnaz Akhmetzhan",
        "Nurbek Moldakhmetov",
        "Omar Polat",
        "Galymzhan Zharas"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-07 11:18:10+00:00",
      "link": "https://arxiv.org/pdf/2601.03812v1",
      "tags": [
        "keyword:大语言模型",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03808v1",
      "title": "From Brute Force to Semantic Insight: Performance-Guided Data Transformation Design with LLMs",
      "abstract": "Large language models (LLMs) have achieved notable performance in code synthesis; however, data-aware augmentation remains a limiting factor, handled via heuristic design or brute-force approaches. We introduce a performance-aware, closed-loop solution in the NNGPT ecosystem of projects that enables LLMs to autonomously engineer optimal transformations by internalizing empirical performance cues. We fine-tune LLMs with Low-Rank Adaptation on a novel repository of more than 6,000 empirically evaluated PyTorch augmentation functions, each annotated solely by downstream model accuracy. Training uses pairwise performance ordering (better-worse transformations), enabling alignment through empirical feedback without reinforcement learning, reward models, or symbolic objectives. This reduces the need for exhaustive search, achieving up to 600x times fewer evaluated candidates than brute-force discovery while maintaining competitive peak accuracy and shifting generation from random synthesis to task-aligned design. Ablation studies show that structured Chain-of-Thought prompting introduces syntactic noise and degrades performance, whereas direct prompting ensures stable optimization in performance-critical code tasks. Qualitative and quantitative analyses demonstrate that the model internalizes semantic performance cues rather than memorizing syntax. These results show that LLMs can exhibit task-level reasoning through non-textual feedback loops, bypassing explicit symbolic rewards.",
      "authors": [
        "Usha Shrestha",
        "Dmitry Ignatov",
        "Radu Timofte"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-01-07 11:13:02+00:00",
      "link": "https://arxiv.org/pdf/2601.03808v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03802v1",
      "title": "Quantum vs. Classical Machine Learning: A Benchmark Study for Financial Prediction",
      "abstract": "In this paper, we present a reproducible benchmarking framework that systematically compares QML models with architecture-matched classical counterparts across three financial tasks: (i) directional return prediction on U.S. and Turkish equities, (ii) live-trading simulation with Quantum LSTMs versus classical LSTMs on the S\\&P 500, and (iii) realized volatility forecasting using Quantum Support Vector Regression. By standardizing data splits, features, and evaluation metrics, our study provides a fair assessment of when current-generation QML models can match or exceed classical methods. Our results reveal that quantum approaches show performance gains when data structure and circuit design are well aligned. In directional classification, hybrid quantum neural networks surpass the parameter-matched ANN by \\textbf{+3.8 AUC} and \\textbf{+3.4 accuracy points} on \\texttt{AAPL} stock and by \\textbf{+4.9 AUC} and \\textbf{+3.6 accuracy points} on Turkish stock \\texttt{KCHOL}. In live trading, the QLSTM achieves higher risk-adjusted returns in \\textbf{two of four} S\\&P~500 regimes. For volatility forecasting, an angle-encoded QSVR attains the \\textbf{lowest QLIKE} on \\texttt{KCHOL} and remains within $\\sim$0.02-0.04 QLIKE of the best classical kernels on \\texttt{S\\&P~500} and \\texttt{AAPL}. Our benchmarking framework clearly identifies the scenarios where current QML architectures offer tangible improvements and where established classical methods continue to dominate.",
      "authors": [
        "Rehan Ahmad",
        "Muhammad Kashif",
        "Nouhaila Innan",
        "Muhammad Shafique"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "quant-ph"
      ],
      "published": "2026-01-07 11:02:03+00:00",
      "link": "https://arxiv.org/pdf/2601.03802v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03798v1",
      "title": "Where meaning lives: Layer-wise accessibility of psycholinguistic features in encoder and decoder language models",
      "abstract": "Understanding where transformer language models encode psychologically meaningful aspects of meaning is essential for both theory and practice. We conduct a systematic layer-wise probing study of 58 psycholinguistic features across 10 transformer models, spanning encoder-only and decoder-only architectures, and compare three embedding extraction methods. We find that apparent localization of meaning is strongly method-dependent: contextualized embeddings yield higher feature-specific selectivity and different layer-wise profiles than isolated embeddings. Across models and methods, final-layer representations are rarely optimal for recovering psycholinguistic information with linear probes. Despite these differences, models exhibit a shared depth ordering of meaning dimensions, with lexical properties peaking earlier and experiential and affective dimensions peaking later. Together, these results show that where meaning \"lives\" in transformer models reflects an interaction between methodological choices and architectural constraints.",
      "authors": [
        "Taisiia Tikhomirova",
        "Dirk U. Wulff"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-07 10:55:04+00:00",
      "link": "https://arxiv.org/pdf/2601.03798v1",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.03792v1",
      "title": "VietMed-MCQ: A Consistency-Filtered Data Synthesis Framework for Vietnamese Traditional Medicine Evaluation",
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable proficiency in general medical domains. However, their performance significantly degrades in specialized, culturally specific domains such as Vietnamese Traditional Medicine (VTM), primarily due to the scarcity of high-quality, structured benchmarks. In this paper, we introduce VietMed-MCQ, a novel multiple-choice question dataset generated via a Retrieval-Augmented Generation (RAG) pipeline with an automated consistency check mechanism. Unlike previous synthetic datasets, our framework incorporates a dual-model validation approach to ensure reasoning consistency through independent answer verification, though the substring-based evidence checking has known limitations. The complete dataset of 3,190 questions spans three difficulty levels and underwent validation by one medical expert and four students, achieving 94.2 percent approval with substantial inter-rater agreement (Fleiss' kappa = 0.82). We benchmark seven open-source models on VietMed-MCQ. Results reveal that general-purpose models with strong Chinese priors outperform Vietnamese-centric models, highlighting cross-lingual conceptual transfer, while all models still struggle with complex diagnostic reasoning. Our code and dataset are publicly available to foster research in low-resource medical domains.",
      "authors": [
        "Huynh Trung Kiet",
        "Dao Sy Duy Minh",
        "Nguyen Dinh Ha Duong",
        "Le Hoang Minh Huy",
        "Long Nguyen",
        "Dien Dinh"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 10:49:56+00:00",
      "link": "https://arxiv.org/pdf/2601.03792v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03783v1",
      "title": "HearSay Benchmark: Do Audio LLMs Leak What They Hear?",
      "abstract": "While Audio Large Language Models (ALLMs) have achieved remarkable progress in understanding and generation, their potential privacy implications remain largely unexplored. This paper takes the first step to investigate whether ALLMs inadvertently leak user privacy solely through acoustic voiceprints and introduces $\\textit{HearSay}$, a comprehensive benchmark constructed from over 22,000 real-world audio clips. To ensure data quality, the benchmark is meticulously curated through a rigorous pipeline involving automated profiling and human verification, guaranteeing that all privacy labels are grounded in factual records. Extensive experiments on $\\textit{HearSay}$ yield three critical findings: $\\textbf{Significant Privacy Leakage}$: ALLMs inherently extract private attributes from voiceprints, reaching 92.89% accuracy on gender and effectively profiling social attributes. $\\textbf{Insufficient Safety Mechanisms}$: Alarmingly, existing safeguards are severely inadequate; most models fail to refuse privacy-intruding requests, exhibiting near-zero refusal rates for physiological traits. $\\textbf{Reasoning Amplifies Risk}$: Chain-of-Thought (CoT) reasoning exacerbates privacy risks in capable models by uncovering deeper acoustic correlations. These findings expose critical vulnerabilities in ALLMs, underscoring the urgent need for targeted privacy alignment. The codes and dataset are available at https://github.com/JinWang79/HearSay_Benchmark",
      "authors": [
        "Jin Wang",
        "Liang Lin",
        "Kaiwen Luo",
        "Weiliu Wang",
        "Yitian Chen",
        "Moayad Aloqaily",
        "Xuehai Tang",
        "Zhenhong Zhou",
        "Kun Wang",
        "Li Sun",
        "Qingsong Wen"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 10:33:44+00:00",
      "link": "https://arxiv.org/pdf/2601.03783v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03782v1",
      "title": "PointWorld: Scaling 3D World Models for In-The-Wild Robotic Manipulation",
      "abstract": "Humans anticipate, from a glance and a contemplated action of their bodies, how the 3D world will respond, a capability that is equally vital for robotic manipulation. We introduce PointWorld, a large pre-trained 3D world model that unifies state and action in a shared 3D space as 3D point flows: given one or few RGB-D images and a sequence of low-level robot action commands, PointWorld forecasts per-pixel displacements in 3D that respond to the given actions. By representing actions as 3D point flows instead of embodiment-specific action spaces (e.g., joint positions), this formulation directly conditions on physical geometries of robots while seamlessly integrating learning across embodiments. To train our 3D world model, we curate a large-scale dataset spanning real and simulated robotic manipulation in open-world environments, enabled by recent advances in 3D vision and simulated environments, totaling about 2M trajectories and 500 hours across a single-arm Franka and a bimanual humanoid. Through rigorous, large-scale empirical studies of backbones, action representations, learning objectives, partial observability, data mixtures, domain transfers, and scaling, we distill design principles for large-scale 3D world modeling. With a real-time (0.1s) inference speed, PointWorld can be efficiently integrated in the model-predictive control (MPC) framework for manipulation. We demonstrate that a single pre-trained checkpoint enables a real-world Franka robot to perform rigid-body pushing, deformable and articulated object manipulation, and tool use, without requiring any demonstrations or post-training and all from a single image captured in-the-wild. Project website at https://point-world.github.io/.",
      "authors": [
        "Wenlong Huang",
        "Yu-Wei Chao",
        "Arsalan Mousavian",
        "Ming-Yu Liu",
        "Dieter Fox",
        "Kaichun Mo",
        "Li Fei-Fei"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "published": "2026-01-07 10:29:12+00:00",
      "link": "https://arxiv.org/pdf/2601.03782v1",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.03780v1",
      "title": "Assessing and Improving the Representativeness of Code Generation Benchmarks Using Knowledge Units (KUs) of Programming Languages -- An Empirical Study",
      "abstract": "Large Language Models (LLMs) such as GPT-4, Claude and LLaMA have shown impressive performance in code generation, typically evaluated using benchmarks (e.g., HumanEval). However, effective code generation requires models to understand and apply a wide range of language concepts. If the concepts exercised in benchmarks are not representative of those used in real-world projects, evaluations may yield incomplete. Despite this concern, the representativeness of code concepts in benchmarks has not been systematically examined.   To address this gap, we present the first empirical study that analyzes the representativeness of code generation benchmarks through the lens of Knowledge Units (KUs) - cohesive sets of programming language capabilities provided by language constructs and APIs. We analyze KU coverage in two widely used Python benchmarks, HumanEval and MBPP, and compare them with 30 real-world Python projects. Our results show that each benchmark covers only half of the identified 20 KUs, whereas projects exercise all KUs with relatively balanced distributions. In contrast, benchmark tasks exhibit highly skewed KU distributions.   To mitigate this misalignment, we propose a prompt-based LLM framework that synthesizes KU-based tasks to rebalance benchmark KU distributions and better align them with real-world usage. Using this framework, we generate 440 new tasks and augment existing benchmarks. The augmented benchmarks substantially improve KU coverage and achieve over a 60% improvement in distributional alignment. Evaluations of state-of-the-art LLMs on these augmented benchmarks reveal consistent and statistically significant performance drops (12.54-44.82%), indicating that existing benchmarks overestimate LLM performance due to their limited KU coverage. Our findings provide actionable guidance for building more realistic evaluations of LLM code-generation capabilities.",
      "authors": [
        "Md Ahasanuzzaman",
        "Bram Adams",
        "Emad Fallahzadeh",
        "Gustavo A. Oliva",
        "Ahmed E. Hassan"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE"
      ],
      "published": "2026-01-07 10:23:33+00:00",
      "link": "https://arxiv.org/pdf/2601.03780v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03774v1",
      "title": "Scalable Machine Learning Force Fields for Macromolecular Systems Through Long-Range Aware Message Passing",
      "abstract": "Machine learning force fields (MLFFs) have revolutionized molecular simulations by providing quantum mechanical accuracy at the speed of molecular mechanical computations. However, a fundamental reliance of these models on fixed-cutoff architectures limits their applicability to macromolecular systems where long-range interactions dominate. We demonstrate that this locality constraint causes force prediction errors to scale monotonically with system size, revealing a critical architectural bottleneck. To overcome this, we establish the systematically designed MolLR25 ({Mol}ecules with {L}ong-{R}ange effect) benchmark up to 1200 atoms, generated using high-fidelity DFT, and introduce E2Former-LSR, an equivariant transformer that explicitly integrates long-range attention blocks. E2Former-LSR exhibits stable error scaling, achieves superior fidelity in capturing non-covalent decay, and maintains precision on complex protein conformations. Crucially, its efficient design provides up to 30% speedup compared to purely local models. This work validates the necessity of non-local architectures for generalizable MLFFs, enabling high-fidelity molecular dynamics for large-scale chemical and biological systems.",
      "authors": [
        "Chu Wang",
        "Lin Huang",
        "Xinran Wei",
        "Tao Qin",
        "Arthur Jiang",
        "Lixue Cheng",
        "Jia Zhang"
      ],
      "primary_category": "physics.chem-ph",
      "categories": [
        "physics.chem-ph",
        "cs.AI",
        "physics.bio-ph"
      ],
      "published": "2026-01-07 10:12:34+00:00",
      "link": "https://arxiv.org/pdf/2601.03774v1",
      "tags": [
        "keyword:resnet",
        "keyword:大语言模型",
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03769v2",
      "title": "EntroCoT: Enhancing Chain-of-Thought via Adaptive Entropy-Guided Segmentation",
      "abstract": "Chain-of-Thought (CoT) prompting has significantly enhanced the mathematical reasoning capabilities of Large Language Models. We find existing fine-tuning datasets frequently suffer from the \"answer right but reasoning wrong\" probelm, where correct final answers are derived from hallucinated, redundant, or logically invalid intermediate steps. This paper proposes EntroCoT, a unified framework for automatically identifying and refining low-quality CoT supervision traces. EntroCoT first proposes an entropy-based mechanism to segment the reasoning trace into multiple steps at uncertain junctures, and then introduces a Monte Carlo rollout-based mechanism to evaluate the marginal contribution of each step. By accurately filtering deceptive reasoning samples, EntroCoT constructs a high-quality dataset where every intermediate step in each reasoning trace facilitates the final answer. Extensive experiments on mathematical benchmarks demonstrate that fine-tuning on the subset constructed by EntroCoT consistently outperforms the baseslines of full-dataset supervision.",
      "authors": [
        "Zihang Li",
        "Yuhang Wang",
        "Yikun Zong",
        "Wenhan Yu",
        "Xiaokun Yuan",
        "Runhan Jiang",
        "Zirui Liu",
        "Tong Yang",
        "Arthur Jiang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-07 10:02:27+00:00",
      "link": "https://arxiv.org/pdf/2601.03769v2",
      "tags": [
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.03753v1",
      "title": "Probabilistic Transformers for Joint Modeling of Global Weather Dynamics and Decision-Centric Variables",
      "abstract": "Weather forecasts sit upstream of high-stakes decisions in domains such as grid operations, aviation, agriculture, and emergency response. Yet forecast users often face a difficult trade-off. Many decision-relevant targets are functionals of the atmospheric state variables, such as extrema, accumulations, and threshold exceedances, rather than state variables themselves. As a result, users must estimate these targets via post-processing, which can be suboptimal and can introduce structural bias. The core issue is that decisions depend on distributions over these functionals that the model is not trained to learn directly.   In this work, we introduce GEM-2, a probabilistic transformer that jointly learns global atmospheric dynamics alongside a suite of variables that users directly act upon. Using this training recipe, we show that a lightweight (~275M params) and computationally efficient (~20-100x training speedup relative to state-of-the-art) transformer trained on the CRPS objective can directly outperform operational numerical weather prediction (NWP) models and be competitive with ML models that rely on expensive multi-step diffusion processes or require bespoke multi-stage fine-tuning strategies. We further demonstrate state-of-the-art economic value metrics under decision-theoretic evaluation, stable convergence to climatology at S2S and seasonal timescales, and a surprising insensitivity to many commonly assumed architectural and training design choices.",
      "authors": [
        "Paulius Rauba",
        "Viktor Cikojevic",
        "Fran Bartolic",
        "Sam Levang",
        "Ty Dickinson",
        "Chase Dwelle"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 09:43:36+00:00",
      "link": "https://arxiv.org/pdf/2601.03753v1",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.03743v1",
      "title": "O-Researcher: An Open Ended Deep Research Model via Multi-Agent Distillation and Agentic RL",
      "abstract": "The performance gap between closed-source and open-source large language models (LLMs) is largely attributed to disparities in access to high-quality training data. To bridge this gap, we introduce a novel framework for the automated synthesis of sophisticated, research-grade instructional data. Our approach centers on a multi-agent workflow where collaborative AI agents simulate complex tool-integrated reasoning to generate diverse and high-fidelity data end-to-end. Leveraging this synthesized data, we develop a two-stage training strategy that integrates supervised fine-tuning with a novel reinforcement learning method, designed to maximize model alignment and capability. Extensive experiments demonstrate that our framework empowers open-source models across multiple scales, enabling them to achieve new state-of-the-art performance on the major deep research benchmark. This work provides a scalable and effective pathway for advancing open-source LLMs without relying on proprietary data or models.",
      "authors": [
        "Yi Yao",
        "He Zhu",
        "Piaohong Wang",
        "Jincheng Ren",
        "Xinlong Yang",
        "Qianben Chen",
        "Xiaowan Li",
        "Dingfeng Shi",
        "Jiaxian Li",
        "Qiexiang Wang",
        "Sinuo Wang",
        "Xinpeng Liu",
        "Jiaqi Wu",
        "Minghao Liu",
        "Wangchunshu Zhou"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-07 09:31:10+00:00",
      "link": "https://arxiv.org/pdf/2601.03743v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03741v1",
      "title": "I2E: From Image Pixels to Actionable Interactive Environments for Text-Guided Image Editing",
      "abstract": "Existing text-guided image editing methods primarily rely on end-to-end pixel-level inpainting paradigm. Despite its success in simple scenarios, this paradigm still significantly struggles with compositional editing tasks that require precise local control and complex multi-object spatial reasoning. This paradigm is severely limited by 1) the implicit coupling of planning and execution, 2) the lack of object-level control granularity, and 3) the reliance on unstructured, pixel-centric modeling. To address these limitations, we propose I2E, a novel \"Decompose-then-Action\" paradigm that revisits image editing as an actionable interaction process within a structured environment. I2E utilizes a Decomposer to transform unstructured images into discrete, manipulable object layers and then introduces a physics-aware Vision-Language-Action Agent to parse complex instructions into a series of atomic actions via Chain-of-Thought reasoning. Further, we also construct I2E-Bench, a benchmark designed for multi-instance spatial reasoning and high-precision editing. Experimental results on I2E-Bench and multiple public benchmarks demonstrate that I2E significantly outperforms state-of-the-art methods in handling complex compositional instructions, maintaining physical plausibility, and ensuring multi-turn editing stability.",
      "authors": [
        "Jinghan Yu",
        "Junhao Xiao",
        "Chenyu Zhu",
        "Jiaming Li",
        "Jia Li",
        "HanMing Deng",
        "Xirui Wang",
        "Guoli Jia",
        "Jianjun Li",
        "Zhiyuan Ma",
        "Xiang Bai",
        "Bowen Zhou"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-07 09:29:57+00:00",
      "link": "https://arxiv.org/pdf/2601.03741v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03736v1",
      "title": "HyperCOD: The First Challenging Benchmark and Baseline for Hyperspectral Camouflaged Object Detection",
      "abstract": "RGB-based camouflaged object detection struggles in real-world scenarios where color and texture cues are ambiguous. While hyperspectral image offers a powerful alternative by capturing fine-grained spectral signatures, progress in hyperspectral camouflaged object detection (HCOD) has been critically hampered by the absence of a dedicated, large-scale benchmark. To spur innovation, we introduce HyperCOD, the first challenging benchmark for HCOD. Comprising 350 high-resolution hyperspectral images, It features complex real-world scenarios with minimal objects, intricate shapes, severe occlusions, and dynamic lighting to challenge current models. The advent of foundation models like the Segment Anything Model (SAM) presents a compelling opportunity. To adapt the Segment Anything Model (SAM) for HCOD, we propose HyperSpectral Camouflage-aware SAM (HSC-SAM). HSC-SAM ingeniously reformulates the hyperspectral image by decoupling it into a spatial map fed to SAM's image encoder and a spectral saliency map that serves as an adaptive prompt. This translation effectively bridges the modality gap. Extensive experiments show that HSC-SAM sets a new state-of-the-art on HyperCOD and generalizes robustly to other public HSI datasets. The HyperCOD dataset and our HSC-SAM baseline provide a robust foundation to foster future research in this emerging area.",
      "authors": [
        "Shuyan Bai",
        "Tingfa Xu",
        "Peifu Liu",
        "Yuhao Qiu",
        "Huiyan Bai",
        "Huan Chen",
        "Yanyan Peng",
        "Jianan Li"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-07 09:26:32+00:00",
      "link": "https://arxiv.org/pdf/2601.03736v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03733v1",
      "title": "RadDiff: Describing Differences in Radiology Image Sets with Natural Language",
      "abstract": "Understanding how two radiology image sets differ is critical for generating clinical insights and for interpreting medical AI systems. We introduce RadDiff, a multimodal agentic system that performs radiologist-style comparative reasoning to describe clinically meaningful differences between paired radiology studies. RadDiff builds on a proposer-ranker framework from VisDiff, and incorporates four innovations inspired by real diagnostic workflows: (1) medical knowledge injection through domain-adapted vision-language models; (2) multimodal reasoning that integrates images with their clinical reports; (3) iterative hypothesis refinement across multiple reasoning rounds; and (4) targeted visual search that localizes and zooms in on salient regions to capture subtle findings. To evaluate RadDiff, we construct RadDiffBench, a challenging benchmark comprising 57 expert-validated radiology study pairs with ground-truth difference descriptions. On RadDiffBench, RadDiff achieves 47% accuracy, and 50% accuracy when guided by ground-truth reports, significantly outperforming the general-domain VisDiff baseline. We further demonstrate RadDiff's versatility across diverse clinical tasks, including COVID-19 phenotype comparison, racial subgroup analysis, and discovery of survival-related imaging features. Together, RadDiff and RadDiffBench provide the first method-and-benchmark foundation for systematically uncovering meaningful differences in radiological data.",
      "authors": [
        "Xiaoxian Shen",
        "Yuhui Zhang",
        "Sahithi Ankireddy",
        "Xiaohan Wang",
        "Maya Varma",
        "Henry Guo",
        "Curtis Langlotz",
        "Serena Yeung-Levy"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.LG"
      ],
      "published": "2026-01-07 09:25:04+00:00",
      "link": "https://arxiv.org/pdf/2601.03733v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03731v1",
      "title": "From Laboratory to Real-World Applications: Benchmarking Agentic Code Reasoning at the Repository Level",
      "abstract": "As large language models (LLMs) evolve into autonomous agents, evaluating repository-level reasoning, the ability to maintain logical consistency across massive, real-world, interdependent file systems, has become critical. Current benchmarks typically fluctuate between isolated code snippets and black-box evaluations. We present RepoReason, a white-box diagnostic benchmark centered on abductive assertion verification. To eliminate memorization while preserving authentic logical depth, we implement an execution-driven mutation framework that utilizes the environment as a semantic oracle to regenerate ground-truth states. Furthermore, we establish a fine-grained diagnostic system using dynamic program slicing, quantifying reasoning via three orthogonal metrics: $ESV$ (reading load), $MCL$ (simulation depth), and $DFI$ (integration width). Comprehensive evaluations of frontier models (e.g., Claude-4.5-Sonnet, DeepSeek-v3.1-Terminus) reveal a prevalent aggregation deficit, where integration width serves as the primary cognitive bottleneck. Our findings provide granular white-box insights for optimizing the next generation of agentic software engineering.",
      "authors": [
        "Jia Li",
        "Yuxin Su",
        "Michael R. Lyu"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "published": "2026-01-07 09:22:28+00:00",
      "link": "https://arxiv.org/pdf/2601.03731v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03729v1",
      "title": "MATANet: A Multi-context Attention and Taxonomy-Aware Network for Fine-Grained Underwater Recognition of Marine Species",
      "abstract": "Fine-grained classification of marine animals supports ecology, biodiversity and habitat conservation, and evidence-based policy-making. However, existing methods often overlook contextual interactions from the surrounding environment and insufficiently incorporate the hierarchical structure of marine biological taxonomy. To address these challenges, we propose MATANet (Multi-context Attention and Taxonomy-Aware Network), a novel model designed for fine-grained marine species classification. MATANet mimics expert strategies by using taxonomy and environmental context to interpret ambiguous features of underwater animals. It consists of two key components: a Multi-Context Environmental Attention Module (MCEAM), which learns relationships between regions of interest (ROIs) and their surrounding environments, and a Hierarchical Separation-Induced Learning Module (HSLM), which encodes taxonomic hierarchy into the feature space. MATANet combines instance and environmental features with taxonomic structure to enhance fine-grained classification. Experiments on the FathomNet2025, FAIR1M, and LifeCLEF2015-Fish datasets demonstrate state-of-the-art performance. The source code is available at: https://github.com/dhlee-work/fathomnet-cvpr2025-ssl",
      "authors": [
        "Donghwan Lee",
        "Byeongjin Kim",
        "Geunhee Kim",
        "Hyukjin Kwon",
        "Nahyeon Maeng",
        "Wooju Kim"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-07 09:21:45+00:00",
      "link": "https://arxiv.org/pdf/2601.03729v1",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.03725v1",
      "title": "EDCO: Dynamic Curriculum Orchestration for Domain-specific Large Language Model Fine-tuning",
      "abstract": "Domain-specific large language models (LLMs), typically developed by fine-tuning a pre-trained general-purpose LLM on specialized datasets, represent a significant advancement in applied AI. A common strategy in LLM fine-tuning is curriculum learning, which pre-orders training samples based on metrics like difficulty to improve learning efficiency compared to a random sampling strategy. However, most existing methods for LLM fine-tuning rely on a static curriculum, designed prior to training, which lacks adaptability to the model's evolving needs during fine-tuning. To address this, we propose EDCO, a novel framework based on two key concepts: inference entropy and dynamic curriculum orchestration. Inspired by recent findings that maintaining high answer entropy benefits long-term reasoning gains, EDCO prioritizes samples with high inference entropy in a continuously adapted curriculum. EDCO integrates three core components: an efficient entropy estimator that uses prefix tokens to approximate full-sequence entropy, an entropy-based curriculum generator that selects data points with the highest inference entropy, and an LLM trainer that optimizes the model on the selected curriculum. Comprehensive experiments in communication, medicine and law domains, EDCO outperforms traditional curriculum strategies for fine-tuning Qwen3-4B and Llama3.2-3B models under supervised and reinforcement learning settings. Furthermore, the proposed efficient entropy estimation reduces computational time by 83.5% while maintaining high accuracy.",
      "authors": [
        "Jing-Cheng Pang",
        "Liu Sun",
        "Chang Zhou",
        "Xian Tang",
        "Haichuan Ma",
        "Kun Jiang",
        "Jianlong Wang",
        "Kai Zhang",
        "Sijie Wu",
        "Haoran Cai",
        "Chenwei Wu",
        "Xubin Li",
        "Xin Chen"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 09:20:05+00:00",
      "link": "https://arxiv.org/pdf/2601.03725v1",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.03714v2",
      "title": "Visual Merit or Linguistic Crutch? A Close Look at DeepSeek-OCR",
      "abstract": "DeepSeek-OCR utilizes an optical 2D mapping approach to achieve high-ratio vision-text compression, claiming to decode text tokens exceeding ten times the input visual tokens. While this suggests a promising solution for the LLM long-context bottleneck, we investigate a critical question: \"Visual merit or linguistic crutch - which drives DeepSeek-OCR's performance?\" By employing sentence-level and word-level semantic corruption, we isolate the model's intrinsic OCR capabilities from its language priors. Results demonstrate that without linguistic support, DeepSeek-OCR's performance plummets from approximately 90% to 20%. Comparative benchmarking against 13 baseline models reveals that traditional pipeline OCR methods exhibit significantly higher robustness to such semantic perturbations than end-to-end methods. Furthermore, we find that lower visual token counts correlate with increased reliance on priors, exacerbating hallucination risks. Context stress testing also reveals a total model collapse around 10,000 text tokens, suggesting that current optical compression techniques may paradoxically aggravate the long-context bottleneck. This study empirically defines DeepSeek-OCR's capability boundaries and offers essential insights for future optimizations of the vision-text compression paradigm. We release all data, results and scripts used in this study at https://github.com/dududuck00/DeepSeekOCR.",
      "authors": [
        "Yunhao Liang",
        "Ruixuan Ying",
        "Bo Li",
        "Hong Li",
        "Kai Yan",
        "Qingwen Li",
        "Min Yang",
        "Okamoto Satoshi",
        "Zhe Cui",
        "Shiwen Ni"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.CV"
      ],
      "published": "2026-01-07 09:01:23+00:00",
      "link": "https://arxiv.org/pdf/2601.03714v2",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03713v1",
      "title": "BREATH-VL: Vision-Language-Guided 6-DoF Bronchoscopy Localization via Semantic-Geometric Fusion",
      "abstract": "Vision-language models (VLMs) have recently shown remarkable performance in navigation and localization tasks by leveraging large-scale pretraining for semantic understanding. However, applying VLMs to 6-DoF endoscopic camera localization presents several challenges: 1) the lack of large-scale, high-quality, densely annotated, and localization-oriented vision-language datasets in real-world medical settings; 2) limited capability for fine-grained pose regression; and 3) high computational latency when extracting temporal features from past frames. To address these issues, we first construct BREATH dataset, the largest in-vivo endoscopic localization dataset to date, collected in the complex human airway. Building on this dataset, we propose BREATH-VL, a hybrid framework that integrates semantic cues from VLMs with geometric information from vision-based registration methods for accurate 6-DoF pose estimation. Our motivation lies in the complementary strengths of both approaches: VLMs offer generalizable semantic understanding, while registration methods provide precise geometric alignment. To further enhance the VLM's ability to capture temporal context, we introduce a lightweight context-learning mechanism that encodes motion history as linguistic prompts, enabling efficient temporal reasoning without expensive video-level computation. Extensive experiments demonstrate that the vision-language module delivers robust semantic localization in challenging surgical scenes. Building on this, our BREATH-VL outperforms state-of-the-art vision-only localization methods in both accuracy and generalization, reducing translational error by 25.5% compared with the best-performing baseline, while achieving competitive computational latency.",
      "authors": [
        "Qingyao Tian",
        "Bingyu Yang",
        "Huai Liao",
        "Xinyan Huang",
        "Junyong Li",
        "Dong Yi",
        "Hongbin Liu"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-07 09:00:52+00:00",
      "link": "https://arxiv.org/pdf/2601.03713v1",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.03708v1",
      "title": "MHRC-Bench: A Multilingual Hardware Repository-Level Code Completion benchmark",
      "abstract": "Large language models (LLMs) have achieved strong performance on code completion tasks in general-purpose programming languages. However, existing repository-level code completion benchmarks focus almost exclusively on software code and largely overlook hardware description languages. In this work, we present \\textbf{MHRC-Bench}, consisting of \\textbf{MHRC-Bench-Train} and \\textbf{MHRC-Bench-Eval}, the first benchmark designed for multilingual hardware code completion at the repository level. Our benchmark targets completion tasks and covers three major hardware design coding styles. Each completion target is annotated with code-structure-level and hardware-oriented semantic labels derived from concrete syntax tree analysis. We conduct a comprehensive evaluation of models on MHRC-Bench-Eval. Comprehensive evaluation results and analysis demonstrate the effectiveness of MHRC-Bench.",
      "authors": [
        "Qingyun Zou",
        "Jiahao Cui",
        "Nuo Chen",
        "Bingsheng He",
        "Weng-Fai Wong"
      ],
      "primary_category": "cs.PL",
      "categories": [
        "cs.PL",
        "cs.AI"
      ],
      "published": "2026-01-07 08:46:10+00:00",
      "link": "https://arxiv.org/pdf/2601.03708v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03707v1",
      "title": "AirNav: A Large-Scale Real-World UAV Vision-and-Language Navigation Dataset with Natural and Diverse Instructions",
      "abstract": "Existing Unmanned Aerial Vehicle (UAV) Vision-Language Navigation (VLN) datasets face issues such as dependence on virtual environments, lack of naturalness in instructions, and limited scale. To address these challenges, we propose AirNav, a large-scale UAV VLN benchmark constructed from real urban aerial data, rather than synthetic environments, with natural and diverse instructions. Additionally, we introduce the AirVLN-R1, which combines Supervised Fine-Tuning and Reinforcement Fine-Tuning to enhance performance and generalization. The feasibility of the model is preliminarily evaluated through real-world tests. Our dataset and code are publicly available.",
      "authors": [
        "Hengxing Cai",
        "Yijie Rao",
        "Ligang Huang",
        "Zanyang Zhong",
        "Jinhan Dong",
        "Jingjun Tan",
        "Wenhao Lu",
        "Renxin Zhong"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 08:46:09+00:00",
      "link": "https://arxiv.org/pdf/2601.03707v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03704v1",
      "title": "Investigating Knowledge Distillation Through Neural Networks for Protein Binding Affinity Prediction",
      "abstract": "The trade-off between predictive accuracy and data availability makes it difficult to predict protein--protein binding affinity accurately. The lack of experimentally resolved protein structures limits the performance of structure-based machine learning models, which generally outperform sequence-based methods. In order to overcome this constraint, we suggest a regression framework based on knowledge distillation that uses protein structural data during training and only needs sequence data during inference. The suggested method uses binding affinity labels and intermediate feature representations to jointly supervise the training of a sequence-based student network under the guidance of a structure-informed teacher network. Leave-One-Complex-Out (LOCO) cross-validation was used to assess the framework on a non-redundant protein--protein binding affinity benchmark dataset. A maximum Pearson correlation coefficient (P_r) of 0.375 and an RMSE of 2.712 kcal/mol were obtained by sequence-only baseline models, whereas a P_r of 0.512 and an RMSE of 2.445 kcal/mol were obtained by structure-based models. With a P_r of 0.481 and an RMSE of 2.488 kcal/mol, the distillation-based student model greatly enhanced sequence-only performance. Improved agreement and decreased bias were further confirmed by thorough error analyses. With the potential to close the performance gap between sequence-based and structure-based models as larger datasets become available, these findings show that knowledge distillation is an efficient method for transferring structural knowledge to sequence-based predictors. The source code for running inference with the proposed distillation-based binding affinity predictor can be accessed at https://github.com/wajidarshad/ProteinAffinityKD.",
      "authors": [
        "Wajid Arshad Abbasi",
        "Syed Ali Abbas",
        "Maryum Bibi",
        "Saiqa Andleeb",
        "Muhammad Naveed Akhtar"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.BM",
        "q-bio.MN",
        "q-bio.QM"
      ],
      "published": "2026-01-07 08:43:08+00:00",
      "link": "https://arxiv.org/pdf/2601.03704v1",
      "tags": [
        "keyword:大语言模型",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03703v1",
      "title": "TreeAdv: Tree-Structured Advantage Redistribution for Group-Based RL",
      "abstract": "Reinforcement learning with group-based objectives, such as Group Relative Policy Optimization (GRPO), is a common framework for aligning large language models on complex reasoning tasks. However, standard GRPO treats each rollout trajectory as an independent flat sequence and assigns a single sequence-level advantage to all tokens, which leads to sample inefficiency and a length bias toward verbose, redundant chains of thought without improving logical depth. We introduce TreeAdv (Tree-Structured Advantage Redistribution for Group-Based RL), which makes the tree structure of group rollouts explicit for both exploration and advantage assignment. Specifically, TreeAdv builds a group of trees (a forest) based on an entropy-driven sampling method where each tree branches at high-uncertainty decisions while sharing low-uncertainty tokens across rollouts. Then, TreeAdv aggregates token-level advantages for internal tree segments by redistributing the advantages of complete rollouts (all leaf nodes), and TreeAdv can easily apply to group-based objectives such as GRPO or GSPO. Across 10 math reasoning benchmarks, TreeAdv consistently outperforms GRPO and GSPO, while using substantially fewer generated tokens under identical supervision, data, and decoding budgets.",
      "authors": [
        "Lang Cao",
        "Hui Ruan",
        "Yongqian Li",
        "Peng Chao",
        "Wu Ning",
        "Haonan Song",
        "Renhong Chen",
        "Yitong Li"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-07 08:42:14+00:00",
      "link": "https://arxiv.org/pdf/2601.03703v1",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.03699v1",
      "title": "RedBench: A Universal Dataset for Comprehensive Red Teaming of Large Language Models",
      "abstract": "As large language models (LLMs) become integral to safety-critical applications, ensuring their robustness against adversarial prompts is paramount. However, existing red teaming datasets suffer from inconsistent risk categorizations, limited domain coverage, and outdated evaluations, hindering systematic vulnerability assessments. To address these challenges, we introduce RedBench, a universal dataset aggregating 37 benchmark datasets from leading conferences and repositories, comprising 29,362 samples across attack and refusal prompts. RedBench employs a standardized taxonomy with 22 risk categories and 19 domains, enabling consistent and comprehensive evaluations of LLM vulnerabilities. We provide a detailed analysis of existing datasets, establish baselines for modern LLMs, and open-source the dataset and evaluation code. Our contributions facilitate robust comparisons, foster future research, and promote the development of secure and reliable LLMs for real-world deployment. Code: https://github.com/knoveleng/redeval",
      "authors": [
        "Quy-Anh Dang",
        "Chris Ngo",
        "Truong-Son Hy"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 08:34:17+00:00",
      "link": "https://arxiv.org/pdf/2601.03699v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03689v1",
      "title": "A Pre-trained Reaction Embedding Descriptor Capturing Bond Transformation Patterns",
      "abstract": "With the rise of data-driven reaction prediction models, effective reaction descriptors are crucial for bridging the gap between real-world chemistry and digital representations. However, general-purpose, reaction-wise descriptors remain scarce. This study introduces RXNEmb, a novel reaction-level descriptor derived from RXNGraphormer, a model pre-trained to distinguish real reactions from fictitious ones with erroneous bond changes, thereby learning intrinsic bond formation and cleavage patterns. We demonstrate its utility by data-driven re-clustering of the USPTO-50k dataset, yielding a classification that more directly reflects bond-change similarities than rule-based categories. Combined with dimensionality reduction, RXNEmb enables visualization of reaction space diversity. Furthermore, attention weight analysis reveals the model's focus on chemically critical sites, providing mechanistic insight. RXNEmb serves as a powerful, interpretable tool for reaction fingerprinting and analysis, paving the way for more data-centric approaches in reaction analysis and discovery.",
      "authors": [
        "Weiqi Liu",
        "Fenglei Cao",
        "Yuan Qi",
        "Li-Cheng Xu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.chem-ph"
      ],
      "published": "2026-01-07 08:24:08+00:00",
      "link": "https://arxiv.org/pdf/2601.03689v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03686v1",
      "title": "Dual-Attention Heterogeneous GNN for Multi-robot Collaborative Area Search via Deep Reinforcement Learning",
      "abstract": "In multi-robot collaborative area search, a key challenge is to dynamically balance the two objectives of exploring unknown areas and covering specific targets to be rescued. Existing methods are often constrained by homogeneous graph representations, thus failing to model and balance these distinct tasks. To address this problem, we propose a Dual-Attention Heterogeneous Graph Neural Network (DA-HGNN) trained using deep reinforcement learning. Our method constructs a heterogeneous graph that incorporates three entity types: robot nodes, frontier nodes, and interesting nodes, as well as their historical states. The dual-attention mechanism comprises the relational-aware attention and type-aware attention operations. The relational-aware attention captures the complex spatio-temporal relationships among robots and candidate goals. Building on this relational-aware heterogeneous graph, the type-aware attention separately computes the relevance between robots and each goal type (frontiers vs. points of interest), thereby decoupling the exploration and coverage from the unified tasks. Extensive experiments conducted in interactive 3D scenarios within the iGibson simulator, leveraging the Gibson and MatterPort3D datasets, validate the superior scalability and generalization capability of the proposed approach.",
      "authors": [
        "Lina Zhu",
        "Jiyu Cheng",
        "Yuehu Liu",
        "Wei Zhang"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-01-07 08:18:49+00:00",
      "link": "https://arxiv.org/pdf/2601.03686v1",
      "tags": [
        "keyword:resnet",
        "keyword:resnet中文",
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.03683v1",
      "title": "Rethinking Recurrent Neural Networks for Time Series Forecasting: A Reinforced Recurrent Encoder with Prediction-Oriented Proximal Policy Optimization",
      "abstract": "Time series forecasting plays a crucial role in contemporary engineering information systems for supporting decision-making across various industries, where Recurrent Neural Networks (RNNs) have been widely adopted due to their capability in modeling sequential data. Conventional RNN-based predictors adopt an encoder-only strategy with sliding historical windows as inputs to forecast future values. However, this approach treats all time steps and hidden states equally without considering their distinct contributions to forecasting, leading to suboptimal performance. To address this limitation, we propose a novel Reinforced Recurrent Encoder with Prediction-oriented Proximal Policy Optimization, RRE-PPO4Pred, which significantly improves time series modeling capacity and forecasting accuracy of the RNN models. The core innovations of this method are: (1) A novel Reinforced Recurrent Encoder (RRE) framework that enhances RNNs by formulating their internal adaptation as a Markov Decision Process, creating a unified decision environment capable of learning input feature selection, hidden skip connection, and output target selection; (2) An improved Prediction-oriented Proximal Policy Optimization algorithm, termed PPO4Pred, which is equipped with a Transformer-based agent for temporal reasoning and develops a dynamic transition sampling strategy to enhance sampling efficiency; (3) A co-evolutionary optimization paradigm to facilitate the learning of the RNN predictor and the policy agent, providing adaptive and interactive time series modeling. Comprehensive evaluations on five real-world datasets indicate that our method consistently outperforms existing baselines, and attains accuracy better than state-of-the-art Transformer models, thus providing an advanced time series predictor in engineering informatics.",
      "authors": [
        "Xin Lai",
        "Shiming Deng",
        "Lu Yu",
        "Yumin Lai",
        "Shenghao Qiao",
        "Xinze Zhang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.NE"
      ],
      "published": "2026-01-07 08:16:55+00:00",
      "link": "https://arxiv.org/pdf/2601.03683v1",
      "tags": [
        "keyword:resnet",
        "keyword:resnet中文",
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.03682v1",
      "title": "From Implicit to Explicit: Token-Efficient Logical Supervision for Mathematical Reasoning in LLMs",
      "abstract": "Recent studies reveal that large language models (LLMs) exhibit limited logical reasoning abilities in mathematical problem-solving, instead often relying on pattern-matching and memorization. We systematically analyze this limitation, focusing on logical relationship understanding, which is a core capability underlying genuine logical reasoning, and reveal that errors related to this capability account for over 90\\% of incorrect predictions, with Chain-of-Thought Supervised Fine-Tuning (CoT-SFT) failing to substantially reduce these errors. To address this bottleneck, we propose First-Step Logical Reasoning (FSLR), a lightweight training framework targeting logical relationship understanding. Our key insight is that the first planning step-identifying which variables to use and which operation to apply-encourages the model to derive logical relationships directly from the problem statement. By training models on this isolated step, FSLR provides explicit supervision for logical relationship understanding, unlike CoT-SFT which implicitly embeds such relationships within complete solution trajectories. Extensive experiments across multiple models and datasets demonstrate that FSLR consistently outperforms CoT-SFT under both in-distribution and out-of-distribution settings, with average improvements of 3.2\\% and 4.6\\%, respectively. Moreover, FSLR achieves 4-6x faster training and reduces training token consumption by over 80\\%.",
      "authors": [
        "Shaojie Wang",
        "Liang Zhang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-07 08:15:01+00:00",
      "link": "https://arxiv.org/pdf/2601.03682v1",
      "tags": [
        "keyword:resnet",
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.03676v1",
      "title": "Towards Compositional Generalization of LLMs via Skill Taxonomy Guided Data Synthesis",
      "abstract": "Large Language Models (LLMs) and agent-based systems often struggle with compositional generalization due to a data bottleneck in which complex skill combinations follow a long-tailed, power-law distribution, limiting both instruction-following performance and generalization in agent-centric tasks. To address this challenge, we propose STEPS, a Skill Taxonomy guided Entropy-based Post-training data Synthesis framework for generating compositionally challenging data. STEPS explicitly targets compositional generalization by uncovering latent relationships among skills and organizing them into an interpretable, hierarchical skill taxonomy using structural information theory. Building on this taxonomy, we formulate data synthesis as a constrained information maximization problem, selecting skill combinations that maximize marginal structural information within the hierarchy while preserving semantic coherence. Experiments on challenging instruction-following benchmarks show that STEPS outperforms existing data synthesis baselines, while also yielding improved compositional generalization in downstream agent-based evaluations.",
      "authors": [
        "Yifan Wei",
        "Li Du",
        "Xiaoyan Yu",
        "Yang Feng",
        "Angsheng Li"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-07 07:58:51+00:00",
      "link": "https://arxiv.org/pdf/2601.03676v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03673v1",
      "title": "Disentangling Aleatoric and Epistemic Uncertainty in Physics-Informed Neural Networks. Application to Insulation Material Degradation Prognostics",
      "abstract": "Physics-Informed Neural Networks (PINNs) provide a framework for integrating physical laws with data. However, their application to Prognostics and Health Management (PHM) remains constrained by the limited uncertainty quantification (UQ) capabilities. Most existing PINN-based prognostics approaches are deterministic or account only for epistemic uncertainty, limiting their suitability for risk-aware decision-making. This work introduces a heteroscedastic Bayesian Physics-Informed Neural Network (B-PINN) framework that jointly models epistemic and aleatoric uncertainty, yielding full predictive posteriors for spatiotemporal insulation material ageing estimation. The approach integrates Bayesian Neural Networks (BNNs) with physics-based residual enforcement and prior distributions, enabling probabilistic inference within a physics-informed learning architecture. The framework is evaluated on transformer insulation ageing application, validated with a finite-element thermal model and field measurements from a solar power plant, and benchmarked against deterministic PINNs, dropout-based PINNs (d-PINNs), and alternative B-PINN variants. Results show that the proposed B-PINN provides improved predictive accuracy and better-calibrated uncertainty estimates than competing approaches. A systematic sensitivity study further analyzes the impact of boundary-condition, initial-condition, and residual sampling strategies on accuracy, calibration, and generalization. Overall, the findings highlight the potential of Bayesian physics-informed learning to support uncertainty-aware prognostics and informed decision-making in transformer asset management.",
      "authors": [
        "Ibai Ramirez",
        "Jokin Alcibar",
        "Joel Pino",
        "Mikel Sanz",
        "Jose I. Aizpurua"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-07 07:54:09+00:00",
      "link": "https://arxiv.org/pdf/2601.03673v1",
      "tags": [
        "keyword:resnet",
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.03670v1",
      "title": "DisastQA: A Comprehensive Benchmark for Evaluating Question Answering in Disaster Management",
      "abstract": "Accurate question answering (QA) in disaster management requires reasoning over uncertain and conflicting information, a setting poorly captured by existing benchmarks built on clean evidence. We introduce DisastQA, a large-scale benchmark of 3,000 rigorously verified questions (2,000 multiple-choice and 1,000 open-ended) spanning eight disaster types. The benchmark is constructed via a human-LLM collaboration pipeline with stratified sampling to ensure balanced coverage. Models are evaluated under varying evidence conditions, from closed-book to noisy evidence integration, enabling separation of internal knowledge from reasoning under imperfect information. For open-ended QA, we propose a human-verified keypoint-based evaluation protocol emphasizing factual completeness over verbosity. Experiments with 20 models reveal substantial divergences from general-purpose leaderboards such as MMLU-Pro. While recent open-weight models approach proprietary systems in clean settings, performance degrades sharply under realistic noise, exposing critical reliability gaps for disaster response. All code, data, and evaluation resources are available at https://github.com/TamuChen18/DisastQA_open.",
      "authors": [
        "Zhitong Chen",
        "Kai Yin",
        "Xiangjue Dong",
        "Chengkai Liu",
        "Xiangpeng Li",
        "Yiming Xiao",
        "Bo Li",
        "Junwei Ma",
        "Ali Mostafavi",
        "James Caverlee"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 07:46:42+00:00",
      "link": "https://arxiv.org/pdf/2601.03670v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03668v1",
      "title": "Discontinuous Galerkin finite element operator network for solving non-smooth PDEs",
      "abstract": "We introduce Discontinuous Galerkin Finite Element Operator Network (DG--FEONet), a data-free operator learning framework that combines the strengths of the discontinuous Galerkin (DG) method with neural networks to solve parametric partial differential equations (PDEs) with discontinuous coefficients and non-smooth solutions. Unlike traditional operator learning models such as DeepONet and Fourier Neural Operator, which require large paired datasets and often struggle near sharp features, our approach minimizes the residual of a DG-based weak formulation using the Symmetric Interior Penalty Galerkin (SIPG) scheme. DG-FEONet predicts element-wise solution coefficients via a neural network, enabling data-free training without the need for precomputed input-output pairs. We provide theoretical justification through convergence analysis and validate the model's performance on a series of one- and two-dimensional PDE problems, demonstrating accurate recovery of discontinuities, strong generalization across parameter space, and reliable convergence rates. Our results highlight the potential of combining local discretization schemes with machine learning to achieve robust, singularity-aware operator approximation in challenging PDE settings.",
      "authors": [
        "Kapil Chawla",
        "Youngjoon Hong",
        "Jae Yong Lee",
        "Sanghyun Lee"
      ],
      "primary_category": "math.NA",
      "categories": [
        "math.NA",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-07 07:43:30+00:00",
      "link": "https://arxiv.org/pdf/2601.03668v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03667v2",
      "title": "TRec: Egocentric Action Recognition using 2D Point Tracks",
      "abstract": "We present a novel approach for egocentric action recognition that leverages 2D point tracks as an additional motion cue. While most existing methods rely on RGB appearance, human pose estimation, or their combination, our work demonstrates that tracking randomly sampled image points across video frames can substantially improve recognition accuracy. Unlike prior approaches, we do not detect hands, objects, or interaction regions. Instead, we employ CoTracker to follow a set of randomly initialized points through each video and use the resulting trajectories, together with the corresponding image frames, as input to a Transformer-based recognition model. Surprisingly, our method achieves notable gains even when only the initial frame and its associated point tracks are provided, without incorporating the full video sequence. Experimental results confirm that integrating 2D point tracks consistently enhances performance compared to the same model trained without motion information, highlighting their potential as a lightweight yet effective representation for egocentric action understanding.",
      "authors": [
        "Dennis Holzmann",
        "Sven Wachsmuth"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-01-07 07:41:57+00:00",
      "link": "https://arxiv.org/pdf/2601.03667v2",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.03665v1",
      "title": "PhysVideoGenerator: Towards Physically Aware Video Generation via Latent Physics Guidance",
      "abstract": "Current video generation models produce high-quality aesthetic videos but often struggle to learn representations of real-world physics dynamics, resulting in artifacts such as unnatural object collisions, inconsistent gravity, and temporal flickering. In this work, we propose PhysVideoGenerator, a proof-of-concept framework that explicitly embeds a learnable physics prior into the video generation process. We introduce a lightweight predictor network, PredictorP, which regresses high-level physical features extracted from a pre-trained Video Joint Embedding Predictive Architecture (V-JEPA 2) directly from noisy diffusion latents. These predicted physics tokens are injected into the temporal attention layers of a DiT-based generator (Latte) via a dedicated cross-attention mechanism. Our primary contribution is demonstrating the technical feasibility of this joint training paradigm: we show that diffusion latents contain sufficient information to recover V-JEPA 2 physical representations, and that multi-task optimization remains stable over training. This report documents the architectural design, technical challenges, and validation of training stability, establishing a foundation for future large-scale evaluation of physics-aware generative models.",
      "authors": [
        "Siddarth Nilol Kundur Satish",
        "Devesh Jaiswal",
        "Hongyu Chen",
        "Abhishek Bakshi"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-07 07:38:58+00:00",
      "link": "https://arxiv.org/pdf/2601.03665v1",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.03661v1",
      "title": "AMIR-GRPO: Inducing Implicit Preference Signals into GRPO",
      "abstract": "Reinforcement learning has become the primary paradigm for aligning large language models (LLMs) on complex reasoning tasks, with group relative policy optimization (GRPO) widely used in large-scale post-training. However, GRPO faces structural limitations in reasoning-heavy settings: sequence-level advantage normalization introduces systematic length bias, penalties for low-quality trajectories are diluted, and the scalar objective discards rich pairwise preference information embedded in within-group reward rankings. As a result, valuable supervision from costly rollouts remains underutilized.   We propose AMIR-GRPO, which augments GRPO with an implicit DPO-style contrastive regularizer constructed directly from intra-group reward rankings, requiring no additional annotations. This mechanism amplifies suppression of low-reward trajectories, attenuates response-level length bias, and transforms each rollout group into a denser set of supervision constraints. Across multiple mathematical reasoning benchmarks, AMIR-GRPO consistently outperforms strong GRPO baselines, yields clearer separation between correct and incorrect reasoning chains, and delivers broader coverage gains beyond the subset of instances solved by standard GRPO.",
      "authors": [
        "Amir Hossein Yari",
        "Fajri Koto"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-07 07:22:58+00:00",
      "link": "https://arxiv.org/pdf/2601.03661v1",
      "tags": [
        "keyword:resnet中文",
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.03660v1",
      "title": "MGPC: Multimodal Network for Generalizable Point Cloud Completion With Modality Dropout and Progressive Decoding",
      "abstract": "Point cloud completion aims to recover complete 3D geometry from partial observations caused by limited viewpoints and occlusions. Existing learning-based works, including 3D Convolutional Neural Network (CNN)-based, point-based, and Transformer-based methods, have achieved strong performance on synthetic benchmarks. However, due to the limitations of modality, scalability, and generative capacity, their generalization to novel objects and real-world scenarios remains challenging. In this paper, we propose MGPC, a generalizable multimodal point cloud completion framework that integrates point clouds, RGB images, and text within a unified architecture. MGPC introduces an innovative modality dropout strategy, a Transformer-based fusion module, and a novel progressive generator to improve robustness, scalability, and geometric modeling capability. We further develop an automatic data generation pipeline and construct MGPC-1M, a large-scale benchmark with over 1,000 categories and one million training pairs. Extensive experiments on MGPC-1M and in-the-wild data demonstrate that the proposed method consistently outperforms prior baselines and exhibits strong generalization under real-world conditions.",
      "authors": [
        "Jiangyuan Liu",
        "Hongxuan Ma",
        "Yuhao Zhao",
        "Zhe Liu",
        "Jian Wang",
        "Wei Zou"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-07 07:16:46+00:00",
      "link": "https://arxiv.org/pdf/2601.03660v1",
      "tags": [
        "keyword:大语言模型",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03655v1",
      "title": "VideoMemory: Toward Consistent Video Generation via Memory Integration",
      "abstract": "Maintaining consistent characters, props, and environments across multiple shots is a central challenge in narrative video generation. Existing models can produce high-quality short clips but often fail to preserve entity identity and appearance when scenes change or when entities reappear after long temporal gaps. We present VideoMemory, an entity-centric framework that integrates narrative planning with visual generation through a Dynamic Memory Bank. Given a structured script, a multi-agent system decomposes the narrative into shots, retrieves entity representations from memory, and synthesizes keyframes and videos conditioned on these retrieved states. The Dynamic Memory Bank stores explicit visual and semantic descriptors for characters, props, and backgrounds, and is updated after each shot to reflect story-driven changes while preserving identity. This retrieval-update mechanism enables consistent portrayal of entities across distant shots and supports coherent long-form generation. To evaluate this setting, we construct a 54-case multi-shot consistency benchmark covering character-, prop-, and background-persistent scenarios. Extensive experiments show that VideoMemory achieves strong entity-level coherence and high perceptual quality across diverse narrative sequences.",
      "authors": [
        "Jinsong Zhou",
        "Yihua Du",
        "Xinli Xu",
        "Luozhou Wang",
        "Zijie Zhuang",
        "Yehang Zhang",
        "Shuaibo Li",
        "Xiaojun Hu",
        "Bolan Su",
        "Ying-cong Chen"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-07 07:10:32+00:00",
      "link": "https://arxiv.org/pdf/2601.03655v1",
      "tags": [
        "keyword:resnet中文",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03646v2",
      "title": "ReLA: Representation Learning and Aggregation for Job Scheduling with Reinforcement Learning",
      "abstract": "Job scheduling is widely used in real-world manufacturing systems to assign ordered job operations to machines under various constraints. Existing solutions remain limited by long running time or insufficient schedule quality, especially when problem scale increases. In this paper, we propose ReLA, a reinforcement-learning (RL) scheduler built on structured representation learning and aggregation. ReLA first learns diverse representations from scheduling entities, including job operations and machines, using two intra-entity learning modules with self-attention and convolution and one inter-entity learning module with cross-attention. These modules are applied in a multi-scale architecture, and their outputs are aggregated to support RL decision-making. Across experiments on small, medium, and large job instances, ReLA achieves the best makespan in most tested settings over the latest solutions. On non-large instances, ReLA reduces the optimality gap of the SOTA baseline by 13.0%, while on large-scale instances it reduces the gap by 78.6%, with the average optimality gaps lowered to 7.3% and 2.1%, respectively. These results confirm that ReLA's learned representations and aggregation provide strong decision support for RL scheduling, and enable fast job completion and decision-making for real-world applications.",
      "authors": [
        "Zhengyi Kwan",
        "Wei Zhang",
        "Aik Beng Ng",
        "Zhengkui Wang",
        "Simon See"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-07 06:50:56+00:00",
      "link": "https://arxiv.org/pdf/2601.03646v2",
      "tags": [
        "keyword:resnet",
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.03640v1",
      "title": "Verbatim Data Transcription Failures in LLM Code Generation: A State-Tracking Stress Test",
      "abstract": "Many real-world software tasks require exact transcription of provided data into code, such as cryptographic constants, protocol test vectors, allowlists, and calibration tables. These tasks are operationally sensitive because small omissions or alterations can remain silent while producing syntactically valid programs. This paper introduces a deliberately minimal transcription-to-code benchmark to isolate this reliability concern in LLM-based code generation. Given a list of high-precision decimal constants, a model must generate Python code that embeds the constants verbatim and performs a simple aggregate computation. We describe the prompting variants, evaluation protocol based on exact-string inclusion, and analysis framework used to characterize state-tracking and long-horizon generation failures. The benchmark is intended as a compact stress test that complements existing code-generation evaluations by focusing on data integrity rather than algorithmic reasoning.",
      "authors": [
        "Mohd Ariful Haque",
        "Kishor Datta Gupta",
        "Mohammad Ashiqur Rahman",
        "Roy George"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE",
        "cs.CR"
      ],
      "published": "2026-01-07 06:38:34+00:00",
      "link": "https://arxiv.org/pdf/2601.03640v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03637v2",
      "title": "CrackSegFlow: Controllable Flow Matching Synthesis for Generalizable Crack Segmentation with a 50K Image-Mask Benchmark",
      "abstract": "Automated crack segmentation is essential for condition assessment, yet deployment is limited by scarce pixel-level labels and domain shift. We present CrackSegFlow, a controllable flow-matching synthesis framework that generates crack images conditioned on binary masks with mask-image alignment. The renderer combines topology-preserving mask injection with edge gating to maintain thin-structure continuity and suppress false positives. A class-conditional flow-matching mask model synthesizes masks with control over crack coverage, enabling balanced, topology-diverse data without manual annotation. We inject masks into crack-free backgrounds to diversify illumination and reduce false positives. On five datasets with a CNN-Transformer backbone, incorporating synthesized pairs improves in-domain performance by 5.37 mIoU and 5.13 F1, and target-guided cross-domain synthesis yields gains of 13.12 mIoU and 14.82 F1 using target mask statistics. We also release CSF-50K, 50,000 image-mask pairs for benchmarking.",
      "authors": [
        "Babak Asadi",
        "Peiyang Wu",
        "Mani Golparvar-Fard",
        "Ramez Hajj"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-07 06:28:16+00:00",
      "link": "https://arxiv.org/pdf/2601.03637v2",
      "tags": [
        "keyword:大语言模型",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03633v1",
      "title": "MFC-RFNet: A Multi-scale Guided Rectified Flow Network for Radar Sequence Prediction",
      "abstract": "Accurate and high-resolution precipitation nowcasting from radar echo sequences is crucial for disaster mitigation and economic planning, yet it remains a significant challenge. Key difficulties include modeling complex multi-scale evolution, correcting inter-frame feature misalignment caused by displacement, and efficiently capturing long-range spatiotemporal context without sacrificing spatial fidelity. To address these issues, we present the Multi-scale Feature Communication Rectified Flow (RF) Network (MFC-RFNet), a generative framework that integrates multi-scale communication with guided feature fusion. To enhance multi-scale fusion while retaining fine detail, a Wavelet-Guided Skip Connection (WGSC) preserves high-frequency components, and a Feature Communication Module (FCM) promotes bidirectional cross-scale interaction. To correct inter-frame displacement, a Condition-Guided Spatial Transform Fusion (CGSTF) learns spatial transforms from conditioning echoes to align shallow features. The backbone adopts rectified flow training to learn near-linear probability-flow trajectories, enabling few-step sampling with stable fidelity. Additionally, lightweight Vision-RWKV (RWKV) blocks are placed at the encoder tail, the bottleneck, and the first decoder layer to capture long-range spatiotemporal dependencies at low spatial resolutions with moderate compute. Evaluations on four public datasets (SEVIR, MeteoNet, Shanghai, and CIKM) demonstrate consistent improvements over strong baselines, yielding clearer echo morphology at higher rain-rate thresholds and sustained skill at longer lead times. These results suggest that the proposed synergy of RF training with scale-aware communication, spatial alignment, and frequency-aware fusion presents an effective and robust approach for radar-based nowcasting.",
      "authors": [
        "Wenjie Luo",
        "Chuanhu Deng",
        "Chaorong Li",
        "Rongyao Deng",
        "Qiang Yang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-01-07 06:24:26+00:00",
      "link": "https://arxiv.org/pdf/2601.03633v1",
      "tags": [
        "keyword:resnet",
        "keyword:resnet中文",
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.03627v2",
      "title": "Evaluating the Pre-Consultation Ability of LLMs using Diagnostic Guidelines",
      "abstract": "We introduce EPAG, a benchmark dataset and framework designed for Evaluating the Pre-consultation Ability of LLMs using diagnostic Guidelines. LLMs are evaluated directly through HPI-diagnostic guideline comparison and indirectly through disease diagnosis. In our experiments, we observe that small open-source models fine-tuned with a well-curated, task-specific dataset can outperform frontier LLMs in pre-consultation. Additionally, we find that increased amount of HPI (History of Present Illness) does not necessarily lead to improved diagnostic performance. Further experiments reveal that the language of pre-consultation influences the characteristics of the dialogue. By open-sourcing our dataset and evaluation pipeline on https://github.com/seemdog/EPAG, we aim to contribute to the evaluation and further development of LLM applications in real-world clinical settings.",
      "authors": [
        "Jean Seo",
        "Gibaeg Kim",
        "Kihun Shin",
        "Seungseop Lim",
        "Hyunkyung Lee",
        "Wooseok Han",
        "Jongwon Lee",
        "Eunho Yang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-07 06:15:21+00:00",
      "link": "https://arxiv.org/pdf/2601.03627v2",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03626v1",
      "title": "Learning from Limited Labels: Transductive Graph Label Propagation for Indian Music Analysis",
      "abstract": "Supervised machine learning frameworks rely on extensive labeled datasets for robust performance on real-world tasks. However, there is a lack of large annotated datasets in audio and music domains, as annotating such recordings is resource-intensive, laborious, and often require expert domain knowledge. In this work, we explore the use of label propagation (LP), a graph-based semi-supervised learning technique, for automatically labeling the unlabeled set in an unsupervised manner. By constructing a similarity graph over audio embeddings, we propagate limited label information from a small annotated subset to a larger unlabeled corpus in a transductive, semi-supervised setting. We apply this method to two tasks in Indian Art Music (IAM): Raga identification and Instrument classification. For both these tasks, we integrate multiple public datasets along with additional recordings we acquire from Prasar Bharati Archives to perform LP. Our experiments demonstrate that LP significantly reduces labeling overhead and produces higher-quality annotations compared to conventional baseline methods, including those based on pretrained inductive models. These results highlight the potential of graph-based semi-supervised learning to democratize data annotation and accelerate progress in music information retrieval.",
      "authors": [
        "Parampreet Singh",
        "Akshay Raina",
        "Sayeedul Islam Sheikh",
        "Vipul Arora"
      ],
      "primary_category": "eess.AS",
      "categories": [
        "eess.AS",
        "cs.LG"
      ],
      "published": "2026-01-07 06:12:48+00:00",
      "link": "https://arxiv.org/pdf/2601.03626v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04262v1",
      "title": "Safety-Utility Conflicts Are Not Global: Surgical Alignment via Head-Level Diagnosis",
      "abstract": "Safety alignment in Large Language Models (LLMs) inherently presents a multi-objective optimization conflict, often accompanied by an unintended degradation of general capabilities. Existing mitigation strategies typically rely on global gradient geometry to resolve these conflicts, yet they overlook Modular Heterogeneity within Transformers, specifically that the functional sensitivity and degree of conflict vary substantially across different attention heads. Such global approaches impose uniform update rules across all parameters, often resulting in suboptimal trade-offs by indiscriminately updating utility sensitive heads that exhibit intense gradient conflicts. To address this limitation, we propose Conflict-Aware Sparse Tuning (CAST), a framework that integrates head-level diagnosis with sparse fine-tuning. CAST first constructs a pre-alignment conflict map by synthesizing Optimization Conflict and Functional Sensitivity, which then guides the selective update of parameters. Experiments reveal that alignment conflicts in LLMs are not uniformly distributed. We find that the drop in general capabilities mainly comes from updating a small group of ``high-conflict'' heads. By simply skipping these heads during training, we significantly reduce this loss without compromising safety, offering an interpretable and parameter-efficient approach to improving the safety-utility trade-off.",
      "authors": [
        "Wang Cai",
        "Yilin Wen",
        "Jinchang Hou",
        "Du Su",
        "Guoqiu Wang",
        "Zhonghou Lv",
        "Chenfu Bao",
        "Yunfang Wu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-07 06:09:52+00:00",
      "link": "https://arxiv.org/pdf/2601.04262v1",
      "tags": [
        "keyword:大语言模型",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04261v1",
      "title": "Inhibitory Attacks on Backdoor-based Fingerprinting for Large Language Models",
      "abstract": "The widespread adoption of Large Language Model (LLM) in commercial and research settings has intensified the need for robust intellectual property protection. Backdoor-based LLM fingerprinting has emerged as a promising solution for this challenge. In practical application, the low-cost multi-model collaborative technique, LLM ensemble, combines diverse LLMs to leverage their complementary strengths, garnering significant attention and practical adoption. Unfortunately, the vulnerability of existing LLM fingerprinting for the ensemble scenario is unexplored. In order to comprehensively assess the robustness of LLM fingerprinting, in this paper, we propose two novel fingerprinting attack methods: token filter attack (TFA) and sentence verification attack (SVA). The TFA gets the next token from a unified set of tokens created by the token filter mechanism at each decoding step. The SVA filters out fingerprint responses through a sentence verification mechanism based on perplexity and voting. Experimentally, the proposed methods effectively inhibit the fingerprint response while maintaining ensemble performance. Compared with state-of-the-art attack methods, the proposed method can achieve better performance. The findings necessitate enhanced robustness in LLM fingerprinting.",
      "authors": [
        "Hang Fu",
        "Wanli Peng",
        "Yinghan Zhou",
        "Jiaxuan Wu",
        "Juan Wen",
        "Yiming Xue"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR"
      ],
      "published": "2026-01-07 06:06:56+00:00",
      "link": "https://arxiv.org/pdf/2601.04261v1",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.03612v1",
      "title": "Mathematical Foundations of Polyphonic Music Generation via Structural Inductive Bias",
      "abstract": "This monograph introduces a novel approach to polyphonic music generation by addressing the \"Missing Middle\" problem through structural inductive bias. Focusing on Beethoven's piano sonatas as a case study, we empirically verify the independence of pitch and hand attributes using normalized mutual information (NMI=0.167) and propose the Smart Embedding architecture, achieving a 48.30% reduction in parameters. We provide rigorous mathematical proofs using information theory (negligible loss bounded at 0.153 bits), Rademacher complexity (28.09% tighter generalization bound), and category theory to demonstrate improved stability and generalization. Empirical results show a 9.47% reduction in validation loss, confirmed by SVD analysis and an expert listening study (N=53). This dual theoretical and applied framework bridges gaps in AI music generation, offering verifiable insights for mathematically grounded deep learning.",
      "authors": [
        "Joonwon Seo"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.SD",
        "eess.AS"
      ],
      "published": "2026-01-07 05:40:09+00:00",
      "link": "https://arxiv.org/pdf/2601.03612v1",
      "tags": [
        "keyword:resnet",
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.03610v1",
      "title": "Investigation into respiratory sound classification for an imbalanced data set using hybrid LSTM-KAN architectures",
      "abstract": "Respiratory sounds captured via auscultation contain critical clues for diagnosing pulmonary conditions. Automated classification of these sounds faces challenges due to subtle acoustic differences and severe class imbalance in clinical datasets. This study investigates respiratory sound classification with a focus on mitigating pronounced class imbalance. We propose a hybrid deep learning model that combines a Long Short-Term Memory (LSTM) network for sequential feature encoding with a Kolmogorov-Arnold Network (KAN) for classification. The model is integrated with a comprehensive feature extraction pipeline and targeted imbalance mitigation strategies. Experiments were conducted on a public respiratory sound database comprising six classes with a highly skewed distribution. Techniques such as focal loss, class-specific data augmentation, and Synthetic Minority Over-sampling Technique (SMOTE) were employed to enhance minority class recognition. The proposed Hybrid LSTM-KAN model achieves an overall accuracy of 94.6 percent and a macro-averaged F1 score of 0.703, despite the dominant COPD class accounting for over 86 percent of the data. Improved detection performance is observed for minority classes compared to baseline approaches, demonstrating the effectiveness of the proposed architecture for imbalanced respiratory sound classification.",
      "authors": [
        "Nithinkumar K.",
        "Anand R"
      ],
      "primary_category": "cs.SD",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "published": "2026-01-07 05:37:57+00:00",
      "link": "https://arxiv.org/pdf/2601.03610v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03609v1",
      "title": "Unveiling Text in Challenging Stone Inscriptions: A Character-Context-Aware Patching Strategy for Binarization",
      "abstract": "Binarization is a popular first step towards text extraction in historical artifacts. Stone inscription images pose severe challenges for binarization due to poor contrast between etched characters and the stone background, non-uniform surface degradation, distracting artifacts, and highly variable text density and layouts. These conditions frequently cause existing binarization techniques to fail and struggle to isolate coherent character regions. Many approaches sub-divide the image into patches to improve text fragment resolution and improve binarization performance. With this in mind, we present a robust and adaptive patching strategy to binarize challenging Indic inscriptions. The patches from our approach are used to train an Attention U-Net for binarization. The attention mechanism allows the model to focus on subtle structural cues, while our dynamic sampling and patch selection method ensures that the model learns to overcome surface noise and layout irregularities. We also introduce a carefully annotated, pixel-precise dataset of Indic stone inscriptions at the character-fragment level. We demonstrate that our novel patching mechanism significantly boosts binarization performance across classical and deep learning baselines. Despite training only on single script Indic dataset, our model exhibits strong zero-shot generalization to other Indic and non-indic scripts, highlighting its robustness and script-agnostic generalization capabilities. By producing clean, structured representations of inscription content, our method lays the foundation for downstream tasks such as script identification, OCR, and historical text analysis. Project page: https://ihdia.iiit.ac.in/shilalekhya-binarization/",
      "authors": [
        "Pratyush Jena",
        "Amal Joseph",
        "Arnav Sharma",
        "Ravi Kiran Sarvadevabhatla"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-07 05:37:29+00:00",
      "link": "https://arxiv.org/pdf/2601.03609v1",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.03605v1",
      "title": "DiVA: Fine-grained Factuality Verification with Agentic-Discriminative Verifier",
      "abstract": "Despite the significant advancements of Large Language Models (LLMs), their factuality remains a critical challenge, fueling growing interest in factuality verification. Existing research on factuality verification primarily conducts binary judgments (e.g., correct or incorrect), which fails to distinguish varying degrees of error severity. This limits its utility for applications such as fine-grained evaluation and preference optimization. To bridge this gap, we propose the Agentic Discriminative Verifier (DiVA), a hybrid framework that synergizes the agentic search capabilities of generative models with the precise scoring aptitude of discriminative models. We also construct a new benchmark, FGVeriBench, as a robust testbed for fine-grained factuality verification. Experimental results on FGVeriBench demonstrate that our DiVA significantly outperforms existing methods on factuality verification for both general and multi-hop questions.",
      "authors": [
        "Hui Huang",
        "Muyun Yang",
        "Yuki Arase"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 05:35:01+00:00",
      "link": "https://arxiv.org/pdf/2601.03605v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03604v1",
      "title": "Interleaved Tool-Call Reasoning for Protein Function Understanding",
      "abstract": "Recent advances in large language models (LLMs) have highlighted the effectiveness of chain-of-thought reasoning in symbolic domains such as mathematics and programming. However, our study shows that directly transferring such text-based reasoning paradigms to protein function understanding is ineffective: reinforcement learning mainly amplifies superficial keyword patterns while failing to introduce new biological knowledge, resulting in limited generalization. We argue that protein function prediction is a knowledge-intensive scientific task that fundamentally relies on external biological priors and computational tools rather than purely internal reasoning. To address this gap, we propose PFUA, a tool-augmented protein reasoning agent that unifies problem decomposition, tool invocation, and grounded answer generation. Instead of relying on long unconstrained reasoning traces, PFUA integrates domain-specific tools to produce verifiable intermediate evidence. Experiments on four benchmarks demonstrate that PFUA consistently outperforms text-only reasoning models with an average performance improvement of 103%.",
      "authors": [
        "Chuanliu Fan",
        "Zicheng Ma",
        "Huanran Meng",
        "Aijia Zhang",
        "Wenjie Du",
        "Jun Zhang",
        "Yi Qin Gao",
        "Ziqiang Cao",
        "Guohong Fu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-07 05:34:38+00:00",
      "link": "https://arxiv.org/pdf/2601.03604v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03603v1",
      "title": "A Comparative Study of Traditional Machine Learning, Deep Learning, and Large Language Models for Mental Health Forecasting using Smartphone Sensing Data",
      "abstract": "Smartphone sensing offers an unobtrusive and scalable way to track daily behaviors linked to mental health, capturing changes in sleep, mobility, and phone use that often precede symptoms of stress, anxiety, or depression. While most prior studies focus on detection that responds to existing conditions, forecasting mental health enables proactive support through Just-in-Time Adaptive Interventions. In this paper, we present the first comprehensive benchmarking study comparing traditional machine learning (ML), deep learning (DL), and large language model (LLM) approaches for mental health forecasting using the College Experience Sensing (CES) dataset, the most extensive longitudinal dataset of college student mental health to date. We systematically evaluate models across temporal windows, feature granularities, personalization strategies, and class imbalance handling. Our results show that DL models, particularly Transformer (Macro-F1 = 0.58), achieve the best overall performance, while LLMs show strength in contextual reasoning but weaker temporal modeling. Personalization substantially improves forecasts of severe mental health states. By revealing how different modeling approaches interpret phone sensing behavioral data over time, this work lays the groundwork for next-generation, adaptive, and human-centered mental health technologies that can advance both research and real-world well-being.",
      "authors": [
        "Kaidong Feng",
        "Zhu Sun",
        "Roy Ka-Wei Lee",
        "Xun Jiang",
        "Yin-Leng Theng",
        "Yi Ding"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 05:33:00+00:00",
      "link": "https://arxiv.org/pdf/2601.03603v1",
      "tags": [
        "keyword:resnet",
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.03594v1",
      "title": "Jailbreaking LLMs & VLMs: Mechanisms, Evaluation, and Unified Defense",
      "abstract": "This paper provides a systematic survey of jailbreak attacks and defenses on Large Language Models (LLMs) and Vision-Language Models (VLMs), emphasizing that jailbreak vulnerabilities stem from structural factors such as incomplete training data, linguistic ambiguity, and generative uncertainty. It further differentiates between hallucinations and jailbreaks in terms of intent and triggering mechanisms. We propose a three-dimensional survey framework: (1) Attack dimension-including template/encoding-based, in-context learning manipulation, reinforcement/adversarial learning, LLM-assisted and fine-tuned attacks, as well as prompt- and image-level perturbations and agent-based transfer in VLMs; (2) Defense dimension-encompassing prompt-level obfuscation, output evaluation, and model-level alignment or fine-tuning; and (3) Evaluation dimension-covering metrics such as Attack Success Rate (ASR), toxicity score, query/time cost, and multimodal Clean Accuracy and Attribute Success Rate. Compared with prior works, this survey spans the full spectrum from text-only to multimodal settings, consolidating shared mechanisms and proposing unified defense principles: variant-consistency and gradient-sensitivity detection at the perception layer, safety-aware decoding and output review at the generation layer, and adversarially augmented preference alignment at the parameter layer. Additionally, we summarize existing multimodal safety benchmarks and discuss future directions, including automated red teaming, cross-modal collaborative defense, and standardized evaluation.",
      "authors": [
        "Zejian Chen",
        "Chaozhuo Li",
        "Chao Li",
        "Xi Zhang",
        "Litian Zhang",
        "Yiming He"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR"
      ],
      "published": "2026-01-07 05:25:33+00:00",
      "link": "https://arxiv.org/pdf/2601.03594v1",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.03590v1",
      "title": "Can LLMs See Without Pixels? Benchmarking Spatial Intelligence from Textual Descriptions",
      "abstract": "Recent advancements in Spatial Intelligence (SI) have predominantly relied on Vision-Language Models (VLMs), yet a critical question remains: does spatial understanding originate from visual encoders or the fundamental reasoning backbone? Inspired by this question, we introduce SiT-Bench, a novel benchmark designed to evaluate the SI performance of Large Language Models (LLMs) without pixel-level input, comprises over 3,800 expert-annotated items across five primary categories and 17 subtasks, ranging from egocentric navigation and perspective transformation to fine-grained robotic manipulation. By converting single/multi-view scenes into high-fidelity, coordinate-aware textual descriptions, we challenge LLMs to perform symbolic textual reasoning rather than visual pattern matching. Evaluation results of state-of-the-art (SOTA) LLMs reveals that while models achieve proficiency in localized semantic tasks, a significant \"spatial gap\" remains in global consistency. Notably, we find that explicit spatial reasoning significantly boosts performance, suggesting that LLMs possess latent world-modeling potential. Our proposed dataset SiT-Bench serves as a foundational resource to foster the development of spatially-grounded LLM backbones for future VLMs and embodied agents. Our code and benchmark will be released at https://github.com/binisalegend/SiT-Bench .",
      "authors": [
        "Zhongbin Guo",
        "Zhen Yang",
        "Yushan Li",
        "Xinyue Zhang",
        "Wenyu Gao",
        "Jiacheng Wang",
        "Chengzhi Li",
        "Xiangrui Liu",
        "Ping Jian"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-01-07 05:13:52+00:00",
      "link": "https://arxiv.org/pdf/2601.03590v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03584v1",
      "title": "Local Gradient Regulation Stabilizes Federated Learning under Client Heterogeneity",
      "abstract": "Federated learning (FL) enables collaborative model training across distributed clients without sharing raw data, yet its stability is fundamentally challenged by statistical heterogeneity in realistic deployments. Here, we show that client heterogeneity destabilizes FL primarily by distorting local gradient dynamics during client-side optimization, causing systematic drift that accumulates across communication rounds and impedes global convergence. This observation highlights local gradients as a key regulatory lever for stabilizing heterogeneous FL systems. Building on this insight, we develop a general client-side perspective that regulates local gradient contributions without incurring additional communication overhead. Inspired by swarm intelligence, we instantiate this perspective through Exploratory--Convergent Gradient Re-aggregation (ECGR), which balances well-aligned and misaligned gradient components to preserve informative updates while suppressing destabilizing effects. Theoretical analysis and extensive experiments, including evaluations on the LC25000 medical imaging dataset, demonstrate that regulating local gradient dynamics consistently stabilizes federated learning across state-of-the-art methods under heterogeneous data distributions.",
      "authors": [
        "Ping Luo",
        "Jiahuan Wang",
        "Ziqing Wen",
        "Tao Sun",
        "Dongsheng Li"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.DC"
      ],
      "published": "2026-01-07 04:58:18+00:00",
      "link": "https://arxiv.org/pdf/2601.03584v1",
      "tags": [
        "keyword:resnet",
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.03578v1",
      "title": "PsychEthicsBench: Evaluating Large Language Models Against Australian Mental Health Ethics",
      "abstract": "The increasing integration of large language models (LLMs) into mental health applications necessitates robust frameworks for evaluating professional safety alignment. Current evaluative approaches primarily rely on refusal-based safety signals, which offer limited insight into the nuanced behaviors required in clinical practice. In mental health, clinically inadequate refusals can be perceived as unempathetic and discourage help-seeking. To address this gap, we move beyond refusal-centric metrics and introduce \\texttt{PsychEthicsBench}, the first principle-grounded benchmark based on Australian psychology and psychiatry guidelines, designed to evaluate LLMs' ethical knowledge and behavioral responses through multiple-choice and open-ended tasks with fine-grained ethicality annotations. Empirical results across 14 models reveal that refusal rates are poor indicators of ethical behavior, revealing a significant divergence between safety triggers and clinical appropriateness. Notably, we find that domain-specific fine-tuning can degrade ethical robustness, as several specialized models underperform their base backbones in ethical alignment. PsychEthicsBench provides a foundation for systematic, jurisdiction-aware evaluation of LLMs in mental health, encouraging more responsible development in this domain.",
      "authors": [
        "Yaling Shen",
        "Stephanie Fong",
        "Yiwen Jiang",
        "Zimu Wang",
        "Feilong Tang",
        "Qingyang Xu",
        "Xiangyu Zhao",
        "Zhongxing Xu",
        "Jiahe Liu",
        "Jinpeng Hu",
        "Dominic Dwyer",
        "Zongyuan Ge"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 04:49:02+00:00",
      "link": "https://arxiv.org/pdf/2601.03578v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03570v1",
      "title": "How Do Large Language Models Learn Concepts During Continual Pre-Training?",
      "abstract": "Human beings primarily understand the world through concepts (e.g., dog), abstract mental representations that structure perception, reasoning, and learning. However, how large language models (LLMs) acquire, retain, and forget such concepts during continual pretraining remains poorly understood. In this work, we study how individual concepts are acquired and forgotten, as well as how multiple concepts interact through interference and synergy. We link these behavioral dynamics to LLMs' internal Concept Circuits, computational subgraphs associated with specific concepts, and incorporate Graph Metrics to characterize circuit structure. Our analysis reveals: (1) LLMs concept circuits provide a non-trivial, statistically significant signal of concept learning and forgetting; (2) Concept circuits exhibit a stage-wise temporal pattern during continual pretraining, with an early increase followed by gradual decrease and stabilization; (3) concepts with larger learning gains tend to exhibit greater forgetting under subsequent training; (4) semantically similar concepts induce stronger interference than weakly related ones; (5) conceptual knowledge differs in their transferability, with some significantly facilitating the learning of others. Together, our findings offer a circuit-level view of concept learning dynamics and inform the design of more interpretable and robust concept-aware training strategies for LLMs.",
      "authors": [
        "Barry Menglong Yao",
        "Sha Li",
        "Yunzhi Yao",
        "Minqian Liu",
        "Zaishuo Xia",
        "Qifan Wang",
        "Lifu Huang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 04:29:15+00:00",
      "link": "https://arxiv.org/pdf/2601.03570v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03569v1",
      "title": "Local Intrinsic Dimensionality of Ground Motion Data for Early Detection of Complex Catastrophic Slope Failure",
      "abstract": "Local Intrinsic Dimensionality (LID) has shown strong potential for identifying anomalies and outliers in high-dimensional data across a wide range of real-world applications, including landslide failure detection in granular media. Early and accurate identification of failure zones in landslide-prone areas is crucial for effective geohazard mitigation. While existing approaches typically rely on surface displacement data analyzed through statistical or machine learning techniques, they often fall short in capturing both the spatial correlations and temporal dynamics that are inherent in such data. To address this gap, we focus on ground-monitored landslides and introduce a novel approach that jointly incorporates spatial and temporal information, enabling the detection of complex landslides and including multiple successive failures occurring in distinct areas of the same slope. To be specific, our method builds upon an existing LID-based technique, known as sLID. We extend its capabilities in three key ways. (1) Kinematic enhancement: we incorporate velocity into the sLID computation to better capture short-term temporal dependencies and deformation rate relationships. (2) Spatial fusion: we apply Bayesian estimation to aggregate sLID values across spatial neighborhoods, effectively embedding spatial correlations into the LID scores. (3) Temporal modeling: we introduce a temporal variant, tLID, that learns long-term dynamics from time series data, providing a robust temporal representation of displacement behavior. Finally, we integrate both components into a unified framework, referred to as spatiotemporal LID (stLID), to identify samples that are anomalous in either or both dimensions. Extensive experiments show that stLID consistently outperforms existing methods in failure detection precision and lead-time.",
      "authors": [
        "Yuansan Liu",
        "Antoinette Tordesillas",
        "James Bailey"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "stat.AP"
      ],
      "published": "2026-01-07 04:29:05+00:00",
      "link": "https://arxiv.org/pdf/2601.03569v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03566v1",
      "title": "Provably Convergent Decentralized Optimization over Directed Graphs under Generalized Smoothness",
      "abstract": "Decentralized optimization has become a fundamental tool for large-scale learning systems; however, most existing methods rely on the classical Lipschitz smoothness assumption, which is often violated in problems with rapidly varying gradients. Motivated by this limitation, we study decentralized optimization under the generalized $(L_0, L_1)$-smoothness framework, in which the Hessian norm is allowed to grow linearly with the gradient norm, thereby accommodating rapidly varying gradients beyond classical Lipschitz smoothness. We integrate gradient-tracking techniques with gradient clipping and carefully design the clipping threshold to ensure accurate convergence over directed communication graphs under generalized smoothness. In contrast to existing distributed optimization results under generalized smoothness that require a bounded gradient dissimilarity assumption, our results remain valid even when the gradient dissimilarity is unbounded, making the proposed framework more applicable to realistic heterogeneous data environments. We validate our approach via numerical experiments on standard benchmark datasets, including LIBSVM and CIFAR-10, using regularized logistic regression and convolutional neural networks, demonstrating superior stability and faster convergence over existing methods.",
      "authors": [
        "Yanan Bo",
        "Yongqiang Wang"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC",
        "cs.LG"
      ],
      "published": "2026-01-07 04:25:33+00:00",
      "link": "https://arxiv.org/pdf/2601.03566v1",
      "tags": [
        "keyword:resnet",
        "keyword:resnet中文",
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04260v1",
      "title": "Towards a Mechanistic Understanding of Propositional Logical Reasoning in Large Language Models",
      "abstract": "Understanding how Large Language Models (LLMs) perform logical reasoning internally remains a fundamental challenge. While prior mechanistic studies focus on identifying taskspecific circuits, they leave open the question of what computational strategies LLMs employ for propositional reasoning. We address this gap through comprehensive analysis of Qwen3 (8B and 14B) on PropLogic-MI, a controlled dataset spanning 11 propositional logic rule categories across one-hop and two-hop reasoning. Rather than asking ''which components are necessary,'' we ask ''how does the model organize computation?'' Our analysis reveals a coherent computational architecture comprising four interlocking mechanisms: Staged Computation (layer-wise processing phases), Information Transmission (information flow aggregation at boundary tokens), Fact Retrospection (persistent re-access of source facts), and Specialized Attention Heads (functionally distinct head types). These mechanisms generalize across model scales, rule types, and reasoning depths, providing mechanistic evidence that LLMs employ structured computational strategies for logical reasoning.",
      "authors": [
        "Danchun Chen",
        "Qiyao Yan",
        "Liangming Pan"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-07 04:20:30+00:00",
      "link": "https://arxiv.org/pdf/2601.04260v1",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.03555v1",
      "title": "SCRIBE: Structured Mid-Level Supervision for Tool-Using Language Models",
      "abstract": "Training reliable tool-augmented agents remains a significant challenge, largely due to the difficulty of credit assignment in multi-step reasoning. While process-level reward models offer a promising direction, existing LLM-based judges often produce noisy and inconsistent signals because they lack fine-grained, task-specific rubrics to distinguish high-level planning from low-level execution. In this work, we introduce SCRIBE (Skill-Conditioned Reward with Intermediate Behavioral Evaluation), a reinforcement learning framework that intervenes at a novel mid-level abstraction. SCRIBE grounds reward modeling in a curated library of skill prototypes, transforming open-ended LLM evaluation into a constrained verification problem. By routing each subgoal to a corresponding prototype, the reward model is equipped with precise, structured rubrics that substantially reduce reward variance.   Experimental results show that SCRIBE achieves state-of-the-art performance across a range of reasoning and tool-use benchmarks. In particular, it improves the AIME25 accuracy of a Qwen3-4B model from 43.3% to 63.3%, and significantly increases success rates in complex multi-turn tool interactions.   Further analysis of training dynamics reveals a co-evolution across abstraction levels, where mastery of mid-level skills consistently precedes the emergence of effective high-level planning behaviors. Finally, we demonstrate that SCRIBE is additive to low-level tool optimizations, providing a scalable and complementary pathway toward more autonomous and reliable tool-using agents.",
      "authors": [
        "Yuxuan Jiang",
        "Francis Ferraro"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-07 03:49:48+00:00",
      "link": "https://arxiv.org/pdf/2601.03555v1",
      "tags": [
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.03551v2",
      "title": "Dissolving a Digital Relationship: A Critical Examination of Digital Severance Behaviours in Close Relationships",
      "abstract": "Fulfilling social connections are crucial for human well-being and belonging, but not all relationships last forever. As interactions increasingly move online, the act of digitally severing a relationship - e.g. through blocking or unfriending - has become progressively more common as well. This study considers actions of \"digital severance\" through interviews with 30 participants with experience as the initiator and/or recipient of such situations. Through a critical interpretative lens, we explore how people perceive and interpret their severance experience and how the online setting of social media shapes these dynamics. We develop themes that position digital severance as being intertwined with power and control, and we highlight (im)balances between an individual's desires that can lead to feelings of disempowerment and ambiguous loss for both parties. We discuss the implications of our research, outlining three key tensions and four open questions regarding digital relationships, meaning-making, and design outcomes for future exploration.",
      "authors": [
        "Michael Yin",
        "Angela Chiang",
        "Robert Xiao"
      ],
      "primary_category": "cs.HC",
      "categories": [
        "cs.HC"
      ],
      "published": "2026-01-07 03:33:29+00:00",
      "link": "https://arxiv.org/pdf/2601.03551v2",
      "tags": [
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.03550v1",
      "title": "ReEfBench: Quantifying the Reasoning Efficiency of LLMs",
      "abstract": "Test-time scaling has enabled Large Language Models (LLMs) to tackle complex reasoning, yet the limitations of current Chain-of-Thought (CoT) evaluation obscures whether performance gains stem from genuine reasoning or mere verbosity. To address this, (1) we propose a novel neuro-symbolic framework for the non-intrusive, comprehensive process-centric evaluation of reasoning. (2) Through this lens, we identify four distinct behavioral prototypes and diagnose the failure modes. (3) We examine the impact of inference mode, training strategy, and model scale. Our analysis reveals that extended token generation is not a prerequisite for deep reasoning. Furthermore, we reveal critical constraints: mixing long and short CoT data in training risks in premature saturation and collapse, while distillation into smaller models captures behavioral length but fails to replicate logical efficacy due to intrinsic capacity limits.",
      "authors": [
        "Zhizhang Fu",
        "Yuancheng Gu",
        "Chenkai Hu",
        "Hanmeng Liu",
        "Yue Zhang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-07 03:33:07+00:00",
      "link": "https://arxiv.org/pdf/2601.03550v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03543v1",
      "title": "EvolMem: A Cognitive-Driven Benchmark for Multi-Session Dialogue Memory",
      "abstract": "Despite recent advances in understanding and leveraging long-range conversational memory, existing benchmarks still lack systematic evaluation of large language models(LLMs) across diverse memory dimensions, particularly in multi-session settings. In this work, we propose EvolMem, a new benchmark for assessing multi-session memory capabilities of LLMs and agent systems. EvolMem is grounded in cognitive psychology and encompasses both declarative and non-declarative memory, further decomposed into multiple fine-grained abilities. To construct the benchmark, we introduce a hybrid data synthesis framework that consists of topic-initiated generation and narrative-inspired transformations. This framework enables scalable generation of multi-session conversations with controllable complexity, accompanied by sample-specific evaluation guidelines. Extensive evaluation reveals that no LLM consistently outperforms others across all memory dimensions. Moreover, agent memory mechanisms do not necessarily enhance LLMs' capabilities and often exhibit notable efficiency limitations. Data and code will be released at https://github.com/shenye7436/EvolMem.",
      "authors": [
        "Ye Shen",
        "Dun Pei",
        "Yiqiu Guo",
        "Junying Wang",
        "Yijin Guo",
        "Zicheng Zhang",
        "Qi Jia",
        "Jun Zhou",
        "Guangtao Zhai"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 03:14:42+00:00",
      "link": "https://arxiv.org/pdf/2601.03543v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03542v1",
      "title": "Layer-Order Inversion: Rethinking Latent Multi-Hop Reasoning in Large Language Models",
      "abstract": "Large language models (LLMs) perform well on multi-hop reasoning, yet how they internally compose multiple facts remains unclear. Recent work proposes \\emph{hop-aligned circuit hypothesis}, suggesting that bridge entities are computed sequentially across layers before later-hop answers. Through systematic analyses on real-world multi-hop queries, we show that this hop-aligned assumption does not generalize: later-hop answer entities can become decodable earlier than bridge entities, a phenomenon we call \\emph{layer-order inversion}, which strengthens with total hops. To explain this behavior, we propose a \\emph{probabilistic recall-and-extract} framework that models multi-hop reasoning as broad probabilistic recall in shallow MLP layers followed by selective extraction in deeper attention layers. This framework is empirically validated through systematic probing analyses, reinterpreting prior layer-wise decoding evidence, explaining chain-of-thought gains, and providing a mechanistic diagnosis of multi-hop failures despite correct single-hop knowledge. Code is available at https://github.com/laquabe/Layer-Order-Inversion.",
      "authors": [
        "Xukai Liu",
        "Ye Liu",
        "Jipeng Zhang",
        "Yanghai Zhang",
        "Kai Zhang",
        "Qi Liu"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-07 03:13:03+00:00",
      "link": "https://arxiv.org/pdf/2601.03542v1",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.03540v1",
      "title": "DeepSynth-Eval: Objectively Evaluating Information Consolidation in Deep Survey Writing",
      "abstract": "The evolution of Large Language Models (LLMs) towards autonomous agents has catalyzed progress in Deep Research. While retrieval capabilities are well-benchmarked, the post-retrieval synthesis stage--where agents must digest massive amounts of context and consolidate fragmented evidence into coherent, long-form reports--remains under-evaluated due to the subjectivity of open-ended writing. To bridge this gap, we introduce DeepSynth-Eval, a benchmark designed to objectively evaluate information consolidation capabilities. We leverage high-quality survey papers as gold standards, reverse-engineering research requests and constructing \"Oracle Contexts\" from their bibliographies to isolate synthesis from retrieval noise. We propose a fine-grained evaluation protocol using General Checklists (for factual coverage) and Constraint Checklists (for structural organization), transforming subjective judgment into verifiable metrics. Experiments across 96 tasks reveal that synthesizing information from hundreds of references remains a significant challenge. Our results demonstrate that agentic plan-and-write workflows significantly outperform single-turn generation, effectively reducing hallucinations and improving adherence to complex structural constraints.",
      "authors": [
        "Hongzhi Zhang",
        "Yuanze Hu",
        "Tinghai Zhang",
        "Jia Fu",
        "Tao Wang",
        "Junwei Jing",
        "Zhaoxin Fan",
        "Qi Wang",
        "Ruiming Tang",
        "Han Li",
        "Guorui Zhou",
        "Kun Gai"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 03:07:52+00:00",
      "link": "https://arxiv.org/pdf/2601.03540v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03531v1",
      "title": "PALM-Bench: A Comprehensive Benchmark for Personalized Audio-Language Models",
      "abstract": "Large Audio-Language Models (LALMs) have demonstrated strong performance in audio understanding and generation. Yet, our extensive benchmarking reveals that their behavior is largely generic (e.g., summarizing spoken content) and fails to adequately support personalized question answering (e.g., summarizing what my best friend says). In contrast, human conditions their interpretation and decision-making on each individual's personal context. To bridge this gap, we formalize the task of Personalized LALMs (PALM) for recognizing personal concepts and reasoning within personal context. Moreover, we create the first benchmark (PALM-Bench) to foster the methodological advances in PALM and enable structured evaluation on several tasks across multi-speaker scenarios. Our extensive experiments on representative open-source LALMs, show that existing training-free prompting and supervised fine-tuning strategies, while yield improvements, remains limited in modeling personalized knowledge and transferring them across tasks robustly. Data and code will be released.",
      "authors": [
        "Yuwen Wang",
        "Xinyuan Qian",
        "Tian-Hao Zhang",
        "Jiaran Gao",
        "Yuchen Pan",
        "Xin Wang",
        "Zhou Pan",
        "Chen Wei",
        "Yiming Wang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 02:44:38+00:00",
      "link": "https://arxiv.org/pdf/2601.03531v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03520v1",
      "title": "A Reinforcement Learning-Based Model for Mapping and Goal-Directed Navigation Using Multiscale Place Fields",
      "abstract": "Autonomous navigation in complex and partially observable environments remains a central challenge in robotics. Several bio-inspired models of mapping and navigation based on place cells in the mammalian hippocampus have been proposed. This paper introduces a new robust model that employs parallel layers of place fields at multiple spatial scales, a replay-based reward mechanism, and dynamic scale fusion. Simulations show that the model improves path efficiency and accelerates learning compared to single-scale baselines, highlighting the value of multiscale spatial representations for adaptive robot navigation.",
      "authors": [
        "Bekarys Dukenbaev",
        "Andrew Gerstenslager",
        "Alexander Johnson",
        "Ali A. Minai"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.RO"
      ],
      "published": "2026-01-07 02:10:52+00:00",
      "link": "https://arxiv.org/pdf/2601.03520v1",
      "tags": [
        "keyword:resnet",
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.04259v1",
      "title": "IGA-LWP: An Iterative Gradient-based Adversarial Attack for Link Weight Prediction",
      "abstract": "Link weight prediction extends classical link prediction by estimating the strength of interactions rather than merely their existence, and it underpins a wide range of applications such as traffic engineering, social recommendation, and scientific collaboration analysis. However, the robustness of link weight prediction against adversarial perturbations remains largely unexplored.In this paper, we formalize the link weight prediction attack problem as an optimization task that aims to maximize the prediction error on a set of target links by adversarially manipulating the weight values of a limited number of links. Based on this formulation, we propose an iterative gradient-based attack framework for link weight prediction, termed IGA-LWP. By employing a self-attention-enhanced graph autoencoder as a surrogate predictor, IGA-LWP leverages backpropagated gradients to iteratively identify and perturb a small subset of links. Extensive experiments on four real-world weighted networks demonstrate that IGA-LWP significantly degrades prediction accuracy on target links compared with baseline methods. Moreover, the adversarial networks generated by IGA-LWP exhibit strong transferability across several representative link weight prediction models. These findings expose a fundamental vulnerability in weighted network inference and highlight the need for developing robust link weight prediction methods.",
      "authors": [
        "Cunlai Pu",
        "Xingyu Gao",
        "Jinbi Liang",
        "Jianhui Guo",
        "Xiangbo Shu",
        "Yongxiang Xia",
        "Rajput Ramiz Sharafat"
      ],
      "primary_category": "cs.SI",
      "categories": [
        "cs.SI"
      ],
      "published": "2026-01-07 02:09:47+00:00",
      "link": "https://arxiv.org/pdf/2601.04259v1",
      "tags": [
        "keyword:resnet",
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.03519v1",
      "title": "A Vision-Language-Action Model with Visual Prompt for OFF-Road Autonomous Driving",
      "abstract": "Efficient trajectory planning in off-road terrains presents a formidable challenge for autonomous vehicles, often necessitating complex multi-step pipelines. However, traditional approaches exhibit limited adaptability in dynamic environments. To address these limitations, this paper proposes OFF-EMMA, a novel end-to-end multimodal framework designed to overcome the deficiencies of insufficient spatial perception and unstable reasoning in visual-language-action (VLA) models for off-road autonomous driving scenarios. The framework explicitly annotates input images through the design of a visual prompt block and introduces a chain-of-thought with self-consistency (COT-SC) reasoning strategy to enhance the accuracy and robustness of trajectory planning. The visual prompt block utilizes semantic segmentation masks as visual prompts, enhancing the spatial understanding ability of pre-trained visual-language models for complex terrains. The COT- SC strategy effectively mitigates the error impact of outliers on planning performance through a multi-path reasoning mechanism. Experimental results on the RELLIS-3D off-road dataset demonstrate that OFF-EMMA significantly outperforms existing methods, reducing the average L2 error of the Qwen backbone model by 13.3% and decreasing the failure rate from 16.52% to 6.56%.",
      "authors": [
        "Liangdong Zhang",
        "Yiming Nie",
        "Haoyang Li",
        "Fanjie Kong",
        "Baobao Zhang",
        "Shunxin Huang",
        "Kai Fu",
        "Chen Min",
        "Liang Xiao"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-01-07 02:08:18+00:00",
      "link": "https://arxiv.org/pdf/2601.03519v1",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.03517v1",
      "title": "Semantic Belief-State World Model for 3D Human Motion Prediction",
      "abstract": "Human motion prediction has traditionally been framed as a sequence regression problem where models extrapolate future joint coordinates from observed pose histories. While effective over short horizons this approach does not separate observation reconstruction with dynamics modeling and offers no explicit representation of the latent causes governing motion. As a result, existing methods exhibit compounding drift, mean-pose collapse, and poorly calibrated uncertainty when rolled forward beyond the training regime. Here we propose a Semantic Belief-State World Model (SBWM) that reframes human motion prediction as latent dynamical simulation on the human body manifold. Rather than predicting poses directly, SBWM maintains a recurrent probabilistic belief state whose evolution is learned independently of pose reconstruction and explicitly aligned with the SMPL-X anatomical parameterization. This alignment imposes a structural information bottleneck that prevents the latent state from encoding static geometry or sensor noise, forcing it to capture motion dynamics, intent, and control-relevant structure. Inspired by belief-state world models developed for model-based reinforcement learning, SBWM adapts stochastic latent transitions and rollout-centric training to the domain of human motion. In contrast to RSSM-based, transformer, and diffusion approaches optimized for reconstruction fidelity, SBWM prioritizes stable forward simulation. We demonstrate coherent long-horizon rollouts, and competitive accuracy at substantially lower computational cost. These results suggest that treating the human body as part of the world models state space rather than its output fundamentally changes how motion is simulated, and predicted.",
      "authors": [
        "Sarim Chaudhry"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-07 02:06:26+00:00",
      "link": "https://arxiv.org/pdf/2601.03517v1",
      "tags": [
        "keyword:resnet",
        "keyword:大语言模型",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03515v1",
      "title": "Mem-Gallery: Benchmarking Multimodal Long-Term Conversational Memory for MLLM Agents",
      "abstract": "Long-term memory is a critical capability for multimodal large language model (MLLM) agents, particularly in conversational settings where information accumulates and evolves over time. However, existing benchmarks either evaluate multi-session memory in text-only conversations or assess multimodal understanding within localized contexts, failing to evaluate how multimodal memory is preserved, organized, and evolved across long-term conversational trajectories. Thus, we introduce Mem-Gallery, a new benchmark for evaluating multimodal long-term conversational memory in MLLM agents. Mem-Gallery features high-quality multi-session conversations grounded in both visual and textual information, with long interaction horizons and rich multimodal dependencies. Building on this dataset, we propose a systematic evaluation framework that assesses key memory capabilities along three functional dimensions: memory extraction and test-time adaptation, memory reasoning, and memory knowledge management. Extensive benchmarking across thirteen memory systems reveals several key findings, highlighting the necessity of explicit multimodal information retention and memory organization, the persistent limitations in memory reasoning and knowledge management, as well as the efficiency bottleneck of current models.",
      "authors": [
        "Yuanchen Bei",
        "Tianxin Wei",
        "Xuying Ning",
        "Yanjun Zhao",
        "Zhining Liu",
        "Xiao Lin",
        "Yada Zhu",
        "Hendrik Hamann",
        "Jingrui He",
        "Hanghang Tong"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-07 02:03:13+00:00",
      "link": "https://arxiv.org/pdf/2601.03515v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03509v1",
      "title": "Evolving Programmatic Skill Networks",
      "abstract": "We study continual skill acquisition in open-ended embodied environments where an agent must construct, refine, and reuse an expanding library of executable skills. We introduce the Programmatic Skill Network (PSN), a framework in which skills are executable symbolic programs forming a compositional network that evolves through experience. PSN defines three core mechanisms instantiated via large language models: (1)REFLECT for structured fault localization over skill compositions, (2) progressive optimization with maturity-aware update gating that stabilizes reliable skills while maintaining plasticity for uncertain ones, and (3) canonical structural refactoring under rollback validation that maintains network compactness. We further show that PSN's learning dynamics exhibit structural parallels to neural network training. Experiments on MineDojo and Crafter demonstrate robust skill reuse, rapid adaptation, and strong generalization across open-ended task distributions.\\footnote{We plan to open-source the code.",
      "authors": [
        "Haochen Shi",
        "Xingdi Yuan",
        "Bang Liu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.NE"
      ],
      "published": "2026-01-07 01:43:25+00:00",
      "link": "https://arxiv.org/pdf/2601.03509v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03505v1",
      "title": "Beyond Perplexity: A Lightweight Benchmark for Knowledge Retention in Supervised Fine-Tuning",
      "abstract": "Supervised Fine-Tuning (SFT) is a standard approach for injecting domain knowledge into Large Language Models (LLMs). However, relying on validation perplexity to monitor training is often insufficient, as it confounds stylistic mimicry with genuine factual internalization. To address this, we introduce the Knowledge Retention (KR) Test , a lightweight, corpus-grounded evaluation framework designed to distinguish factual learning from linguistics. KR-Test utilizes automatically generated contrastive examples to measure likelihood preferences for correct versus incorrect continuations, requiring no instruction tuning or generative decoding. We validate the framework's integrity through a \"blind vs. oracle\" baseline analysis. Furthermore, we demonstrate the diagnostic capabilities of KR-Test by analyzing the training dynamics of Low-Rank Adaptation (LoRA). By exposing the fine-grained dissociation between linguistic convergence and knowledge retention, KR-Test enhances the interpretability of fine-tuning dynamics.",
      "authors": [
        "Soheil Zibakhsh Shabgahi",
        "Pedram Aghazadeh",
        "Farinaz Koushanfar"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-07 01:34:28+00:00",
      "link": "https://arxiv.org/pdf/2601.03505v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03500v1",
      "title": "SDCD: Structure-Disrupted Contrastive Decoding for Mitigating Hallucinations in Large Vision-Language Models",
      "abstract": "Large Vision-Language Models (LVLMs) demonstrate significant progress in multimodal understanding and reasoning, yet object hallucination remains a critical challenge. While existing research focuses on mitigating language priors or high-level statistical biases, they often overlook the internal complexities of the visual encoding process. We identify that visual statistical bias, arising from the inherent Bag-of-Patches behavior of Vision Encoders under weak structural supervision, acts as a contributing factor of object hallucinations. Under this bias, models prioritize local texture features within individual patches over holistic geometric structures. This tendency may induce spurious visual confidence and result in hallucinations. To address this, we introduce a training-free algorithm called Structure-Disrupted Contrastive Decoding (SDCD), which performs contrastive calibration of the output distribution by introducing a shuffled structure-disrupted view. By penalizing tokens that maintain high confidence under this structure-less view, SDCD effectively suppresses the texture-driven bias. Experimental results demonstrate that SDCD significantly mitigates hallucinations across multiple benchmarks and enhances the overall multimodal capabilities of LVLMs.",
      "authors": [
        "Yuxuan Xia",
        "Siheng Wang",
        "Peng Li"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-01-07 01:27:58+00:00",
      "link": "https://arxiv.org/pdf/2601.03500v1",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.03496v1",
      "title": "STELLA: Self-Reflective Terminology-Aware Framework for Building an Aerospace Information Retrieval Benchmark",
      "abstract": "Tasks in the aerospace industry heavily rely on searching and reusing large volumes of technical documents, yet there is no public information retrieval (IR) benchmark that reflects the terminology- and query-intent characteristics of this domain. To address this gap, this paper proposes the STELLA (Self-Reflective TErminoLogy-Aware Framework for BuiLding an Aerospace Information Retrieval Benchmark) framework. Using this framework, we introduce the STELLA benchmark, an aerospace-specific IR evaluation set constructed from NASA Technical Reports Server (NTRS) documents via a systematic pipeline that comprises document layout detection, passage chunking, terminology dictionary construction, synthetic query generation, and cross-lingual extension. The framework generates two types of queries: the Terminology Concordant Query (TCQ), which includes the terminology verbatim to evaluate lexical matching, and the Terminology Agnostic Query (TAQ), which utilizes the terminology's description to assess semantic matching. This enables a disentangled evaluation of the lexical and semantic matching capabilities of embedding models. In addition, we combine Chain-of-Density (CoD) and the Self-Reflection method with query generation to improve quality and implement a hybrid cross-lingual extension that reflects real user querying practices. Evaluation of seven embedding models on the STELLA benchmark shows that large decoder-based embedding models exhibit the strongest semantic understanding, while lexical matching methods such as BM25 remain highly competitive in domains where exact lexical matching technical term is crucial. The STELLA benchmark provides a reproducible foundation for reliable performance evaluation and improvement of embedding models in aerospace-domain IR tasks. The STELLA benchmark can be found in https://huggingface.co/datasets/telepix/STELLA.",
      "authors": [
        "Bongmin Kim"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.CL"
      ],
      "published": "2026-01-07 01:23:44+00:00",
      "link": "https://arxiv.org/pdf/2601.03496v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03495v1",
      "title": "Cyberattack Detection in Virtualized Microgrids Using LightGBM and Knowledge-Distilled Classifiers",
      "abstract": "Modern microgrids depend on distributed sensing and communication interfaces, making them increasingly vulnerable to cyber physical disturbances that threaten operational continuity and equipment safety. In this work, a complete virtual microgrid was designed and implemented in MATLAB/Simulink, integrating heterogeneous renewable sources and secondary controller layers. A structured cyberattack framework was developed using MGLib to inject adversarial signals directly into the secondary control pathways. Multiple attack classes were emulated, including ramp, sinusoidal, additive, coordinated stealth, and denial of service behaviors. The virtual environment was used to generate labeled datasets under both normal and attack conditions. The datasets trained Light Gradient Boosting Machine (LightGBM) models to perform two functions: detecting the presence of an intrusion (binary) and distinguishing among attack types (multiclass). The multiclass model attained 99.72% accuracy and a 99.62% F1 score, while the binary model attained 94.8% accuracy and a 94.3% F1 score. A knowledge-distillation step reduced the size of the multiclass model, allowing faster predictions with only a small drop in performance. Real-time tests showed a processing delay of about 54 to 67 ms per 1000 samples, demonstrating suitability for CPU-based edge deployment in microgrid controllers. The results confirm that lightweight machine learning based intrusion detection methods can provide fast, accurate, and efficient cyberattack detection without relying on complex deep learning models. Key contributions include: (1) development of a complete MATLAB-based virtual microgrid, (2) structured attack injection at the control layer, (3) creation of multiclass labeled datasets, and (4) design of low-cost AI models suitable for practical microgrid cybersecurity.",
      "authors": [
        "Osasumwen Cedric Ogiesoba-Eguakun",
        "Suman Rath"
      ],
      "primary_category": "eess.SY",
      "categories": [
        "eess.SY",
        "cs.AI"
      ],
      "published": "2026-01-07 01:23:13+00:00",
      "link": "https://arxiv.org/pdf/2601.03495v1",
      "tags": [
        "keyword:resnet",
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.03483v1",
      "title": "CALM: Culturally Self-Aware Language Models",
      "abstract": "Cultural awareness in language models is the capacity to understand and adapt to diverse cultural contexts. However, most existing approaches treat culture as static background knowledge, overlooking its dynamic and evolving nature. This limitation reduces their reliability in downstream tasks that demand genuine cultural sensitivity. In this work, we introduce CALM, a novel framework designed to endow language models with cultural self-awareness. CALM disentangles task semantics from explicit cultural concepts and latent cultural signals, shaping them into structured cultural clusters through contrastive learning. These clusters are then aligned via cross-attention to establish fine-grained interactions among related cultural features and are adaptively integrated through a Mixture-of-Experts mechanism along culture-specific dimensions. The resulting unified representation is fused with the model's original knowledge to construct a culturally grounded internal identity state, which is further enhanced through self-prompted reflective learning, enabling continual adaptation and self-correction. Extensive experiments conducted on multiple cross-cultural benchmark datasets demonstrate that CALM consistently outperforms state-of-the-art methods.",
      "authors": [
        "Lingzhi Shen",
        "Xiaohao Cai",
        "Yunfei Long",
        "Imran Razzak",
        "Guanming Chen",
        "Shoaib Jameel"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.CY",
        "cs.LG"
      ],
      "published": "2026-01-07 00:28:33+00:00",
      "link": "https://arxiv.org/pdf/2601.03483v1",
      "tags": [
        "keyword:resnet",
        "keyword:大语言模型",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03481v1",
      "title": "Self-Explaining Hate Speech Detection with Moral Rationales",
      "abstract": "Hate speech detection models rely on surface-level lexical features, increasing vulnerability to spurious correlations and limiting robustness, cultural contextualization, and interpretability. We propose Supervised Moral Rationale Attention (SMRA), the first self-explaining hate speech detection framework to incorporate moral rationales as direct supervision for attention alignment. Based on Moral Foundations Theory, SMRA aligns token-level attention with expert-annotated moral rationales, guiding models to attend to morally salient spans rather than spurious lexical patterns. Unlike prior rationale-supervised or post-hoc approaches, SMRA integrates moral rationale supervision directly into the training objective, producing inherently interpretable and contextualized explanations. To support our framework, we also introduce HateBRMoralXplain, a Brazilian Portuguese benchmark dataset annotated with hate labels, moral categories, token-level moral rationales, and socio-political metadata. Across binary hate speech detection and multi-label moral sentiment classification, SMRA consistently improves performance (e.g., +0.9 and +1.5 F1, respectively) while substantially enhancing explanation faithfulness, increasing IoU F1 (+7.4 pp) and Token F1 (+5.0 pp). Although explanations become more concise, sufficiency improves (+2.3 pp) and fairness remains stable, indicating more faithful rationales without performance or bias trade-offs",
      "authors": [
        "Francielle Vargas",
        "Jackson Trager",
        "Diego Alves",
        "Surendrabikram Thapa",
        "Matteo Guida",
        "Berk Atil",
        "Daryna Dementieva",
        "Andrew Smart",
        "Ameeta Agrawal"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 00:17:16+00:00",
      "link": "https://arxiv.org/pdf/2601.03481v1",
      "tags": [
        "keyword:resnet中文",
        "keyword:大语言模型",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03479v1",
      "title": "Efficient Sequential Recommendation for Long Term User Interest Via Personalization",
      "abstract": "Recent years have witnessed success of sequential modeling, generative recommender, and large language model for recommendation. Though the scaling law has been validated for sequential models, it showed inefficiency in computational capacity when considering real-world applications like recommendation, due to the non-linear(quadratic) increasing nature of the transformer model. To improve the efficiency of the sequential model, we introduced a novel approach to sequential recommendation that leverages personalization techniques to enhance efficiency and performance. Our method compresses long user interaction histories into learnable tokens, which are then combined with recent interactions to generate recommendations. This approach significantly reduces computational costs while maintaining high recommendation accuracy. Our method could be applied to existing transformer based recommendation models, e.g., HSTU and HLLM. Extensive experiments on multiple sequential models demonstrate its versatility and effectiveness. Source code is available at \\href{https://github.com/facebookresearch/PerSRec}{https://github.com/facebookresearch/PerSRec}.",
      "authors": [
        "Qiang Zhang",
        "Hanchao Yu",
        "Ivan Ji",
        "Chen Yuan",
        "Yi Zhang",
        "Chihuang Liu",
        "Xiaolong Wang",
        "Christopher E. Lambert",
        "Ren Chen",
        "Chen Kovacs",
        "Xinzhu Bei",
        "Renqin Cai",
        "Rui Li",
        "Lizhu Zhang",
        "Xiangjun Fan",
        "Qunshu Zhang",
        "Benyu Zhang"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "published": "2026-01-07 00:15:44+00:00",
      "link": "https://arxiv.org/pdf/2601.03479v1",
      "tags": [
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.03477v1",
      "title": "Hybrid Approach for Driver Behavior Analysis with Machine Learning, Feature Optimization, and Explainable AI",
      "abstract": "Progressive driver behavior analytics is crucial for improving road safety and mitigating the issues caused by aggressive or inattentive driving. Previous studies have employed machine learning and deep learning techniques, which often result in low feature optimization, thereby compromising both high performance and interpretability. To fill these voids, this paper proposes a hybrid approach to driver behavior analysis that uses a 12,857-row and 18-column data set taken from Kaggle. After applying preprocessing techniques such as label encoding, random oversampling, and standard scaling, 13 machine learning algorithms were tested. The Random Forest Classifier achieved an accuracy of 95%. After deploying the LIME technique in XAI, the top 10 features with the most significant positive and negative influence on accuracy were identified, and the same algorithms were retrained. The accuracy of the Random Forest Classifier decreased slightly to 94.2%, confirming that the efficiency of the model can be improved without sacrificing performance. This hybrid model can provide a return on investment in terms of the predictive power and explainability of the driver behavior process.",
      "authors": [
        "Mehedi Hasan Shuvo",
        "Md. Raihan Tapader",
        "Nur Mohammad Tamjid",
        "Sajjadul Islam",
        "Ahnaf Atef Choudhury",
        "Jia Uddin"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 00:12:39+00:00",
      "link": "https://arxiv.org/pdf/2601.03477v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03474v1",
      "title": "SegNSP: Revisiting Next Sentence Prediction for Linear Text Segmentation",
      "abstract": "Linear text segmentation is a long-standing problem in natural language processing (NLP), focused on dividing continuous text into coherent and semantically meaningful units. Despite its importance, the task remains challenging due to the complexity of defining topic boundaries, the variability in discourse structure, and the need to balance local coherence with global context. These difficulties hinder downstream applications such as summarization, information retrieval, and question answering. In this work, we introduce SegNSP, framing linear text segmentation as a next sentence prediction (NSP) task. Although NSP has largely been abandoned in modern pre-training, its explicit modeling of sentence-to-sentence continuity makes it a natural fit for detecting topic boundaries. We propose a label-agnostic NSP approach, which predicts whether the next sentence continues the current topic without requiring explicit topic labels, and enhance it with a segmentation-aware loss combined with harder negative sampling to better capture discourse continuity. Unlike recent proposals that leverage NSP alongside auxiliary topic classification, our approach avoids task-specific supervision. We evaluate our model against established baselines on two datasets, CitiLink-Minutes, for which we establish the first segmentation benchmark, and WikiSection. On CitiLink-Minutes, SegNSP achieves a B-$F_1$ of 0.79, closely aligning with human-annotated topic transitions, while on WikiSection it attains a B-F$_1$ of 0.65, outperforming the strongest reproducible baseline, TopSeg, by 0.17 absolute points. These results demonstrate competitive and robust performance, highlighting the effectiveness of modeling sentence-to-sentence continuity for improving segmentation quality and supporting downstream NLP applications.",
      "authors": [
        "José Isidro",
        "Filipe Cunha",
        "Purificação Silvano",
        "Alípio Jorge",
        "Nuno Guimarães",
        "Sérgio Nunes",
        "Ricardo Campos"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "published": "2026-01-07 00:02:30+00:00",
      "link": "https://arxiv.org/pdf/2601.03474v1",
      "tags": [
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.05210v1",
      "title": "Ricci-harmonic flow of $\\mathrm{G}_2$ and Spin(7)-structures",
      "abstract": "We introduce and study a new general flow of $\\mathrm{G}_2$-structures which we call the Ricci-harmonic flow of $\\mathrm{G}_2$-structures. The flow is the coupling of the Ricci flow of underlying metrics and the isometric flow of $\\mathrm{G}_2$-structures, but we also provide explicit lower order in the torsion terms. The lower order terms and the flow are obtained by analyzing the second order term in the Taylor series expansion of $\\mathrm{G}_2$-structures in normal coordinates. As such, the Ricci-harmonic flow described in the paper can be interpreted as the \"heat equation\" for $\\mathrm{G}_2$-structures. The lower order terms allow us to prove that the stationary points of the Ricci-harmonic flow are exactly torsion-free $\\mathrm{G}_2$-structures on compact manifolds. We study various analytic and geometric properties of the flow. We show that the flow has short-time existence and uniqueness on compact manifolds starting with an arbitrary $\\mathrm{G}_2$-structure and prove global Shi-type estimates. We also prove a modified local Shi-type estimates for the flow which assume bounds on the initial derivatives of the Riemann curvature tensor and the torsion but give uniform bounds on these quantities for all times. We prove a compactness theorem for the solutions of the flow and use it to prove that the Ricci-harmonic flow exists as long as the velocity of the flow remains bounded. We also study Ricci-harmonic solitons where we prove that there are no compact expanding solitons and the only steady solitons are torsion-free. We derive an analog of Hamilton's identity for gradient Ricci-harmonic solitons and prove some integral identities for the solitons. Finally, we prove a version of the Taylor series expansion for Spin(7)-structures and use it to derive the Ricci-harmonic flow of Spin(7)-structures.",
      "authors": [
        "Shubham Dwivedi"
      ],
      "primary_category": "math.DG",
      "categories": [
        "math.DG"
      ],
      "published": "2026-01-08 18:35:21+00:00",
      "link": "https://arxiv.org/pdf/2601.05210v1",
      "tags": [
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.05204v1",
      "title": "Extended Heun Hierarchy in Quantum Seiberg-Witten Geometry",
      "abstract": "We investigate the quantum geometry of the Seiberg-Witten curve for $\\mathcal{N}=2$, $\\mathrm{SU(2)}^n$ linear quiver gauge theories. By applying the Weyl quantization prescription to the algebraic curve, we derive the corresponding second-order differential equation and demonstrate that it is isomorphic to the Extended Heun Equation with $n+3$ regular singular points. The physical parameters of the gauge theory are linked to the canonical coefficients of the Heun equation via a polynomial representation of the Seiberg-Witten curve. This framework provides the necessary mathematical foundation to apply non-perturbative gauge-theoretic techniques, such as instanton counting, to spectral problems in gravitational physics, most notably for higher-dimensional black holes.",
      "authors": [
        "Peng Yang",
        "Yi-Rong Wang",
        "Kilar Zhang"
      ],
      "primary_category": "hep-th",
      "categories": [
        "hep-th",
        "astro-ph.HE",
        "gr-qc",
        "hep-ph",
        "math-ph"
      ],
      "published": "2026-01-08 18:29:02+00:00",
      "link": "https://arxiv.org/pdf/2601.05204v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.05146v1",
      "title": "A simple rigorous integrator for semilinear parabolic PDEs",
      "abstract": "Simulations of the dynamics generated by partial differential equations (PDEs) provide approximate, numerical solutions to initial value problems. Such simulations are ubiquitous in scientific computing, but the correctness of the results is usually not guaranteed. We propose a new method for the rigorous integration of parabolic PDEs, i.e., the derivation of rigorous and explicit error bounds between the numerically obtained approximate solution and the exact one, which is then proven to exist over the entire time interval considered. These guaranteed error bounds are obtained a posteriori, using a fixed point reformulation based on a piece-wise in time constant approximation of the linearization around the numerical solution. Our setup leads to relatively simple-to-understand estimates, which has several advantages. Most critically, it allows us to optimize various aspects of the proof, and in particular to provide an adaptive time-stepping strategy. In case the solution converges to a stable hyperbolic equilibrium, we are also able to prove this convergence, applying our rigorous integrator with a final, infinitely long timestep. We showcase the ability of our method to rigorously integrate over relatively long time intervals, and to capture non-trivial dynamics, via examples on the Swift--Hohenberg equation, the Ohta--Kawasaki equation and the Kuramoto--Sivashinsky equation. We expect that the simplicity and efficiency of the approach will enable generalization to a wide variety of other parabolic PDEs, as well as applications to boundary value problems.",
      "authors": [
        "Jan Bouwe van den Berg",
        "Maxime Breden"
      ],
      "primary_category": "math.NA",
      "categories": [
        "math.NA",
        "math.AP",
        "math.DS"
      ],
      "published": "2026-01-08 17:34:40+00:00",
      "link": "https://arxiv.org/pdf/2601.05146v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.05130v1",
      "title": "Sparsity and uniform regularity for regularised optimal transport",
      "abstract": "We consider regularised quadratic optimal transport with subquadratic polynomial or entropic regularisation. In both cases, we prove interior Lipschitz-estimates on a transport-like map and interior gradient Lipschitz-estimates on the potentials, under the assumption that the transport map solving the unregularised problem is bi-$C^{1,α}$-regular. For strictly subquadratic and entropic regularisation, the estimates improve to interior $C^1$ and $C^2$ estimates for the transport-like map and the potentials, respectively. Our estimates are uniform in the regularisation parameter. As a consequence of this, we obtain convergence of the transport-like map (resp. the potentials) to the unregularised transport map (resp. Kantorovich potentials) in $C^{0,1-}_{\\mathrm{loc}}$ (resp. $C^{1,1-}_{\\mathrm{loc}}$).   Central to our approach are sharp local bounds on the size of the support for regularised optimal transport which we derive for a general convex, superlinear regularisation term. These bounds are of independent interest and imply global bias bounds for the regularised transport plans. Our global bounds, while not necessarily sharp, improve on the best known results in the literature for quadratic regularisation.",
      "authors": [
        "Rishabh S. Gvalani",
        "Lukas Koch"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-01-08 17:20:00+00:00",
      "link": "https://arxiv.org/pdf/2601.05130v1",
      "tags": [
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.05056v1",
      "title": "ZIVR: An Incremental Variance Reduction Technique For Zeroth-Order Composite Problems",
      "abstract": "This paper investigates zeroth-order (ZO) finite-sum composite optimization. Recently, variance reduction techniques have been applied to ZO methods to mitigate the non-vanishing variance of 2-point estimators in constrained/composite optimization, yielding improved convergence rates. However, existing ZO variance reduction methods typically involve batch sampling of size at least $Θ(n)$ or $Θ(d)$, which can be computationally prohibitive for large-scale problems. In this work, we propose a general variance reduction framework, Zeroth-Order Incremental Variance Reduction (ZIVR), which supports flexible implementations$\\unicode{x2014}$including a pure 2-point zeroth-order algorithm that eliminates the need for large batch sampling. Furthermore, we establish comprehensive convergence guarantees for ZIVR across strongly-convex, convex, and non-convex settings that match their first-order counterparts. Numerical experiments validate the effectiveness of our proposed algorithm.",
      "authors": [
        "Silan Zhang",
        "Yujie Tang"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC",
        "eess.SY"
      ],
      "published": "2026-01-08 15:58:16+00:00",
      "link": "https://arxiv.org/pdf/2601.05056v1",
      "tags": [
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.04865v1",
      "title": "Forming invariant stochastic differential systems with a given first integral",
      "abstract": "This article proposes a method for forming invariant stochastic differential systems, namely dynamic systems with trajectories belonging to a given smooth manifold. The Itô or Stratonovich stochastic differential equations with the Wiener component describe dynamic systems, and the manifold is implicitly defined by a differentiable function. A convenient implementation of the algorithm for forming invariant stochastic differential systems within symbolic computation environments characterizes the proposed method. It is based on determining a basis associated with a tangent hyperplane to the manifold. The article discusses the problem of basis degeneration and examines variants that allow for the simple construction of a basis that does not degenerate. Examples of invariant stochastic differential systems are given, and numerical simulations are performed for them.",
      "authors": [
        "Konstantin A. Rybakov"
      ],
      "primary_category": "math.PR",
      "categories": [
        "math.PR"
      ],
      "published": "2026-01-08 12:00:00+00:00",
      "link": "https://arxiv.org/pdf/2601.04865v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04783v1",
      "title": "Szegő Mapping and Hermite--Padé Polynomials for Multiple Orthogonality on the Unit Circle",
      "abstract": "We investigate generalized Laurent multiple orthogonal polynomials on the unit circle satisfying simultaneous orthogonality conditions with respect to $r$ probability measures or linear functionals on the unit circle. We show that these polynomials can be characterized as solutions of a general two-point Hermite--Padé approximation problem.   We derive Szegő-type recurrence relations, establish compatibility conditions for the associated recurrence coefficients, and obtain Christoffel--Darboux formulas as well as Heine-type determinantal representations.   Furthermore, by extending the Szegő mapping and the Geronimus relations, we relate these Laurent multiple orthogonal polynomials to multiple orthogonal polynomials on the real line, thereby making explicit the connection between multiple orthogonality on the unit circle and on the real line.",
      "authors": [
        "Rostyslav Kozhan",
        "Marcus Vaktnäs"
      ],
      "primary_category": "math.CA",
      "categories": [
        "math.CA",
        "math.SP"
      ],
      "published": "2026-01-08 10:05:16+00:00",
      "link": "https://arxiv.org/pdf/2601.04783v1",
      "tags": [
        "keyword:resnet",
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.04532v1",
      "title": "Mixed-mode loading of a straight crack with surface strain-gradient elasticity",
      "abstract": "This work models brittle fracture using a linearized surface-substrate theory in which the crack faces possess surface stresses derived from a surface strain-gradient elastic energy. The model incorporates surface stretching, curvature, and surface gradients of stretching into the surface energy, thereby capturing small-length-scale effects absent from earlier surface elasticity formulations. The theory, supplemented with physically motivated tip conditions, is applied to the mixed mode-I/mode-II loading of a finite straight crack in an infinite isotropic plate. Using complex-analytic techniques, it is shown that the resulting stress and strain fields remain bounded up to the crack tips for nearly all admissible parameter values. Combined with previous results for mode-III loading, the analysis demonstrates that linearized surface-substrate models incorporating surface strain-gradient elasticity eliminate crack-tip singularities across all principal modes of far-field loading.",
      "authors": [
        "C. Rodriguez",
        "A. Zemlyanova"
      ],
      "primary_category": "math-ph",
      "categories": [
        "math-ph",
        "cond-mat.mtrl-sci"
      ],
      "published": "2026-01-08 02:58:30+00:00",
      "link": "https://arxiv.org/pdf/2601.04532v1",
      "tags": [
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.04530v1",
      "title": "On identity Seidel switches",
      "abstract": "Seidel switching is a classical operation on graphs which plays a central role in the theory of two-graphs, signed graphs, and switching classes. In this paper we focus on those switches which leave a given graph invariant up to isomorphism. We call such subsets of the vertex set \\emph{identity Seidel switches}. After recalling basic properties of Seidel switching and the associated abelian group structure, we introduce Seidel equivalence classes of graphs and then study the structure of the family of identity Seidel switches of a fixed graph. We show that this family forms a 14 pages; 2--group under composition, and we obtain structural constraints on graphs in which many vertices or edges give rise to identity switches. In particular, we derive necessary conditions in terms of degree parameters, and we characterize certain edge-identity switches via an automorphism of an induced subgraph. Several constructions and examples are presented, and some open problems are proposed.",
      "authors": [
        "Severino V. Gervacio"
      ],
      "primary_category": "math.CO",
      "categories": [
        "math.CO"
      ],
      "published": "2026-01-08 02:54:41+00:00",
      "link": "https://arxiv.org/pdf/2601.04530v1",
      "tags": [
        "keyword:resnet",
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.04496v1",
      "title": "Adaptive Multi-Grade Deep Learning for Highly Oscillatory Fredholm Integral Equations of the Second Kind",
      "abstract": "This paper studies the use of Multi-Grade Deep Learning (MGDL) for solving highly oscillatory Fredholm integral equations of the second kind. We provide rigorous error analyses of continuous and discrete MGDL models, showing that the discrete model retains the convergence and stability of its continuous counterpart under sufficiently small quadrature error. We identify the DNN training error as the primary source of approximation error, motivating a novel adaptive MGDL algorithm that selects the network grade based on training performance. Numerical experiments with highly oscillatory (including wavenumber 500) and singular solutions confirm the accuracy, effectiveness and robustness of the proposed approach.",
      "authors": [
        "Jie Jiang",
        "Yuesheng Xu"
      ],
      "primary_category": "math.NA",
      "categories": [
        "math.NA"
      ],
      "published": "2026-01-08 02:00:06+00:00",
      "link": "https://arxiv.org/pdf/2601.04496v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04429v1",
      "title": "Toward genuine efficiency and cluster robustness of preconditioned CG-like eigensolvers",
      "abstract": "The performance of eigenvalue problem solvers (eigensolvers) depends on various factors such as preconditioning and eigenvalue distribution. Developing stable and rapidly converging vectorwise eigensolvers is a crucial step in improving the overall efficiency of their blockwise implementations. The present paper is concerned with the locally optimal block preconditioned conjugate gradient (LOBPCG) method for Hermitian eigenvalue problems, and motivated by two recently proposed alternatives for its single-vector version LOPCG. A common basis of these eigensolvers is the well-known CG method for linear systems. However, the optimality of CG search directions cannot perfectly be transferred to CG-like eigensolvers. In particular, while computing clustered eigenvalues, LOPCG and its alternatives suffer from frequent delays, leading to a staircase-shaped convergence behavior which cannot be explained by the existing estimates. Keeping this in mind, we construct a class of cluster robust vector iterations where LOPCG is replaced by asymptotically equivalent two-term recurrences and the search directions are timely corrected by selecting a far previous iterate as augmentation. The new approach significantly reduces the number of required steps and the total computational time.",
      "authors": [
        "Ming Zhou",
        "Klaus Neymeyr"
      ],
      "primary_category": "math.NA",
      "categories": [
        "math.NA"
      ],
      "published": "2026-01-07 22:26:09+00:00",
      "link": "https://arxiv.org/pdf/2601.04429v1",
      "tags": [
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.04408v1",
      "title": "G-KdVNet: ANN-ADM Surrogate for Geophysical KdV Equation",
      "abstract": "This article explores the impact of the Coriolis constant on the interpretation of the Korteweg-de Vries (KdV) equation. It introduces an intelligent computing approach, viz., G-KdVNet, to approximate the KdV equation. The Adomian decomposition method (ADM) has been applied to generate the training data for G-KdVNet. When we compared it with benchmark methods, it achieved superior performance, with absolute errors of up to 0.001 for unseen data. Additionally, tabular and graphical representations have been included to offer deeper insights into the effects of the Coriolis parameter.",
      "authors": [
        "Mrutyunjaya Sahoo",
        "Arup Kumar Sahoo",
        "Snehashish Chakraverty"
      ],
      "primary_category": "math.DS",
      "categories": [
        "math.DS"
      ],
      "published": "2026-01-07 21:28:19+00:00",
      "link": "https://arxiv.org/pdf/2601.04408v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04173v1",
      "title": "Trace regularity of solutions to the Navier equations",
      "abstract": "We present results on the trace regularity of the stress vector on the boundary of an elastic solid satisfying the time-dependent, displacement-traction problem for the Navier equations of linear elasticity in a bounded domain of $\\mathbb{R}^3$. Specifically, the solid's displacement is subject to Dirichlet- and Neumann-type conditions on different portions of its boundary and possibly non-zero body forces and initial data. Our regularity results are reminiscent of the so-called \"hidden trace regularity\" results for solutions to the scalar wave equation obtained in [12].",
      "authors": [
        "Jerin Tasnim Farin",
        "Giusy Mazzone"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-01-07 18:42:01+00:00",
      "link": "https://arxiv.org/pdf/2601.04173v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04146v1",
      "title": "Embedding of Toeplitz operators with smooth symbols into strongly continuous semigroups",
      "abstract": "Using the model theory for Toeplitz operators with smooth symbols developed by the fourth author in the 80's, we study whether such operators $T_{F}$ can be embedded into a $C_{0}$-semigroup of operators on the Hardy space $H^p$ of the open unit disk, $1<p<\\infty$. We show that it is the case as soon as $0$ belongs to the unbounded connected component of $\\mathbb{C}$ minus the interior of the spectrum of $T_{F}$. We provide several conditions on the symbol $F$, both geometric and analytic in nature, ensuring that this sufficient condition is also necessary. For a certain class of symbols, where the curve $F(\\mathbb{T})$ is a ``figure eight in a loop\" such that $\\mathbb{C}\\setminusσ(T_F)$ has a bounded connected component, we obtain a complete characterization of the embeddability of $T_F$ into a $C_0$-semigroup. In the last part of the paper, we discuss the embeddability of $T_F$ when the symbol $F$ is not necessarily smooth, using connections with the numerical range and the functional calculus for bounded sectorial operators.",
      "authors": [
        "Emmanuel Fricain",
        "Sophie Grivaux",
        "Maëva Ostermann",
        "Dmitry Yakubovich"
      ],
      "primary_category": "math.FA",
      "categories": [
        "math.FA"
      ],
      "published": "2026-01-07 17:58:36+00:00",
      "link": "https://arxiv.org/pdf/2601.04146v1",
      "tags": [
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.04117v1",
      "title": "Teukolsky on slowly-rotating Kerr-de Sitter in the vanishing $Λ$ limit",
      "abstract": "We prove energy, Morawetz and $r^p$-weighted estimates for solutions to the Teukolsky equation set on a slowly-rotating Kerr-de Sitter background. The main feature of our estimates is their uniformity with respect to the cosmological constant $Λ>0$ (thus allowed to tend to $0$), while they hold on the whole domain of outer communications, extending up to $r\\sim Λ^{-\\frac{1}{2}}$. As an application of our result, we recover well-known corresponding estimates for solutions to Teukolsky on a slowly-rotating Kerr background in the limit $Λ\\to 0$.",
      "authors": [
        "Allen Juntao Fang",
        "Jérémie Szeftel",
        "Arthur Touati"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-01-07 17:26:19+00:00",
      "link": "https://arxiv.org/pdf/2601.04117v1",
      "tags": [
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.04109v2",
      "title": "Automorphisms of odd dimensional $(2,2)$-complete intersections in characteristic $2$",
      "abstract": "We compute the automorphism scheme of a generic odd dimensional $(2,2)$-complete intersection in characteristic $2$. This is the only case for complete intersections having a non-trivial identity component in automorphism schemes apart from quadric hypersurfaces and genus $1$ curves.",
      "authors": [
        "Yang Zhang"
      ],
      "primary_category": "math.AG",
      "categories": [
        "math.AG"
      ],
      "published": "2026-01-07 17:14:22+00:00",
      "link": "https://arxiv.org/pdf/2601.04109v2",
      "tags": [
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.04105v1",
      "title": "Time Reparametrization and Chaotic Dynamics in Conformable $C_0$-Semigroups",
      "abstract": "Conformable derivatives provide a fractional-looking calculus that remains local and admits a simple representation through classical derivatives with explicit weights. In this paper we develop a systematic operator-theoretic perspective showing that conformable time evolution is, in essence, a classical $C_0$-semigroup observed through a nonlinear clock. We introduce the conformable time map $ψ(t)=t^α/α$ and prove that every $C_0$--$α$-semigroup $\\{T_α(t)\\}_{t\\ge0}$ can be written as $T_α(t)=T(ψ(t))$ for a uniquely determined classical $C_0$-semigroup $\\{T(s)\\}_{s\\ge0}$, with generators agreeing on a common domain. This correspondence yields a one-to-one transfer of mild solutions and shows that orbit-based linear dynamics are invariant under conformable reparametrization. In particular, $α$-hypercyclicity and $α$--chaos coincide with the usual notions for the associated classical semigroup. As a consequence, we obtain a conformable version of the Desch--Schappacher--Webb spectral criterion for chaos. We also place the analysis in the natural functional setting provided by conformable Lebesgue spaces $L^{p,α}$ and their explicit isometric identification with standard $L^p$ spaces, which allows one to transport estimates and spectral arguments without loss. The results clarify which dynamical phenomena in conformable models are genuinely new and which are inherited from classical semigroup dynamics via a nonlinear change of time.",
      "authors": [
        "Mohamed Khoulane",
        "Aziz El Ghazouani",
        "M'hamed El Omari"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP",
        "math.DS",
        "math.FA"
      ],
      "published": "2026-01-07 17:11:23+00:00",
      "link": "https://arxiv.org/pdf/2601.04105v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04064v2",
      "title": "AKSZ construction for shifted Poisson structures",
      "abstract": "We prove the AKSZ theorem for shifted Poisson structures: if $X$ is an $n$-shifted Poisson derived stack, and $Y$ a $d$-oriented derived stack, then the mapping stack \\[\\underline{\\mathrm{Map}}(Y,X)\\] is naturally endowed with an $(n-d)$-shifted Poisson structure. For this, we prove that the data of an $n$-shifted Poisson structure on a derived Artin stack is equivalent to the data of an $(n+1)$-shifted Lagrangian thickening of it. We also extend the definition of shifted Poisson structures to derived prestacks having a deformation theory and give two applications, one for mapping stacks with a non-proper source and one in BV formalism.",
      "authors": [
        "Nikola Tomić"
      ],
      "primary_category": "math.AG",
      "categories": [
        "math.AG",
        "math.AT"
      ],
      "published": "2026-01-07 16:29:34+00:00",
      "link": "https://arxiv.org/pdf/2601.04064v2",
      "tags": [
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.03920v1",
      "title": "Adaptive thresholding for wavelet-based nonparametric heteroskedastic variance estimation on the sphere",
      "abstract": "This paper investigates the nonparametric estimation of a heteroskedastic variance function on the sphere in a regression framework, assuming the variance belongs to a Besov regularity class. A needlet-based estimator is proposed, combining multiresolution analysis with hard thresholding. The method exploits the spatial and spectral localization of needlets to adapt to unknown smoothness and is shown to attain minimax-optimal convergence rates over Besov spaces.",
      "authors": [
        "Claudio Durastanti",
        "Radomyra Shevchenko"
      ],
      "primary_category": "math.ST",
      "categories": [
        "math.ST"
      ],
      "published": "2026-01-07 13:41:39+00:00",
      "link": "https://arxiv.org/pdf/2601.03920v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03906v1",
      "title": "Exact Continuous Reformulations of Logic Constraints in Nonlinear Optimization and Optimal Control Problems",
      "abstract": "Many nonlinear optimal control and optimization problems involve constraints that combine continuous dynamics with discrete logic conditions. Standard approaches typically rely on mixed-integer programming, which introduces scalability challenges and requires specialized solvers. This paper presents an exact reformulation of broad classes of logical constraints as binary-variable-free expressions whose differentiability properties coincide with those of the underlying predicates, enabling their direct integration into nonlinear programming models. Our approach rewrites arbitrary logical propositions into conjunctive normal form, converts them into equivalent max--min constraints, and applies a smoothing procedure that preserves the exact feasible set. The method is evaluated on two benchmark problems, a quadrotor trajectory optimization with obstacle avoidance and a hybrid two-tank system with temporal logic constraints, and is shown to obtain optimal solutions more consistently and efficiently than existing binary variable elimination techniques.",
      "authors": [
        "Jad Wehbeh",
        "Eric C. Kerrigan"
      ],
      "primary_category": "eess.SY",
      "categories": [
        "eess.SY",
        "math.OC"
      ],
      "published": "2026-01-07 13:16:33+00:00",
      "link": "https://arxiv.org/pdf/2601.03906v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03876v1",
      "title": "Graded Bridgeman dilogarithm identities on hyperbolic surfaces",
      "abstract": "We establish graded versions of Bridgeman's dilogarithm identity for hyperbolic cone surfaces, including surfaces with only cusps and cone points, and provide applications to the study of orthogeodesics.",
      "authors": [
        "Ara Basmajian",
        "Nhat Minh Doan",
        "Hugo Parlier",
        "Ser Peow Tan"
      ],
      "primary_category": "math.GT",
      "categories": [
        "math.GT",
        "math.DG"
      ],
      "published": "2026-01-07 12:40:34+00:00",
      "link": "https://arxiv.org/pdf/2601.03876v1",
      "tags": [
        "keyword:resnet",
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.03759v1",
      "title": "Connecting Max-entropy With Computational Geometry, LP And SDP",
      "abstract": "We consider the well-known max-(relative) entropy problem $Θ$(y) = infQ$\\ll$P DKL(Q P ) with Kullback-Leibler divergence on a domain $Ω$ $\\subset$ R d , and with ''moment'' constraints h dQ = y, y $\\in$ R m . We show that when m $\\le$ d, $Θ$ is the Cram{é}r transform of a function v that solves a simply related computational geometry problem. Also, and remarkably, to the canonical LP: min x$\\ge$0 {c T x\\,: A x = y}, with A $\\in$ R mxd , one may associate a max-entropy problem with a suitably chosen reference measure P on R d + and linear mapping h(x) = Ax, such that its associated perspective function $ε$ $Θ$(y/$ε$) is the optimal value of the log-barrier formulation (with parameter $ε$) of the dual LP (and so it converges to the LP optimal value as $ε$ $\\rightarrow$ 0). An analogous result also holds for the canonical SDP: min X 0 { C, X\\,: A(X) = y }.",
      "authors": [
        "Jean B Lasserre"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-01-07 09:48:10+00:00",
      "link": "https://arxiv.org/pdf/2601.03759v1",
      "tags": [
        "keyword:resnet",
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.03755v1",
      "title": "$BV$-Estimates for Non-Linear Parabolic PDE with Linear Drift",
      "abstract": "In the present work, we establish space Bounded Variation $(BV)$ regularity of the solution for a non-linear parabolic partial differential equations involving a linear drift term. We study the problem in a bounded domain with mixed Dirichlet-Neumann boundary conditions, a general non-linearity and reasonable assumptions on the data. Our results also cover, as a particular case, the linear transport equation in a bounded domain with an outward-pointing drift vector field on the boundary.",
      "authors": [
        "El Mahdi Erraji",
        "Noureddine Igbida",
        "Fahd Karami",
        "Driss Meskine"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-01-07 09:45:32+00:00",
      "link": "https://arxiv.org/pdf/2601.03755v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03747v1",
      "title": "Matrix Riccati BSDEs with singular terminal condition and stochastic LQ control with linear terminal constraint",
      "abstract": "We analyze a class of multidimensional linear-quadratic stochastic control problems with random coefficients, motivated by multi-asset optimal trade execution. The problems feature non-diffusive controlled state dynamics and a terminal constraint that restricts the terminal state to a prescribed random linear subspace. We derive the associated Riccati backward stochastic differential equation (BSDE) and identify a suitable formalization of its singular terminal condition. Via a penalization approach, we establish existence of a minimal supersolution of the Riccati BSDE and use it to characterize both the value function and the optimal control. We analyze the asymptotic behavior of the supersolution near terminal time and discuss special cases where closed-form solutions can be obtained.",
      "authors": [
        "Julia Ackermann",
        "Thomas Kruse",
        "Petr Petrov",
        "Alexandre Popier"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC",
        "math.PR"
      ],
      "published": "2026-01-07 09:37:25+00:00",
      "link": "https://arxiv.org/pdf/2601.03747v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03742v1",
      "title": "Mean-field limits for interacting particles on general adaptive dynamical networks",
      "abstract": "We study the large-population limit of interacting particle systems evolving on adaptive dynamical networks, motivated in particular by models of opinion dynamics. In such systems, agents interact through weighted graphs whose structure evolves over time in a coupled manner with the agents' states, leading to non-exchangeable dynamics. In the dense-graph regime, we show that the asymptotic behavior is described by a Vlasov-type equation posed on an extended phase space that includes both the agents' states and identities and the evolving interaction weights. We establish this limiting equation through two complementary approaches. The first follows the mean-field methodology in the spirit of Sznitman [28]. In this framework, we impose the additional assumption that the weight dynamics is independent of one of the agent's states, an assumption that remains well motivated from a modeling perspective and allows for a direct derivation of the mean-field limit. The second approach is based on the graph limit framework and is formulated in a deterministic setting. This perspective makes it possible to remove the aforementioned restriction on the weight dynamics and to handle more general interaction structures. Our analysis includes wellposedness and stability results for the limiting Vlasov-type equation, as well as quantitative estimates ensuring the propagation of independence. We further clarify the relationship between the continuum (graph limit) formulation and the mean-field limit, thereby providing a unified description of the asymptotic dynamics of interacting particle systems on adaptive dynamical networks.",
      "authors": [
        "Nathalie Ayi"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-01-07 09:30:01+00:00",
      "link": "https://arxiv.org/pdf/2601.03742v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03721v1",
      "title": "Liouville theorems and gradient estimates of a nonlinear elliptic equation for the V-Laplacian",
      "abstract": "In this paper we establish gradient estimates for positive solutions to the nonlinear elliptic equation $$Δ_{V}u^{m}+μ(x)u+p(x)u^α=0 , \\quad m>1$$on any smooth metric measure space whose $k$-Bakry-Émery curvature is bounded from below by $-(k-1)K$ with $K \\geq 0$. Additionally, we obtain related Liouville theorems and Harnack inequalities. We partially extend conclusions of Wang, when $V=0$, $μ=0$ the equation becomes $Δu^{m}+p(x)u^α=0$. And $V=f$, $μ=c, p=0 $, the equation becomes $Δ_{f}u^{m}+cu=0 $.",
      "authors": [
        "Yike Jia"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP",
        "math.DG"
      ],
      "published": "2026-01-07 09:17:49+00:00",
      "link": "https://arxiv.org/pdf/2601.03721v1",
      "tags": [
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.04913v1",
      "title": "Bayesian Additive Regression Tree Copula Processes for Scalable Distributional Prediction",
      "abstract": "We show how to construct the implied copula process of response values from a Bayesian additive regression tree (BART) model with prior on the leaf node variances. This copula process, defined on the covariate space, can be paired with any marginal distribution for the dependent variable to construct a flexible distributional BART model. Bayesian inference is performed via Markov chain Monte Carlo on an augmented posterior, where we show that key sampling steps can be realized as those of Chipman et al. (2010), preserving scalability and computational efficiency even though the copula process is high dimensional. The posterior predictive distribution from the copula process model is derived in closed form as the push-forward of the posterior predictive distribution of the underlying BART model with an optimal transport map. Under suitable conditions, we establish posterior consistency for the regression function and posterior means and prove convergence in distribution of the predictive process and conditional expectation. Simulation studies demonstrate improved accuracy of distributional predictions compared to the original BART model and leading benchmarks. Applications to five real datasets with 506 to 515,345 observations and 8 to 90 covariates further highlight the efficacy and scalability of our proposed BART copula process model.",
      "authors": [
        "Jan Martin Wenkel",
        "Michael Stanley Smith",
        "Nadja Klein"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME"
      ],
      "published": "2026-01-08 13:11:37+00:00",
      "link": "https://arxiv.org/pdf/2601.04913v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04608v1",
      "title": "Forecasting the U.S. Treasury Yield Curve: A Distributionally Robust Machine Learning Approach",
      "abstract": "We study U.S. Treasury yield curve forecasting under distributional uncertainty and recast forecasting as an operations research and managerial decision problem. Rather than minimizing average forecast error, the forecaster selects a decision rule that minimizes worst case expected loss over an ambiguity set of forecast error distributions. To this end, we propose a distributionally robust ensemble forecasting framework that integrates parametric factor models with high dimensional nonparametric machine learning models through adaptive forecast combinations. The framework consists of three machine learning components. First, a rolling window Factor Augmented Dynamic Nelson Siegel model captures level, slope, and curvature dynamics using principal components extracted from economic indicators. Second, Random Forest models capture nonlinear interactions among macro financial drivers and lagged Treasury yields. Third, distributionally robust forecast combination schemes aggregate heterogeneous forecasts under moment uncertainty, penalizing downside tail risk via expected shortfall and stabilizing second moment estimation through ridge regularized covariance matrices. The severity of the worst case criterion is adjustable, allowing the forecaster to regulate the trade off between robustness and statistical efficiency. Using monthly data, we evaluate out of sample forecasts across maturities and horizons from one to twelve months ahead. Adaptive combinations deliver superior performance at short horizons, while Random Forest forecasts dominate at longer horizons. Extensions to global sovereign bond yields confirm the stability and generalizability of the proposed framework.",
      "authors": [
        "Jinjun Liu",
        "Ming-Yen Cheng"
      ],
      "primary_category": "q-fin.MF",
      "categories": [
        "q-fin.MF",
        "q-fin.CP",
        "stat.ML"
      ],
      "published": "2026-01-08 05:26:43+00:00",
      "link": "https://arxiv.org/pdf/2601.04608v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04138v1",
      "title": "On the Distributed Estimation for Scalar-on-Function Regression Models",
      "abstract": "This paper proposes distributed estimation procedures for three scalar-on-function regression models: the functional linear model (FLM), the functional non-parametric model (FNPM), and the functional partial linear model (FPLM). The framework addresses two key challenges in functional data analysis, namely the high computational cost of large samples and limitations on sharing raw data across institutions. Monte Carlo simulations show that the distributed estimators substantially reduce computation time while preserving high estimation and prediction accuracy for all three models. When block sizes become too small, the FPLM exhibits overfitting, leading to narrower prediction intervals and reduced empirical coverage probability. An example of an empirical study using the \\textit{tecator} dataset further supports these findings.",
      "authors": [
        "Peilun He",
        "Han Lin Shang",
        "Nan Zou"
      ],
      "primary_category": "stat.CO",
      "categories": [
        "stat.CO"
      ],
      "published": "2026-01-07 17:51:46+00:00",
      "link": "https://arxiv.org/pdf/2601.04138v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04101v1",
      "title": "Ridge Estimation of High Dimensional Two-Way Fixed Effect Regression",
      "abstract": "We study a ridge estimator for the high-dimensional two-way fixed effect regression model with a sparse bipartite network. We develop concentration inequalities showing that when the ridge parameters increase as the log of the network size, the bias, and the variance-covariance matrix of the vector of estimated fixed effects converge to deterministic equivalents that depend only on the expected network. We provide simulations and an application using administrative data on wages for worker-firm matches.",
      "authors": [
        "Junnan He",
        "Jean-Marc Robin"
      ],
      "primary_category": "econ.EM",
      "categories": [
        "econ.EM",
        "stat.ME"
      ],
      "published": "2026-01-07 17:06:18+00:00",
      "link": "https://arxiv.org/pdf/2601.04101v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03927v1",
      "title": "A comprehensive review and analysis of different modeling approaches for financial index tracking problem",
      "abstract": "Index tracking, also known as passive investing, has gained significant traction in financial markets due to its cost-effective and efficient approach to replicating the performance of a specific market index. This review paper provides a comprehensive overview of the various modeling approaches and strategies developed for index tracking, highlighting the strengths and limitations of each approach. We categorize the index tracking models into three broad frameworks: optimization-based models, statistical-based models and machine learning based data-driven approach. A comprehensive empirical study conducted on the S\\&P 500 dataset demonstrates that the tracking error volatility model under the optimization-based framework delivers the most precise index tracking, the convex co-integration model, under the statistical-based framework achieves the strongest return-risk balance, and the deep neural network with fixed noise model within the data-driven framework provides a competitive performance with notably low turnover and high computational efficiency. By combining a critical review of the existing literature with comparative empirical analysis, this paper aims to provide insights into the evolving landscape of index tracking and its practical implications for investors and fund managers.",
      "authors": [
        "Vrinda Dhingra",
        "Amita Sharma",
        "Anubha Goel"
      ],
      "primary_category": "q-fin.PM",
      "categories": [
        "q-fin.PM",
        "stat.ML"
      ],
      "published": "2026-01-07 13:47:55+00:00",
      "link": "https://arxiv.org/pdf/2601.03927v1",
      "tags": [
        "keyword:resnet",
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.03815v1",
      "title": "High-Dimensional Precision Matrix Quadratic Forms: Estimation Framework for $p > n$",
      "abstract": "We propose a novel estimation framework for quadratic functionals of precision matrices in high-dimensional settings, particularly in regimes where the feature dimension $p$ exceeds the sample size $n$. Traditional moment-based estimators with bias correction remain consistent when $p<n$ (i.e., $p/n \\to c <1$). However, they break down entirely once $p>n$, highlighting a fundamental distinction between the two regimes due to rank deficiency and high-dimensional complexity. Our approach resolves these issues by combining a spectral-moment representation with constrained optimization, resulting in consistent estimation under mild moment conditions.   The proposed framework provides a unified approach for inference on a broad class of high-dimensional statistical measures. We illustrate its utility through two representative examples: the optimal Sharpe ratio in portfolio optimization and the multiple correlation coefficient in regression analysis. Simulation studies demonstrate that the proposed estimator effectively overcomes the fundamental $p>n$ barrier where conventional methods fail.",
      "authors": [
        "Shizhe Hong",
        "Weiming Li",
        "Guangming Pan"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME"
      ],
      "published": "2026-01-07 11:19:28+00:00",
      "link": "https://arxiv.org/pdf/2601.03815v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03760v1",
      "title": "Non-Homogeneous Markov-Switching Generalized Additive Models for Location, Scale, and Shape",
      "abstract": "We propose an extension of Markov-switching generalized additive models for location, scale, and shape (MS-GAMLSS) that allows covariates to influence not only the parameters of the state-dependent distributions but also the state transition probabilities. Traditional MS-GAMLSS, which combine distributional regression with hidden Markov models, typically assume time-homogeneous (i.e., constant) transition probabilities, thereby preventing regime shifts from responding to covariate-driven changes. Our approach overcomes this limitation by modeling the transition probabilities as smooth functions of covariates, enabling a flexible, data-driven characterization of covariate-dependent regime dynamics. Estimation is carried out within a penalized likelihood framework, where automatic smoothness selection controls model complexity and guards against overfitting. We evaluate the proposed methodology through simulations and applications to daily Lufthansa stock prices and Spanish energy prices. Our results show that incorporating macroeconomic indicators into the transition probabilities yields additional insights into market dynamics. Data and R code to reproduce the results are available online.",
      "authors": [
        "Katharina Ammann",
        "Timo Adam",
        "Jan-Ole Koslik"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME"
      ],
      "published": "2026-01-07 09:52:01+00:00",
      "link": "https://arxiv.org/pdf/2601.03760v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03674v1",
      "title": "Multi-transport Distributional Regression",
      "abstract": "We study distribution-on-distribution regression problems in which a response distribution depends on multiple distributional predictors. Such settings arise naturally in applications where the outcome distribution is driven by several heterogeneous distributional sources, yet remain challenging due to the nonlinear geometry of the Wasserstein space. We propose an intrinsic regression framework that aggregates predictor-specific transported distributions through a weighted Fréchet mean in the Wasserstein space. The resulting model admits multiple distributional predictors, assigns interpretable weights quantifying their relative contributions, and defines a flexible regression operator that is invariant to auxiliary construction choices, such as the selection of a reference distribution. From a theoretical perspective, we establish identifiability of the induced regression operator and derive asymptotic guarantees for its estimation under a predictive Wasserstein semi-norm, which directly characterizes convergence of the composite prediction map. Extensive simulation studies and a real data application demonstrate the improved predictive performance and interpretability of the proposed approach compared with existing Wasserstein regression methods.",
      "authors": [
        "Yuanying Chen",
        "Tongyu Li",
        "Yang Bai",
        "Zhenhua Lin"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME"
      ],
      "published": "2026-01-07 07:54:20+00:00",
      "link": "https://arxiv.org/pdf/2601.03674v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04325v1",
      "title": "When evolution realizes large deviations of fitness: from speciation to dynamical phase transitions",
      "abstract": "We explore the connection between evolution and large-deviation theory. To do so, we study evolutionary dynamics in which individuals experience mutations, reproduction, and selection using variants of the Moran model. We show that, in the large population size limit, the impact of reproduction and selection amounts to realizing a large-deviation dynamics for the non-interacting random walk in which individuals simply explore the genome landscape due to mutations. This mapping, which holds at all times, allows us to recast transitions in the population genome distribution as dynamical phase transitions, which can then be studied using the toolbox of large-deviation theory. Finally, we show that the mapping extends beyond the class of Moran models.",
      "authors": [
        "Sara Dal Cengio",
        "Quentin Laurenceau",
        "Vivien Lecomte",
        "Charline Smadi",
        "Julien Tailleur"
      ],
      "primary_category": "q-bio.PE",
      "categories": [
        "q-bio.PE",
        "cond-mat.stat-mech"
      ],
      "published": "2026-01-07 19:02:52+00:00",
      "link": "https://arxiv.org/pdf/2601.04325v1",
      "tags": [
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.04896v1",
      "title": "Deep Reinforcement Learning for Optimum Order Execution: Mitigating Risk and Maximizing Returns",
      "abstract": "Optimal Order Execution is a well-established problem in finance that pertains to the flawless execution of a trade (buy or sell) for a given volume within a specified time frame. This problem revolves around optimizing returns while minimizing risk, yet recent research predominantly focuses on addressing one aspect of this challenge. In this paper, we introduce an innovative approach to Optimal Order Execution within the US market, leveraging Deep Reinforcement Learning (DRL) to effectively address this optimization problem holistically. Our study assesses the performance of our model in comparison to two widely employed execution strategies: Volume Weighted Average Price (VWAP) and Time Weighted Average Price (TWAP). Our experimental findings clearly demonstrate that our DRL-based approach outperforms both VWAP and TWAP in terms of return on investment and risk management. The model's ability to adapt dynamically to market conditions, even during periods of market stress, underscores its promise as a robust solution.",
      "authors": [
        "Khabbab Zakaria",
        "Jayapaulraj Jerinsh",
        "Andreas Maier",
        "Patrick Krauss",
        "Stefano Pasquali",
        "Dhagash Mehta"
      ],
      "primary_category": "q-fin.CP",
      "categories": [
        "q-fin.CP"
      ],
      "published": "2026-01-08 12:49:11+00:00",
      "link": "https://arxiv.org/pdf/2601.04896v1",
      "tags": [
        "keyword:resnet",
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.04602v1",
      "title": "Forecasting Equity Correlations with Hybrid Transformer Graph Neural Network",
      "abstract": "This paper studies forward-looking stock-stock correlation forecasting for S\\&P 500 constituents and evaluates whether learned correlation forecasts can improve graph-based clustering used in basket trading strategies. We cast 10-day ahead correlation prediction in Fisher-z space and train a Temporal-Heterogeneous Graph Neural Network (THGNN) to predict residual deviations from a rolling historical baseline. The architecture combines a Transformer-based temporal encoder, which captures non-stationary, complex, temporal dependencies, with an edge-aware graph attention network that propagates cross-asset information over the equity network. Inputs span daily returns, technicals, sector structure, previous correlations, and macro signals, enabling regime-aware forecasts and attention-based feature and neighbor importance to provide interpretability. Out-of-sample results from 2019-2024 show that the proposed model meaningfully reduces correlation forecasting error relative to rolling-window estimates. When integrated into a graph-based clustering framework, forward-looking correlations produce adaptable and economically meaningfully baskets, particularly during periods of market stress. These findings suggest that improvements in correlation forecasts translate into meaningful gains during portfolio construction tasks.",
      "authors": [
        "Jack Fanshawe",
        "Rumi Masih",
        "Alexander Cameron"
      ],
      "primary_category": "q-fin.CP",
      "categories": [
        "q-fin.CP",
        "q-fin.TR"
      ],
      "published": "2026-01-08 05:16:06+00:00",
      "link": "https://arxiv.org/pdf/2601.04602v1",
      "tags": [
        "keyword:resnet",
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.04067v1",
      "title": "Diversification Preferences and Risk Attitudes",
      "abstract": "Portfolio diversification is a cornerstone of modern finance, while risk aversion is central to decision theory; both concepts are long-standing and foundational. We investigate their connections by studying how different forms of diversification correspond to notions of risk aversion. We focus on the classical distinctions between weak and strong risk aversion, and consider diversification preferences for pairs of risks that are identically distributed, comonotonic, antimonotonic, independent, or exchangeable, as well as their intersections. Under a weak continuity condition and without assuming completeness of preferences, diversification for antimonotonic and identically distributed pairs implies weak risk aversion, and diversification for exchangeable pairs is equivalent to strong risk aversion. The implication from diversification for independent pairs to weak risk aversion requires a stronger continuity. We further provide results and examples that clarify the relationships between various diversification preferences and risk attitudes, in particular justifying the one-directional nature of many implications.",
      "authors": [
        "Xiangxin He",
        "Fangda Liu",
        "Ruodu Wang"
      ],
      "primary_category": "econ.TH",
      "categories": [
        "econ.TH",
        "q-fin.MF"
      ],
      "published": "2026-01-07 16:30:54+00:00",
      "link": "https://arxiv.org/pdf/2601.04067v1",
      "tags": [
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.04062v2",
      "title": "Smart Predict--then--Optimize Paradigm for Portfolio Optimization in Real Markets",
      "abstract": "Improvements in return forecast accuracy do not always lead to proportional improvements in portfolio decision quality, especially under realistic trading frictions and constraints. This paper adopts the Smart Predict--then--Optimize (SPO) paradigm for portfolio optimization in real markets, which explicitly aligns the learning objective with downstream portfolio decision quality rather than pointwise prediction accuracy. Within this paradigm, predictive models are trained using an SPO-based surrogate loss that directly reflects the performance of the resulting investment decisions. To preserve interpretability and robustness, we employ linear predictors built on return-based and technical-indicator features and integrate them with portfolio optimization models that incorporate transaction costs, turnover control, and regularization. We evaluate the proposed approach on U.S. ETF data (2015--2025) using a rolling-window backtest with monthly rebalancing. Empirical results show that decision-focused training consistently improves risk-adjusted performance over predict--then--optimize baselines and classical optimization benchmarks, and yields strong robustness during adverse market regimes (e.g., the 2020 COVID-19). These findings highlight the practical value of the Smart Predict--then--Optimize paradigm for portfolio optimization in realistic and non-stationary financial environments.",
      "authors": [
        "Wang Yi",
        "Takashi Hasuike"
      ],
      "primary_category": "q-fin.PM",
      "categories": [
        "q-fin.PM"
      ],
      "published": "2026-01-07 16:28:30+00:00",
      "link": "https://arxiv.org/pdf/2601.04062v2",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.05087v1",
      "title": "Online Bayesian Learning of Agent Behavior in Differential Games",
      "abstract": "This work introduces an online Bayesian game-theoretic method for behavior identification in multi-agent dynamical systems. By casting Hamilton-Jacobi-Bellman optimality conditions as linear-in-parameter residuals, the method enables fast sequential Bayesian updates, uncertainty-aware inference, and robust prediction from limited, noisy data-without history stacks. The approach accommodates nonlinear dynamics and nonquadratic value functions through basis expansions, providing flexible models. Experiments, including linear-quadratic and nonlinear shared-control scenarios, demonstrate accurate prediction with quantified uncertainty, highlighting the method's relevance for adaptive interaction and real-time decision making.",
      "authors": [
        "Francesco Bianchin",
        "Robert Lefringhausen",
        "Sandra Hirche"
      ],
      "primary_category": "eess.SY",
      "categories": [
        "eess.SY"
      ],
      "published": "2026-01-08 16:35:43+00:00",
      "link": "https://arxiv.org/pdf/2601.05087v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04775v1",
      "title": "Towards a Unified Theoretical Framework for Self-Supervised MRI Reconstruction",
      "abstract": "The demand for high-resolution, non-invasive imaging continues to drive innovation in magnetic resonance imaging (MRI), yet prolonged acquisition times hinder accessibility and real-time applications. While deep learning-based reconstruction methods have accelerated MRI, their predominant supervised paradigm depends on fully-sampled reference data that are challenging to acquire. Recently, self-supervised learning (SSL) approaches have emerged as promising alternatives, but most are empirically designed and fragmented. Therefore, we introduce UNITS (Unified Theory for Self-supervision), a general framework for self-supervised MRI reconstruction. UNITS unifies prior SSL strategies within a common formalism, enabling consistent interpretation and systematic benchmarking. We prove that SSL can achieve the same expected performance as supervised learning. Under this theoretical guarantee, we introduce sampling stochasticity and flexible data utilization, which improve network generalization under out-of-domain distributions and stabilize training. Together, these contributions establish UNITS as a theoretical foundation and a practical paradigm for interpretable, generalizable, and clinically applicable self-supervised MRI reconstruction.",
      "authors": [
        "Siying Xu",
        "Kerstin Hammernik",
        "Daniel Rueckert",
        "Sergios Gatidis",
        "Thomas Küstner"
      ],
      "primary_category": "eess.IV",
      "categories": [
        "eess.IV"
      ],
      "published": "2026-01-08 09:57:39+00:00",
      "link": "https://arxiv.org/pdf/2601.04775v1",
      "tags": [
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.04581v1",
      "title": "Spectral point transformer for significant wave height estimation from sea clutter",
      "abstract": "This paper presents a method for estimating significant wave height (Hs) from sparse S_pectral P_oint using a T_ransformer-based approach (SPT). Based on empirical observations that only a minority of spectral points with strong power contribute to wave energy, the proposed SPT effectively integrates geometric and spectral characteristics of ocean surface waves to estimate Hs through multi-dimensional feature representation. The experiment reveals an intriguing phenomenon: the learned features of SPT align well with physical dispersion relations, where the contribution-score map of selected points is concentrated along dispersion curves. Compared to conventional vision networks that process image sequences and full spectra, SPT demonstrates superior performance in Hs regression while consuming significantly fewer computational resources. On a consumer-grade GPU, SPT completes the training of regression model for 1080 sea clutter image sequences within 4 minutes, showcasing its potential to reduce deployment costs for radar wave-measuring systems. The open-source implementation of SPT will be available at https://github.com/joeyee/spt",
      "authors": [
        "Yi Zhou",
        "Li Wang",
        "Hang Su",
        "Tian Wang"
      ],
      "primary_category": "eess.SP",
      "categories": [
        "eess.SP"
      ],
      "published": "2026-01-08 04:26:19+00:00",
      "link": "https://arxiv.org/pdf/2601.04581v1",
      "tags": [
        "keyword:大语言模型",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04069v1",
      "title": "Hybrid Downlink Beamforming with Outage Constraints under Imperfect CSI using Model-Driven Deep Learning",
      "abstract": "We consider energy-efficient multi-user hybrid downlink beamforming (BF) and power allocation under imperfect channel state information (CSI) and probabilistic outage constraints. In this domain, classical optimization methods resort to computationally costly conic optimization problems. Meanwhile, generic deep network (DN) architectures lack interpretability and require large training data sets to generalize well. In this paper, we therefore propose a lightweight model-aided deep learning architecture based on a greedy selection algorithm for analog beam codewords. The architecture relies on an instance-adaptive augmentation of the signal model to estimate the impact of the CSI error. To learn the DN parameters, we derive a novel and efficient implicit representation of the nested constrained BF problem and prove sufficient conditions for the existence of the corresponding gradient. In the loss function, we utilize an annealing-based approximation of the outage compared to conventional quantile-based loss terms. This approximation adaptively anneals towards the exact probabilistic constraint depending on the current level of quality of service (QoS) violation. Simulations validate that the proposed DN can achieve the nominal outage level under CSI error due to channel estimation and channel compression, while allocating less power than benchmarks. Thereby, a single trained model generalizes to different numbers of users, QoS requirements and levels of CSI quality. We further show that the adaptive annealing-based loss function can accelerate the training and yield a better power-outage trade-off.",
      "authors": [
        "Lukas Schynol",
        "Marius Pesavento"
      ],
      "primary_category": "eess.SP",
      "categories": [
        "eess.SP"
      ],
      "published": "2026-01-07 16:33:01+00:00",
      "link": "https://arxiv.org/pdf/2601.04069v1",
      "tags": [
        "keyword:resnet",
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.03745v1",
      "title": "Two-stage Multi-beam Training for Multiuser Millimeter-Wave Communications",
      "abstract": "In this letter, we study an efficient multi-beam training method for multiuser millimeter-wave communication systems. Unlike the conventional single-beam training method that relies on exhaustive search, multi-beam training design faces a key challenge in balancing the trade-off between beam training overhead and success beam-identification rate, exacerbated by severe inter-beam interference. To tackle this challenge, we propose a new two-stage multi-beam training method with two distinct multi-beam patterns to enable fast and accurate user angle identification. Specifically, in the first stage, the antenna array is divided into sparse subarrays to generate multiple beams (with high array gains), for identifying candidate user angles. In the second stage, the array is redivided into dense subarrays to generate flexibly steered wide beams, for which a cross-validation method is employed to effectively resolve the remaining angular ambiguity in the first stage. Last, numerical results demonstrate that the proposed method significantly improves the success beam-identification rate compared to existing multi-beam training methods, while retaining or even reducing the required beam training overhead.",
      "authors": [
        "Weijia Wang",
        "Changsheng You",
        "Xiaodan Shao",
        "Rui Zhang"
      ],
      "primary_category": "eess.SP",
      "categories": [
        "eess.SP"
      ],
      "published": "2026-01-07 09:33:30+00:00",
      "link": "https://arxiv.org/pdf/2601.03745v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03712v2",
      "title": "TellWhisper: Tell Whisper Who Speaks When",
      "abstract": "Multi-speaker automatic speech recognition (MASR) aims to predict ''who spoke when and what'' from multi-speaker speech, a key technology for multi-party dialogue understanding. However, most existing approaches decouple temporal modeling and speaker modeling when addressing ''when'' and ''who'': some inject speaker cues before encoding (e.g., speaker masking), which can cause irreversible information loss; others fuse identity by mixing speaker posteriors after encoding, which may entangle acoustic content with speaker identity. This separation is brittle under rapid turn-taking and overlapping speech, often leading to degraded performance. To address these limitations, we propose TellWhisper, a unified framework that jointly models speaker identity and temporal within the speech encoder. Specifically, we design TS-RoPE, a time-speaker rotary positional encoding: time coordinates are derived from frame indices, while speaker coordinates are derived from speaker activity and pause cues. By applying region-specific rotation angles, the model explicitly captures per-speaker continuity, speaker-turn transitions, and state dynamics, enabling the attention mechanism to simultaneously attend to ''when'' and ''who''. Moreover, to estimate frame-level speaker activity, we develop Hyper-SD, which casts speaker classification in hyperbolic space to enhance inter-class separation and refine speaker-activity estimates. Extensive experiments demonstrate the effectiveness of the proposed approach.",
      "authors": [
        "Yifan Hu",
        "Peiji Yang",
        "Zhisheng Wang",
        "Yicheng Zhong",
        "Rui Liu"
      ],
      "primary_category": "eess.AS",
      "categories": [
        "eess.AS"
      ],
      "published": "2026-01-07 08:58:45+00:00",
      "link": "https://arxiv.org/pdf/2601.03712v2",
      "tags": [
        "keyword:resnet",
        "keyword:resnet中文",
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.03639v1",
      "title": "Zak-OTFS ISAC with Bistatic Sensing via Semi-Blind Atomic Norm Denoising Scheme",
      "abstract": "Integrated sensing and communication (ISAC) through Zak-transform-based orthogonal time frequency space (Zak-OTFS) modulation is a promising solution for high-mobility scenarios. Realizing accurate bistatic sensing and robust communication necessitates precise channel estimation; however, this remains a formidable challenge in doubly dispersive environments, where fractional delay-Doppler shifts induce severe channel spreading. This paper proposes a semi-blind atomic norm denoising scheme for Zak-OTFS ISAC with bistatic sensing. We first derive the discrete-time input-output (I/O) relationship of Zak-OTFS under fractional delay-Doppler shifts and rectangular windowing. Based on this I/O relation, we formulate the joint channel parameter estimation and data detection task as an atomic norm denoising problem, utilizing the negative square penalty method to handle the non-convex discrete constellation constraints. To solve this problem efficiently, we develop an accelerated iterative algorithm that integrates majorization-minimization, accelerated projected gradient, and inexact accelerated proximal gradient methods. We provide a rigorous convergence proof for the proposed algorithm. Simulation results demonstrate that the proposed scheme achieves super-resolution sensing accuracy and communication performance approaching the perfect channel state information lower bound.",
      "authors": [
        "Kecheng Zhang",
        "Weijie Yuan",
        "Maria Sabrina Greco"
      ],
      "primary_category": "eess.SP",
      "categories": [
        "eess.SP"
      ],
      "published": "2026-01-07 06:33:13+00:00",
      "link": "https://arxiv.org/pdf/2601.03639v1",
      "tags": [
        "keyword:resnet",
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.03486v1",
      "title": "Adaptive Model-Based Reinforcement Learning for Orbit Feedback Control in NSLS-II Storage Ring",
      "abstract": "The National Synchrotron Light Source II (NSLS-II) uses highly stable electron beam to produce high-quality X-ray beams with high brightness and low-emittance synchrotron radiation. The traditional algorithm to stabilize the beam applies singular value decomposition (SVD) on the orbit response matrix to remove noise and extract actions. Supervised learning has been studied on NSLS-II storage ring stabilization and other accelerator facilities recently. Several problems, for example, machine status drifting, environment noise, and non-linear accelerator dynamics, remain unresolved in the SVD-based and supervised learning algorithms. To address these problems, we propose an adaptive training framework based on model-based reinforcement learning. This framework consists of two types of optimizations: trajectory optimization attempts to minimize the expected total reward in a differentiable environment, and online model optimization learns non-linear machine dynamics through the agent-environment interaction. Through online training, this framework tracks the internal status drifting in the electron beam ring. Simulation and real in-facility experiments on NSLS-II reveal that our method stabilizes the beam position and minimizes the alignment error, defined as the root mean square (RMS) error between adjusted beam positions and the reference position, down to ~1$μ$m.",
      "authors": [
        "Zeyu Dong",
        "Yuke Tian",
        "Yu Sun"
      ],
      "primary_category": "eess.SY",
      "categories": [
        "eess.SY"
      ],
      "published": "2026-01-07 00:49:57+00:00",
      "link": "https://arxiv.org/pdf/2601.03486v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04438v1",
      "title": "The Endogenous Grid Method for Epstein-Zin Preferences",
      "abstract": "The endogenous grid method (EGM) accelerates dynamic programming by inverting the Euler equation, but it appears incompatible with Epstein-Zin preferences where the value function enters the Euler equation. This paper shows that a power transformation resolves the difficulty. The resulting algorithm requires no root-finding, achieves speed gains of one to two orders of magnitude over value function iteration, and improves accuracy by more than one order of magnitude. Holding accuracy constant, the speedup is two to three orders of magnitude. VFI and time iteration face a speed-accuracy tradeoff; EGM sidesteps it entirely.",
      "authors": [
        "Alan Lujan"
      ],
      "primary_category": "econ.GN",
      "categories": [
        "econ.GN"
      ],
      "published": "2026-01-07 22:52:17+00:00",
      "link": "https://arxiv.org/pdf/2601.04438v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03750v1",
      "title": "Multivariate kernel regression in vector and product metric spaces",
      "abstract": "This paper derives limit properties of nonparametric kernel regression estimators without requiring existence of density for regressors in $\\mathbb{R}^{q}.$ In functional regression limit properties are established for multivariate functional regression. The rate and asymptotic normality for the Nadaraya-Watson (NW) estimator is established for distributions of regressors in $\\mathbb{R}^{q}$ that allow for mass points, factor structure, multicollinearity and nonlinear dependence, as well as fractal distribution; when bounded density exists we provide statistical guarantees for the standard rate and the asymptotic normality without requiring smoothness. We demonstrate faster convergence associated with dimension reducing types of singularity, such as a fractal distribution or a factor structure in the regressors. The paper extends asymptotic normality of kernel functional regression to multivariate regression over a product of any number of metric spaces. Finite sample evidence confirms rate improvement due to singularity in regression over $\\mathbb{R}^{q}.$ For functional regression the simulations underline the importance of accounting for multiple functional regressors. We demonstrate the applicability and advantages of the NW estimator in our empirical study, which reexamines the job training program evaluation based on the LaLonde data.",
      "authors": [
        "Marcia Schafgans",
        "Victoria Zinde-Walsh"
      ],
      "primary_category": "econ.EM",
      "categories": [
        "econ.EM"
      ],
      "published": "2026-01-07 09:40:54+00:00",
      "link": "https://arxiv.org/pdf/2601.03750v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03598v1",
      "title": "Uncovering Sparse Financial Networks with Information Criteria",
      "abstract": "Empirical measures of financial connectedness based on Forecast Error Variance Decompositions (FEVDs) often yield dense network structures that obscure true transmission channels and complicate the identification of systemic risk. This paper proposes a novel information-criterion-based approach to uncover sparse, economically meaningful financial networks. By reformulating FEVD-based connectedness as a regression problem, we develop a model selection framework that consistently recovers the active set of spillover channels. We extend this method to generalized FEVDs to accommodate correlated shocks and introduce a data-driven procedure for tuning the penalty parameter using pseudo-out-of-sample forecast performance. Monte Carlo simulations demonstrate the approach's effectiveness with finite samples and its robustness to approximately sparse networks and heavy-tailed errors. Applications to global stock markets, S&P 500 sectoral indices, and commodity futures highlight the prevalence of sparse networks in empirical settings.",
      "authors": [
        "Fu Ouyang",
        "Thomas T. Yang",
        "Wenying Yao"
      ],
      "primary_category": "econ.EM",
      "categories": [
        "econ.EM"
      ],
      "published": "2026-01-07 05:29:18+00:00",
      "link": "https://arxiv.org/pdf/2601.03598v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.05160v1",
      "title": "Revisiting the scale dependence of the Reynolds number in correlated fluctuating fluids",
      "abstract": "For the incompressible Navier--Stokes equation, the Reynolds number ($\\mathrm{Re}$) is a dimensionless parameter quantifying the relative importance of inertial over viscous forces. In the low-$\\mathrm{Re}$ regime ($\\mathrm{Re} \\ll 1$), the flow dynamics are commonly approximated by the linear Stokes equation. Here we show that, within the framework of spatially fluctuating hydrodynamics, this linearization breaks down when the thermal noise is spatially correlated, even if $\\mathrm{Re} \\ll 1$. We perform direct numerical simulations of spatially correlated fluctuating hydrodynamics in both one and two dimensions. In one dimension, the linearized dynamics exhibit significantly slower relaxation of high-wavenumber Fourier modes than the full nonlinear dynamics. In two dimensions, an analogous discrepancy arises in the particle velocity autocorrelation function, which decays more slowly in the correlated linear Stokes case than in the correlated nonlinear Navier--Stokes case. In both settings, spatial correlations inhibit viscous momentum diffusion at small scales, leading to prolonged relaxation under the linear dynamics, whereas nonlinear mode coupling accelerates small-scale relaxation. Thus, the interplay between nonlinear coupling and viscous damping becomes scale dependent, invalidating the use of a single global Reynolds number. Taken together, these findings show that, for spatially correlated fluctuating fluids, the effective Reynolds number must be reinterpreted as a scale-dependent quantity.",
      "authors": [
        "Sijie Huang",
        "Ayush Saurabh",
        "Steve Pressé"
      ],
      "primary_category": "physics.flu-dyn",
      "categories": [
        "physics.flu-dyn",
        "physics.bio-ph"
      ],
      "published": "2026-01-08 17:49:52+00:00",
      "link": "https://arxiv.org/pdf/2601.05160v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.05090v1",
      "title": "Surveying exogenous species in Saturn with ALMA I. Detecting and Mapping CO",
      "abstract": "The origin of carbon monoxide (CO) in Saturn's stratosphere remains uncertain, with proposed sources including internal thermochemical production, cometary impacts, and exogenic material from the rings and icy moons (i.e. Enceladus). We aim to constrain the vertical and meridional distribution of stratospheric CO and assess the relative contributions of these potential sources. Here, we analysed high-spectral-resolution ALMA observations of the CO (J=3-2) line obtained on 25 May 2018, sampling Saturn's limb from 20°S to 69°N. CO vertical profiles were retrieved using a line-by-line radiative transfer model combined with spectral inversion techniques, testing multiple prior scenarios representative of different source hypotheses. CO is confined to a narrow layer between 0.1 and 1 mbar, with a robust negative vertical gradient and mean abundances of (3.7+/- 0.8) x 10$^{-8}$ at 0.1 mbar and (7.2 +/- 0.9) x 10$^{-8}$ at 1 mbar. The meridional distribution is statistically homogeneous, with a marginal enhancement near 60° N plausibly related to Enceladus. No significant equatorial enhancement is detected. The absence of a strong equatorial enhancement rules out a long-lived steady source associated with ring infall. The observations are most consistent with a relatively recent ($\\approx$200-year-old or younger) cometary impact whose material has since been horizontally mixed, while any Cassini Grand Finale ring influx was either too recent or inefficient to affect CO abundances at the probed pressure levels.",
      "authors": [
        "Deborah Bardet",
        "Thierry Fouchet",
        "Thibault Cavalié",
        "Raphaël Moreno",
        "Emmanuel Lellouch",
        "Camille Lefour",
        "Bilal Benmahi",
        "Sandrine Guerlet"
      ],
      "primary_category": "astro-ph.EP",
      "categories": [
        "astro-ph.EP",
        "physics.ao-ph"
      ],
      "published": "2026-01-08 16:37:41+00:00",
      "link": "https://arxiv.org/pdf/2601.05090v1",
      "tags": [
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.04821v1",
      "title": "Bi-level Multi-criteria Optimization for Risk-informed Radiotherapy",
      "abstract": "In radiation therapy (RT) treatment planning, multi-criteria optimization (MCO) supports efficient plan selection but is usually solved for population-based dosimetric criteria and ignores patient-specific biological risk, potentially compromising outcomes in high-risk patients. We propose risk-guided MCO, a one-shot method that embeds a clinical risk model into conventional MCO, enabling interactive navigation between dosimetric and biological endpoints. The proposed algorithm uses a special order relation to fuse the classical MCO sandwiching algorithm with bi-level optimization, restricting the Pareto set to plans that achieve improvement in the secondary risk objective for user-defined, acceptable loss in primary clinical objectives. Thus, risk-guided MCO generates risk-optimized counterparts of clinical plans in a single run rather than by sequential or lexicographic planning. To assess the performance, we retrospectively analyzed 19 lung cancer patients treated with RT. The endpoint was the risk of grade 2+ radiation pneumonitis (RP), modeled using bootstrapped stepwise logistics regression with interaction terms, including baseline lung function, smoking history, and dosimetric factors. The risk-guided plans yielded a mean reduction of 8.0% in total lung V20 and 9.5% in right lung V5, translating into an average RP risk reduction of 7.7% (range=0.3%-20.1%), with small changes in target coverage (mean -1.2 D98[%] for CTV) and modest increase in heart dose (mean +1.74 Gy). This study presents the first proof-of-concept for integrating biological risk models directly within multi-criteria RT planning, enabling an interactive balance between established population-wide dose protocols and individualized outcome prediction. Our results demonstrate that the risk-informed MCO can reduce the risk of RP while maintaining target coverage.",
      "authors": [
        "Mara Schubert",
        "Katrin Teichert",
        "Zhongxing Liao",
        "Thomas Bortfeld",
        "Ali Ajdari"
      ],
      "primary_category": "physics.med-ph",
      "categories": [
        "physics.med-ph"
      ],
      "published": "2026-01-08 10:57:53+00:00",
      "link": "https://arxiv.org/pdf/2601.04821v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04735v1",
      "title": "sidmkit: A Reproducible Toolkit for SIDM Phenomenology and Galaxy Rotation-Curve Modeling",
      "abstract": "Self-interacting dark matter (SIDM) is a well-motivated extension of cold dark matter that can modify halo structure on galactic and group scales while remaining consistent with large-scale structure. However, practical SIDM work often requires bridging several layers, including microphysical scattering models, velocity-dependent effective cross sections, phenomenological astrophysical constraints, and (separately) data-driven halo fits, such as rotation curves. In this paper, we describe \\texttt{sidmkit}, a transparent and reproducible Python package designed to support SIDM ``micro$\\rightarrow$macro'' calculations and to provide a robust batch pipeline for fitting rotation curves in the SPARC data. On the SIDM side, \\texttt{sidmkit} implements velocity-dependent momentum-transfer cross sections for a Yukawa interaction using standard analytic approximations (Born, classical, and Hulthén-based) with a numerical partial-wave option for spot checks. It also provides consistent velocity-moment averaging for Maxwellian relative speeds, scattering-rate utilities, and curated literature \\emph{summary} constraints for regression tests and exploratory scans. On the rotation-curve side, we implement bounded non-linear least squares fits of NFW and Burkert halo models to SPARC baryonic decompositions, with optional mass-to-light priors and information-criterion summaries (AIC/BIC). For the demonstration dataset, we process 191 \\texttt{rotmod} galaxies (LTG+ETG bundles) and fit both NFW and Burkert models (382 total fits). We find that Burkert is preferred by $Δ\\mathrm{BIC} > 0$ for $65.4\\%$ of galaxies, with ``strong'' preference ($Δ\\mathrm{BIC}>6$) in $32.5\\%$ of galaxies;",
      "authors": [
        "Nalin Dhiman"
      ],
      "primary_category": "astro-ph.IM",
      "categories": [
        "astro-ph.IM",
        "physics.comp-ph"
      ],
      "published": "2026-01-08 08:56:56+00:00",
      "link": "https://arxiv.org/pdf/2601.04735v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04400v1",
      "title": "JAX-Shock: A Differentiable, GPU-Accelerated, Shock-Capturing Neural Solver for Compressible Flow Simulation",
      "abstract": "Understanding shock-solid interactions remains a central challenge in compressiblefluiddynamics. WepresentJAX-Shock: afully-differentiable,GPU-accelerated, high-order shock-capturing solver for efficient simulation of the compressible Navier-Stokes equations. Built entirely in JAX, the framework leverages automatic differentiation to enable gradient-based optimization, parameter inference, and end-to-end training of deep learning-augmented models. The solver integrates fifth-order WENO reconstruction with an HLLC flux to resolve shocks and discontinuities with high fidelity. To handle complex geometries, an immersed boundary method is implemented for accurate representation of solid interfaces within the compressible flow field. In addition, we introduce a neural flux module trained to augment the numerical fluxes with data-driven corrections, significantly improving accuracy and generalization. JAX-Shock also supports sequence-to-sequence learning for shock interaction prediction and reverse-mode inference to identify key physical parameters from data. Compared with purely data-driven approaches, JAX-Shock enhances generalization while preserving physical consistency. The framework establishes a flexible platform for differentiable physics, learning-based modeling, and inverse design in compressible flow regimes dominated by complex shock-solid interactions.",
      "authors": [
        "Bo Zhang"
      ],
      "primary_category": "physics.flu-dyn",
      "categories": [
        "physics.flu-dyn"
      ],
      "published": "2026-01-07 21:18:24+00:00",
      "link": "https://arxiv.org/pdf/2601.04400v1",
      "tags": [
        "keyword:resnet",
        "keyword:resnet中文",
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.04386v1",
      "title": "Numerical Investigation of the Effect of a Magnetic Field on the Transport of Oxygen in Air",
      "abstract": "The effects of magnetisation forces in a binary mixture of gases characterised by large differences in magnetic susceptibility are studied using numerical simulations, with a focus on the differential diffusion of the species and the role of the gradient of mixture composition on the flow field resulting from magnetically-induced forces. A quiescent binary mixture of nitrogen and oxygen, representative of air, confined between two parallel plates is considered. In all simulations, a gradient of $\\mathbf{B}^2$, the square of the magnetic flux density magnitude, uniform and directed normal to the walls is imposed. Cases characterised by different pressures, different strengths of $\\nabla(\\mathbf{B}^2)$, and different initial gradients of species composition are investigated, while the same initial temperature is used in all cases. Non-dimensional groups related to the examined configuration are proposed. In cases characterised by an initially uniform mixture composition, species tend to separate and accumulate at opposite walls, due to differential magnetic forces arising from the differences in magnetic susceptibility. For a given strength of $\\nabla(\\mathbf{B}^2)$, the effect of the magnetic field on the separation of species increases with decreasing pressure.In addition to species separation, it is shown that an initial gradient in the mixture composition perpendicular to $\\nabla(\\mathbf{B}^2)$ induces a significant change in the velocity field, which enhances the transport of species. This effect is due to a lack of alignment between the gradient of averaged magnetic susceptibility and $\\nabla(\\mathbf{B}^2)$ and could be exploited to achieve targeted mixing using engineered magnetic fields.",
      "authors": [
        "Alexander C. Kruse",
        "Pavlos G. Aleiferis",
        "Andrea Giusti"
      ],
      "primary_category": "physics.flu-dyn",
      "categories": [
        "physics.flu-dyn"
      ],
      "published": "2026-01-07 20:47:45+00:00",
      "link": "https://arxiv.org/pdf/2601.04386v1",
      "tags": [
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.04172v1",
      "title": "Stochastic Path Compression for Spectral Tensor Networks on Cyclic Graphs",
      "abstract": "We develop a new approach to compress cyclic tensor networks called stochastic path compression (SPC) that uses an iterative importance sampling procedure to target edges with large bond-dimensions. Closed random walks in SPC form compression pathways that spatially localize large bond-dimensions in the tensor network. Analogous to the phase separation of two immiscible liquids, SPC separates the graph of bond-dimensions into spatially distinct high and low density regions. When combined with our integral decimation algorithm, SPC facilitates the accurate compression of cyclic tensor networks with continuous degrees of freedom. To benchmark and illustrate the methods, we compute the absolute thermodynamics of $q$-state clock models on two-dimensional square lattices and an XY model on a Watts-Strogatz graph, which is a small-world network with random connectivity between spins.",
      "authors": [
        "Ryan T. Grimm",
        "Joel D. Eaves"
      ],
      "primary_category": "cond-mat.stat-mech",
      "categories": [
        "cond-mat.stat-mech",
        "physics.comp-ph"
      ],
      "published": "2026-01-07 18:39:49+00:00",
      "link": "https://arxiv.org/pdf/2601.04172v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03964v1",
      "title": "Toward Quantum-Aware Machine Learning: Improved Prediction of Quantum Dissipative Dynamics via Complex Valued Neural Networks",
      "abstract": "Accurately modeling quantum dissipative dynamics remains challenging due to environmental complexity and non-Markovian memory effects. Although machine learning provides a promising alternative to conventional simulation techniques, most existing models employ real-valued neural networks (RVNNs) that inherently mismatch the complex-valued nature of quantum mechanics. By decoupling the real and imaginary parts of the density matrix, RVNNs can obscure essential amplitude-phase correlations, compromising physical consistency. Here, we introduce complex-valued neural networks (CVNNs) as a physics-consistent framework for learning quantum dissipative dynamics. CVNNs operate directly on complex-valued inputs, preserve the algebraic structure of quantum states, and naturally encode quantum coherences. Through numerical benchmarks on the spin-boson model and several variants of the Fenna-Matthews-Olson complex, we demonstrate that CVNNs outperform RVNNs in convergence speed, training stability, and physical fidelity -- including significantly improved trace conservation and Hermiticity. These advantages increase with system size and coherence complexity, establishing CVNNs as a robust, scalable, quantum-aware classical approach for simulating open quantum systems in the pre-fault-tolerant quantum era.",
      "authors": [
        "Muhammad Atif",
        "Arif Ullah",
        "Ming Yang"
      ],
      "primary_category": "physics.chem-ph",
      "categories": [
        "physics.chem-ph"
      ],
      "published": "2026-01-07 14:26:39+00:00",
      "link": "https://arxiv.org/pdf/2601.03964v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03922v1",
      "title": "Integration and Resource Estimation of Cryoelectronics for Superconducting Fault-Tolerant Quantum Computers",
      "abstract": "Scaling superconducting quantum computers to the fault-tolerant regime calls for a commensurate scaling of the classical control and readout stack. Today's systems largely rely on room-temperature, rack-based instrumentation connected to dilution-refrigerator cryostats through many coaxial cables. Looking ahead, superconducting fault-tolerant quantum computers (FTQCs) will likely adopt a heterogeneous quantum-classical architecture that places selected electronics at cryogenic stages -- for example, cryo-CMOS at 4~K and superconducting digital logic at 4~K and/or mK stages -- to curb wiring and thermal-load overheads. This review distills key requirements, surveys representative room-temperature and cryogenic approaches, and provides a transparent first-order accounting framework for cryoelectronics. Using an RSA-2048-scale benchmark as a concrete reference point, we illustrate how scaling targets motivate constraints on multiplexing and stage-wise cryogenic power, and discuss implications for functional partitioning across room-temperature electronics, cryo-CMOS, and superconducting logic.",
      "authors": [
        "Shiro Kawabata"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "cond-mat.mes-hall",
        "cond-mat.supr-con",
        "physics.app-ph"
      ],
      "published": "2026-01-07 13:42:21+00:00",
      "link": "https://arxiv.org/pdf/2601.03922v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03913v1",
      "title": "Stratified-turbulence observations in the deep Mediterranean",
      "abstract": "A nearly half-cubic hectometer of deep Mediterranean-Sea waters is yearlong sampled with about 3000 high-resolution temperature sensors to study different sources of turbulent waterflows, which are vital for life. Although temperature differences are never larger than 0.01degrC, daily, weekly, and seasonal variations are observed. About half the time, relatively warm stratified waters are moved from 100's of meters higher levels to near the seafloor. These internal-wave and sub-mesoscale eddy-induced motions are half an order of magnitude more turbulent than those induced via general geothermal heating from below, and about one order of magnitude more turbulent than those from open-ocean processes. A rough estimate shows that eddy-induced stratified turbulence is likely more important for deep-sea life than rare, not observed, deep dense-water formation at the abyssal-plain mooring site. With a delay of about a week, the stratified turbulence tracks atmospheric disturbances, which are found 35% more energetic in winter than in summer. From comparison of turbulence-calculation methods, of band-pass filtering with vertical-displacement reordering, for data over one-four days, a generalization is proposed for the filter cut-offs under weakly stratified and near-homogeneous conditions in the deep Mediterranean.",
      "authors": [
        "Hans van Haren"
      ],
      "primary_category": "physics.ao-ph",
      "categories": [
        "physics.ao-ph"
      ],
      "published": "2026-01-07 13:27:11+00:00",
      "link": "https://arxiv.org/pdf/2601.03913v1",
      "tags": [
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.03870v1",
      "title": "Turbulence demonstrates height variations in closely spaced deep-sea mooring lines",
      "abstract": "It may be important to precisely know heights of moored oceanographic instrumentation. For example, moorings can be closely spaced or accidentally be located on small rocks or in small gullies. Height variations O(1 m) will yield registration of different values when conditions such as small-scale density stratification vary strongly. Such little height variations may prove difficult to measure in the deep sea, requiring high-accuracy pressure sensors preferably on all instruments in a mooring-array. In this paper, an alternative method for relative height determination is presented using high-resolution temperature sensors moored on multiple densely-spaced lines in the deep Western Mediterranean. While it was anticipated that height variations between lines could be detected under near-homogeneous conditions via adiabatic lapse rate O(0.0001degrC m-1) by the 0.00003degrC-noise-level sensors, such was prevented by the impossibility of properly correcting for short-term bias due to electronic drift. Instead, a satisfactory height determination was found during a period of relatively strong stratification and large turbulence activity. By band-pass filtering data of the highest-resolved turbulent motions across the strongest temperature gradient, significant height variations were detectable to within +/-0.2 m.",
      "authors": [
        "Hans van Haren"
      ],
      "primary_category": "physics.ao-ph",
      "categories": [
        "physics.ao-ph"
      ],
      "published": "2026-01-07 12:32:55+00:00",
      "link": "https://arxiv.org/pdf/2601.03870v1",
      "tags": [
        "keyword:resnet",
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.03830v1",
      "title": "DeepBessel: deep learning-based full-field vibration profilometry using single-shot time-averaged interference microscopy",
      "abstract": "Full-field vibration profilometry is essential for dynamic characterizing microelectromechanical systems (MEMS/MOEMS). Time-averaged interferometry (TAI) encodes spatial information about MEMS or MOEMS vibration amplitude in the interferogram's amplitude modulation using Bessel function (besselogram). Classical approaches for interferogram analysis are specialized for cosine function fringe patterns and therefore introduce reconstruction errors for besselogram decoding. This paper presents the DeepBessel: a deep learning-based approach for single-shot TAI interferogram analysis. A convolutional neural network (CNN) was trained using synthetic data, where the input consisted of besselograms, and the output corresponded to the underlying vibration amplitude distribution. Numerical validation and experimental testing demonstrated that DeepBessel significantly reduces reconstruction errors compared to the state-of-the-art approaches, e.g., Hilbert Spiral Transform (HST) method. The proposed network effectively mitigates errors caused by the mismatch between the Bessel and cosine functions. The results indicate that deep learning can improve the accuracy of full-field vibration measurements, offering new possibilities for optical metrology in MEMS or MOEMS applications.",
      "authors": [
        "Maria Cywinska",
        "Wiktor Forjasz",
        "Emilia Wdowiak",
        "Michal Jozwik",
        "Adam Styk",
        "Krzysztof Patorski",
        "Maciej Trusiak"
      ],
      "primary_category": "physics.optics",
      "categories": [
        "physics.optics"
      ],
      "published": "2026-01-07 11:49:37+00:00",
      "link": "https://arxiv.org/pdf/2601.03830v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03613v1",
      "title": "PhysicsFormer: An Efficient and Fast Attention-Based Physics Informed Neural Network for Solving Incompressible Navier Stokes Equations",
      "abstract": "Traditional experimental and numerical approaches for fluid dynamics problems often suffer from high computational cost, mesh sensitivity, and limited capability in capturing complex physical behaviors. Moreover, conventional physics-informed neural networks (PINNs) frequently struggle in chaotic and highly unsteady flow regimes. In this work, we propose \\textit{PhysicsFormer}, a fast and efficient transformer-based physics-informed framework that incorporates multi-head encoder-decoder cross-attention. Unlike multilayer perceptron-based PINNs, PhysicsFormer operates on sequential representations constructed from spatio-temporal data, enabling effective learning of long-range temporal dependencies and improved propagation of initial condition information. A data-embedding strategy is employed to convert spatio-temporal points into pseudo-sequences, while a dynamics-weighted loss function replaces the standard PINNs formulation. Owing to its parallel learning structure, PhysicsFormer demonstrates superior computational efficiency compared to existing transformer-based approaches. The framework is validated on Burgers' equation and flow reconstruction governed by the Navier-Stokes equations, achieving mean squared errors on the order of $10^{-6}$. In addition, an inverse problem involving parameter identification in the two-dimensional incompressible Navier-Stokes equations is investigated. For clean data, PhysicsFormer achieves zero identification error for both $λ_1$ and $λ_2$; under $1\\%$ Gaussian noise, the errors are $0.07\\%$ for $λ_1$ and $0\\%$ for $λ_2$. These results demonstrate that PhysicsFormer provides a reliable and computationally efficient surrogate modeling framework for time-dependent fluid flow problems.",
      "authors": [
        "Biswanath Barman",
        "Debdeep Chatterjee",
        "Rajendra K. Ray"
      ],
      "primary_category": "physics.flu-dyn",
      "categories": [
        "physics.flu-dyn"
      ],
      "published": "2026-01-07 05:41:50+00:00",
      "link": "https://arxiv.org/pdf/2601.03613v1",
      "tags": [
        "keyword:大语言模型",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03591v1",
      "title": "Interplay of activity and non-reciprocity in tracer dynamics: From non-equilibrium fluctuation-dissipation to giant diffusion",
      "abstract": "Non-reciprocal interactions play a key role in shaping transport in active and passive systems, giving rise to striking nonequilibrium behavior. Here, we study the dynamics of a tracer -- active or passive -- embedded in a bath of active or passive particles, coupled through non-reciprocal interactions. Starting from the microscopic stochastic dynamics of the full system, we derive an overdamped generalized Langevin equation for the tracer, incorporating a non-Markovian memory kernel that captures bath-mediated correlations. This framework enables us to compute the tracer's velocity and displacement response, derive a generalized nonequilibrium fluctuation-dissipation relation that quantifies deviations from equilibrium behavior, and determine the mean-squared displacement (MSD). We find that while the MSD becomes asymptotically diffusive, the effective diffusivity depends non-monotonically on the degree of non-reciprocity and diverges at an intermediate value. This regime of giant diffusivity provides a generic mechanism for enhanced transport in active soft matter and has direct implications for biological systems exhibiting chase-and-run or predator-prey interactions. Our analytical predictions are supported by numerical simulations of active Brownian particles, highlighting experimentally accessible signatures of non-reciprocal interactions in soft matter.",
      "authors": [
        "Subhajit Paul",
        "Debasish Chaudhuri"
      ],
      "primary_category": "cond-mat.stat-mech",
      "categories": [
        "cond-mat.stat-mech",
        "cond-mat.soft",
        "physics.bio-ph"
      ],
      "published": "2026-01-07 05:21:17+00:00",
      "link": "https://arxiv.org/pdf/2601.03591v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.05126v1",
      "title": "Acoustic signatures of the field-induced electronic-topological transitions in YbNi$_4$P$_2$",
      "abstract": "We investigated the magnetoelastic properties of an YbNi$_4$P$_2$ single crystal at low temperatures under magnetic fields directed along the crystallographic [001] axis. We report a series of strong anomalies in the sound velocity, which is consistent with the cascade of electronic-topological transitions reported previously for this compound. In particular, we identify the vanishing of a small orbit on the Fermi surface, associated with a quantum-oscillation frequency of 34 T. Furthermore, the different transitions are better resolved with acoustic modes of particular symmetry. Using a microscopic model adapted to the strongly correlated electronic structure of YbNi$_4$P$_2$, we describe our results by inspecting realistic electron-phonon couplings in reciprocal space for each acoustic mode. This shows how the $k$ selectivity of ultrasound experiments allows to investigate Fermi-surface reconstructions in strongly correlated electronic systems.",
      "authors": [
        "E. -O. Eljaouhari",
        "B. V. Schwarze",
        "K. Kliemt",
        "C. Krellner",
        "F. Husstedt",
        "J. Wosnitza",
        "S. Zherlitsyn",
        "G. Zwicknagl",
        "J. Sourd"
      ],
      "primary_category": "cond-mat.str-el",
      "categories": [
        "cond-mat.str-el"
      ],
      "published": "2026-01-08 17:15:23+00:00",
      "link": "https://arxiv.org/pdf/2601.05126v1",
      "tags": [
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.04755v1",
      "title": "Scalable Dielectric Tensor Predictions for Inorganic Materials using Equivariant Graph Neural Networks",
      "abstract": "Accurate prediction of dielectric tensors is essential for accelerating the discovery of next-generation inorganic dielectric materials. Existing machine learning approaches, such as equivariant graph neural networks, typically rely on specially-designed network architectures to enforce O(3) equivariance. However, to preserve equivariance, these specially-designed models restrict the update of equivariant features during message passing to linear transformations or gated equivariant nonlinearities. The inability to implicitly characterize more complex nonlinear structures may reduce the predictive accuracy of the model. In this study, we introduce a frame-averaging-based approach to achieve equivariant dielectric tensor prediction. We propose GoeCTP, an O(3)-equivariant framework that predicts dielectric tensors without imposing any structural restrictions on the backbone network. We benchmark its performance against several state-of-the-art models and further employ it for large-scale virtual screening of thermodynamically stable materials from the Materials Project database. GoeCTP successfully identifies various promising candidates, such as Zr(InBr$_3$)$_2$ (band gap $E_g = 2.41$ eV, dielectric constant $\\overline{\\varepsilon} = 194.72$) and SeI$_2$ (anisotropy ratio $α_r = 96.763$), demonstrating its accuracy and efficiency in accelerating the discovery of advanced inorganic dielectric materials.",
      "authors": [
        "Haowei Hua",
        "Chen Liang",
        "Ding Pan",
        "Shengchao Liu",
        "Irwin King",
        "Koji Tsuda",
        "Wanyu Lin"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "categories": [
        "cond-mat.mtrl-sci"
      ],
      "published": "2026-01-08 09:20:51+00:00",
      "link": "https://arxiv.org/pdf/2601.04755v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04702v1",
      "title": "Chaos in high-dimensional dynamical systems with tunable non-reciprocity",
      "abstract": "High-dimensional dynamical systems of interacting degrees of freedom are ubiquitous in the study of complex systems. When the directed interactions are totally uncorrelated, sufficiently strong and non-linear, many of these systems exhibit a chaotic attractor characterized by a positive maximal Lyapunov exponent (MLE). On the contrary, when the interactions are completely symmetric, the dynamics takes the form of a gradient descent on a carefully defined cost function, and it exhibits slow dynamics and aging. In this work, we consider the intermediate case in which the interactions are partially symmetric, with a parameter α tuning the degree of non-reciprocity. We show that for any value of α for which the corresponding system has non-reciprocal interactions, the dynamics lands on a chaotic attractor. Correspondingly, the MLE is a non-monotonous function of the degree of non-reciprocity. This implies that conservative forcing deriving from the gradient field of a rough energy landscape can make the system more chaotic.",
      "authors": [
        "Samantha Fournier",
        "Pierfrancesco Urbani"
      ],
      "primary_category": "cond-mat.dis-nn",
      "categories": [
        "cond-mat.dis-nn"
      ],
      "published": "2026-01-08 08:13:25+00:00",
      "link": "https://arxiv.org/pdf/2601.04702v1",
      "tags": [
        "keyword:resnet中文",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04640v1",
      "title": "Construction of asymptotic quantum many-body scar states in the SU($N$) Hubbard model",
      "abstract": "We construct asymptotic quantum many-body scars (AQMBS) in one-dimensional SU($N$) Hubbard chains ($N\\geq 3$) by embedding the scar subspace into an auxiliary Hilbert subspace $\\mathcal{H}_P$ and identifying a parent Hamiltonian within it, together with a corresponding extension of the restricted spectrum-generating algebra to the multi-ladder case. Unlike previous applications of the parent-Hamiltonian scheme, we show that the parent Hamiltonian becomes the SU($N$) ferromagnetic Heisenberg model rather than the spin-1/2 case, so that its gapless magnons realize explicit AQMBS of the original model. Working in the doublon-holon subspace, we derive this mapping, obtain the one-magnon dispersion for periodic and open boundaries, and prove (i) orthogonality to the tower of scar states, (ii) vanishing energy variance in the thermodynamic limit, and (iii) subvolume entanglement entropy with rigorous MPS/MPO bounds. Our results broaden the parent-Hamiltonian family for AQMBS beyond spin-1/2 and provide analytic, low-entanglement excitations in SU($N$)-symmetric systems.",
      "authors": [
        "Daiki Hashimoto",
        "Masaya Kunimi",
        "Tetsuro Nikuni"
      ],
      "primary_category": "cond-mat.stat-mech",
      "categories": [
        "cond-mat.stat-mech"
      ],
      "published": "2026-01-08 06:21:05+00:00",
      "link": "https://arxiv.org/pdf/2601.04640v1",
      "tags": [
        "keyword:resnet",
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.04535v1",
      "title": "Momentum-Space Entanglement Entropy as a Universal Signature of Dynamical Quantum Phase Transitions",
      "abstract": "We introduce a momentum-space entanglement entropy to quantify quantum correlations between distinct momentum modes following a quench. We prove analytically in the transverse-field Ising (TFI) model and the Su-Schrieffer-Heeger (SSH) chain that every critical momentum $k^{*}$ associated with a dynamical quantum phase transition (DQPT) saturates its entanglement entropy to the maximal value $\\ln{d}$ ($d=2$ in TFI and SSH models), coinciding with the vanishing of the Loschmidt echo. This saturation of mode entanglement thus provides a universal, direct signature of DQPTs. Our work thus establishes a unified, entanglement-based perspective on dynamical quantum phase transitions.",
      "authors": [
        "Kaiyuan Cao",
        "Mingzhi Li",
        "Xiang-Ping Jiang",
        "Shu Chen",
        "Jian Wang"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "cond-mat.quant-gas"
      ],
      "published": "2026-01-08 03:03:51+00:00",
      "link": "https://arxiv.org/pdf/2601.04535v1",
      "tags": [
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.04419v1",
      "title": "Hidden dynamics in fast force curves: Transient Damping and Brownian-Driven Contact Resonance",
      "abstract": "Force distance curves (FCs) are among the most direct measurements performed in atomic force microscopy (AFM), yet their information content is often reduced by filtering and quasi-static interpretation. Here, enabled by a new interferometric detector, we show that fast FCs inherently excite short-lived cantilever oscillations whose transient frequency and decay encode local stiffness and dissipation. By analyzing these dynamics on a single-curve, single-pixel basis, we extract time-local mechanical information without external broadband excitation or multi-pass imaging. We develop a state-dependent single-mode harmonic oscillator model that captures snap-in excitation, hydration-mediated dissipation, and contact stiffness during fast force mapping. Experimental analysis of high-bandwidth force-curve data and numerical simulations demonstrate that multiple dynamically distinct interaction regimes occur within a single FC. Accessing these transient dynamics enables high-throughput, high-resolution mapping of mechanical contrast and reveals heterogeneous and non-repeatable behaviors that are lost under conventional averaging or with conventional detection schemes with higher noise floors.",
      "authors": [
        "Roger Proksch"
      ],
      "primary_category": "cond-mat.mes-hall",
      "categories": [
        "cond-mat.mes-hall"
      ],
      "published": "2026-01-07 21:55:34+00:00",
      "link": "https://arxiv.org/pdf/2601.04419v1",
      "tags": [
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.04345v1",
      "title": "Scalable cold-atom quantum simulator of a $3+1$D U$(1)$ lattice gauge theory with dynamical matter",
      "abstract": "The stated overarching goal of the highly active field of quantum simulation of high-energy physics (HEP) is to achieve the capability to study \\textit{ab-initio} real-time microscopic dynamics of $3+1$D quantum chromodynamics (QCD). However, existing experimental realizations and theoretical proposals for future ones have remained restricted to one or two spatial dimensions. Here, we take a big step towards this goal by proposing a concrete experimentally feasible scalable cold-atom quantum simulator of a U$(1)$ quantum link model of quantum electrodynamics (QED) in three spatial dimensions, employing \\textit{linear gauge protection} to stabilize gauge invariance. Using tree tensor network simulations, we benchmark the performance of this quantum simulator through near- and far-from-equilibrium observables, showing excellent agreement with the ideal gauge theory. Additionally, we introduce a method for \\textit{analog quantum error mitigation} that accounts for unwanted first-order tunneling processes, vastly improving agreement between quantum-simulator and ideal-gauge-theory results. Our findings pave the way towards realistic quantum simulators of $3+1$D lattice gauge theories that can probe regimes well beyond classical simulability.",
      "authors": [
        "Simone Orlando",
        "Guo-Xian Su",
        "Bing Yang",
        "Jad C. Halimeh"
      ],
      "primary_category": "cond-mat.quant-gas",
      "categories": [
        "cond-mat.quant-gas",
        "hep-lat",
        "quant-ph"
      ],
      "published": "2026-01-07 19:32:05+00:00",
      "link": "https://arxiv.org/pdf/2601.04345v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03937v1",
      "title": "Layer Hall effect induced by altermagnetism",
      "abstract": "In this work, we propose a scheme to realize the layer Hall effect in the ferromagnetic topological insulator Bi$_2$Se$_3$ via proximity to $d$-wave altermagnets. We show that an altermagnet and an in-plane magnetic field applied near one surface gap the corresponding Dirac cone, yielding an altermagnet-induced half-quantized Hall effect. When altermagnets with antiparallel Néel vectors are placed near the top and bottom surfaces, giving rise to the layer Hall effect with vanishing net Hall conductance, i.e., the altermagnet-induced layer Hall effect. In contrast, altermagnets with parallel Néel vectors lead to a quantized Chern insulating state, i.e., the altermagnet-induced anomalous Hall effect. We further analyze the dependence of the Hall conductance on the orientation of the in-plane magnetic field and demonstrate that the layer Hall effect becomes observable under a perpendicular electric field. Our results establish a route to engineer altermagnet-induced topological phases in ferromagnetic topological insulators.",
      "authors": [
        "Fang Qin",
        "Rui Chen"
      ],
      "primary_category": "cond-mat.mes-hall",
      "categories": [
        "cond-mat.mes-hall"
      ],
      "published": "2026-01-07 13:54:33+00:00",
      "link": "https://arxiv.org/pdf/2601.03937v1",
      "tags": [
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.03933v1",
      "title": "Material exploration through active learning -- METAL",
      "abstract": "The discovery and design of new materials are paramount in the development of green technologies. High entropy oxides represent one such group that has only been tentatively explored, mainly due to the inherent problem of navigating vast compositional spaces. Thanks to the emergence of machine learning, however, suitable tools are now readily available. Here, the task of finding oxygen carriers for chemical looping processes has been tackled by leveraging active learning-based strategies combined with first-principles calculations. High efficiency and efficacy have, moreover, been achieved by exploiting the power of recently developed machine learning interatomic potentials. Firstly, the proposed approaches were validated based on an established computational framework for identifying high entropy perovskites that can be used in chemical looping air separation and dry reforming. Chief among the insights thus gained was the identification of the best performing strategies, in the form of greedy or Thompson-based sampling based on uncertainty estimates obtained from Gaussian processes. Building on this newfound knowledge, the concept was applied to a more complex problem, namely the discovery of high entropy oxygen carriers for chemical looping oxygen uncoupling. This resulted in both qualitative as well as quantitative outcomes, including lists of specific materials with high oxygen transfer capacities and configurational entropies. Specifically, the best candidates were based on the known oxygen carrier CaMnO3 but also contained a variety of additional species, of which some, e.g., Ti; Co; Cu; and Ti, were expected while others were not, e.g., Y and Sm. The results suggest that adopting active learning approaches is critical in materials discovery, given that these methods are already shifting research practice and soon will be the norm.",
      "authors": [
        "Joakim Brorsson",
        "Henrik Klein Moberg",
        "Joel Hildingsson",
        "Jonatan Gastaldi",
        "Tobias Mattisson",
        "Anders Hellman"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "categories": [
        "cond-mat.mtrl-sci"
      ],
      "published": "2026-01-07 13:52:11+00:00",
      "link": "https://arxiv.org/pdf/2601.03933v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04782v1",
      "title": "QCD Crossover at Low Temperatures from Lee-Yang Edge Singularity",
      "abstract": "We provide the first lattice-QCD estimate of the crossover line down to $T\\simeq108$~MeV. We introduce a new method that combines the Lee-Yang edge in the complex plane of baryon chemical potential $μ_B$ with universal chiral scaling to determine the $μ_B$ dependence of the QCD chiral critical and pseudo-critical temperatures. By performing $(2\\!+\\!1)$-flavor lattice QCD simulations at $T\\simeq108$~MeV and purely imaginary $μ_B$ with a single lattice spacing and two volumes, we compute $μ_B$-dependent baryon-number susceptibilities and extract the location of the Lee-Yang edge. Together with universal scaling near the QCD chiral transition, it constrains the mapping function between $\\{T,μ_B\\}$ and the scaling variable (\\textit{i.e.}\\ the argument of the universal scaling functions). This mapping function then yields the $μ_B$ dependence of the critical and pseudo-critical temperatures for $T\\gtrsim108$~MeV. While our calculation is performed only at a single value of low temperature without explicit input from small-$μ_B$ expansion, the resulting $μ_B$ dependence of the pseudo-critical temperature is consistent with established lattice-QCD determinations at small $μ_B$ and compatible with chemical freeze-out parameters of heavy-ion collisions down to low temperatures, demonstrating the validity and robustness of the method. Application of this method can be systematically extended to additional temperatures and finer discretizations, opening a pathway to charting the QCD phase diagram in the low-$T$, high-$μ_B$ regime.",
      "authors": [
        "D. A. Clarke",
        "H. -T. Ding",
        "J. -B. Gu",
        "S. -T. Li",
        "Swagato Mukherjee",
        "P. Petreczky",
        "C. Schmidt",
        "H. -T. Shu",
        "K. -F. Ye"
      ],
      "primary_category": "hep-lat",
      "categories": [
        "hep-lat",
        "hep-ph",
        "nucl-ex",
        "nucl-th"
      ],
      "published": "2026-01-08 10:04:11+00:00",
      "link": "https://arxiv.org/pdf/2601.04782v1",
      "tags": [
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.04106v1",
      "title": "Effect of event classification on the Tsallis-thermometer",
      "abstract": "We analyze identified hadron spectra in pp collisions at $\\sqrt{s} = 13$ TeV measured by ALICE within a non-extensive statistical framework. Spectra classified by multiplicity, flattenicity, and spherocity were fitted with the Tsallis-Pareto distribution, and the parameters were studied on the Tsallis-thermometer. Multiplicity and flattenicity classes follow a previously observed scaling, while the non-extensivity parameter shows a distinct sensitivity to the spherocity. A data-driven parametrization confirms a proportionality between the Tsallis temperature and mean transverse momentum, offering a simple estimate of the effective temperature. These results highlight the ability of the Tsallis-thermometer to capture both multiplicity and event-shape effects, linking soft and hard processes in small systems.",
      "authors": [
        "Laszlo Gyulai",
        "Gabor Biro",
        "Robert Vertesi",
        "Gergely Gabor Barnafoldi"
      ],
      "primary_category": "hep-ph",
      "categories": [
        "hep-ph"
      ],
      "published": "2026-01-07 17:11:49+00:00",
      "link": "https://arxiv.org/pdf/2601.04106v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03912v1",
      "title": "Beyond Form Factors: Precise Angular Tests in Hadronic $τ$ Decays",
      "abstract": "Semileptonic $τ$ decays mainly proceed via interactions between charged lepton and quark currents. The hadronization of the quark current is intrinsically nonperturbative and generally cannot be addressed analytically. In these proceedings, we propose using symmetry arguments alone to construct clean angular observables, which, within the Standard Model and in the absence of long-distance electromagnetic corrections, remain form-factor independent. These predictions can be experimentally tested, and any observed deviation could signal either effects of physics beyond the Standard Model or provide a clean benchmark for long-distance electromagnetic corrections. We also perform a first estimate of the expected impact of new physics in an EFT framework.",
      "authors": [
        "E. Estrada",
        "E. Passemar",
        "S. Paz",
        "A. Rodríguez-Sánchez",
        "P. Roig"
      ],
      "primary_category": "hep-ph",
      "categories": [
        "hep-ph",
        "hep-ex"
      ],
      "published": "2026-01-07 13:26:27+00:00",
      "link": "https://arxiv.org/pdf/2601.03912v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04333v1",
      "title": "Local gauge-invariant vector operators in the adjoint $SU(2)$ Higgs model",
      "abstract": "In this work, we scrutinize local gauge-invariant vector operators of dimension four in the adjoint $SU(2)$ Higgs model, which are candidates for interpolating fields of the fundamental excitations of the model due to the so-called FMS mechanism. We use the equations of motion and the properties of the BRST operator to derive a Ward identity that allows us to determine whether a given operator can propagate. To corroborate this analysis, we explicitly compute the two-point function of the non-propagating operator at the one-loop level.",
      "authors": [
        "Giovani Peruzzo"
      ],
      "primary_category": "hep-th",
      "categories": [
        "hep-th",
        "hep-lat"
      ],
      "published": "2026-01-07 19:12:53+00:00",
      "link": "https://arxiv.org/pdf/2601.04333v1",
      "tags": [
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.04290v1",
      "title": "A Relativistic MOND",
      "abstract": "We present a minimal relativistic completion of MOND in which (i) General Relativity is recovered exactly in the high-acceleration regime, while (ii) the Bekenstein--Milgrom (AQUAL) equation emerges in the low-acceleration regime, without introducing additional propagating fields beyond those already present in a right-handed gauge sector. The construction is motivated by an $E_6\\times E_6$ framework in which $SU(3)_R\\rightarrow SU(2)_R\\times U(1)_{Y'}\\rightarrow U(1)_{\\rm dem}$, leaving a healthy repulsive $U(1)_{\\rm dem}$ interaction whose charge is the square-root mass label. Gravity itself arises from the $SU(2)_R$ connection via a Plebanski/MacDowell--Mansouri mechanism, yielding an emergent tetrad and the Einstein--Hilbert action. MOND is implemented by an infrared (IR) metric deformation $ΔS_{\\rm IR}[g]$ that is UV-vanishing (so GR is recovered) while its deep-MOND/static limit is fixed by a symmetry principle: in three spatial dimensions, the deep-MOND action is conformally invariant with a 10-parameter group isomorphic to $SO(4,1)$ (the de Sitter group). The single MOND acceleration scale is set by a de Sitter radius selected dynamically in the IR, $a_0=c^2/(ξ\\,\\ell_{\\rm dS})$ with $ξ={ O}(1)$ fixed by matching to the static limit. MOND resides in perturbations and quasistatic systems; the homogeneous FRW background is controlled by the IR vacuum kinematics rather than an ad hoc cosmological constant.",
      "authors": [
        "Tejinder P. Singh"
      ],
      "primary_category": "gr-qc",
      "categories": [
        "gr-qc",
        "astro-ph.CO",
        "astro-ph.GA"
      ],
      "published": "2026-01-07 15:08:50+00:00",
      "link": "https://arxiv.org/pdf/2601.04290v1",
      "tags": [
        "keyword:resnet",
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.05203v1",
      "title": "Symbolically regressing dark matter halo profiles using weak lensing",
      "abstract": "The structure of dark matter haloes is often described by radial density profiles motivated by cosmological simulations. These are typically assumed to have a fixed functional form (e.g. NFW), with some free parameters that can be constrained with observations. However, relying on simulations has the disadvantage that the resulting profiles depend on the dark matter model and the baryonic physics implementation, which are highly uncertain. Instead, we present a method to constrain halo density profiles directly from observations. This is done using a symbolic regression algorithm called Exhaustive Symbolic Regression (ESR). ESR searches for the optimal analytic expression to fit data, combining both accuracy and simplicity. We apply ESR to a sample of 149 galaxy clusters from the HSC-XXL survey to identify which functional forms perform best across the entire sample of clusters. We identify density profiles that statistically outperform NFW under a minimum-description-length criterion. Within the radial range probed by the weak-lensing data ($R \\sim 0.3 - 3$ h$^{-1}$ Mpc), the highest-ranked ESR profiles exhibit shallow inner behaviour and a maximum in the density profile. As a practical application, we show how the best-fitting ESR models can be used to obtain enclosed mass estimates. We find masses that are, on average, higher than those derived using NFW, highlighting a source of potential bias when assuming the wrong density profile. These results have important knock-on effects for analyses that utilise clusters, for example cosmological constraints on $σ_8$ and $Ω_m$ from cluster abundance and clustering. Beyond the HSC dataset, the method is readily applicable to any data constraining the dark matter distribution in galaxies and galaxy clusters, such as other weak lensing surveys, galactic rotation curves, or complementary probes.",
      "authors": [
        "Alicia Martín",
        "Tariq Yasin",
        "Deaglan J. Bartlett",
        "Harry Desmond",
        "Pedro G. Ferreira"
      ],
      "primary_category": "astro-ph.CO",
      "categories": [
        "astro-ph.CO",
        "astro-ph.GA"
      ],
      "published": "2026-01-08 18:26:43+00:00",
      "link": "https://arxiv.org/pdf/2601.05203v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04939v1",
      "title": "Multi-Messenger Studies with High-Energy Neutrinos and Gamma Rays: The WST Opportunity",
      "abstract": "The search for the sources of ultra-high-energy cosmic rays (UHECRs) using high-energy neutrinos represents a frontier in high-energy astrophysics. However, a critical bottleneck remains: the ability to rapidly survey the sizable sky areas defined by the localization uncertainties of neutrino detectors and to provide rapid spectroscopic classification of the multitude of optical transients found within them.   By deploying a large field-of-view with high-multiplex Multi-Object Spectroscopy (MOS) on a large aperture telescope, one can instantaneously cover neutrino error circles, thus providing crucial spectroscopic classifications of potential counterparts discovered, for example, by the Vera C. Rubin Observatory (LSST) with unprecedented efficiency. Furthermore, simultaneous operation of a giant panoramic central Integral Field Spectrograph (IFS) would allow for detailed kinematic and environmental characterization of primary candidates. This facility would unlock deep synergies between next-generation neutrino telescopes (IceCube-Gen2, KM3NeT) and gamma-ray observatories (CTAO), transforming unique multi-messenger alerts into a comprehensive physical understanding.",
      "authors": [
        "Fabian Schüssler",
        "Sofia Bisero",
        "Bernardo Cornejo",
        "Filippo D'Ammando",
        "Richard I. Anderson",
        "Ilja Jaroschewski",
        "Silvia Piranomonte",
        "Fatemeh Zahra Majid"
      ],
      "primary_category": "astro-ph.IM",
      "categories": [
        "astro-ph.IM",
        "astro-ph.HE"
      ],
      "published": "2026-01-08 13:43:02+00:00",
      "link": "https://arxiv.org/pdf/2601.04939v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04773v1",
      "title": "Optimization of Deep Learning Models for Radio Galaxy Classification",
      "abstract": "Modern radio telescope surveys, capable of detecting billions of galaxies in wide-field surveys, have made manual morphological classification impracticable. This applies in particular when the Square Kilometre Array Observatory (SKAO) becomes operable in 2027, which is expected to close an important gap in our understanding of the Epoch of Reionization (EoR) and other areas of astrophysics. To this end, foreground objects, contaminants of the 21-cm signal, need to be identified and subtracted. Source finding and identification is thus an important albeit challenging task. We investigate the ability of AI and deep learning (DL) methods that have been previously trained on other data domains to localize and classify radio galaxies with minimal changes to their architectures. Various well-known pretrained neural network architectures for image classification and object detection are trained and fine-tuned and their performance is evaluated on a public radio galaxy dataset derived from the Radio Galaxy Zoo. A comparison between convolutional neural network (CNN)- and transformer-based algorithms is performed. The best performing architecture is systematically optimized and an uncertainty estimation is performed by means of an ensemble analysis. Radio source classification performance nearly comparable to the current leading customized models can be obtained using existing standard pretrained DL architectures, without modification and increase in complexity of the model architectures but rather adaptation of the data, by combining various transformations on replicated image channels. Using an ensemble of models can also further improve performance to over 90% accuracy, on par with top-performing models in the literature. The results can be transferred to other survey data, e.g. from the Murchison Wide-field Array (MWA), and in the future be used to study the EoR with the SKAO.",
      "authors": [
        "Philipp Denzel",
        "Manuel Weiss",
        "Elena Gavagnin",
        "Frank-Peter Schilling"
      ],
      "primary_category": "astro-ph.GA",
      "categories": [
        "astro-ph.GA"
      ],
      "published": "2026-01-08 09:55:47+00:00",
      "link": "https://arxiv.org/pdf/2601.04773v1",
      "tags": [
        "keyword:resnet",
        "keyword:大语言模型"
      ]
    },
    {
      "id": "2601.04552v1",
      "title": "Studies in Astronomical Time Series Analysis: The Double Lomb-Scargle Periodogram and Super Resolution",
      "abstract": "Multiple-frequency periodograms -- based on time series models consisting of two or more independent sinusoids -- have long been discussed. What is new here is the presentation of a practical, simple-to-use computational framework implementing this concept. Our algorithms have super resolution that evades the Rayleigh criterion, as well as provision for statistical weighting and tapering. They can be used for essentially any time series (e.g. time-tagged events or point measurements) with arbitrary sampling -- even or uneven. Examples of super resolution of synthetic data, sunspot numbers, and the rich pulsations of white dwarf J0135+5722, demonstrate practical applications. Appendices derive generalized periodograms using an arbitrary number of arbitrary basis functions (following Bretthorst, 1988)and define several examples of non-sinusoidal bases for these ``omnigrams.'' Application beyond the frequency domain is demonstrated with an autoregressive model exhibiting super resolution in the time domain. A GitHub repository containing omnigram code, and symbolic algebra scripts for generating it, will soon be available.",
      "authors": [
        "Jeffrey D. Scargle",
        "Sarah Wagner"
      ],
      "primary_category": "astro-ph.IM",
      "categories": [
        "astro-ph.IM"
      ],
      "published": "2026-01-08 03:29:14+00:00",
      "link": "https://arxiv.org/pdf/2601.04552v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04059v1",
      "title": "Spiral galaxies with flat radial abundance gradients at large radii",
      "abstract": "We consider the oxygen abundance distributions for a sample of massive spiral galaxies from the MaNGA survey in which the radial abundance gradient flattens to a constant value outside of the outer break radius, Rb,outer. The outer break radius can be considered as a dividing radius between the galaxy and the circumgalactic medium (CGM). The values of the Rb,outer range from 0.8R_{25} to 1.45R_{25}, where R_{25} is the optical radius of the galaxy. The oxygen abundances in the CGM range from 12+log(O/H) ~ 8.0 to ~ 8.5. The O/H distribution in each of our galaxies also shows the inner break in the radial abundance profile at the radius Rb,inner. The metallicity gradient in the outer part of the galaxy is steeper than in the inner part. The behaviour of the radial abundance distributions in these galaxies can be explained by assuming an interaction with (capture of the gas from) a small companion and adopting the model for the chemical evolution of galaxies with a radial gas flow. The interaction with a companion results in the mixing of gas and a flat metallicity gradient in the CGM. The capture of the gas from a companion increases the radial gas inflow rate and changes the slope of the radial abundance gradient in the outer part of the galaxy.",
      "authors": [
        "L. S. Pilyugin",
        "G. Tautvaisiene"
      ],
      "primary_category": "astro-ph.GA",
      "categories": [
        "astro-ph.GA"
      ],
      "published": "2026-01-07 16:22:44+00:00",
      "link": "https://arxiv.org/pdf/2601.04059v1",
      "tags": [
        "keyword:resnet中文"
      ]
    },
    {
      "id": "2601.04032v1",
      "title": "Two-source terrestrial planet formation with a sweeping secular resonance",
      "abstract": "The models that most successfully reproduce the orbital architecture of the Solar System terrestrial planets start from a narrow annulus of material that grows into embryos and then planets. However, it is not clear how this ring model can be made consistent with the chemical structure of the inner Solar System, which shows a reduced-to-oxidized gradient from Mercury to Mars and a parallel gradient in the asteroid belt. We propose that there were two primary reservoirs in the early inner Solar System: a narrow, refractory enriched ring inside of 1 au, and a less massive, extended planetesimal disk outside of 1 au with oxidation states ranging from enstatite chondrites to ordinary chondrites. We show through a suite of N-body simulations that an inwardly sweeping secular resonance, caused by aerodynamic drag and perturbations from a mean-motion resonant Jupiter and Saturn, gathers the outer planetesimal disk into a narrow ring that migrates radially, forms Mars, and contributes oxidized material to proto-Earth. Remaining unaccreted planetesimals can be implanted into the asteroid belt as the parent bodies of aubrites and non-carbonaceous iron meteorites, while the most reduced material is not implanted and thus unsampled in the meteorite collection. This model explains the oxidation and isotopic gradients within the inner Solar System within the context of a low-viscosity, magnetic wind-driven disk.",
      "authors": [
        "Max Goldberg",
        "David Nesvorný",
        "Alessandro Morbidelli"
      ],
      "primary_category": "astro-ph.EP",
      "categories": [
        "astro-ph.EP"
      ],
      "published": "2026-01-07 15:47:09+00:00",
      "link": "https://arxiv.org/pdf/2601.04032v1",
      "tags": [
        "keyword:resnet"
      ]
    }
  ],
  "queries": [
    {
      "type": "keyword",
      "alias": "符号回归（示例）",
      "tag": "keyword:符号回归（示例）",
      "query_text": "symbolic regression",
      "sim_scores": {
        "2601.04051v1": {
          "score": 5.539888972672755,
          "rank": 1
        },
        "2601.04799v1": {
          "score": 4.3575866543877,
          "rank": 2
        },
        "2601.05051v1": {
          "score": 3.086428816929337,
          "rank": 3
        },
        "2601.03808v1": {
          "score": 3.07271901147809,
          "rank": 4
        },
        "2601.04789v1": {
          "score": 2.954122691161171,
          "rank": 5
        },
        "2601.05203v1": {
          "score": 2.8721506486459694,
          "rank": 6
        },
        "2601.03674v1": {
          "score": 2.8533329260073237,
          "rank": 7
        },
        "2601.04610v1": {
          "score": 2.8459483865929736,
          "rank": 8
        },
        "2601.03598v1": {
          "score": 2.797963107694047,
          "rank": 9
        },
        "2601.03486v1": {
          "score": 2.782872809601721,
          "rank": 10
        },
        "2601.04568v1": {
          "score": 2.75678405462515,
          "rank": 11
        },
        "2601.05033v1": {
          "score": 2.7059716285505364,
          "rank": 12
        },
        "2601.04138v1": {
          "score": 2.6858387526874488,
          "rank": 13
        },
        "2601.04101v1": {
          "score": 2.5876268596089536,
          "rank": 14
        },
        "2601.04507v1": {
          "score": 2.49853292346543,
          "rank": 15
        },
        "2601.04176v1": {
          "score": 2.4469640665811836,
          "rank": 16
        },
        "2601.03910v1": {
          "score": 2.431781692740656,
          "rank": 17
        },
        "2601.03509v1": {
          "score": 2.4314759523247633,
          "rank": 18
        },
        "2601.03750v1": {
          "score": 2.349532070594979,
          "rank": 19
        },
        "2601.04473v1": {
          "score": 2.342198092907978,
          "rank": 20
        },
        "2601.03604v1": {
          "score": 2.244520901727005,
          "rank": 21
        },
        "2601.04366v1": {
          "score": 2.222745282911786,
          "rank": 22
        },
        "2601.03933v1": {
          "score": 2.2129961150031026,
          "rank": 23
        },
        "2601.04899v1": {
          "score": 2.2118126548343437,
          "rank": 24
        },
        "2601.04509v1": {
          "score": 2.1567961790207955,
          "rank": 25
        },
        "2601.04581v1": {
          "score": 2.1501533579599323,
          "rank": 26
        },
        "2601.03812v1": {
          "score": 2.0894325265173816,
          "rank": 27
        },
        "2601.04620v1": {
          "score": 2.08877715167706,
          "rank": 28
        },
        "2601.04413v1": {
          "score": 2.0456124630838013,
          "rank": 29
        },
        "2601.04821v1": {
          "score": 2.0374370533503,
          "rank": 30
        },
        "2601.03566v1": {
          "score": 2.023405467341897,
          "rank": 31
        },
        "2601.05087v1": {
          "score": 2.003491897175914,
          "rank": 32
        },
        "2601.03760v1": {
          "score": 1.931342581069784,
          "rank": 33
        },
        "2601.03858v1": {
          "score": 1.9139746589532998,
          "rank": 34
        },
        "2601.05194v1": {
          "score": 1.9063736774053175,
          "rank": 35
        },
        "2601.05151v1": {
          "score": 1.885724449457045,
          "rank": 36
        },
        "2601.03755v1": {
          "score": 1.8844150834194526,
          "rank": 37
        },
        "2601.03747v1": {
          "score": 1.8744498878061064,
          "rank": 38
        },
        "2601.04521v1": {
          "score": 1.8738357777585157,
          "rank": 39
        },
        "2601.04915v1": {
          "score": 1.8597925796437578,
          "rank": 40
        },
        "2601.03613v1": {
          "score": 1.8491339659347745,
          "rank": 41
        },
        "2601.03906v1": {
          "score": 1.8490538843662014,
          "rank": 42
        },
        "2601.04873v1": {
          "score": 1.829511091943772,
          "rank": 43
        },
        "2601.04675v1": {
          "score": 1.8290585306858103,
          "rank": 44
        },
        "2601.04913v1": {
          "score": 1.8158953387243972,
          "rank": 45
        },
        "2601.03964v1": {
          "score": 1.8056812648302636,
          "rank": 46
        },
        "2601.04392v1": {
          "score": 1.7952953909941765,
          "rank": 47
        },
        "2601.04505v1": {
          "score": 1.7772412196519898,
          "rank": 48
        },
        "2601.04670v1": {
          "score": 1.7755443093822016,
          "rank": 49
        },
        "2601.04411v1": {
          "score": 1.7629310771195783,
          "rank": 50
        },
        "2601.03844v1": {
          "score": 1.7608284151924283,
          "rank": 51
        },
        "2601.05160v1": {
          "score": 1.7510103519207385,
          "rank": 52
        },
        "2601.04755v1": {
          "score": 1.7488597022926522,
          "rank": 53
        },
        "2601.03550v1": {
          "score": 1.7275160440049067,
          "rank": 54
        },
        "2601.04262v1": {
          "score": 1.7274913476869653,
          "rank": 55
        },
        "2601.04688v1": {
          "score": 1.7145015961683374,
          "rank": 56
        },
        "2601.03815v1": {
          "score": 1.7133212069861288,
          "rank": 57
        },
        "2601.04801v1": {
          "score": 1.7023091449385546,
          "rank": 58
        },
        "2601.03570v1": {
          "score": 1.695559379566681,
          "rank": 59
        },
        "2601.03704v1": {
          "score": 1.6893684430986313,
          "rank": 60
        },
        "2601.03774v1": {
          "score": 1.6835782363968954,
          "rank": 61
        },
        "2601.05240v1": {
          "score": 1.6668350564732448,
          "rank": 62
        },
        "2601.05002v1": {
          "score": 1.6651682336936453,
          "rank": 63
        },
        "2601.04767v1": {
          "score": 1.6593644371792775,
          "rank": 64
        },
        "2601.05227v1": {
          "score": 1.6460605479515469,
          "rank": 65
        },
        "2601.03845v1": {
          "score": 1.6361964498284571,
          "rank": 66
        },
        "2601.04547v1": {
          "score": 1.6339416520928975,
          "rank": 67
        },
        "2601.03477v1": {
          "score": 1.6293619587564094,
          "rank": 68
        },
        "2601.04334v1": {
          "score": 1.625334135236651,
          "rank": 69
        },
        "2601.04449v1": {
          "score": 1.617905257814933,
          "rank": 70
        },
        "2601.04476v1": {
          "score": 1.6064503369866903,
          "rank": 71
        },
        "2601.03517v1": {
          "score": 1.6058189817763804,
          "rank": 72
        },
        "2601.03802v1": {
          "score": 1.5976347230871117,
          "rank": 73
        },
        "2601.04552v1": {
          "score": 1.589328211141143,
          "rank": 74
        },
        "2601.05204v1": {
          "score": 1.5832095130645902,
          "rank": 75
        },
        "2601.03591v1": {
          "score": 1.535529400540762,
          "rank": 76
        },
        "2601.04062v2": {
          "score": 1.5235404838475497,
          "rank": 77
        },
        "2601.03742v1": {
          "score": 1.523288684913611,
          "rank": 78
        },
        "2601.03920v1": {
          "score": 1.5183878143702025,
          "rank": 79
        },
        "2601.04058v1": {
          "score": 1.5180704945208048,
          "rank": 80
        },
        "2601.04735v1": {
          "score": 1.5129304693509131,
          "rank": 81
        },
        "2601.04702v1": {
          "score": 1.4954875904090492,
          "rank": 82
        },
        "2601.04438v1": {
          "score": 1.4797306934646233,
          "rank": 83
        },
        "2601.04865v1": {
          "score": 1.466249316118791,
          "rank": 84
        },
        "2601.03689v1": {
          "score": 1.4449284706215981,
          "rank": 85
        },
        "2601.04486v1": {
          "score": 1.444531852130052,
          "rank": 86
        },
        "2601.03977v1": {
          "score": 1.435203602217411,
          "rank": 87
        },
        "2601.04968v1": {
          "score": 1.4184070512618376,
          "rank": 88
        },
        "2601.03745v1": {
          "score": 1.4151666067921806,
          "rank": 89
        },
        "2601.03569v1": {
          "score": 1.40934871926003,
          "rank": 90
        },
        "2601.04918v1": {
          "score": 1.4033358241943614,
          "rank": 91
        },
        "2601.04173v1": {
          "score": 1.3840620156623227,
          "rank": 92
        },
        "2601.03626v1": {
          "score": 1.3725005900540483,
          "rank": 93
        },
        "2601.05146v1": {
          "score": 1.3724597333014155,
          "rank": 94
        },
        "2601.04703v1": {
          "score": 1.3644487400846683,
          "rank": 95
        },
        "2601.04105v1": {
          "score": 1.3564687798350425,
          "rank": 96
        },
        "2601.05137v1": {
          "score": 1.3476101824721327,
          "rank": 97
        },
        "2601.04106v1": {
          "score": 1.3438532385061852,
          "rank": 98
        },
        "2601.04608v1": {
          "score": 1.3221380745670344,
          "rank": 99
        },
        "2601.03969v1": {
          "score": 1.3145444886387472,
          "rank": 100
        }
      }
    },
    {
      "type": "keyword",
      "alias": "大语言模型",
      "tag": "keyword:大语言模型",
      "query_text": "transformer",
      "sim_scores": {
        "2601.05143v1": {
          "score": 4.628212662640422,
          "rank": 1
        },
        "2601.03928v1": {
          "score": 3.979571266779795,
          "rank": 2
        },
        "2601.03613v1": {
          "score": 3.919968953261521,
          "rank": 3
        },
        "2601.04359v1": {
          "score": 3.908949158627594,
          "rank": 4
        },
        "2601.04367v1": {
          "score": 3.892008076544477,
          "rank": 5
        },
        "2601.04299v1": {
          "score": 3.890866140068934,
          "rank": 6
        },
        "2601.04342v1": {
          "score": 3.474951918297385,
          "rank": 7
        },
        "2601.04401v1": {
          "score": 3.2663169917862955,
          "rank": 8
        },
        "2601.05083v1": {
          "score": 3.2492040818831667,
          "rank": 9
        },
        "2601.04602v1": {
          "score": 3.1578028032299583,
          "rank": 10
        },
        "2601.03798v1": {
          "score": 3.1120241820167034,
          "rank": 11
        },
        "2601.03712v2": {
          "score": 2.957200678584337,
          "rank": 12
        },
        "2601.04376v1": {
          "score": 2.9332206870909046,
          "rank": 13
        },
        "2601.03774v1": {
          "score": 2.9237761820881536,
          "rank": 14
        },
        "2601.04480v1": {
          "score": 2.875235186088191,
          "rank": 15
        },
        "2601.03517v1": {
          "score": 2.8636471703204625,
          "rank": 16
        },
        "2601.03479v1": {
          "score": 2.802232757462275,
          "rank": 17
        },
        "2601.05127v1": {
          "score": 2.7588162596594623,
          "rank": 18
        },
        "2601.03483v1": {
          "score": 2.6068472452520606,
          "rank": 19
        },
        "2601.04719v1": {
          "score": 2.59942177824184,
          "rank": 20
        },
        "2601.04509v1": {
          "score": 2.591314623057559,
          "rank": 21
        },
        "2601.04445v1": {
          "score": 2.5827804559874052,
          "rank": 22
        },
        "2601.04098v1": {
          "score": 2.5573219593008787,
          "rank": 23
        },
        "2601.04607v1": {
          "score": 2.5543982521618886,
          "rank": 24
        },
        "2601.03667v2": {
          "score": 2.5095658706612443,
          "rank": 25
        },
        "2601.03882v1": {
          "score": 2.5041557095165494,
          "rank": 26
        },
        "2601.03686v1": {
          "score": 2.4981931575883243,
          "rank": 27
        },
        "2601.03660v1": {
          "score": 2.484672234598045,
          "rank": 28
        },
        "2601.03888v2": {
          "score": 2.480146937113057,
          "rank": 29
        },
        "2601.03603v1": {
          "score": 2.4560723612600617,
          "rank": 30
        },
        "2601.05047v1": {
          "score": 2.453098196753575,
          "rank": 31
        },
        "2601.03753v1": {
          "score": 2.4428082468349475,
          "rank": 32
        },
        "2601.04550v1": {
          "score": 2.429178388028342,
          "rank": 33
        },
        "2601.04968v1": {
          "score": 2.376656284742537,
          "rank": 34
        },
        "2601.04262v1": {
          "score": 2.3695027519041725,
          "rank": 35
        },
        "2601.03673v1": {
          "score": 2.3382237041114817,
          "rank": 36
        },
        "2601.04443v1": {
          "score": 2.3102784167515718,
          "rank": 37
        },
        "2601.05174v1": {
          "score": 2.3059632147517677,
          "rank": 38
        },
        "2601.04891v1": {
          "score": 2.2993614453884557,
          "rank": 39
        },
        "2601.03646v2": {
          "score": 2.288625660414872,
          "rank": 40
        },
        "2601.04054v1": {
          "score": 2.273345873982436,
          "rank": 41
        },
        "2601.04159v1": {
          "score": 2.2711585713274216,
          "rank": 42
        },
        "2601.04260v1": {
          "score": 2.2534623125604405,
          "rank": 43
        },
        "2601.03683v1": {
          "score": 2.2534006469247205,
          "rank": 44
        },
        "2601.03812v1": {
          "score": 2.221057541081355,
          "rank": 45
        },
        "2601.04581v1": {
          "score": 2.1482692084088466,
          "rank": 46
        },
        "2601.03481v1": {
          "score": 2.1426173259524424,
          "rank": 47
        },
        "2601.03704v1": {
          "score": 2.140024682525067,
          "rank": 48
        },
        "2601.04261v1": {
          "score": 2.1195437611960144,
          "rank": 49
        },
        "2601.05201v1": {
          "score": 2.1083997120669853,
          "rank": 50
        },
        "2601.04121v1": {
          "score": 2.107408867696207,
          "rank": 51
        },
        "2601.03661v1": {
          "score": 2.0687566921750578,
          "rank": 52
        },
        "2601.04674v1": {
          "score": 2.058881082661714,
          "rank": 53
        },
        "2601.04646v1": {
          "score": 2.031235938069881,
          "rank": 54
        },
        "2601.03542v1": {
          "score": 2.028422757774285,
          "rank": 55
        },
        "2601.04442v1": {
          "score": 2.0240094307423995,
          "rank": 56
        },
        "2601.04876v1": {
          "score": 2.018638442609992,
          "rank": 57
        },
        "2601.03665v1": {
          "score": 2.010782226868223,
          "rank": 58
        },
        "2601.03703v1": {
          "score": 1.998470310758235,
          "rank": 59
        },
        "2601.04398v1": {
          "score": 1.9837668164991646,
          "rank": 60
        },
        "2601.04118v2": {
          "score": 1.979212500190464,
          "rank": 61
        },
        "2601.03500v1": {
          "score": 1.9769076733971347,
          "rank": 62
        },
        "2601.04786v1": {
          "score": 1.949198634842308,
          "rank": 63
        },
        "2601.03729v1": {
          "score": 1.9054915863714086,
          "rank": 64
        },
        "2601.04653v1": {
          "score": 1.8912512420188499,
          "rank": 65
        },
        "2601.03713v1": {
          "score": 1.8878275025250622,
          "rank": 66
        },
        "2601.03519v1": {
          "score": 1.8722527672127347,
          "rank": 67
        },
        "2601.04517v1": {
          "score": 1.8524043777063426,
          "rank": 68
        },
        "2601.05063v1": {
          "score": 1.8503703398769078,
          "rank": 69
        },
        "2601.03823v1": {
          "score": 1.8447354413913144,
          "rank": 70
        },
        "2601.03725v1": {
          "score": 1.8242298303445725,
          "rank": 71
        },
        "2601.04497v1": {
          "score": 1.8178752251042196,
          "rank": 72
        },
        "2601.04956v1": {
          "score": 1.7661677648843654,
          "rank": 73
        },
        "2601.04562v1": {
          "score": 1.7578859581098834,
          "rank": 74
        },
        "2601.04400v1": {
          "score": 1.7570849497083043,
          "rank": 75
        },
        "2601.05239v1": {
          "score": 1.7407502563000063,
          "rank": 76
        },
        "2601.05004v1": {
          "score": 1.7385654003064863,
          "rank": 77
        },
        "2601.05251v1": {
          "score": 1.736130084157209,
          "rank": 78
        },
        "2601.03594v1": {
          "score": 1.728947358313191,
          "rank": 79
        },
        "2601.03782v1": {
          "score": 1.727389452748737,
          "rank": 80
        },
        "2601.05159v1": {
          "score": 1.7086968210407956,
          "rank": 81
        },
        "2601.04564v1": {
          "score": 1.707390659282162,
          "rank": 82
        },
        "2601.05059v1": {
          "score": 1.6841094760332342,
          "rank": 83
        },
        "2601.04861v1": {
          "score": 1.6646021288727668,
          "rank": 84
        },
        "2601.04773v1": {
          "score": 1.6350982181678801,
          "rank": 85
        },
        "2601.04177v1": {
          "score": 1.620171241433684,
          "rank": 86
        },
        "2601.04785v1": {
          "score": 1.590052937787855,
          "rank": 87
        },
        "2601.05106v1": {
          "score": 1.579658046096218,
          "rank": 88
        },
        "2601.04699v1": {
          "score": 1.5779877334982262,
          "rank": 89
        },
        "2601.04696v1": {
          "score": 1.5630243176093814,
          "rank": 90
        },
        "2601.03633v1": {
          "score": 1.5628981514134657,
          "rank": 91
        },
        "2601.03609v1": {
          "score": 1.5620343739738431,
          "rank": 92
        },
        "2601.04765v1": {
          "score": 1.538942400230271,
          "rank": 93
        },
        "2601.03637v2": {
          "score": 1.5338705855109909,
          "rank": 94
        },
        "2601.03915v1": {
          "score": 1.527503467368017,
          "rank": 95
        },
        "2601.04506v1": {
          "score": 1.5157316378190013,
          "rank": 96
        },
        "2601.04052v1": {
          "score": 1.4949888776636415,
          "rank": 97
        },
        "2601.04151v1": {
          "score": 1.4740363195021875,
          "rank": 98
        },
        "2601.04531v1": {
          "score": 1.4674271710369604,
          "rank": 99
        },
        "2601.04348v1": {
          "score": 1.4484850723645881,
          "rank": 100
        }
      }
    },
    {
      "type": "keyword",
      "alias": "resnet",
      "tag": "keyword:resnet",
      "query_text": "resnet",
      "sim_scores": {
        "2601.04352v1": {
          "score": 2.7900206631483755,
          "rank": 1
        },
        "2601.04727v1": {
          "score": 2.342131766927479,
          "rank": 2
        },
        "2601.04397v1": {
          "score": 2.1322282006637407,
          "rank": 3
        },
        "2601.04069v1": {
          "score": 1.9262737934813963,
          "rank": 4
        },
        "2601.04270v1": {
          "score": 1.707527342931563,
          "rank": 5
        },
        "2601.04668v1": {
          "score": 1.632646937540964,
          "rank": 6
        },
        "2601.04005v1": {
          "score": 1.5775863288945184,
          "rank": 7
        },
        "2601.05227v1": {
          "score": 1.5400297912756726,
          "rank": 8
        },
        "2601.05052v1": {
          "score": 1.5200195788218633,
          "rank": 9
        },
        "2601.04918v1": {
          "score": 1.4916410956831692,
          "rank": 10
        },
        "2601.04716v1": {
          "score": 1.4381847776125793,
          "rank": 11
        },
        "2601.03914v1": {
          "score": 1.4224605681956906,
          "rank": 12
        },
        "2601.03612v1": {
          "score": 1.3674965199736817,
          "rank": 13
        },
        "2601.03673v1": {
          "score": 1.3203009957979193,
          "rank": 14
        },
        "2601.04607v1": {
          "score": 1.320012399957411,
          "rank": 15
        },
        "2601.04896v1": {
          "score": 1.3144497713180794,
          "rank": 16
        },
        "2601.05249v1": {
          "score": 1.308713172821769,
          "rank": 17
        },
        "2601.03822v1": {
          "score": 1.2912977221603907,
          "rank": 18
        },
        "2601.04519v1": {
          "score": 1.2847687568828488,
          "rank": 19
        },
        "2601.04710v1": {
          "score": 1.267488759611402,
          "rank": 20
        },
        "2601.04011v1": {
          "score": 1.2482553971590629,
          "rank": 21
        },
        "2601.04509v1": {
          "score": 1.2477514632335258,
          "rank": 22
        },
        "2601.04842v1": {
          "score": 1.2443538454328427,
          "rank": 23
        },
        "2601.04462v1": {
          "score": 1.2217188669134231,
          "rank": 24
        },
        "2601.03584v1": {
          "score": 1.2200099498611447,
          "rank": 25
        },
        "2601.03850v1": {
          "score": 1.2121295008602218,
          "rank": 26
        },
        "2601.04282v1": {
          "score": 1.206537880452296,
          "rank": 27
        },
        "2601.03520v1": {
          "score": 1.1777336801223437,
          "rank": 28
        },
        "2601.03714v2": {
          "score": 1.1513502157550035,
          "rank": 29
        },
        "2601.04640v1": {
          "score": 1.1499636153261867,
          "rank": 30
        },
        "2601.04912v1": {
          "score": 1.1425585457033967,
          "rank": 31
        },
        "2601.05063v1": {
          "score": 1.1385456057156513,
          "rank": 32
        },
        "2601.04445v1": {
          "score": 1.1262059374979372,
          "rank": 33
        },
        "2601.03875v1": {
          "score": 1.1197261241706993,
          "rank": 34
        },
        "2601.04400v1": {
          "score": 1.1180065298101711,
          "rank": 35
        },
        "2601.04676v1": {
          "score": 1.104552378844384,
          "rank": 36
        },
        "2601.04783v1": {
          "score": 1.1038829139599167,
          "rank": 37
        },
        "2601.04720v1": {
          "score": 1.0891055191970944,
          "rank": 38
        },
        "2601.04293v1": {
          "score": 1.0785426547892123,
          "rank": 39
        },
        "2601.03686v1": {
          "score": 1.0725861690117355,
          "rank": 40
        },
        "2601.04279v1": {
          "score": 1.0620004345434382,
          "rank": 41
        },
        "2601.03633v1": {
          "score": 1.0561128992429114,
          "rank": 42
        },
        "2601.04361v1": {
          "score": 1.0476165590931399,
          "rank": 43
        },
        "2601.04290v1": {
          "score": 1.040861604207544,
          "rank": 44
        },
        "2601.03566v1": {
          "score": 1.031691582428843,
          "rank": 45
        },
        "2601.03924v1": {
          "score": 1.030723131561237,
          "rank": 46
        },
        "2601.04530v1": {
          "score": 1.0296421507878033,
          "rank": 47
        },
        "2601.04707v1": {
          "score": 1.0258293016977302,
          "rank": 48
        },
        "2601.03646v2": {
          "score": 1.0243027304757546,
          "rank": 49
        },
        "2601.04390v1": {
          "score": 1.0203342185029733,
          "rank": 50
        },
        "2601.04520v1": {
          "score": 1.0109013077576339,
          "rank": 51
        },
        "2601.03955v1": {
          "score": 1.009932865218105,
          "rank": 52
        },
        "2601.04773v1": {
          "score": 0.9962877696396071,
          "rank": 53
        },
        "2601.03870v1": {
          "score": 0.9926238858983534,
          "rank": 54
        },
        "2601.03884v1": {
          "score": 0.9897947525735051,
          "rank": 55
        },
        "2601.04705v1": {
          "score": 0.9885584251412609,
          "rank": 56
        },
        "2601.03759v1": {
          "score": 0.9877472518520043,
          "rank": 57
        },
        "2601.05150v1": {
          "score": 0.9801612929362773,
          "rank": 58
        },
        "2601.03639v1": {
          "score": 0.97099702205339,
          "rank": 59
        },
        "2601.03830v1": {
          "score": 0.9618658414512549,
          "rank": 60
        },
        "2601.03910v1": {
          "score": 0.961537994430856,
          "rank": 61
        },
        "2601.04268v1": {
          "score": 0.9588437290529661,
          "rank": 62
        },
        "2601.04592v1": {
          "score": 0.9545043556289152,
          "rank": 63
        },
        "2601.04496v1": {
          "score": 0.931433456371479,
          "rank": 64
        },
        "2601.04768v1": {
          "score": 0.9302911264502878,
          "rank": 65
        },
        "2601.04813v1": {
          "score": 0.9271980835511293,
          "rank": 66
        },
        "2601.04867v1": {
          "score": 0.9269882616484597,
          "rank": 67
        },
        "2601.03495v1": {
          "score": 0.9182297501610015,
          "rank": 68
        },
        "2601.03610v1": {
          "score": 0.91499256664803,
          "rank": 69
        },
        "2601.04602v1": {
          "score": 0.9014087839041336,
          "rank": 70
        },
        "2601.04032v1": {
          "score": 0.898495890993041,
          "rank": 71
        },
        "2601.04939v1": {
          "score": 0.8930800726563601,
          "rank": 72
        },
        "2601.04518v1": {
          "score": 0.8845241217057481,
          "rank": 73
        },
        "2601.04881v1": {
          "score": 0.8839119462423571,
          "rank": 74
        },
        "2601.03668v1": {
          "score": 0.8834542385649301,
          "rank": 75
        },
        "2601.03683v1": {
          "score": 0.8831663203680971,
          "rank": 76
        },
        "2601.03853v1": {
          "score": 0.8791217051966846,
          "rank": 77
        },
        "2601.05241v1": {
          "score": 0.8783073456189912,
          "rank": 78
        },
        "2601.04401v1": {
          "score": 0.8778843451637073,
          "rank": 79
        },
        "2601.04065v1": {
          "score": 0.8763005594556953,
          "rank": 80
        },
        "2601.04862v1": {
          "score": 0.8712431656780986,
          "rank": 81
        },
        "2601.04057v1": {
          "score": 0.8673645408820894,
          "rank": 82
        },
        "2601.03603v1": {
          "score": 0.8657115811748781,
          "rank": 83
        },
        "2601.05202v1": {
          "score": 0.8630806927944623,
          "rank": 84
        },
        "2601.04428v1": {
          "score": 0.8539709057887774,
          "rank": 85
        },
        "2601.03517v1": {
          "score": 0.849864122947245,
          "rank": 86
        },
        "2601.03483v1": {
          "score": 0.8432345429551824,
          "rank": 87
        },
        "2601.03712v2": {
          "score": 0.8424408385446858,
          "rank": 88
        },
        "2601.04728v1": {
          "score": 0.8418075462293062,
          "rank": 89
        },
        "2601.04259v1": {
          "score": 0.8409829374444722,
          "rank": 90
        },
        "2601.03682v1": {
          "score": 0.8406164129924969,
          "rank": 91
        },
        "2601.03976v1": {
          "score": 0.8405844392421387,
          "rank": 92
        },
        "2601.03676v1": {
          "score": 0.8356157556636982,
          "rank": 93
        },
        "2601.04120v1": {
          "score": 0.8276111760470131,
          "rank": 94
        },
        "2601.05084v1": {
          "score": 0.8205753700646865,
          "rank": 95
        },
        "2601.03927v1": {
          "score": 0.8197208962367786,
          "rank": 96
        },
        "2601.03876v1": {
          "score": 0.8160312486180645,
          "rank": 97
        },
        "2601.04378v1": {
          "score": 0.813017839877196,
          "rank": 98
        },
        "2601.04506v1": {
          "score": 0.8121635929694186,
          "rank": 99
        },
        "2601.03774v1": {
          "score": 0.81070860756289,
          "rank": 100
        }
      }
    },
    {
      "type": "keyword",
      "alias": "resnet中文",
      "tag": "keyword:resnet中文",
      "query_text": "残差神经网络",
      "sim_scores": {
        "2601.04270v1": {
          "score": 1.3733954863395494,
          "rank": 1
        },
        "2601.04668v1": {
          "score": 1.2889388999457174,
          "rank": 2
        },
        "2601.04519v1": {
          "score": 1.2847687568828488,
          "rank": 3
        },
        "2601.05227v1": {
          "score": 1.1958734135605003,
          "rank": 4
        },
        "2601.04676v1": {
          "score": 1.1881397353418932,
          "rank": 5
        },
        "2601.04069v1": {
          "score": 1.1689613865839035,
          "rank": 6
        },
        "2601.04640v1": {
          "score": 1.1499636153261867,
          "rank": 7
        },
        "2601.04783v1": {
          "score": 1.1038829139599167,
          "rank": 8
        },
        "2601.04293v1": {
          "score": 1.0785426547892123,
          "rank": 9
        },
        "2601.03822v1": {
          "score": 1.0701394335805345,
          "rank": 10
        },
        "2601.04290v1": {
          "score": 1.040861604207544,
          "rank": 11
        },
        "2601.04530v1": {
          "score": 1.0296421507878033,
          "rank": 12
        },
        "2601.03682v1": {
          "score": 1.026939862644472,
          "rank": 13
        },
        "2601.04390v1": {
          "score": 1.0203342185029733,
          "rank": 14
        },
        "2601.04282v1": {
          "score": 1.0147926965253173,
          "rank": 15
        },
        "2601.04520v1": {
          "score": 1.0109013077576339,
          "rank": 16
        },
        "2601.04896v1": {
          "score": 1.0048579785300422,
          "rank": 17
        },
        "2601.03870v1": {
          "score": 0.9926238858983534,
          "rank": 18
        },
        "2601.03759v1": {
          "score": 0.9877472518520043,
          "rank": 19
        },
        "2601.05150v1": {
          "score": 0.9801612929362773,
          "rank": 20
        },
        "2601.04716v1": {
          "score": 0.9766330828707822,
          "rank": 21
        },
        "2601.03639v1": {
          "score": 0.97099702205339,
          "rank": 22
        },
        "2601.04127v1": {
          "score": 0.9453859849909487,
          "rank": 23
        },
        "2601.05249v1": {
          "score": 0.941057475048738,
          "rank": 24
        },
        "2601.04768v1": {
          "score": 0.9302911264502878,
          "rank": 25
        },
        "2601.04842v1": {
          "score": 0.8919225265322284,
          "rank": 26
        },
        "2601.05241v1": {
          "score": 0.8783073456189912,
          "rank": 27
        },
        "2601.04775v1": {
          "score": 0.8761186996461412,
          "rank": 28
        },
        "2601.05063v1": {
          "score": 0.8756834337788497,
          "rank": 29
        },
        "2601.05202v1": {
          "score": 0.8630806927944623,
          "rank": 30
        },
        "2601.03584v1": {
          "score": 0.8613504345765898,
          "rank": 31
        },
        "2601.04766v1": {
          "score": 0.8589378075496487,
          "rank": 32
        },
        "2601.03914v1": {
          "score": 0.8577340450624465,
          "rank": 33
        },
        "2601.03712v2": {
          "score": 0.8424408385446858,
          "rank": 34
        },
        "2601.04259v1": {
          "score": 0.8409829374444722,
          "rank": 35
        },
        "2601.03520v1": {
          "score": 0.8288397489271061,
          "rank": 36
        },
        "2601.04279v1": {
          "score": 0.8278903696643993,
          "rank": 37
        },
        "2601.03566v1": {
          "score": 0.8190874704348969,
          "rank": 38
        },
        "2601.04710v1": {
          "score": 0.8178567560678439,
          "rank": 39
        },
        "2601.03876v1": {
          "score": 0.8160312486180645,
          "rank": 40
        },
        "2601.04064v2": {
          "score": 0.806444831464785,
          "rank": 41
        },
        "2601.03924v1": {
          "score": 0.8044436124598587,
          "rank": 42
        },
        "2601.04117v1": {
          "score": 0.7947560348355126,
          "rank": 43
        },
        "2601.05090v1": {
          "score": 0.7921480219813393,
          "rank": 44
        },
        "2601.04551v1": {
          "score": 0.79063096663846,
          "rank": 45
        },
        "2601.04325v1": {
          "score": 0.7867066546031682,
          "rank": 46
        },
        "2601.03686v1": {
          "score": 0.7785220392730261,
          "rank": 47
        },
        "2601.04400v1": {
          "score": 0.773400640798471,
          "rank": 48
        },
        "2601.03875v1": {
          "score": 0.7718051371509743,
          "rank": 49
        },
        "2601.04535v1": {
          "score": 0.7695374309870842,
          "rank": 50
        },
        "2601.04109v2": {
          "score": 0.7676378078491491,
          "rank": 51
        },
        "2601.03655v1": {
          "score": 0.7495698530461341,
          "rank": 52
        },
        "2601.04747v1": {
          "score": 0.7451163865968624,
          "rank": 53
        },
        "2601.04744v1": {
          "score": 0.7390958369017253,
          "rank": 54
        },
        "2601.04532v1": {
          "score": 0.7376197799257951,
          "rank": 55
        },
        "2601.04059v1": {
          "score": 0.7293612288896014,
          "rank": 56
        },
        "2601.04912v1": {
          "score": 0.7278713750992335,
          "rank": 57
        },
        "2601.05127v1": {
          "score": 0.7272738494071929,
          "rank": 58
        },
        "2601.04700v1": {
          "score": 0.7271656283998681,
          "rank": 59
        },
        "2601.03769v2": {
          "score": 0.7221490867413012,
          "rank": 60
        },
        "2601.04419v1": {
          "score": 0.7202598210800524,
          "rank": 61
        },
        "2601.04067v1": {
          "score": 0.7168482950939101,
          "rank": 62
        },
        "2601.05210v1": {
          "score": 0.7128068124510774,
          "rank": 63
        },
        "2601.03612v1": {
          "score": 0.7121711131672392,
          "rank": 64
        },
        "2601.03923v1": {
          "score": 0.709682554921517,
          "rank": 65
        },
        "2601.04614v1": {
          "score": 0.7094159693586994,
          "rank": 66
        },
        "2601.05056v1": {
          "score": 0.706370634768008,
          "rank": 67
        },
        "2601.04885v1": {
          "score": 0.7033110284960609,
          "rank": 68
        },
        "2601.04386v1": {
          "score": 0.7027501970631077,
          "rank": 69
        },
        "2601.03721v1": {
          "score": 0.701242487103638,
          "rank": 70
        },
        "2601.03661v1": {
          "score": 0.7007667009768269,
          "rank": 71
        },
        "2601.04852v1": {
          "score": 0.6984202982522278,
          "rank": 72
        },
        "2601.04879v1": {
          "score": 0.6935758502555699,
          "rank": 73
        },
        "2601.03551v2": {
          "score": 0.6918623834204485,
          "rank": 74
        },
        "2601.05130v1": {
          "score": 0.6900304032184617,
          "rank": 75
        },
        "2601.05126v1": {
          "score": 0.6881493043911845,
          "rank": 76
        },
        "2601.04429v1": {
          "score": 0.6867882468389324,
          "rank": 77
        },
        "2601.03913v1": {
          "score": 0.6855152358105638,
          "rank": 78
        },
        "2601.03481v1": {
          "score": 0.6692921274968674,
          "rank": 79
        },
        "2601.03555v1": {
          "score": 0.6685806049316521,
          "rank": 80
        },
        "2601.04764v1": {
          "score": 0.6685595857809824,
          "rank": 81
        },
        "2601.04269v1": {
          "score": 0.666955022473126,
          "rank": 82
        },
        "2601.03937v1": {
          "score": 0.6658213709421503,
          "rank": 83
        },
        "2601.04065v1": {
          "score": 0.659503707117079,
          "rank": 84
        },
        "2601.03495v1": {
          "score": 0.6569295785878242,
          "rank": 85
        },
        "2601.04333v1": {
          "score": 0.6555776985384499,
          "rank": 86
        },
        "2601.04918v1": {
          "score": 0.6544979149517084,
          "rank": 87
        },
        "2601.04146v1": {
          "score": 0.6482842012419423,
          "rank": 88
        },
        "2601.04268v1": {
          "score": 0.6479421757907874,
          "rank": 89
        },
        "2601.04782v1": {
          "score": 0.6446936073164965,
          "rank": 90
        },
        "2601.04727v1": {
          "score": 0.6343119440136117,
          "rank": 91
        },
        "2601.03474v1": {
          "score": 0.6323803365250735,
          "rank": 92
        },
        "2601.03633v1": {
          "score": 0.6320353560933301,
          "rank": 93
        },
        "2601.04983v1": {
          "score": 0.6294017919004464,
          "rank": 94
        },
        "2601.05192v1": {
          "score": 0.626163641290298,
          "rank": 95
        },
        "2601.04702v1": {
          "score": 0.6249860404539209,
          "rank": 96
        },
        "2601.03847v1": {
          "score": 0.6211051399216528,
          "rank": 97
        },
        "2601.03683v1": {
          "score": 0.6206963966585034,
          "rank": 98
        },
        "2601.04867v1": {
          "score": 0.6206318173164243,
          "rank": 99
        },
        "2601.03927v1": {
          "score": 0.6169218586432073,
          "rank": 100
        }
      }
    },
    {
      "type": "llm_query",
      "alias": "sr-bench",
      "tag": "query:sr-bench",
      "query_text": "我希望找一些跟符号回归相关的论文，我是做benchmark的希望找一些benchmark和符号回归结合的论文",
      "sim_scores": {
        "2601.03986v1": {
          "score": 10.532478772772613,
          "rank": 1
        },
        "2601.03496v1": {
          "score": 9.609397488998063,
          "rank": 2
        },
        "2601.04643v1": {
          "score": 9.542291328416917,
          "rank": 3
        },
        "2601.04824v1": {
          "score": 8.99788487704331,
          "rank": 4
        },
        "2601.03783v1": {
          "score": 8.892265130024619,
          "rank": 5
        },
        "2601.03708v1": {
          "score": 8.882216862508496,
          "rank": 6
        },
        "2601.04160v2": {
          "score": 8.78236386082085,
          "rank": 7
        },
        "2601.04925v1": {
          "score": 8.542285055805936,
          "rank": 8
        },
        "2601.03543v1": {
          "score": 8.530625197845225,
          "rank": 9
        },
        "2601.03670v1": {
          "score": 8.3818931112608,
          "rank": 10
        },
        "2601.04693v1": {
          "score": 8.380879364803638,
          "rank": 11
        },
        "2601.03926v1": {
          "score": 8.292916119827227,
          "rank": 12
        },
        "2601.05101v1": {
          "score": 8.141669008112215,
          "rank": 13
        },
        "2601.03736v1": {
          "score": 7.975432649887117,
          "rank": 14
        },
        "2601.04758v1": {
          "score": 7.84528254206958,
          "rank": 15
        },
        "2601.04540v1": {
          "score": 7.776945835853948,
          "rank": 16
        },
        "2601.03640v1": {
          "score": 7.559734995858514,
          "rank": 17
        },
        "2601.04695v1": {
          "score": 7.451573141230392,
          "rank": 18
        },
        "2601.03531v1": {
          "score": 7.438270143598904,
          "rank": 19
        },
        "2601.03780v1": {
          "score": 7.236644661180436,
          "rank": 20
        },
        "2601.04474v1": {
          "score": 7.120472713937808,
          "rank": 21
        },
        "2601.05039v1": {
          "score": 7.000829539373992,
          "rank": 22
        },
        "2601.03940v1": {
          "score": 7.000829539373992,
          "rank": 23
        },
        "2601.03733v1": {
          "score": 6.907971475553183,
          "rank": 24
        },
        "2601.04043v1": {
          "score": 6.885140580306216,
          "rank": 25
        },
        "2601.03997v2": {
          "score": 6.885140580306216,
          "rank": 26
        },
        "2601.03590v1": {
          "score": 6.873781631522538,
          "rank": 27
        },
        "2601.04876v1": {
          "score": 6.851175802595169,
          "rank": 28
        },
        "2601.04887v1": {
          "score": 6.718602850918353,
          "rank": 29
        },
        "2601.04895v1": {
          "score": 6.601506249109692,
          "rank": 30
        },
        "2601.05187v1": {
          "score": 6.549619233286449,
          "rank": 31
        },
        "2601.04589v1": {
          "score": 6.518876698569853,
          "rank": 32
        },
        "2601.03849v1": {
          "score": 6.428356637753601,
          "rank": 33
        },
        "2601.04408v1": {
          "score": 6.26235959991332,
          "rank": 34
        },
        "2601.04566v1": {
          "score": 6.171276610064398,
          "rank": 35
        },
        "2601.04922v1": {
          "score": 6.133300136931105,
          "rank": 36
        },
        "2601.03848v1": {
          "score": 6.133300136931105,
          "rank": 37
        },
        "2601.03707v1": {
          "score": 6.06191242529379,
          "rank": 38
        },
        "2601.03912v1": {
          "score": 5.97498120037252,
          "rank": 39
        },
        "2601.04745v1": {
          "score": 5.712821013996741,
          "rank": 40
        },
        "2601.03915v1": {
          "score": 5.697197759542314,
          "rank": 41
        },
        "2601.03605v1": {
          "score": 5.635550015517181,
          "rank": 42
        },
        "2601.03627v2": {
          "score": 5.620345977288028,
          "rank": 43
        },
        "2601.03981v1": {
          "score": 5.56034143925584,
          "rank": 44
        },
        "2601.04172v1": {
          "score": 5.530817089178655,
          "rank": 45
        },
        "2601.05073v1": {
          "score": 5.516172179303341,
          "rank": 46
        },
        "2601.03699v1": {
          "score": 5.4726991169778785,
          "rank": 47
        },
        "2601.03505v1": {
          "score": 5.458359969260627,
          "rank": 48
        },
        "2601.05083v1": {
          "score": 5.444095765856623,
          "rank": 49
        },
        "2601.04719v1": {
          "score": 5.444095765856623,
          "rank": 50
        },
        "2601.04506v1": {
          "score": 5.429905920746679,
          "rank": 51
        },
        "2601.04960v1": {
          "score": 5.415789854005473,
          "rank": 52
        },
        "2601.03906v1": {
          "score": 5.415789854005473,
          "rank": 53
        },
        "2601.04673v1": {
          "score": 5.318995711186367,
          "rank": 54
        },
        "2601.04025v1": {
          "score": 5.318995711186367,
          "rank": 55
        },
        "2601.04367v1": {
          "score": 5.291972509102451,
          "rank": 56
        },
        "2601.03850v1": {
          "score": 5.291972509102451,
          "rank": 57
        },
        "2601.04699v1": {
          "score": 5.265222502255108,
          "rank": 58
        },
        "2601.04389v1": {
          "score": 5.251948655663949,
          "rank": 59
        },
        "2601.03922v1": {
          "score": 5.251948655663949,
          "rank": 60
        },
        "2601.03743v1": {
          "score": 5.238741568616298,
          "rank": 61
        },
        "2601.04131v1": {
          "score": 5.2256007387343635,
          "rank": 62
        },
        "2601.05091v1": {
          "score": 5.212525668668389,
          "rank": 63
        },
        "2601.03637v2": {
          "score": 5.212525668668389,
          "rank": 64
        },
        "2601.03731v1": {
          "score": 5.1736901179780475,
          "rank": 65
        },
        "2601.04794v1": {
          "score": 5.122800702999891,
          "rank": 66
        },
        "2601.03540v1": {
          "score": 5.122800702999891,
          "rank": 67
        },
        "2601.03483v1": {
          "score": 5.097729576785932,
          "rank": 68
        },
        "2601.05116v1": {
          "score": 5.07290265298823,
          "rank": 69
        },
        "2601.05076v1": {
          "score": 5.07290265298823,
          "rank": 70
        },
        "2601.04842v1": {
          "score": 5.060579654723261,
          "rank": 71
        },
        "2601.03774v1": {
          "score": 5.060579654723261,
          "rank": 72
        },
        "2601.03566v1": {
          "score": 5.036112398560524,
          "rank": 73
        },
        "2601.04638v1": {
          "score": 5.023967278559993,
          "rank": 74
        },
        "2601.04339v1": {
          "score": 5.023967278559993,
          "rank": 75
        },
        "2601.04120v1": {
          "score": 5.023967278559993,
          "rank": 76
        },
        "2601.03660v1": {
          "score": 5.023967278559993,
          "rank": 77
        },
        "2601.03515v1": {
          "score": 5.011880596125009,
          "rank": 78
        },
        "2601.03578v1": {
          "score": 4.999851930499782,
          "rank": 79
        },
        "2601.04855v1": {
          "score": 4.987880864958148,
          "rank": 80
        },
        "2601.03655v1": {
          "score": 4.975966986755458,
          "rank": 81
        },
        "2601.04390v1": {
          "score": 4.928875229156381,
          "rank": 82
        },
        "2601.04732v1": {
          "score": 4.9172412325485,
          "rank": 83
        },
        "2601.05205v1": {
          "score": 4.905662027813638,
          "rank": 84
        },
        "2601.04574v1": {
          "score": 4.905662027813638,
          "rank": 85
        },
        "2601.04564v1": {
          "score": 4.871249321254518,
          "rank": 86
        },
        "2601.03792v1": {
          "score": 4.871249321254518,
          "rank": 87
        },
        "2601.04770v1": {
          "score": 4.848574492279772,
          "rank": 88
        },
        "2601.04646v1": {
          "score": 4.837316054556695,
          "rank": 89
        },
        "2601.04500v1": {
          "score": 4.826109780116506,
          "rank": 90
        },
        "2601.03481v1": {
          "score": 4.814955307267942,
          "rank": 91
        },
        "2601.05215v1": {
          "score": 4.803852277655894,
          "rank": 92
        },
        "2601.04897v1": {
          "score": 4.803852277655894,
          "rank": 93
        },
        "2601.05011v1": {
          "score": 4.792800336223043,
          "rank": 94
        },
        "2601.03741v1": {
          "score": 4.792800336223043,
          "rank": 95
        },
        "2601.04345v1": {
          "score": 4.792800336223043,
          "rank": 96
        },
        "2601.05150v1": {
          "score": 4.759947539102101,
          "rank": 97
        },
        "2601.03858v1": {
          "score": 4.759947539102101,
          "rank": 98
        },
        "2601.04755v1": {
          "score": 4.749096464454757,
          "rank": 99
        },
        "2601.04996v1": {
          "score": 4.738294750860158,
          "rank": 100
        }
      }
    },
    {
      "type": "llm_query",
      "alias": "大厂llm",
      "tag": "query:大厂llm",
      "query_text": "我希望找一些大厂出的大模型技术论文或者技术报告",
      "sim_scores": {
        "2601.05251v1": {
          "score": 0.0,
          "rank": 1
        },
        "2601.05249v1": {
          "score": 0.0,
          "rank": 2
        },
        "2601.05250v1": {
          "score": 0.0,
          "rank": 3
        },
        "2601.05248v1": {
          "score": 0.0,
          "rank": 4
        },
        "2601.05247v1": {
          "score": 0.0,
          "rank": 5
        },
        "2601.05246v1": {
          "score": 0.0,
          "rank": 6
        },
        "2601.05245v1": {
          "score": 0.0,
          "rank": 7
        },
        "2601.05244v1": {
          "score": 0.0,
          "rank": 8
        },
        "2601.05243v1": {
          "score": 0.0,
          "rank": 9
        },
        "2601.05242v1": {
          "score": 0.0,
          "rank": 10
        },
        "2601.05241v1": {
          "score": 0.0,
          "rank": 11
        },
        "2601.05240v1": {
          "score": 0.0,
          "rank": 12
        },
        "2601.05239v1": {
          "score": 0.0,
          "rank": 13
        },
        "2601.05237v1": {
          "score": 0.0,
          "rank": 14
        },
        "2601.05232v1": {
          "score": 0.0,
          "rank": 15
        },
        "2601.05230v1": {
          "score": 0.0,
          "rank": 16
        },
        "2601.05227v1": {
          "score": 0.0,
          "rank": 17
        },
        "2601.05225v1": {
          "score": 0.0,
          "rank": 18
        },
        "2601.05219v1": {
          "score": 0.0,
          "rank": 19
        },
        "2601.05217v1": {
          "score": 0.0,
          "rank": 20
        },
        "2601.05215v1": {
          "score": 0.0,
          "rank": 21
        },
        "2601.05214v1": {
          "score": 0.0,
          "rank": 22
        },
        "2601.05212v1": {
          "score": 0.0,
          "rank": 23
        },
        "2601.05208v1": {
          "score": 0.0,
          "rank": 24
        },
        "2601.05205v1": {
          "score": 0.0,
          "rank": 25
        },
        "2601.05202v1": {
          "score": 0.0,
          "rank": 26
        },
        "2601.05201v1": {
          "score": 0.0,
          "rank": 27
        },
        "2601.05200v1": {
          "score": 0.0,
          "rank": 28
        },
        "2601.05199v1": {
          "score": 0.0,
          "rank": 29
        },
        "2601.05195v1": {
          "score": 0.0,
          "rank": 30
        },
        "2601.05194v1": {
          "score": 0.0,
          "rank": 31
        },
        "2601.05192v1": {
          "score": 0.0,
          "rank": 32
        },
        "2601.05191v1": {
          "score": 0.0,
          "rank": 33
        },
        "2601.05187v1": {
          "score": 0.0,
          "rank": 34
        },
        "2601.05184v1": {
          "score": 0.0,
          "rank": 35
        },
        "2601.05181v1": {
          "score": 0.0,
          "rank": 36
        },
        "2601.05180v1": {
          "score": 0.0,
          "rank": 37
        },
        "2601.05175v1": {
          "score": 0.0,
          "rank": 38
        },
        "2601.05174v1": {
          "score": 0.0,
          "rank": 39
        },
        "2601.05173v1": {
          "score": 0.0,
          "rank": 40
        },
        "2601.05172v1": {
          "score": 0.0,
          "rank": 41
        },
        "2601.05171v1": {
          "score": 0.0,
          "rank": 42
        },
        "2601.05170v1": {
          "score": 0.0,
          "rank": 43
        },
        "2601.05167v1": {
          "score": 0.0,
          "rank": 44
        },
        "2601.05166v1": {
          "score": 0.0,
          "rank": 45
        },
        "2601.05165v1": {
          "score": 0.0,
          "rank": 46
        },
        "2601.05163v1": {
          "score": 0.0,
          "rank": 47
        },
        "2601.05162v1": {
          "score": 0.0,
          "rank": 48
        },
        "2601.05159v1": {
          "score": 0.0,
          "rank": 49
        },
        "2601.05157v1": {
          "score": 0.0,
          "rank": 50
        },
        "2601.05152v1": {
          "score": 0.0,
          "rank": 51
        },
        "2601.05151v1": {
          "score": 0.0,
          "rank": 52
        },
        "2601.05150v1": {
          "score": 0.0,
          "rank": 53
        },
        "2601.05149v1": {
          "score": 0.0,
          "rank": 54
        },
        "2601.05148v1": {
          "score": 0.0,
          "rank": 55
        },
        "2601.05144v1": {
          "score": 0.0,
          "rank": 56
        },
        "2601.05143v1": {
          "score": 0.0,
          "rank": 57
        },
        "2601.05138v1": {
          "score": 0.0,
          "rank": 58
        },
        "2601.05137v1": {
          "score": 0.0,
          "rank": 59
        },
        "2601.05134v1": {
          "score": 0.0,
          "rank": 60
        },
        "2601.05127v1": {
          "score": 0.0,
          "rank": 61
        },
        "2601.05125v1": {
          "score": 0.0,
          "rank": 62
        },
        "2601.05124v1": {
          "score": 0.0,
          "rank": 63
        },
        "2601.05116v1": {
          "score": 0.0,
          "rank": 64
        },
        "2601.05114v1": {
          "score": 0.0,
          "rank": 65
        },
        "2601.05111v1": {
          "score": 0.0,
          "rank": 66
        },
        "2601.05110v1": {
          "score": 0.0,
          "rank": 67
        },
        "2601.05109v1": {
          "score": 0.0,
          "rank": 68
        },
        "2601.05108v1": {
          "score": 0.0,
          "rank": 69
        },
        "2601.05107v1": {
          "score": 0.0,
          "rank": 70
        },
        "2601.05106v1": {
          "score": 0.0,
          "rank": 71
        },
        "2601.05105v1": {
          "score": 0.0,
          "rank": 72
        },
        "2601.05104v1": {
          "score": 0.0,
          "rank": 73
        },
        "2601.05103v1": {
          "score": 0.0,
          "rank": 74
        },
        "2601.05101v1": {
          "score": 0.0,
          "rank": 75
        },
        "2601.05099v1": {
          "score": 0.0,
          "rank": 76
        },
        "2601.05098v1": {
          "score": 0.0,
          "rank": 77
        },
        "2601.05095v1": {
          "score": 0.0,
          "rank": 78
        },
        "2601.05093v1": {
          "score": 0.0,
          "rank": 79
        },
        "2601.05092v1": {
          "score": 0.0,
          "rank": 80
        },
        "2601.05091v1": {
          "score": 0.0,
          "rank": 81
        },
        "2601.05084v1": {
          "score": 0.0,
          "rank": 82
        },
        "2601.05083v1": {
          "score": 0.0,
          "rank": 83
        },
        "2601.05082v1": {
          "score": 0.0,
          "rank": 84
        },
        "2601.05081v1": {
          "score": 0.0,
          "rank": 85
        },
        "2601.05076v1": {
          "score": 0.0,
          "rank": 86
        },
        "2601.05075v1": {
          "score": 0.0,
          "rank": 87
        },
        "2601.05074v1": {
          "score": 0.0,
          "rank": 88
        },
        "2601.05073v1": {
          "score": 0.0,
          "rank": 89
        },
        "2601.05072v1": {
          "score": 0.0,
          "rank": 90
        },
        "2601.05065v1": {
          "score": 0.0,
          "rank": 91
        },
        "2601.05063v1": {
          "score": 0.0,
          "rank": 92
        },
        "2601.05062v1": {
          "score": 0.0,
          "rank": 93
        },
        "2601.05059v1": {
          "score": 0.0,
          "rank": 94
        },
        "2601.05057v1": {
          "score": 0.0,
          "rank": 95
        },
        "2601.05053v1": {
          "score": 0.0,
          "rank": 96
        },
        "2601.05052v1": {
          "score": 0.0,
          "rank": 97
        },
        "2601.05051v1": {
          "score": 0.0,
          "rank": 98
        },
        "2601.05050v1": {
          "score": 0.0,
          "rank": 99
        },
        "2601.05049v1": {
          "score": 0.0,
          "rank": 100
        }
      }
    }
  ]
}