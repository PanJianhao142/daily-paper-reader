{
  "mode": "standard",
  "generated_at": "2026-02-16T06:18:42.222233+00:00",
  "stats": {
    "mode": "standard",
    "tag_count": 3,
    "deep_divecandidates": 1,
    "deep_cap": 8,
    "deep_selected": 1,
    "quick_candidates": 6,
    "quick_skim_target": 13,
    "quick_selected": 6
  },
  "deep_dive": [
    {
      "id": "2602.12679v1",
      "title": "Motion Prior Distillation in Time Reversal Sampling for Generative Inbetweening",
      "abstract": "Recent progress in image-to-video (I2V) diffusion models has significantly advanced the field of generative inbetweening, which aims to generate semantically plausible frames between two keyframes. In particular, inference-time sampling strategies, which leverage the generative priors of large-scale pre-trained I2V models without additional training, have become increasingly popular. However, existing inference-time sampling, either fusing forward and backward paths in parallel or alternating them sequentially, often suffers from temporal discontinuities and undesirable visual artifacts due to the misalignment between the two generated paths. This is because each path follows the motion prior induced by its own conditioning frame. In this work, we propose Motion Prior Distillation (MPD), a simple yet effective inference-time distillation technique that suppresses bidirectional mismatch by distilling the motion residual of the forward path into the backward path. Our method can deliberately avoid denoising the end-conditioned path which causes the ambiguity of the path, and yield more temporally coherent inbetweening results with the forward motion prior. We not only perform quantitative evaluations on standard benchmarks, but also conduct extensive user studies to demonstrate the effectiveness of our approach in practical scenarios.",
      "authors": [
        "Wooseok Jeon",
        "Seunghyun Shin",
        "Dongmin Shin",
        "Hae-Gon Jeon"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-13 07:20:45+00:00",
      "link": "https://arxiv.org/pdf/2602.12679v1",
      "tags": [
        "keyword:FM",
        "keyword:MDM",
        "query:课题"
      ],
      "llm_score": 8.0,
      "llm_evidence_en": "Addresses generative inbetweening using diffusion models and motion priors",
      "llm_evidence_cn": "使用扩散模型和运动先验解决生成式插帧问题",
      "llm_evidence": "使用扩散模型和运动先验解决生成式插帧问题",
      "llm_tldr_en": "Improves generative inbetweening by distilling motion priors in time-reversal diffusion sampling.",
      "llm_tldr_cn": "通过在时间反转扩散采样中蒸馏运动先验，改进生成式动作插帧。",
      "llm_tldr": "通过在时间反转扩散采样中蒸馏运动先验，改进生成式动作插帧。",
      "llm_tags": [
        "keyword:MDM",
        "query:课题"
      ]
    }
  ],
  "quick_skim": [
    {
      "id": "2602.12734v1",
      "title": "Scaling Single Human Demonstrations for Imitation Learning using Generative Foundational Models",
      "abstract": "Imitation learning is a popular paradigm to teach robots new tasks, but collecting robot demonstrations through teleoperation or kinesthetic teaching is tedious and time-consuming. In contrast, directly demonstrating a task using our human embodiment is much easier and data is available in abundance, yet transfer to the robot can be non-trivial. In this work, we propose Real2Gen to train a manipulation policy from a single human demonstration. Real2Gen extracts required information from the demonstration and transfers it to a simulation environment, where a programmable expert agent can demonstrate the task arbitrarily many times, generating an unlimited amount of data to train a flow matching policy. We evaluate Real2Gen on human demonstrations from three different real-world tasks and compare it to a recent baseline. Real2Gen shows an average increase in the success rate of 26.6% and better generalization of the trained policy due to the abundance and diversity of training data. We further deploy our purely simulation-trained policy zero-shot in the real world. We make the data, code, and trained models publicly available at real2gen.cs.uni-freiburg.de.",
      "authors": [
        "Nick Heppert",
        "Minh Quang Nguyen",
        "Abhinav Valada"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-13 09:04:18+00:00",
      "link": "https://arxiv.org/pdf/2602.12734v1",
      "tags": [
        "keyword:FM",
        "keyword:MDM"
      ],
      "llm_score": 7.0,
      "llm_evidence_en": "Trains a flow matching policy for motion generation from human demonstrations",
      "llm_evidence_cn": "通过人类演示训练用于动作生成的流匹配策略",
      "llm_evidence": "通过人类演示训练用于动作生成的流匹配策略",
      "llm_tldr_en": "Uses generative models to scale human demonstrations for training flow matching robot policies.",
      "llm_tldr_cn": "利用生成模型扩展人类演示数据，用于训练流匹配机器人策略。",
      "llm_tldr": "利用生成模型扩展人类演示数据，用于训练流匹配机器人策略。",
      "llm_tags": [
        "keyword:FM",
        "query:课题"
      ],
      "quick_tier": "7"
    },
    {
      "id": "2602.12656v1",
      "title": "PMG: Parameterized Motion Generator for Human-like Locomotion Control",
      "abstract": "Recent advances in data-driven reinforcement learning and motion tracking have substantially improved humanoid locomotion, yet critical practical challenges remain. In particular, while low-level motion tracking and trajectory-following controllers are mature, whole-body reference-guided methods are difficult to adapt to higher-level command interfaces and diverse task contexts: they require large, high-quality datasets, are brittle across speed and pose regimes, and are sensitive to robot-specific calibration. To address these limitations, we propose the Parameterized Motion Generator (PMG), a real-time motion generator grounded in an analysis of human motion structure that synthesizes reference trajectories using only a compact set of parameterized motion data together with High-dimensional control commands. Combined with an imitation-learning pipeline and an optimization-based sim-to-real motor parameter identification module, we validate the complete approach on our humanoid prototype ZERITH Z1 and show that, within a single integrated system, PMG produces natural, human-like locomotion, responds precisely to high-dimensional control inputs-including VR-based teleoperation-and enables efficient, verifiable sim-to-real transfer. Together, these results establish a practical, experimentally validated pathway toward natural and deployable humanoid control.",
      "authors": [
        "Chenxi Han",
        "Yuheng Min",
        "Zihao Huang",
        "Ao Hong",
        "Hang Liu",
        "Yi Cheng",
        "Houde Liu"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "published": "2026-02-13 06:38:04+00:00",
      "link": "https://arxiv.org/pdf/2602.12656v1",
      "tags": [
        "keyword:FM",
        "keyword:MDM",
        "query:课题"
      ],
      "llm_score": 6.0,
      "llm_evidence_en": "Synthesizes human-like locomotion trajectories using parameterized motion structure",
      "llm_evidence_cn": "利用参数化运动结构合成类人运动轨迹",
      "llm_evidence": "利用参数化运动结构合成类人运动轨迹",
      "llm_tldr_en": "A real-time motion generator for humanoid locomotion grounded in human motion structure analysis.",
      "llm_tldr_cn": "一种基于人体运动结构分析的类人猿实时运动生成器。",
      "llm_tldr": "一种基于人体运动结构分析的类人猿实时运动生成器。",
      "llm_tags": [
        "query:课题"
      ],
      "quick_tier": "6"
    },
    {
      "id": "2602.12794v1",
      "title": "SafeFlowMPC: Predictive and Safe Trajectory Planning for Robot Manipulators with Learning-based Policies",
      "abstract": "The emerging integration of robots into everyday life brings several major challenges. Compared to classical industrial applications, more flexibility is needed in combination with real-time reactivity. Learning-based methods can train powerful policies based on demonstrated trajectories, such that the robot generalizes a task to similar situations. However, these black-box models lack interpretability and rigorous safety guarantees. Optimization-based methods provide these guarantees but lack the required flexibility and generalization capabilities. This work proposes SafeFlowMPC, a combination of flow matching and online optimization to combine the strengths of learning and optimization. This method guarantees safety at all times and is designed to meet the demands of real-time execution by using a suboptimal model-predictive control formulation. SafeFlowMPC achieves strong performance in three real-world experiments on a KUKA 7-DoF manipulator, namely two grasping experiment and a dynamic human-robot object handover experiment. A video of the experiments is available at http://www.acin.tuwien.ac.at/42d6. The code is available at https://github.com/TU-Wien-ACIN-CDS/SafeFlowMPC.",
      "authors": [
        "Thies Oelerich",
        "Gerald Ebmer",
        "Christian Hartl-Nesic",
        "Andreas Kugi"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-13 10:23:43+00:00",
      "link": "https://arxiv.org/pdf/2602.12794v1",
      "tags": [
        "keyword:FM"
      ],
      "llm_score": 6.0,
      "llm_evidence_en": "Uses flow matching for trajectory planning and learning-based policies",
      "llm_evidence_cn": "使用流匹配进行轨迹规划和基于学习的策略",
      "llm_evidence": "使用流匹配进行轨迹规划和基于学习的策略",
      "llm_tldr_en": "Combines flow matching with online optimization for safe robot manipulator trajectory planning.",
      "llm_tldr_cn": "结合流匹配与在线优化，实现机器人机械臂的安全轨迹规划。",
      "llm_tldr": "结合流匹配与在线优化，实现机器人机械臂的安全轨迹规划。",
      "llm_tags": [
        "keyword:FM"
      ],
      "quick_tier": "6"
    },
    {
      "id": "2602.12829v1",
      "title": "FLAC: Maximum Entropy RL via Kinetic Energy Regularized Bridge Matching",
      "abstract": "Iterative generative policies, such as diffusion models and flow matching, offer superior expressivity for continuous control but complicate Maximum Entropy Reinforcement Learning because their action log-densities are not directly accessible. To address this, we propose Field Least-Energy Actor-Critic (FLAC), a likelihood-free framework that regulates policy stochasticity by penalizing the kinetic energy of the velocity field. Our key insight is to formulate policy optimization as a Generalized Schrödinger Bridge (GSB) problem relative to a high-entropy reference process (e.g., uniform). Under this view, the maximum-entropy principle emerges naturally as staying close to a high-entropy reference while optimizing return, without requiring explicit action densities. In this framework, kinetic energy serves as a physically grounded proxy for divergence from the reference: minimizing path-space energy bounds the deviation of the induced terminal action distribution. Building on this view, we derive an energy-regularized policy iteration scheme and a practical off-policy algorithm that automatically tunes the kinetic energy via a Lagrangian dual mechanism. Empirically, FLAC achieves superior or comparable performance on high-dimensional benchmarks relative to strong baselines, while avoiding explicit density estimation.",
      "authors": [
        "Lei Lv",
        "Yunfei Li",
        "Yu Luo",
        "Fuchun Sun",
        "Xiao Ma"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-13 11:32:10+00:00",
      "link": "https://arxiv.org/pdf/2602.12829v1",
      "tags": [
        "keyword:FM",
        "keyword:MDM"
      ],
      "llm_score": 6.0,
      "llm_evidence_en": "Utilizes flow matching and diffusion for continuous control policies",
      "llm_evidence_cn": "利用流匹配和扩散模型进行连续控制策略",
      "llm_evidence": "利用流匹配和扩散模型进行连续控制策略",
      "llm_tldr_en": "Proposes FLAC, a likelihood-free RL framework using kinetic energy regularized bridge matching for expressivity.",
      "llm_tldr_cn": "提出FLAC框架，利用动能正则化桥接匹配实现高表达力的强化学习策略。",
      "llm_tldr": "提出FLAC框架，利用动能正则化桥接匹配实现高表达力的强化学习策略。",
      "llm_tags": [
        "keyword:FM",
        "keyword:MDM"
      ],
      "quick_tier": "6"
    },
    {
      "id": "2602.12978v1",
      "title": "Learning Native Continuation for Action Chunking Flow Policies",
      "abstract": "Action chunking enables Vision Language Action (VLA) models to run in real time, but naive chunked execution often exhibits discontinuities at chunk boundaries. Real-Time Chunking (RTC) alleviates this issue but is external to the policy, leading to spurious multimodal switching and trajectories that are not intrinsically smooth. We propose Legato, a training-time continuation method for action-chunked flow-based VLA policies. Specifically, Legato initializes denoising from a schedule-shaped mixture of known actions and noise, exposing the model to partial action information. Moreover, Legato reshapes the learned flow dynamics to ensure that the denoising process remains consistent between training and inference under per-step guidance. Legato further uses randomized schedule condition during training to support varying inference delays and achieve controllable smoothness. Empirically, Legato produces smoother trajectories and reduces spurious multimodal switching during execution, leading to less hesitation and shorter task completion time. Extensive real-world experiments show that Legato consistently outperforms RTC across five manipulation tasks, achieving approximately 10% improvements in both trajectory smoothness and task completion time.",
      "authors": [
        "Yufeng Liu",
        "Hang Yu",
        "Juntu Zhao",
        "Bocheng Li",
        "Di Zhang",
        "Mingzhu Li",
        "Wenxuan Wu",
        "Yingdong Hu",
        "Junyuan Xie",
        "Junliang Guo",
        "Dequan Wang",
        "Yang Gao"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "published": "2026-02-13 14:56:06+00:00",
      "link": "https://arxiv.org/pdf/2602.12978v1",
      "tags": [
        "keyword:FM",
        "keyword:MDM",
        "query:课题"
      ],
      "llm_score": 6.0,
      "llm_evidence_en": "flow-based policies for action chunking and motion smoothness",
      "llm_evidence_cn": "用于动作分块和运动平滑度的流匹配策略",
      "llm_evidence": "用于动作分块和运动平滑度的流匹配策略",
      "llm_tldr_en": "Introduces Legato, a training method for flow-based policies to ensure smooth action continuation in VLA models.",
      "llm_tldr_cn": "引入Legato，一种针对流匹配策略的训练方法，确保VLA模型中动作衔接的平滑性。",
      "llm_tldr": "引入Legato，一种针对流匹配策略的训练方法，确保VLA模型中动作衔接的平滑性。",
      "llm_tags": [
        "keyword:FM",
        "query:课题"
      ],
      "quick_tier": "6"
    },
    {
      "id": "2602.13061v1",
      "title": "Diverging Flows: Detecting Extrapolations in Conditional Generation",
      "abstract": "The ability of Flow Matching (FM) to model complex conditional distributions has established it as the state-of-the-art for prediction tasks (e.g., robotics, weather forecasting). However, deployment in safety-critical settings is hindered by a critical extrapolation hazard: driven by smoothness biases, flow models yield plausible outputs even for off-manifold conditions, resulting in silent failures indistinguishable from valid predictions. In this work, we introduce Diverging Flows, a novel approach that enables a single model to simultaneously perform conditional generation and native extrapolation detection by structurally enforcing inefficient transport for off-manifold inputs. We evaluate our method on synthetic manifolds, cross-domain style transfer, and weather temperature forecasting, demonstrating that it achieves effective detection of extrapolations without compromising predictive fidelity or inference latency. These results establish Diverging Flows as a robust solution for trustworthy flow models, paving the way for reliable deployment in domains such as medicine, robotics, and climate science.",
      "authors": [
        "Constantinos Tsakonas",
        "Serena Ivaldi",
        "Jean-Baptiste Mouret"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "published": "2026-02-13 16:15:58+00:00",
      "link": "https://arxiv.org/pdf/2602.13061v1",
      "tags": [
        "keyword:FM",
        "keyword:MDM",
        "query:课题"
      ],
      "llm_score": 6.0,
      "llm_evidence_en": "Flow Matching for prediction tasks and extrapolation detection",
      "llm_evidence_cn": "用于预测任务和外推检测的流匹配技术",
      "llm_evidence": "用于预测任务和外推检测的流匹配技术",
      "llm_tldr_en": "Introduces Diverging Flows to detect silent failures in Flow Matching models during prediction tasks.",
      "llm_tldr_cn": "引入发散流技术，用于检测流匹配模型在预测任务中由于样本外推导致的静默失败。",
      "llm_tldr": "引入发散流技术，用于检测流匹配模型在预测任务中由于样本外推导致的静默失败。",
      "llm_tags": [
        "keyword:FM"
      ],
      "quick_tier": "6"
    }
  ]
}