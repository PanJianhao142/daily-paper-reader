{
  "mode": "standard",
  "generated_at": "2026-02-20T05:49:22.271172+00:00",
  "stats": {
    "mode": "standard",
    "tag_count": 3,
    "deep_divecandidates": 0,
    "deep_cap": 8,
    "deep_selected": 0,
    "quick_candidates": 7,
    "quick_skim_target": 13,
    "quick_selected": 7
  },
  "deep_dive": [],
  "quick_skim": [
    {
      "id": "2602.16968v1",
      "title": "DDiT: Dynamic Patch Scheduling for Efficient Diffusion Transformers",
      "abstract": "Diffusion Transformers (DiTs) have achieved state-of-the-art performance in image and video generation, but their success comes at the cost of heavy computation. This inefficiency is largely due to the fixed tokenization process, which uses constant-sized patches throughout the entire denoising phase, regardless of the content's complexity. We propose dynamic tokenization, an efficient test-time strategy that varies patch sizes based on content complexity and the denoising timestep. Our key insight is that early timesteps only require coarser patches to model global structure, while later iterations demand finer (smaller-sized) patches to refine local details. During inference, our method dynamically reallocates patch sizes across denoising steps for image and video generation and substantially reduces cost while preserving perceptual generation quality. Extensive experiments demonstrate the effectiveness of our approach: it achieves up to $3.52\\times$ and $3.2\\times$ speedup on FLUX-1.Dev and Wan $2.1$, respectively, without compromising the generation quality and prompt adherence.",
      "authors": [
        "Dahye Kim",
        "Deepti Ghadiyaram",
        "Raghudeep Gadde"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-02-19 00:15:20+00:00",
      "link": "https://arxiv.org/pdf/2602.16968v1",
      "tags": [
        "keyword:FM",
        "keyword:MDM"
      ],
      "llm_score": 7.0,
      "llm_evidence_en": "variable spatio-temporal resolutions via dynamic patching",
      "llm_evidence_cn": "通过动态分块实现可变时空分辨率",
      "llm_evidence": "通过动态分块实现可变时空分辨率",
      "llm_tldr_en": "Varies patch sizes in Diffusion Transformers based on content complexity and denoising timesteps.",
      "llm_tldr_cn": "根据内容复杂度和去噪步数动态调整扩散Transformer中的分块大小。",
      "llm_tldr": "根据内容复杂度和去噪步数动态调整扩散Transformer中的分块大小。",
      "llm_tags": [
        "keyword:MDM",
        "query:课题"
      ],
      "quick_tier": "7"
    },
    {
      "id": "2602.17089v1",
      "title": "Synergizing Transport-Based Generative Models and Latent Geometry for Stochastic Closure Modeling",
      "abstract": "Diffusion models recently developed for generative AI tasks can produce high-quality samples while still maintaining diversity among samples to promote mode coverage, providing a promising path for learning stochastic closure models. Compared to other types of generative AI models, such as GANs and VAEs, the sampling speed is known as a key disadvantage of diffusion models. By systematically comparing transport-based generative models on a numerical example of 2D Kolmogorov flows, we show that flow matching in a lower-dimensional latent space is suited for fast sampling of stochastic closure models, enabling single-step sampling that is up to two orders of magnitude faster than iterative diffusion-based approaches. To control the latent space distortion and thus ensure the physical fidelity of the sampled closure term, we compare the implicit regularization offered by a joint training scheme against two explicit regularizers: metric-preserving (MP) and geometry-aware (GA) constraints. Besides offering a faster sampling speed, both explicitly and implicitly regularized latent spaces inherit the key topological information from the lower-dimensional manifold of the original complex dynamical system, which enables the learning of stochastic closure models without demanding a huge amount of training data.",
      "authors": [
        "Xinghao Dong",
        "Huchen Yang",
        "Jin-long Wu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "math.DS",
        "physics.comp-ph"
      ],
      "published": "2026-02-19 05:24:00+00:00",
      "link": "https://arxiv.org/pdf/2602.17089v1",
      "tags": [
        "keyword:FM",
        "keyword:MDM"
      ],
      "llm_score": 6.0,
      "llm_evidence_en": "flow matching for stochastic modeling",
      "llm_evidence_cn": "用于随机建模的流匹配",
      "llm_evidence": "用于随机建模的流匹配",
      "llm_tldr_en": "Demonstrates that flow matching in latent space enables fast sampling for stochastic closure models.",
      "llm_tldr_cn": "证明了潜空间中的流匹配可以实现随机闭合模型的快速采样。",
      "llm_tldr": "证明了潜空间中的流匹配可以实现随机闭合模型的快速采样。",
      "llm_tags": [
        "keyword:FM"
      ],
      "quick_tier": "6"
    },
    {
      "id": "2602.17586v1",
      "title": "Conditional Flow Matching for Continuous Anomaly Detection in Autonomous Driving on a Manifold-Aware Spectral Space",
      "abstract": "Safety validation for Level 4 autonomous vehicles (AVs) is currently bottlenecked by the inability to scale the detection of rare, high-risk long-tail scenarios using traditional rule-based heuristics. We present Deep-Flow, an unsupervised framework for safety-critical anomaly detection that utilizes Optimal Transport Conditional Flow Matching (OT-CFM) to characterize the continuous probability density of expert human driving behavior. Unlike standard generative approaches that operate in unstable, high-dimensional coordinate spaces, Deep-Flow constrains the generative process to a low-rank spectral manifold via a Principal Component Analysis (PCA) bottleneck. This ensures kinematic smoothness by design and enables the computation of the exact Jacobian trace for numerically stable, deterministic log-likelihood estimation. To resolve multi-modal ambiguity at complex junctions, we utilize an Early Fusion Transformer encoder with lane-aware goal conditioning, featuring a direct skip-connection to the flow head to maintain intent-integrity throughout the network. We introduce a kinematic complexity weighting scheme that prioritizes high-energy maneuvers (quantified via path tortuosity and jerk) during the simulation-free training process. Evaluated on the Waymo Open Motion Dataset (WOMD), our framework achieves an AUC-ROC of 0.766 against a heuristic golden set of safety-critical events. More significantly, our analysis reveals a fundamental distinction between kinematic danger and semantic non-compliance. Deep-Flow identifies a critical predictability gap by surfacing out-of-distribution behaviors, such as lane-boundary violations and non-normative junction maneuvers, that traditional safety filters overlook. This work provides a mathematically rigorous foundation for defining statistical safety gates, enabling objective, data-driven validation for the safe deployment of autonomous fleets.",
      "authors": [
        "Antonio Guillen-Perez"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-02-19 18:10:16+00:00",
      "link": "https://arxiv.org/pdf/2602.17586v1",
      "tags": [
        "keyword:FM",
        "keyword:MDM",
        "query:课题"
      ],
      "llm_score": 7.0,
      "llm_evidence_en": "conditional flow matching for human driving behavior",
      "llm_evidence_cn": "用于人类驾驶行为的条件流匹配",
      "llm_evidence": "用于人类驾驶行为的条件流匹配",
      "llm_tldr_en": "Uses Optimal Transport Conditional Flow Matching to model continuous human driving behavior for anomaly detection.",
      "llm_tldr_cn": "使用最优传输条件流匹配对连续的人类驾驶行为进行建模，用于异常检测。",
      "llm_tldr": "使用最优传输条件流匹配对连续的人类驾驶行为进行建模，用于异常检测。",
      "llm_tags": [
        "keyword:FM",
        "query:课题"
      ],
      "quick_tier": "7"
    },
    {
      "id": "2602.17110v1",
      "title": "Grasp Synthesis Matching From Rigid To Soft Robot Grippers Using Conditional Flow Matching",
      "abstract": "A representation gap exists between grasp synthesis for rigid and soft grippers. Anygrasp [1] and many other grasp synthesis methods are designed for rigid parallel grippers, and adapting them to soft grippers often fails to capture their unique compliant behaviors, resulting in data-intensive and inaccurate models. To bridge this gap, this paper proposes a novel framework to map grasp poses from a rigid gripper model to a soft Fin-ray gripper. We utilize Conditional Flow Matching (CFM), a generative model, to learn this complex transformation. Our methodology includes a data collection pipeline to generate paired rigid-soft grasp poses. A U-Net autoencoder conditions the CFM model on the object's geometry from a depth image, allowing it to learn a continuous mapping from an initial Anygrasp pose to a stable Fin-ray gripper pose. We validate our approach on a 7-DOF robot, demonstrating that our CFM-generated poses achieve a higher overall success rate for seen and unseen objects (34% and 46% respectively) compared to the baseline rigid poses (6% and 25% respectively) when executed by the soft gripper. The model shows significant improvements, particularly for cylindrical (50% and 100% success for seen and unseen objects) and spherical objects (25% and 31% success for seen and unseen objects), and successfully generalizes to unseen objects. This work presents CFM as a data-efficient and effective method for transferring grasp strategies, offering a scalable methodology for other soft robotic systems.",
      "authors": [
        "Tanisha Parulekar",
        "Ge Shi",
        "Josh Pinskier",
        "David Howard",
        "Jen Jen Chung"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-19 06:12:29+00:00",
      "link": "https://arxiv.org/pdf/2602.17110v1",
      "tags": [
        "keyword:FM"
      ],
      "llm_score": 6.0,
      "llm_evidence_en": "utilizes Conditional Flow Matching for pose mapping",
      "llm_evidence_cn": "利用条件流匹配进行姿态映射",
      "llm_evidence": "利用条件流匹配进行姿态映射",
      "llm_tldr_en": "Uses Conditional Flow Matching to map grasp poses from rigid to soft grippers using object geometry.",
      "llm_tldr_cn": "利用条件流匹配（CFM）将抓取姿态从刚性夹具映射到软体夹具。",
      "llm_tldr": "利用条件流匹配（CFM）将抓取姿态从刚性夹具映射到软体夹具。",
      "llm_tags": [
        "keyword:FM"
      ],
      "quick_tier": "6"
    },
    {
      "id": "2602.17211v1",
      "title": "MGD: Moment Guided Diffusion for Maximum Entropy Generation",
      "abstract": "Generating samples from limited information is a fundamental problem across scientific domains. Classical maximum entropy methods provide principled uncertainty quantification from moment constraints but require sampling via MCMC or Langevin dynamics, which typically exhibit exponential slowdown in high dimensions. In contrast, generative models based on diffusion and flow matching efficiently transport noise to data but offer limited theoretical guarantees and can overfit when data is scarce. We introduce Moment Guided Diffusion (MGD), which combines elements of both approaches. Building on the stochastic interpolant framework, MGD samples maximum entropy distributions by solving a stochastic differential equation that guides moments toward prescribed values in finite time, thereby avoiding slow mixing in equilibrium-based methods. We formally obtain, in the large-volatility limit, convergence of MGD to the maximum entropy distribution and derive a tractable estimator of the resulting entropy computed directly from the dynamics. Applications to financial time series, turbulent flows, and cosmological fields using wavelet scattering moments yield estimates of negentropy for high-dimensional multiscale processes.",
      "authors": [
        "Etienne Lempereur",
        "Nathanaël Cuvelle--Magar",
        "Florentin Coeurdoux",
        "Stéphane Mallat",
        "Eric Vanden-Eijnden"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "published": "2026-02-19 10:03:03+00:00",
      "link": "https://arxiv.org/pdf/2602.17211v1",
      "tags": [
        "keyword:FM",
        "keyword:MDM"
      ],
      "llm_score": 6.0,
      "llm_evidence_en": "flow matching and diffusion for generation",
      "llm_evidence_cn": "用于生成的流匹配与扩散模型",
      "llm_evidence": "用于生成的流匹配与扩散模型",
      "llm_tldr_en": "Combines flow matching and diffusion with moment constraints for maximum entropy generative modeling.",
      "llm_tldr_cn": "将流匹配、扩散模型与矩约束相结合，用于最大熵生成建模。",
      "llm_tldr": "将流匹配、扩散模型与矩约束相结合，用于最大熵生成建模。",
      "llm_tags": [
        "keyword:FM",
        "keyword:MDM"
      ],
      "quick_tier": "6"
    },
    {
      "id": "2602.17231v1",
      "title": "HiMAP: History-aware Map-occupancy Prediction with Fallback",
      "abstract": "Accurate motion forecasting is critical for autonomous driving, yet most predictors rely on multi-object tracking (MOT) with identity association, assuming that objects are correctly and continuously tracked. When tracking fails due to, e.g., occlusion, identity switches, or missed detections, prediction quality degrades and safety risks increase. We present \\textbf{HiMAP}, a tracking-free, trajectory prediction framework that remains reliable under MOT failures. HiMAP converts past detections into spatiotemporally invariant historical occupancy maps and introduces a historical query module that conditions on the current agent state to iteratively retrieve agent-specific history from unlabeled occupancy representations. The retrieved history is summarized by a temporal map embedding and, together with the final query and map context, drives a DETR-style decoder to produce multi-modal future trajectories. This design lifts identity reliance, supports streaming inference via reusable encodings, and serves as a robust fallback when tracking is unavailable. On Argoverse~2, HiMAP achieves performance comparable to tracking-based methods while operating without IDs, and it substantially outperforms strong baselines in the no-tracking setting, yielding relative gains of 11\\% in FDE, 12\\% in ADE, and a 4\\% reduction in MR over a fine-tuned QCNet. Beyond aggregate metrics, HiMAP delivers stable forecasts for all agents simultaneously without waiting for tracking to recover, highlighting its practical value for safety-critical autonomy. The code is available under: https://github.com/XuYiMing83/HiMAP.",
      "authors": [
        "Yiming Xu",
        "Yi Yang",
        "Hao Cheng",
        "Monika Sester"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-19 10:24:02+00:00",
      "link": "https://arxiv.org/pdf/2602.17231v1",
      "tags": [
        "keyword:FM",
        "keyword:MDM",
        "query:课题"
      ],
      "llm_score": 6.0,
      "llm_evidence_en": "spatio-temporal occupancy for motion prediction",
      "llm_evidence_cn": "用于运动预测的时空占用图",
      "llm_evidence": "用于运动预测的时空占用图",
      "llm_tldr_en": "A tracking-free trajectory prediction framework using spatiotemporal occupancy maps for autonomous driving.",
      "llm_tldr_cn": "一种利用时空占用图进行自动驾驶轨迹预测的免跟踪框架。",
      "llm_tldr": "一种利用时空占用图进行自动驾驶轨迹预测的免跟踪框架。",
      "llm_tags": [
        "query:课题"
      ],
      "quick_tier": "6"
    },
    {
      "id": "2602.17477v1",
      "title": "Variational Grey-Box Dynamics Matching",
      "abstract": "Deep generative models such as flow matching and diffusion models have shown great potential in learning complex distributions and dynamical systems, but often act as black-boxes, neglecting underlying physics. In contrast, physics-based simulation models described by ODEs/PDEs remain interpretable, but may have missing or unknown terms, unable to fully describe real-world observations. We bridge this gap with a novel grey-box method that integrates incomplete physics models directly into generative models. Our approach learns dynamics from observational trajectories alone, without ground-truth physics parameters, in a simulation-free manner that avoids scalability and stability issues of Neural ODEs. The core of our method lies in modelling a structured variational distribution within the flow matching framework, by using two latent encodings: one to model the missing stochasticity and multi-modal velocity, and a second to encode physics parameters as a latent variable with a physics-informed prior. Furthermore, we present an adaptation of the framework to handle second-order dynamics. Our experiments on representative ODE/PDE problems show that our method performs on par with or superior to fully data-driven approaches and previous grey-box baselines, while preserving the interpretability of the physics model. Our code is available at https://github.com/DMML-Geneva/VGB-DM.",
      "authors": [
        "Gurjeet Sangra Singh",
        "Frantzeska Lavda",
        "Giangiacomo Mercatali",
        "Alexandros Kalousis"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-19 15:43:22+00:00",
      "link": "https://arxiv.org/pdf/2602.17477v1",
      "tags": [
        "keyword:FM",
        "keyword:MDM",
        "query:课题"
      ],
      "llm_score": 6.0,
      "llm_evidence_en": "Flow matching and diffusion for grey-box dynamics",
      "llm_evidence_cn": "用于灰盒动力学的流匹配与扩散模型",
      "llm_evidence": "用于灰盒动力学的流匹配与扩散模型",
      "llm_tldr_en": "Integrates physics-based ODEs/PDEs into flow matching and diffusion models to learn complex dynamical systems.",
      "llm_tldr_cn": "将基于物理的方程集成到流匹配和扩散模型中，以学习复杂的动力系统。",
      "llm_tldr": "将基于物理的方程集成到流匹配和扩散模型中，以学习复杂的动力系统。",
      "llm_tags": [
        "keyword:FM",
        "keyword:MDM",
        "query:课题"
      ],
      "quick_tier": "6"
    }
  ]
}