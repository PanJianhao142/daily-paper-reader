---
title: "Quant VideoGen: Auto-Regressive Long Video Generation via 2-Bit KV-Cache Quantization"
title_zh: Quant VideoGen：通过 2-Bit KV-Cache 量化实现自回归长视频生成
authors: "Haocheng Xi, Shuo Yang, Yilong Zhao, Muyang Li, Han Cai, Xingyang Li, Yujun Lin, Zhuoyang Zhang, Jintao Zhang, Xiuyu Li, Zhiying Xu, Jun Wu, Chenfeng Xu, Ion Stoica, Song Han, Kurt Keutzer"
date: 2026-02-03
pdf: "https://arxiv.org/pdf/2602.02958v1"
tags: ["keyword:MDM", "query:课题"]
score: 6.0
evidence: 解决了自回归视频扩散中的长时一致性和时空冗余问题。
tldr: 针对自回归视频扩散模型中KV缓存占用内存过大的瓶颈，本文提出Quant VideoGen (QVG) 框架。该框架无需训练，通过语义感知平滑和渐进式残差量化技术，利用视频时空冗余实现2-bit KV缓存量化。QVG在显著降低内存消耗（高达7倍）的同时，保持了长视频生成的一致性，并在多个基准测试中达到了质量与效率的最优平衡。
motivation: 自回归视频生成中不断增长的KV缓存严重限制了长视频的一致性及在主流硬件上的部署。
method: 提出语义感知平滑以产生易于量化的残差，并结合渐进式残差量化实现多阶段粗到精的量化误差缩减。
result: "在多个基准测试中，QVG实现了高达7倍的KV缓存内存缩减，且端到端延迟开销低于4%，生成质量优于现有基准。"
conclusion: QVG为长视频生成提供了一种高效且无需训练的KV缓存压缩方案，有效解决了显存瓶颈并提升了生成性能。
---

## 摘要
尽管自回归视频扩散模型取得了快速进展，但一个新兴的系统算法瓶颈限制了其部署能力和生成能力：KV 缓存（KV cache）内存。在自回归视频生成模型中，KV 缓存随生成历史增长并迅速占据 GPU 显存，通常超过 30 GB，阻碍了其在通用硬件上的部署。更关键的是，受限的 KV 缓存预算限制了有效工作内存，直接降低了身份、布局和运动的长时一致性。为了应对这一挑战，我们提出了 Quant VideoGen (QVG)，这是一个针对自回归视频扩散模型的免训练 KV 缓存量化框架。QVG 通过语义感知平滑（Semantic Aware Smoothing）利用视频的时空冗余，产生低幅值且易于量化的残差。它进一步引入了渐进式残差量化（Progressive Residual Quantization），这是一种由粗到精的多阶段方案，在降低量化误差的同时实现了质量与内存之间的平滑权衡。在 LongCat Video、HY WorldPlay 和 Self Forcing 基准测试中，QVG 在质量和内存效率之间建立了新的帕累托前沿（Pareto frontier），将 KV 缓存内存减少了高达 7.0 倍，端到端延迟开销低于 4%，同时在生成质量上持续优于现有基准。

## Abstract
Despite rapid progress in autoregressive video diffusion, an emerging system algorithm bottleneck limits both deployability and generation capability: KV cache memory. In autoregressive video generation models, the KV cache grows with generation history and quickly dominates GPU memory, often exceeding 30 GB, preventing deployment on widely available hardware. More critically, constrained KV cache budgets restrict the effective working memory, directly degrading long horizon consistency in identity, layout, and motion. To address this challenge, we present Quant VideoGen (QVG), a training free KV cache quantization framework for autoregressive video diffusion models. QVG leverages video spatiotemporal redundancy through Semantic Aware Smoothing, producing low magnitude, quantization friendly residuals. It further introduces Progressive Residual Quantization, a coarse to fine multi stage scheme that reduces quantization error while enabling a smooth quality memory trade off. Across LongCat Video, HY WorldPlay, and Self Forcing benchmarks, QVG establishes a new Pareto frontier between quality and memory efficiency, reducing KV cache memory by up to 7.0 times with less than 4% end to end latency overhead while consistently outperforming existing baselines in generation quality.