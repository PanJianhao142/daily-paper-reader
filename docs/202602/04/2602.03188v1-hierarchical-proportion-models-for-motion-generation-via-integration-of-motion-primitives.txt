Title: Hierarchical Proportion Models for Motion Generation via Integration of Motion Primitives

URL Source: https://arxiv.org/pdf/2602.03188v1

Published Time: Wed, 04 Feb 2026 01:45:01 GMT

Number of Pages: 6

Markdown Content:
# Hierarchical Proportion Models for Motion Generation via Integration of Motion Primitives 

1st Yu-Han, Shu 

Intelligent and Mechanical Interaction Systems University of Tsukuba 

Tsukuba, Japan shu.yuhan.tkb en@u.tsukuba.ac.jp 

2nd Toshiaki Tsuji 

Science and Engineering Saitama University 

Saitama, Japan tsuji@ees.saitama-u.ac.jp 

3rd Sho Sakaino 

Systems and Information Engineering University of Tsukuba 

Tsukuba, Japan sakaino@iit.tsukuba.ac.jp 

Abstract —Imitation learning (IL) enables robots to acquire human-like motion skills from demonstrations, but it still requires extensive high-quality data and retraining to handle complex or long-horizon tasks. To improve data efficiency and adaptability, this study proposes a hierarchical IL framework that integrates motion primitives with proportion-based motion synthesis. The proposed method employs a two-layer architecture, where the upper layer performs long-term planning, while a set of lower-layer models learn individual motion primitives, which are combined according to specific proportions. Three model variants are introduced to explore different trade-offs between learning flexibility, computational cost, and adaptability: a learning-based proportion model, a sampling-based proportion model, and a playback-based proportion model, which differ in how the pro-portions are determined and whether the upper layer is trainable. Through real-robot pick-and-place experiments, the proposed models successfully generated complex motions not included in the primitive set. The sampling-based and playback-based proportion models achieved more stable and adaptable motion generation than the standard hierarchical model, demonstrating the effectiveness of proportion-based motion integration for practical robot learning. 

Index Terms —Imitation Learning, Bilateral Control, Model Predictive Control, Motion Planning, Intelligent Robotics. 

I. I NTRODUCTION 

Robotic technologies that support household, human sup-port, and production activities are increasingly anticipated. In recent years, approaches based on machine learning have been actively studied to enable robotic behaviors that adapt to changing environments [1]. Among these, imitation learning (IL) has emerged as a promising method to efficiently transfer human motion skills to robots [2]. By leveraging demonstra-tions, IL improves data efficiency and reduces training time. In recent years, research on IL utilizing force information and bilateral control has further enhanced flexibility and stability in robotic motions [3], [4]. Bilateral control is a teleoperation technique between robots, which involves the synchronization of position and force. Compared to con-ventional demonstration methods, such as direct teaching or virtual reality-based teaching [5], learning from data collected 

This work was supported by JSPS KAKENHI Grant Number 24K00905, JST, PRESTO Grant Number JPMJPR24T3 Japan, and JST ALCA-Next Japan, Grant Number JPMJAN24F1. This study was based on the results obtained from the JPNP20004 project subsidized by the New Energy and Industrial Technology Development Organization (NEDO). 

through bilateral control has achieved faster motion while maintaining equivalent flexibility [6], [7]. Nevertheless, IL still requires large volumes of high-quality demonstrations, which is especially challenging for long-horizon or complex tasks [8]. Repeated data collection and retraining are necessary to achieve task success or adapt to new tasks, which significantly limits its practical deployment. A potential solution is to decompose tasks into reusable mo-tion primitives that can be recombined to generate novel tasks [9]. Previous studies following this concept have proposed approaches in which individual motion primitives are learned by expert models, while a higher-level controller selects the optimal model at each time step [10], [11]. The Mixture of Experts (MoE) framework offers a promis-ing alternative by integrating multiple expert outputs through weighted averaging, enabling smooth transitions and adapt-ability [12]. In the context of robotic motion generation, MoE has also demonstrated promising results in simulation; how-ever, verification in real-world environments remains limited [13]. In parallel, Monte Carlo Model Predictive Control (MC-MPC) provides sampling-based optimization that generates diverse motion candidates and selects the optimal one based on evaluation values, achieving precise and robust performance under uncertainty [14]. This capability makes MC-MPC par-ticularly effective for handling unknown environments and deformable object manipulation [15]. Building on these prior works, this study proposes an extended approach that integrates a hierarchical structure into IL based on bilateral control [16]. The method employs a two-layer model: the lower layer learns individual motion primitives, while the upper layer performs long-term planning. Afterward, the task motions are generated by computing a weighted average of the motion primitives according to specific proportions. Within this framework, three model vari-ants are investigated, which differ in how the combination proportions are determined and whether the upper layer is learned: 1) Learning-based proportion model: The upper layer learns the long-term planning and the proportions for combining motion primitives. This model was previ-ously introduced in our earlier study [17]. 

> arXiv:2602.03188v1 [cs.RO] 3 Feb 2026

2) Sampling-based proportion model: The upper layer learns only the long-term planning. The proportions are derived from the difference between upper- and lower-layer outputs. 3) Playback-based proportion model: The upper layer is replaced with motion data, and the proportions are computed from the difference between data and lower-layer outputs. Compared with the original hierarchical model, which requires task-specific training of both layers, the proposed framework emphasizes reusable motion primitives and task adaptation through proportion determination. In particular, the learning-based proportion model learns the combination pro-portions and typically requires retraining when the primitive set is modified. In contrast, the sampling-based and playback-based variants determine proportions without proportion-level learning, enabling more stable motion generation and simpler updates of the lower-layer models. The effectiveness of the proposed models was validated through pick-and-place experiments, including a complex task not included in the primitive set. While the learning-based proportion model faced challenges in estimating ap-propriate proportions when many primitives were involved, the sampling-based and playback-based proportion models achieved higher motion quality. Moreover, the lower-layer models can be shared across multiple tasks, and the playback-based proportion model can even operate without upper-layer learning, thereby reducing the overall learning cost. This paper is organized as follows: Section II presents the fundamental background. Section III describes the proposed model, detailing its design and implementation. Section IV reports the experimental setup and results. Finally, Section V concludes the study and outlines potential directions for future research. II. T ECHNICAL FOUNDATIONS 

A. Bilateral Control 

Bilateral control is a teleoperation technique that employs two robots: a leader and a follower. The leader is directly manipulated by an operator, while the follower reproduces the leader’s motion. During operation, the two robots synchronize their joint angles θ and angular velocities ω, while exchanging torque feedback τ with each other. The control objectives of the system are defined as follows: 

θres l − θres f = 0 , (1) 

τ res l + τ res f = 0 , (2) where the superscripts l and f denote the leader and follower states, respectively, and the subscript res represents the re-sponse values. Bilateral control has been shown to enable fast and stable motion by providing synchronized position and force feedback between the two robots [18]. 

Fig. 1: Structure of hierarchical model. 

B. Hierarchical Model 

Previous studies have demonstrated that when the predicted response of the leader obtained through bilateral control is used as the command input for the follower, the robot can re-produce appropriate imitative motions [4]. In this approach, the model outputs the next leader prediction ˆLk+1 directly from the follower’s response Fk. To further enhance the efficiency of long-term motion generation in bilateral control-based im-itation learning, a hierarchical model was proposed [16]. A hierarchical model processes information across multi-ple layers, enabling robots to perform long-term tasks more effectively through IL. However, conventional single Long Short-Term Memory (LSTM) networks have limited memory capacity, which reduces efficiency and prediction accuracy for longer sequences. The hierarchical model addresses this issue by dividing responsibilities between two neural networks: the upper layer manages long-term task planning, while the lower layer captures short-term detailed motions. Based on the long-term prediction provided by the upper layer, the lower layer constructs command samples for the next step, resulting in more adaptive and consistent motion generation. The structure of the hierarchical model is illustrated in Figure 1, where F and L denote the state vectors [θ, ω, τ ] of the follower and leader, respectively. Within this framework, the upper layer predicts the follower state ˆFk+n n steps ahead based on the current follower state Fk, with updates occurring every n time steps. Meanwhile, the lower layer predicts the next leader state ˆLk+1 at each step using the upper-layer output 

ˆFk+n and the current follower state Fk.

C. Monte Carlo Model Predictive Control (MC-MPC) 

MC-MPC is a sampling-based control method that deter-mines optimal input sequences by generating a large set of candidates and simulating their outcomes over a prediction horizon [19]. In contrast to traditional MPC, MC-MPC does not depend on smooth cost functions or accurate system dy-namics, making it appropriate to highly nonlinear and discon-tinuous problems such as collisions or slippage. Moreover, its compatibility with parallel computation enables efficient real-time performance, making MC-MPC a robust, flexible, and practical framework for robot motion generation in complex environments. Fig. 2: Algorithm of MC-MPC. As illustrated in Figure 2, the algorithm begins with an initial trajectory derived from the previous cycle’s optimal sequence. Multiple randomized input sequences are then gen-erated in parallel to explore diverse control strategies. Each sample is evaluated using a cost function, and the top-performing candidates are selected to compute a weighted average as the final input sequence. Subsequently, the first element of the optimized input sequence is applied to the system, while the remaining elements are retained for the next control cycle. The weights for the averaging process are computed through a cross-entropy formulation, expressed as follows: 

uk|i =

P 

> m∈M

umk|i exp 



− Lm

> ρ

P 

> m∈M

exp 



− Lm

> ρ

 (3) where umk|i denotes the input at step i of sample m in control cycle k, Lm is the corresponding cost function value, ρ is the temperature parameter, and M represents the set of top-performing samples. III. P ROPOSED METHOD 

In this section, we present the proposed hierarchical model, in which the lower-layer model learns simpler primitive mo-tions decomposed from a complex task. The desired task motion is then constructed as a weighted average of these primitives, with the weighting scheme varying across the different proposed models. 

A. Decomposition and Combination of Complex Motions 

A natural approach to decomposing complex tasks is to sep-arate them based on action contents. For example, in the pick-and-place task, the robot grasps an object, moves and places it at the destination, which can be divided into “grasping,” “moving,” and “placing”. With this decomposition strategy, the lower-layer models learn each decomposed motion primitive, 

Fig. 3: Comparison between different data separation methods. 

Fig. 4: Structure of the learning-based proportion model. while an upper-layer model combines them to generate the overall task [11]. In this study, we introduce a motion decomposition strategy without task-specific segmentation to enhance generalization. As shown in Figure 3, motion primitives are separated using uniform time-based separation instead. By combining these primitives, the model is expected to achieve greater flexibility, enabling the execution of a broader range of tasks, including those not explicitly learned. For instance, a new motion such as “rotating” may be generated by appropriately combining the primitives “grasping,” “transporting,” and “placing.” 

B. Proposed Model 

We propose three models that differ in the method used to determine the combination proportions of motion primitives and in whether the upper layer is implemented as a trained network or as target data. 

1) Learning-based Proportion Model: The structure of the proposed hierarchical model is illustrated in Figure 4. The model consists of multiple lower-layer models that generate specific motion primitives, and an upper layer that learns both the combination proportions of these primitives and long-term motion planning. To ensure that the generated actions remain within a reasonable range, the output proportions are passed through a softmax function. Based on these proportions, a weighted average of the lower-layer outputs is calculated to produce the execution command for the next time step. To capture long-term dependencies across time steps in motion data, an LSTM network is employed in the upper layer. In contrast, since long-term information processing is unnecessary in the lower layer, each lower-layer model is implemented as a multi-layer perceptron (MLP) without internal states. The training procedure begins with the training of the lower-layer models for each motion primitive. Afterward, the process shifts to the upper-layer model, where the pre-trained lower-layer models are executed together with the upper layer to learn the optimal proportions of the motion primitives. A softmax function is applied to the proportion outputs to ensure that the combined control input remains within a valid joint position range. 

2) Sampling-based Proportion Model: This section in-troduces a framework that integrates the concept of MC-MPC into the hierarchical structure. Similar to MC-MPC, the basic idea is to generate a large number of randomized samples, evaluate them, and compute their weighted average. Specifically, the upper layer predicts future follower states based on the current system state. Using this prediction, the lower layer generates leader trajectories with added noise to increase sample diversity. Each sample is evaluated using a cost function, and the weighted average of the top-performing samples is used to produce the next command. The conceptual overview is illustrated in Figure 5. The overall architecture is presented in Figure 6. The upper layer outputs a sequence of long-term follower states, 

ˆF k+1: k+n. Based on this, the lower layer predicts leader states, 

ˆLmk+1: k+n, and noise Ni is added to generate diverse samples. To compute the cost, the leader outputs are converted into follower commands using a pre-trained mapping network L to 

F , which is trained on motion data collected through bilateral control. The cost function is defined as follows: 

Lθ = M SE (ˆθmk+1 − ˆθk+1 ),

Lω = M SE ( ˆ ωmk+1 − ˆωk+1 ),

Lτ = M SE (ˆ τ mk+1 − ˆτ k+1 ),

L = α · L θ + β · L ω + γ · L τ ,

where Lθ , Lω , and Lτ correspond to the joint angle, angular velocity, and torque costs, respectively. The total cost L is a weighted sum of these terms with coefficients α, β, and γ.The cross-entropy method (3) is then applied, assigning higher weights to samples with smaller errors. Using these weights, a weighted average is computed, and the first element ˆLk+1 

is applied to the system, and the above process is repeated. The key advantage of this architecture compared with the learning-based proportion model is the ease of modifying the lower-layer set. As a result, the number of motion primitives and samples can be readily increased, thereby enhancing motion accuracy and generalization capability. The training procedures for the upper and lower layers are independent and can be executed in parallel, reducing the overall training time. The L to F model is also trained separately. 

3) Playback-based Proportion Model: The model illus-trated in Figure 7 represents a variation of the sampling-based proportion model, in which the upper layer is replaced with pre-collected motion data. The data required for the lower-layer prediction and cost computation are directly provided by the upper-layer motion data. Similar to the sampling-based proportion model, the lower layer generates multiple samples, which are evaluated against the upper-layer data, and the final outputs are synthesized using the weights derived from equation (3). The key advantage of this configuration is that retraining of the upper layer is unnecessary, allowing rapid adaptation to new tasks or modifications. This flexibility further reduces overall learning costs and enhances responsiveness to environ-mental and task variations. Although pre-recorded motion data are used, the framework retains key advantages of learning-based characteristics, as the lower-layer models implicitly adapt to variations in execution conditions without explicit retuning of the control parameters. The training procedure for the lower-layer models is the same as in the other two models, where each learns a cor-responding motion primitive. A demonstration dataset of the desired motion is applied to the upper layer. IV. E XPERIMENTS 

A. Data collection 

A pick-and-place task was conducted to validate the pro-posed models. In this task, the robot starts from an initial position, moves to the target object, picks it up, and transfers it to a terminal position. For the training data of motion primitives, datasets were prepared for 5 different positions and directions: left-to-right, right-to-left, front-to-back, right-bottom-to-left-upper, and right-upper-to-left-bottom, as illus-trated in Figure 8(a). The data were then divided into 10 overlapping segments along the timeline, each ranging from 0.9 to 1.1 times the length of 1/10 of the total duration. Consequently, 50 motion primitives were used to train the lower-layer models. For the upper-layer training, two tasks were designed to evaluate the model performance. The first corresponds to the same right-to-left motion used in the lower layer. The second is a more complex two-object transfer task that was not included in the primitive set, in order to verify whether new tasks can be generated by reusing and recombining existing motion primitives without introducing additional task-specific primitives. A schematic diagram of the two tasks is shown in Figure 8(b). To evaluate adaptability to environmental changes, the objects used during execution differed from those used during demonstration in terms of shape and stiffness. All demonstration data were collected using the bilateral control method. 

B. Model Preparation 

In addition to the proposed methods—the learning-based, sampling-based, and playback-based proportion models—a standard hierarchical model was used as a baseline for compar-ison. In the baseline model, both the upper and lower layers are trained on the target task, whereas in the proposed methods, the upper layer learns the target task and the lower layers learn 50 motion primitives. To improve robustness and diversity, the number of lower-layer outputs was augmented tenfold by adding noise, resulting in a total of 500 samples. However, in Fig. 5: Algorithm of proposed sampling-based proportion model. 

Fig. 6: Structure of the proposed sampling-based proportion model. 

Fig. 7: Structure of the proposed playback-based proportion model. the learning-based proportion model, training with 50 primi-tives requires the upper layer to learn all possible combinations among them, which exceeds its learning capacity. Therefore, the number of motion primitives was reduced to 30 for the learning-based proportion model. The hyperparameters summarized in Table I were empiri-cally selected to ensure stable training and reliable motion gen-eration. All models shared the same hyperparameter settings. Although they were not exhaustively optimized, the final con-figuration achieved consistent and reproducible performance in robotic motion execution. 

C. Experimental results 

Both validation tasks were performed 10 times to evaluate the success rates. Although the number of trials is limited, consistent trends were observed across repetitions, indicating that the performance differences among models are reliable within the scope of the presented experiments. The results are summarized in Table II. First, the baseline model achieved a success rate of 90% in the right-to-left task but only 60% in the two-object task, indicating that the latter task was more challenging. Two  

> (a) Motion primitives. (b) Validation task.

Fig. 8: Overview of the experimental environment. TABLE I: Hyperparameters for the models used in validation experiment.                           

> Model role Architecture Layer Neuron Learning rate Batch size
> Upper layer LSTM 10 80 5×10 −416 Lower layer MLP 8200 5×10 −416 L to F MLP 10 80 5×10 −416

primary failure modes were observed: (1) failure to properly grasp the second object, and (2) premature termination after completing only the first pick. Second, the learning-based proportion model showed lower success rates of 70% and 40% in the two tasks, respectively. This is attributed to the reliance on fully learned proportion prediction under uncertainty in both upper-layer planning and lower-layer motion generation, which can lead to inaccurate combinations. Nevertheless, the model still demonstrated the ability to generate a task not included in the primitive set in the two-object task. In contrast, the sampling-based and playback-based propor-tion models performed with outstanding motion quality and achieved higher success rates. Both models achieved 100% success in the right-to-left task, and success rates of 70% and 90% in the two-object task, respectively, outperforming the baseline. Their primary cause of failure was the premature termination after completing the first pick. Compared with the baseline, both models generated more stable motions and properly grasped the objects. However, the playback-based model exhibited motion-copying characteristics by ex-ecuting actions synchronized with the reference motion data rather than adapting to environmental conditions or situational changes [20]. It should also be noted that the proposed models were TABLE II: Comparison of success rates across models. 

Model Task success rate (%) Right-to-left Two-object 

Baseline 90 60 Learning-based 70 40 Sampling-based 100 70 Playback-based 100 90 

trained using a larger amount of demonstration data than the baseline, because multiple lower-layer models were trained on different task datasets. This difference may have contributed to the improved performance. According to the above results, the sampling-based and playback-based proportion models successfully generated the complex task by reusing motion primitives. However, devia-tions were observed for the second object and the placement positions, with errors of approximately 10 cm and 3 cm, re-spectively. These deviations are attributed to the corresponding target positions lying outside the training range of the motion primitives. Increasing the diversity and spatial range of motion primitives is expected to mitigate this limitation in future work. Finally, the sampling-based and playback-based variants share the same lower-layer computation, and their effective update periods were comparable, operating at approximately 2.2 ms on average, which is sufficient for real-time execution on the physical robot. V. C ONCLUSIONS 

This study proposed an extended motion generation model based on bilateral control-based IL, which decomposes com-plex motions into motion primitives and accomplishes diverse tasks through their weighted combination. In the pick-and-place experiment, a complex motion not included in the primitive set was successfully generated using these primitives learned from other tasks, with task-level adaptation performed only at the upper layer. Furthermore, the lower-layer models can be easily modified and shared across different tasks, demonstrating the flexibility and reusability of the proposed architecture while reducing the overall learning cost. Among the three proposed models, the learning-based pro-portion model showed lower stability when handling a large number of motion primitives, resulting in reduced accuracy. In contrast, the sampling-based proportion model achieved more stable and adaptable motion generation by learning a motion plan and the sampling-based combination. The playback-based proportion model demonstrated the fastest adaptability, requiring no upper-layer training and reproducing complex motions with high consistency. Overall, the results confirm the effectiveness of integrating hierarchical structures with bilateral control for efficient and adaptive motion generation. It should be noted that the pro-posed models were trained with a larger set of demonstration data, as the lower-layer models learned multiple tasks, which may have partially contributed to the improved performance. Future work will focus on improving positional accuracy and enhancing generalization by introducing a world model [21] or a large-scale model [22] into the upper layer, enabling more adaptive and flexible robotic behaviors. REFERENCES [1] J. Wang et al. , “A survey of learning-based robot motion planning,” IET Cyber-Systems and Robotics , vol. 3, no. 4, pp. 302–314, 2021. [2] M. Zare, P. M. Kebria, A. Khosravi, and S. Nahavandi, “A survey of imitation learning: Algorithms, recent developments, and challenges,” 2023. [3] T. Tsuji et al. , “A survey on imitation learning for contact-rich tasks in robotics,” arXiv preprint arXiv:2506.13498 , 2025. [4] T. Adachi, K. Fujimoto, S. Sakaino, and T. Tsuji, “Imitation learning for object manipulation based on position/force information using bilateral control,” in 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) , 2018, pp. 3648–3653. [5] T. Zhang et al. , “Deep imitation learning for complex manipulation tasks from virtual reality teleoperation,” in 2018 IEEE International Conference on Robotics and Automation (ICRA) , 2018, pp. 5628–5635. [6] A. Sasagawa, S. Sakaino, and T. Tsuji, “Motion generation using bilateral control-based imitation learning with autoregressive learning,” 

IEEE Access , vol. 9, pp. 20 508–20 520, 2021. [7] Y. Kato, S. Sakaino, and T. Tsuji, “Contact state recognition for selective cutting task of flexible objects,” in 2021 IEEE International Conference on Development and Learning (ICDL) , 2021, pp. 1–6. [8] B. Zheng, S. Verma, J. Zhou, I. W. Tsang, and F. Chen, “Imitation learning: Progress, taxonomies and challenges,” IEEE Transactions on Neural Networks and Learning Systems , vol. 35, no. 5, pp. 6322–6337, 2024. [9] T. Gao, S. Nasiriany, H. Liu, Q. Yang, and Y. Zhu, “Prime: Scaffolding manipulation tasks with behavior primitives for data-efficient imitation learning,” IEEE Robotics and Automation Letters , vol. 9, no. 10, pp. 8322–8329, 2024. [10] H. Ito, K. Yamamoto, H. Mori, and T. Ogata, “Efficient multitask learning with an embodied predictive model for door opening and entry with whole-body control,” Science Robotics , vol. 7, no. 65, p. eaax8177, 2022. [11] J. Luo et al. , “Multistage cable routing through hierarchical imitation learning,” IEEE Transactions on Robotics , vol. 40, pp. 1476–1491, 2024. [12] W. Cai, J. Jiang, F. Wang, J. Tang, S. Kim, and J. Huang, “A survey on mixture of experts,” ArXiv , vol. abs/2407.06204, 2024. [13] O. C ¸ elik, D. Zhou, G. Li, P. Becker, and G. Neumann, “Specializing versatile skill libraries using local mixture of experts,” in Conference on Robot Learning , 2021. [14] L. Janson, E. Schmerling, and M. Pavone, “Monte carlo motion plan-ning for robot trajectory optimization under uncertainty,” in Robotics Research: Volume 2 . Springer, 2017, pp. 343–361. [15] S. Nakamura, C. H. Arias, M. Bhardwaj, and B. Boots, “Robotic system performing dynamic interaction in human-robot cooperative work for assembly operation,” in 2024 IEEE/SICE International Symposium on System Integration (SII) , 2024, pp. 1132–1138. [16] K. Hayashi, S. Sakaino, and T. Tsuji, “An independently learnable hierar-chical model for bilateral control-based imitation learning applications,” 

IEEE Access , vol. 10, pp. 32 766–32 781, 2022. [17] Y. Shu, K. Inami, K. Yamane, S. Sakaino, and T. Tsuji, “A preliminary study on weighted average hierarchical model in bilateral control-based imitation learning,” Proceedings of the Annual Conference of JSAI , vol. JSAI2025, pp. 3Q5GS801–3Q5GS801, 2025. [18] A. Sasagawa, K. Fujimoto, S. Sakaino, and T. Tsuji, “Imitation learning based on bilateral control for human–robot cooperation,” IEEE Robotics and Automation Letters , vol. 5, no. 4, pp. 6169–6176, 2020. [19] S. Nakatani and H. Date, “Swing up control of inverted pendulum on a cart with collision by monte carlo model predictive control,” in 

2019 58th Annual Conference of the Society of Instrument and Control Engineers of Japan (SICE) , 2019, pp. 1050–1055. [20] Y. Yokokura, S. Katsura, and K. Ohishi, “Motion copying system based on real-world haptics in variable speed,” in 2008 13th International Power Electronics and Motion Control Conference , 2008, pp. 1604– 1609. [21] D. Ha and J. Schmidhuber, “World models,” CoRR , vol. abs/1803.10122, 2018. [22] M. Kim et al. , “Openvla: An open-source vision-language-action model,” 2024. [Online]. Available: https://arxiv.org/abs/2406.09246