---
title: A Unified Density Operator View of Flow Control and Merging
title_zh: 流控制与合并的统一密度算子视角
authors: "Riccardo De Santi, Malte Franke, Ya-Ping Hsieh, Andreas Krause"
date: 2026-02-08
pdf: "https://arxiv.org/pdf/2602.08012v1"
tags: ["keyword:FM"]
score: 6.0
evidence: 讨论了生成模型的流匹配和奖励引导的流合并
tldr: 本研究针对流模型和扩散模型的奖励适配与模型合并两大挑战，提出了一个统一的概率空间框架。通过密度算子视角，该框架实现了生成模型的交集、并集和插值等逻辑运算。核心贡献是引入了奖励引导的流合并（RFM）方案，利用镜像下降将复杂合并问题转化为微调序列，并提供了理论保证。实验证明该方法在分子设计等高维任务中能有效结合多个预训练模型并实现任务感知。
motivation: 现有的流模型奖励适配与多模型合并方法相互独立，缺乏一个能同时处理逻辑组合与奖励引导的统一理论框架。
method: 提出基于密度算子的统一框架，并开发了奖励引导流合并（RFM）算法，通过镜像下降实现高效的模型融合与优化。
result: 在可视化实验及高维分子设计、低能构象生成任务中，成功实现了多模型的高效合并与任务导向的性能提升。
conclusion: 该研究为生成式流模型的组合与控制提供了坚实的理论基础和实用的算法工具。
---

## 摘要
大规模流模型和扩散模型的最新进展提出了两个基本的算法挑战：(i) 预训练流的基于控制的奖励自适应，以及 (ii) 多个模型的集成，即流合并。虽然目前的方法分别处理这两个问题，但我们引入了一个统一的概率空间框架，将两者都作为极限情况包含在内，并实现了奖励引导的流合并，从而允许对多个预训练流进行有原则的、任务感知的组合（例如，在最大化药物发现效用的同时合并先验）。我们的公式使得在生成模型密度上表达丰富的算子族成为可能，包括交集（例如，为了强制安全性）、并集（例如，为了组合多样化的模型）、插值（例如，为了发现）、它们的奖励引导对应项，以及通过生成电路实现的复杂逻辑表达式。接下来，我们介绍了奖励引导流合并 (RFM)，这是一种镜像下降方案，它将奖励引导流合并简化为一系列标准的微调问题。然后，我们为通过 RFM 进行的奖励引导流合并和纯流合并提供了首创的理论保证。最后，我们在说明性设置中展示了所提方法的能力，提供了视觉上可解释的见解，并将我们的方法应用于高维从头分子设计和低能构象异构体生成。

## Abstract
Recent progress in large-scale flow and diffusion models raised two fundamental algorithmic challenges: (i) control-based reward adaptation of pre-trained flows, and (ii) integration of multiple models, i.e., flow merging. While current approaches address them separately, we introduce a unifying probability-space framework that subsumes both as limit cases, and enables reward-guided flow merging, allowing principled, task-aware combination of multiple pre-trained flows (e.g., merging priors while maximizing drug-discovery utilities). Our formulation renders possible to express a rich family of operators over generative models densities, including intersection (e.g., to enforce safety), union (e.g., to compose diverse models), interpolation (e.g., for discovery), their reward-guided counterparts, as well as complex logical expressions via generative circuits. Next, we introduce Reward-Guided Flow Merging (RFM), a mirror-descent scheme that reduces reward-guided flow merging to a sequence of standard fine-tuning problems. Then, we provide first-of-their-kind theoretical guarantees for reward-guided and pure flow merging via RFM. Ultimately, we showcase the capabilities of the proposed method on illustrative settings providing visually interpretable insights, and apply our method to high-dimensional de-novo molecular design and low-energy conformer generation.