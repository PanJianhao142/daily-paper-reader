---
title: "FLAG-4D: Flow-Guided Local-Global Dual-Deformation Model for 4D Reconstruction"
title_zh: FLAG-4D：用于 4D 重建的光流引导局部-全局双重变形模型
authors: "Guan Yuan Tan, Ngoc Tuan Vu, Arghya Pal, Sailaja Rajanala, Raphael Phan C. -W., Mettu Srinivas, Chee-Ming Ting"
date: 2026-02-09
pdf: "https://arxiv.org/pdf/2602.08558v1"
tags: ["keyword:FM", "query:课题"]
score: 6.0
evidence: 流引导的全局运动与时间变形
tldr: FLAG-4D 针对动态场景 4D 重建中复杂运动捕捉难、细节丢失的问题，提出了一种流引导的局部-全局双变形模型。该模型结合了用于精细局部变形的瞬时变形网络（IDN）和用于捕捉长程动态的全局运动网络（GMN），并通过预训练光流特征和变形引导注意力机制增强时空一致性。实验证明，该方法在稀疏视角下也能实现高保真、连贯的动态场景重建。
motivation: 现有 4D 重建方法依赖单一 MLP 建模变形，难以在稀疏视角下准确捕捉复杂的点运动和精细的动态细节。
method: 提出双变形网络（IDN 与 GMN）结合互学习机制，并利用预训练光流特征与变形引导注意力机制来对齐并平滑 3D 高斯球的演化。
result: 在多个实验中，FLAG-4D 在重建保真度、时间连贯性以及细节保留方面均优于现有的先进方法。
conclusion: 该研究通过局部与全局运动的协同建模及光流引导，显著提升了动态场景 4D 重建的质量和稳定性。
---

## 摘要
我们提出了 FLAG-4D，这是一个通过重建 3D 高斯基元（3D Gaussian primitives）在时空中的演化过程，从而生成动态场景新视角的创新框架。现有方法通常依赖单一的多层感知机（MLP）来建模时间变形，在处理复杂点运动和细粒度动态细节时，往往难以在时间上保持一致性，尤其是在输入视角稀疏的情况下。我们的方法 FLAG-4D 通过采用双重变形网络克服了这一问题，该网络随时间将一组规范的 3D 高斯动态扭曲到新的位置和各向异性形状。该双重变形网络由用于建模细粒度局部变形的瞬时变形网络（IDN）和用于捕捉长程动力学的全局运动网络（GMN）组成，并通过相互学习进行优化。为了确保这些变形既准确又在时间上平滑，FLAG-4D 整合了来自预训练光流骨干网络的密集运动特征。我们融合了来自相邻时间帧的运动线索，并使用变形引导的注意力机制将这些光流信息与每个演化中的 3D 高斯的当前状态相对齐。大量实验表明，与现有最先进的方法相比，FLAG-4D 实现了更高保真度和更具时间连贯性的重建，并保留了更精细的细节。

## Abstract
We introduce FLAG-4D, a novel framework for generating novel views of dynamic scenes by reconstructing how 3D Gaussian primitives evolve through space and time. Existing methods typically rely on a single Multilayer Perceptron (MLP) to model temporal deformations, and they often struggle to capture complex point motions and fine-grained dynamic details consistently over time, especially from sparse input views. Our approach, FLAG-4D, overcomes this by employing a dual-deformation network that dynamically warps a canonical set of 3D Gaussians over time into new positions and anisotropic shapes. This dual-deformation network consists of an Instantaneous Deformation Network (IDN) for modeling fine-grained, local deformations and a Global Motion Network (GMN) for capturing long-range dynamics, refined through mutual learning. To ensure these deformations are both accurate and temporally smooth, FLAG-4D incorporates dense motion features from a pretrained optical flow backbone. We fuse these motion cues from adjacent timeframes and use a deformation-guided attention mechanism to align this flow information with the current state of each evolving 3D Gaussian. Extensive experiments demonstrate that FLAG-4D achieves higher-fidelity and more temporally coherent reconstructions with finer detail preservation than state-of-the-art methods.