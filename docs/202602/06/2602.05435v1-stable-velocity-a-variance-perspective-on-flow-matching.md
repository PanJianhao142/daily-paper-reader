---
title: "Stable Velocity: A Variance Perspective on Flow Matching"
title_zh: Stable Velocity：流匹配的方差视角
authors: "Donglin Yang, Yongxing Zhang, Xin Yu, Liang Hou, Xin Tao, Pengfei Wan, Xiaojuan Qi, Renjie Liao"
date: 2026-02-05
pdf: "https://arxiv.org/pdf/2602.05435v1"
tags: ["keyword:FM"]
score: 6.0
evidence: 流匹配中的方差减少以实现稳定优化
tldr: 针对流匹配（Flow Matching）中单样本条件速度导致的高方差训练问题，本文提出了 Stable Velocity 框架。通过分析方差分布，识别出靠近先验的高方差区和靠近数据的低方差区。研究提出了 StableVM 目标函数和 VA-REPA 辅助监督以稳定训练，并利用低方差区的动力学简化实现 StableVS 加速采样。在 ImageNet 及 SD3.5、Flux、Wan2.2 等大规模模型上验证了其在提升训练效率和实现 2 倍以上无损采样加速方面的显著效果。
motivation: 流匹配训练中条件速度的高方差导致优化不稳定且收敛缓慢，限制了生成模型的训练效率和推理性能。
method: 提出包含方差缩减目标 StableVM、自适应辅助监督 VA-REPA 以及无需微调的加速采样 StableVS 的统一框架。
result: 在多个主流预训练文生图与文生视频模型上，该方法显著提升了训练稳定性，并在不损失质量的前提下实现了超过 2 倍的采样加速。
conclusion: 通过从方差视角重新审视流匹配动力学，本研究为优化大规模生成模型的训练与推理提供了一种高效且普适的解决方案。
---

## 摘要
尽管流匹配（flow matching）非常优雅，但它对单样本条件速度的依赖导致了高方差的训练目标，从而使优化不稳定并减慢了收敛速度。通过显式地刻画这种方差，我们识别出：1) 先验分布附近的高方差区域，该区域的优化具有挑战性；2) 数据分布附近的低方差区域，该区域的条件速度与边缘速度几乎重合。利用这一见解，我们提出了 Stable Velocity，这是一个同时改进训练和采样的统一框架。在训练方面，我们引入了 Stable Velocity Matching (StableVM)——一种无偏的方差缩减目标，以及方差感知表示对齐 (VA-REPA)，后者在低方差区域自适应地加强辅助监督。在推理方面，我们证明了低方差区域的动力学允许闭式简化，从而实现了 Stable Velocity Sampling (StableVS)，这是一种无需微调的加速方法。在 ImageNet $256\times256$ 以及包括 SD3.5、Flux、Qwen-Image 和 Wan2.2 在内的大型预训练文本生成图像和文本生成视频模型上的广泛实验表明，该方法在训练效率上有一致的提升，并且在不降低样本质量的情况下，在低方差区域实现了超过 2 倍的采样加速。我们的代码可在 https://github.com/linYDTHU/StableVelocity 获取。

## Abstract
While flow matching is elegant, its reliance on single-sample conditional velocities leads to high-variance training targets that destabilize optimization and slow convergence. By explicitly characterizing this variance, we identify 1) a high-variance regime near the prior, where optimization is challenging, and 2) a low-variance regime near the data distribution, where conditional and marginal velocities nearly coincide. Leveraging this insight, we propose Stable Velocity, a unified framework that improves both training and sampling. For training, we introduce Stable Velocity Matching (StableVM), an unbiased variance-reduction objective, along with Variance-Aware Representation Alignment (VA-REPA), which adaptively strengthen auxiliary supervision in the low-variance regime. For inference, we show that dynamics in the low-variance regime admit closed-form simplifications, enabling Stable Velocity Sampling (StableVS), a finetuning-free acceleration. Extensive experiments on ImageNet $256\times256$ and large pretrained text-to-image and text-to-video models, including SD3.5, Flux, Qwen-Image, and Wan2.2, demonstrate consistent improvements in training efficiency and more than $2\times$ faster sampling within the low-variance regime without degrading sample quality. Our code is available at https://github.com/linYDTHU/StableVelocity.