---
title: "FastVMT: Eliminating Redundancy in Video Motion Transfer"
title_zh: FastVMT：消除视频动作迁移中的冗余
authors: "Yue Ma, Zhikai Wang, Tianhao Ren, Mingzhe Zheng, Hongyu Liu, Jiayi Guo, Mark Fong, Yuxuan Xue, Zixiang Zhao, Konrad Schindler, Qifeng Chen, Linfeng Zhang"
date: 2026-02-05
pdf: "https://arxiv.org/pdf/2602.05551v1"
tags: ["keyword:MDM", "query:课题"]
score: 6.0
evidence: 使用扩散Transformer处理视频动作迁移并解决时间冗余问题
tldr: 本研究针对视频动作迁移（VMT）中Diffusion Transformer（DiT）架构计算效率低下的问题，提出了FastVMT。通过识别并消除运动冗余（帧间运动微小且平滑）和梯度冗余（扩散轨迹中梯度变化缓慢），该方法引入了局部注意力掩码和梯度重用优化方案。在保持视频质量和时间一致性的前提下，FastVMT实现了平均3.43倍的推理加速，显著提升了生成效率。
motivation: 现有的视频动作迁移方法在DiT架构中存在严重的结构性计算冗余，导致推理速度缓慢且效率低下。
method: 通过引入局部注意力掩码减少不必要的远距离像素交互，并设计梯度重用方案以跳过扩散过程中的冗余计算。
result: 实验结果显示，FastVMT在不损失视觉保真度和时间一致性的情况下，实现了平均3.43倍的生成加速。
conclusion: FastVMT通过针对性地消除运动和梯度冗余，为实现高效、高质量的视频动作迁移提供了一种有效的优化方案。
---

## 摘要
视频动作迁移旨在根据文本提示生成视觉内容，同时迁移参考视频中观察到的动作模式。最近的方法主要采用扩散 Transformer (DiT) 架构。为了获得满意的运行时间，一些方法尝试加速 DiT 中的计算，但未能解决结构性的低效根源。在这项工作中，我们识别并消除了早期工作中的两种计算冗余：动作冗余源于通用 DiT 架构未能反映帧间运动微小且平滑的事实；梯度冗余则发生在忽略梯度沿扩散轨迹缓慢变化的情况下。为了减轻动作冗余，我们将相应的注意力层掩码限制在局部邻域内，从而避免在不必要的远处图像区域计算交互权重。为了利用梯度冗余，我们设计了一种优化方案，重用先前扩散步骤的梯度并跳过不必要的梯度计算。平均而言，FastVMT 在不降低生成视频的视觉保真度或时间一致性的情况下，实现了 3.43 倍的加速。

## Abstract
Video motion transfer aims to synthesize videos by generating visual content according to a text prompt while transferring the motion pattern observed in a reference video. Recent methods predominantly use the Diffusion Transformer (DiT) architecture. To achieve satisfactory runtime, several methods attempt to accelerate the computations in the DiT, but fail to address structural sources of inefficiency. In this work, we identify and remove two types of computational redundancy in earlier work: motion redundancy arises because the generic DiT architecture does not reflect the fact that frame-to-frame motion is small and smooth; gradient redundancy occurs if one ignores that gradients change slowly along the diffusion trajectory. To mitigate motion redundancy, we mask the corresponding attention layers to a local neighborhood such that interaction weights are not computed unnecessarily distant image regions. To exploit gradient redundancy, we design an optimization scheme that reuses gradients from previous diffusion steps and skips unwarranted gradient computations. On average, FastVMT achieves a 3.43x speedup without degrading the visual fidelity or the temporal consistency of the generated videos.