---
title: "4RC: 4D Reconstruction via Conditional Querying Anytime and Anywhere"
title_zh: 4RC：通过随时随地的条件查询实现 4D 重建
authors: "Yihang Luo, Shangchen Zhou, Yushi Lan, Xingang Pan, Chen Change Loy"
date: 2026-02-10
pdf: "https://arxiv.org/pdf/2602.10094v1"
tags: ["query:课题"]
score: 6.0
evidence: 利用时空潜空间从视频中查询运动动力学。
tldr: 4RC是一个针对单目视频的统一前馈4D重建框架。它通过Transformer将视频编码为时空潜空间，并采用“一次编码，随时随地查询”的范式，利用条件解码器在任意时间点查询任意帧的3D几何和运动。该方法将4D属性分解为基础几何和相对运动，实现了高效且密集的场景重建，在多项任务中表现优于现有方法。
motivation: 现有方法通常将运动与几何解耦或仅生成有限的4D属性，难以全面捕捉密集的场景几何与动态变化。
method: 引入一种“一次编码，随时随地查询”的范式，通过Transformer编码视频并利用条件解码器将4D属性分解为基础几何与相对运动进行预测。
result: 在广泛的4D重建任务实验中，4RC的性能显著超越了先前及同期的先进方法。
conclusion: 4RC通过统一的端到端框架实现了高效、密集的单目视频4D重建，为处理复杂的时空动态提供了强有力的解决方案。
---

## 摘要
我们提出了 4RC，这是一个用于单目视频 4D 重建的统一前馈框架。与通常将运动与几何解耦，或仅产生有限 4D 属性（如稀疏轨迹或两视图场景流）的现有方法不同，4RC 学习了一种整体的 4D 表示，能够同时捕捉密集的场景几何和运动动力学。其核心在于，4RC 引入了一种新颖的“一次编码，随时随地查询”范式：Transformer 骨干网络将整个视频编码进一个紧凑的时空潜空间，条件解码器可以从中高效地查询任何查询帧在任何目标时间戳的 3D 几何和运动。为了促进学习，我们将每个视图的 4D 属性表示为最小分解形式，将其分解为基础几何和随时间变化的相对运动。大量的实验表明，4RC 在广泛的 4D 重建任务中优于先前和同时期的方法。

## Abstract
We present 4RC, a unified feed-forward framework for 4D reconstruction from monocular videos. Unlike existing approaches that typically decouple motion from geometry or produce limited 4D attributes such as sparse trajectories or two-view scene flow, 4RC learns a holistic 4D representation that jointly captures dense scene geometry and motion dynamics. At its core, 4RC introduces a novel encode-once, query-anywhere and anytime paradigm: a transformer backbone encodes the entire video into a compact spatio-temporal latent space, from which a conditional decoder can efficiently query 3D geometry and motion for any query frame at any target timestamp. To facilitate learning, we represent per-view 4D attributes in a minimally factorized form by decomposing them into base geometry and time-dependent relative motion. Extensive experiments demonstrate that 4RC outperforms prior and concurrent methods across a wide range of 4D reconstruction tasks.