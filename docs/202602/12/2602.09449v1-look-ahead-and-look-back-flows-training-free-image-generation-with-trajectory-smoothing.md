---
title: "Look-Ahead and Look-Back Flows: Training-Free Image Generation with Trajectory Smoothing"
title_zh: 前瞻与回溯流：基于轨迹平滑的免训练图像生成
authors: "Yan Luo, Henry Huang, Todd Y. Zhou, Mengyu Wang"
date: 2026-02-10
pdf: "https://arxiv.org/pdf/2602.09449v1"
tags: ["keyword:FM"]
score: 6.0
evidence: 用于轨迹调整的流匹配框架
tldr: 本研究针对流匹配生成模型中速度场调整易导致误差累积的问题，提出了Look-Ahead和Look-Back两种无需训练的潜空间轨迹平滑方法。Look-Ahead通过曲率门控权重融合未来潜变量，Look-Back则利用指数移动平均平滑历史轨迹。该方法直接在潜空间优化生成路径，在无需重新训练的情况下，显著提升了图像生成的质量与稳定性。
motivation: 修改速度场会引入随路径传播的累积误差，而直接调整潜空间轨迹能更好地利用预训练网络的纠错能力来减少误差。
method: 提出了Look-Ahead（基于曲率门控融合当前与下一步潜变量）和Look-Back（利用带衰减的指数移动平均平滑轨迹）两种轨迹平滑方案。
result: 在COCO17、CUB-200和Flickr30K等多个数据集上的实验证明，该方法在多项性能指标上均显著优于现有的先进模型。
conclusion: 通过在潜空间引入轨迹平滑机制，可以在不增加训练成本的前提下，有效优化流匹配模型的生成路径并提升图像生成质量。
---

## 摘要
近期的进展通过流匹配（flow matching）框架将扩散模型重新表述为确定性常微分方程（ODE），为从噪声到数据的生成过程提供了一个统一的公式。目前已开发出多种免训练的流匹配方法，通过调整流速度场来改进图像生成，从而消除了昂贵的重新训练需求。然而，修改速度场 $v$ 会引入在整个生成路径中传播的误差，而对潜变量轨迹 $z$ 的调整则会被预训练的速度网络自然地修正，从而减少误差累积。在本文中，我们提出了两种互补的免训练潜变量轨迹调整方法，基于未来和过去的速度 $v$ 以及潜变量轨迹 $z$ 的信息，直接在潜空间中优化生成路径。我们提出了两种免训练的轨迹平滑方案：Look-Ahead（前瞻），它使用曲率门控权重对当前和下一步的潜变量进行平均；以及 Look-Back（回溯），它使用带衰减的指数移动平均来平滑潜变量。我们通过广泛的实验和全面的评估指标证明，所提出的免训练轨迹平滑模型在包括 COCO17、CUB-200 和 Flickr30K 在内的多个数据集上显著优于各种最先进的模型。

## Abstract
Recent advances have reformulated diffusion models as deterministic ordinary differential equations (ODEs) through the framework of flow matching, providing a unified formulation for the noise-to-data generative process. Various training-free flow matching approaches have been developed to improve image generation through flow velocity field adjustment, eliminating the need for costly retraining. However, Modifying the velocity field $v$ introduces errors that propagate through the full generation path, whereas adjustments to the latent trajectory $z$ are naturally corrected by the pretrained velocity network, reducing error accumulation. In this paper, we propose two complementary training-free latent-trajectory adjustment approaches based on future and past velocity $v$ and latent trajectory $z$ information that refine the generative path directly in latent space. We propose two training-free trajectory smoothing schemes: \emph{Look-Ahead}, which averages the current and next-step latents using a curvature-gated weight, and \emph{Look-Back}, which smoothes latents using an exponential moving average with decay. We demonstrate through extensive experiments and comprehensive evaluation metrics that the proposed training-free trajectory smoothing models substantially outperform various state-of-the-art models across multiple datasets including COCO17, CUB-200, and Flickr30K.