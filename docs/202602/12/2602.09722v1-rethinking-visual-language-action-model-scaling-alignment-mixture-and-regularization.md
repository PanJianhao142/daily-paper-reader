---
title: "Rethinking Visual-Language-Action Model Scaling: Alignment, Mixture, and Regularization"
title_zh: 重新思考视觉-语言-动作模型缩放：对齐、混合与正则化
authors: "Ye Wang, Sipeng Zheng, Hao Luo, Wanpeng Zhang, Haoqi Yuan, Chaoyi Xu, Haiweng Xu, Yicheng Feng, Mingyang Yu, Zhiyu Kang, Zongqing Lu, Qin Jin"
date: 2026-02-10
pdf: "https://arxiv.org/pdf/2602.09722v1"
tags: ["keyword:FM", "query:课题"]
score: 6.0
evidence: 结合视觉语言骨干与流匹配进行机器人控制
tldr: 本研究系统地探讨了视觉-语言-动作（VLA）模型在跨机器人数据缩放时的关键设计选择。通过在多样化机器人数据集上进行受控实验，研究发现统一的末端执行器相对动作表示对跨具身迁移至关重要，而盲目合并异构数据往往导致负迁移。此外，研究还评估了正则化策略的效果，并引入了减少实验偏差的评估协议，为构建大规模通用机器人策略提供了实践指导。
motivation: 旨在解决在异构机器人数据（不同传感器、动作空间等）背景下，VLA模型如何有效实现数据缩放和跨具身迁移的问题。
method: 采用结合视觉语言骨干网络与流匹配的VLA框架，通过消融实验研究物理对齐、数据混合和训练正则化，并引入分组盲测评估协议。
result: 实验表明统一的末端执行器相对动作表示是迁移的关键，而简单的数据池化常引发负迁移，且常见的正则化手段在大规模训练中效果有限。
conclusion: 挑战了具身智能缩放中的常见假设，强调了物理对齐和精细化数据管理在训练大规模通用VLA模型中的核心地位。
---

## 摘要
尽管视觉-语言-动作（VLA）模型在通用机器人控制方面展现出巨大潜力，但目前尚不清楚标准的“数据缩放”方案是否以及在何种条件下适用于机器人领域，因为机器人训练数据在具身形式、传感器和动作空间方面具有固有的异构性。我们对 VLA 缩放进行了系统且受控的研究，重新审视了跨多样化机器人预训练的核心训练选择。我们采用一个结合了视觉-语言骨干网络与流匹配（flow-matching）的代表性 VLA 框架，在受控条件下对关键设计决策进行了消融实验，并在广泛的仿真和真实机器人实验中进行了评估。为了提高真实世界结果的可靠性，我们引入了一种“分组盲测集成”（Grouped Blind Ensemble）协议，该协议使操作员对模型身份保持盲态，并将策略执行与结果判定分离，从而减少实验者偏差。我们的分析针对 VLA 缩放的三个维度：(1) 物理对齐：我们证明了统一的末端执行器（EEF）相对动作表示对于鲁棒的跨具身迁移至关重要；(2) 具身混合：我们发现，简单地汇集异构机器人数据集往往会导致负迁移而非收益，这凸显了盲目数据缩放的脆弱性；(3) 训练正则化：我们观察到，诸如传感器丢弃（sensory dropout）和多阶段微调等直观策略在模型缩放时并不能持续提升性能。总之，本研究挑战了关于具身缩放的一些常见假设，并为利用多样化机器人数据训练大规模 VLA 策略提供了实践指导。项目网站：https://research.beingbeyond.com/rethink_vla

## Abstract
While Vision-Language-Action (VLA) models show strong promise for generalist robot control, it remains unclear whether -- and under what conditions -- the standard "scale data" recipe translates to robotics, where training data is inherently heterogeneous across embodiments, sensors, and action spaces. We present a systematic, controlled study of VLA scaling that revisits core training choices for pretraining across diverse robots. Using a representative VLA framework that combines a vision-language backbone with flow-matching, we ablate key design decisions under matched conditions and evaluate in extensive simulation and real-robot experiments. To improve the reliability of real-world results, we introduce a Grouped Blind Ensemble protocol that blinds operators to model identity and separates policy execution from outcome judgment, reducing experimenter bias. Our analysis targets three dimensions of VLA scaling. (1) Physical alignment: we show that a unified end-effector (EEF)-relative action representation is critical for robust cross-embodiment transfer. (2) Embodiment mixture: we find that naively pooling heterogeneous robot datasets often induces negative transfer rather than gains, underscoring the fragility of indiscriminate data scaling. (3) Training regularization: we observe that intuitive strategies, such as sensory dropout and multi-stage fine-tuning, do not consistently improve performance at scale. Together, this study challenge some common assumptions about embodied scaling and provide practical guidance for training large-scale VLA policies from diverse robotic data. Project website: https://research.beingbeyond.com/rethink_vla