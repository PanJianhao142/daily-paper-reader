---
title: "Binary Flow Matching: Prediction-Loss Space Alignment for Robust Learning"
title_zh: 二进制流匹配：用于鲁棒学习的预测-损失空间对齐
authors: "Jiadong Hong, Lei Liu, Xinyu Bian, Wenjie Wang, Zhaoyang Zhang"
date: 2026-02-11
pdf: "https://arxiv.org/pdf/2602.10420v1"
tags: ["keyword:FM"]
score: 6.0
evidence: 研究流匹配预测与损失的对齐
tldr: 本研究探讨了二元流匹配在离散数据生成中的应用，揭示了信号空间预测与速度损失函数之间存在结构性不匹配，导致梯度对近似误差高度敏感。通过提出“预测-损失空间对齐”原则，研究证明采用信号空间损失（x-loss）能消除奇异权重，从而在无需启发式调度的情况下实现鲁棒训练。该工作为二元及离散领域的流匹配提供了理论基础，强调了空间对齐在扩散学习中的重要性。
motivation: 旨在解决二元流匹配中因预测目标与损失函数空间不一致导致的梯度奇异性和训练不稳定性问题。
method: 形式化了预测-损失对齐条件，通过将优化目标重新对齐至信号空间（x-loss）来确保梯度的均匀有界性。
result: 消除了训练中对复杂时间步调度的依赖，实现了在均匀采样下的鲁棒学习，并厘清了概率目标与几何损失在二元拓扑下的差异。
conclusion: 信号空间对齐是构建鲁棒二元流匹配模型的关键准则，为离散域生成模型提供了有效的理论指导和实践方案。
---

## 摘要
流匹配（Flow matching）已成为生成建模的一种强大框架，最近的实证成功突显了信号空间预测（$x$-预测）的有效性。在这项工作中，我们研究了将这一范式迁移到二进制流形（binary manifolds）的情况，这是离散数据生成建模的一个基础设置。虽然 $x$-预测仍然有效，但我们发现当它与基于速度的目标（$v$-损失）结合时，会出现一种潜在的结构性失配，导致产生随时间变化的奇异权重（singular weighting），从而放大了梯度对近似误差的敏感性。受此观察启发，我们将预测-损失对齐（prediction-loss alignment）形式化为流匹配训练的一个必要条件。我们证明，将目标重新对齐到信号空间（$x$-损失）可以消除奇异权重，产生一致有界的梯度，并能在不依赖启发式调度的情况下，在均匀时间步采样下实现鲁棒训练。最后，在确保对齐的前提下，我们研究了针对二进制数据的特定设计选择，揭示了概率目标（如交叉熵）与几何损失（如均方误差）之间存在依赖于拓扑的区别。总之，这些结果为二进制及相关离散领域的鲁棒流匹配提供了理论基础和实践指南，将信号空间对齐定位为鲁棒扩散学习的一个关键原则。

## Abstract
Flow matching has emerged as a powerful framework for generative modeling, with recent empirical successes highlighting the effectiveness of signal-space prediction ($x$-prediction). In this work, we investigate the transfer of this paradigm to binary manifolds, a fundamental setting for generative modeling of discrete data. While $x$-prediction remains effective, we identify a latent structural mismatch that arises when it is coupled with velocity-based objectives ($v$-loss), leading to a time-dependent singular weighting that amplifies gradient sensitivity to approximation errors. Motivated by this observation, we formalize prediction-loss alignment as a necessary condition for flow matching training. We prove that re-aligning the objective to the signal space ($x$-loss) eliminates the singular weighting, yielding uniformly bounded gradients and enabling robust training under uniform timestep sampling without reliance on heuristic schedules. Finally, with alignment secured, we examine design choices specific to binary data, revealing a topology-dependent distinction between probabilistic objectives (e.g., cross-entropy) and geometric losses (e.g., mean squared error). Together, these results provide theoretical foundations and practical guidelines for robust flow matching on binary -- and related discrete -- domains, positioning signal-space alignment as a key principle for robust diffusion learning.