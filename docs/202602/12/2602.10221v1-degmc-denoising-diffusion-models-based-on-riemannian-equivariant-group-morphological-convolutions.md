---
title: "DEGMC: Denoising Diffusion Models Based on Riemannian Equivariant Group Morphological Convolutions"
title_zh: DEGMC：基于黎曼等变群形态学卷积的去噪扩散模型
authors: "El Hadji S. Diop, Thierno Fall, Mohamed Daoudi"
date: 2026-02-10
pdf: "https://arxiv.org/pdf/2602.10221v1"
tags: ["keyword:MDM"]
score: 6.0
evidence: 用于几何特征提取的去噪扩散模型
tldr: 针对去噪扩散概率模型（DDPM）在几何特征提取和等变性方面的局限，本文提出DEGMC模型。该模型引入黎曼流形上的群形态学卷积，利用Hamilton-Jacobi偏微分方程的粘性解实现多尺度膨胀与腐蚀，并结合对流项和特征线法处理非线性结构。实验证明，该方法在MNIST、RotoMNIST和CIFAR-10数据集上显著提升了生成质量和等变性表现。
motivation: 现有的DDPM模型主要依赖仅具平移等变性的U-net架构，难以有效提取复杂的几何特征并满足旋转、反射等更广泛的欧几里得群等变性需求。
method: 提出基于黎曼流形的群形态学卷积，通过求解带有对流项的Hamilton-Jacobi方程来捕捉非线性几何结构，并利用特征线法将其整合进学习过程。
result: 在MNIST、RotoMNIST和CIFAR-10等数据集上的实验结果显示，该方法在捕捉薄几何结构和处理对称性方面优于基准DDPM模型。
conclusion: 结合群形态学卷积和黎曼几何的扩散模型能更有效地处理几何特征和对称性，为提升生成模型的结构表达能力提供了新路径。
---

## 摘要
在这项工作中，我们解决了近期去噪扩散概率模型（DDPM）中的两个主要问题：1）几何关键特征提取，以及 2）网络等变性。由于 DDPM 预测网络依赖于 U-net 架构，而该架构在理论上仅具有平移等变性，因此我们引入了一种几何方法，并结合了更通用的欧几里得群（包括旋转、镜像和置换）的等变性质。我们在黎曼流形中引入了群形态学卷积的概念，这些卷积源自一阶 Hamilton-Jacobi 型偏微分方程（PDE）的粘性解，起到了形态学多尺度膨胀和腐蚀的作用。我们在模型中加入了一个对流项，并使用特征线法进行求解。这有助于我们更好地捕捉非线性、表示细微的几何结构，并将对称性融入学习过程。在 MNIST、RotoMNIST 和 CIFAR-10 数据集上的实验结果表明，与基准 DDPM 模型相比，该方法有显著改进。

## Abstract
In this work, we address two major issues in recent Denoising Diffusion Probabilistic Models (DDPM): {\bf 1)} geometric key feature extraction and {\bf 2)} network equivariance. Since the DDPM prediction network relies on the U-net architecture, which is theoretically only translation equivariant, we introduce a geometric approach combined with an equivariance property of the more general Euclidean group, which includes rotations, reflections, and permutations. We introduce the notion of group morphological convolutions in Riemannian manifolds, which are derived from the viscosity solutions of first-order Hamilton-Jacobi-type partial differential equations (PDEs) that act as morphological multiscale dilations and erosions. We add a convection term to the model and solve it using the method of characteristics. This helps us better capture nonlinearities, represent thin geometric structures, and incorporate symmetries into the learning process. Experimental results on the MNIST, RotoMNIST, and CIFAR-10 datasets show noticeable improvements compared to the baseline DDPM model.