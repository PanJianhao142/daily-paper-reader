---
title: "VLS: Steering Pretrained Robot Policies via Vision-Language Models"
title_zh: VLS：通过视觉语言模型引导预训练机器人策略
authors: "Shuo Liu, Ishneet Sukhvinder Singh, Yiqing Xu, Jiafei Duan, Ranjay Krishna"
date: 2026-02-03
pdf: "https://arxiv.org/pdf/2602.03973v1"
tags: ["keyword:FM", "keyword:MDM", "query:课题"]
score: 7.0
evidence: 引导预训练的扩散或流匹配策略
tldr: 本研究针对预训练机器人策略在环境偏移（如障碍物、布局变化）下易失效的问题，提出了 Vision-Language Steering (VLS) 框架。这是一种无需训练的推理时自适应方法，通过视觉语言模型（VLM）合成轨迹可微的奖励函数，引导冻结的扩散或流匹配策略在采样过程中生成符合特定空间和任务要求的动作。VLS 在 CALVIN 和 LIBERO-PRO 任务中表现优异，显著提升了策略在分布外场景下的鲁棒性。
motivation: 预训练机器人策略在面临环境偏移时容易失效，且重新训练或微调以适应新场景的成本极高。
method: 提出 VLS 框架，利用视觉语言模型生成可微奖励函数，在推理阶段引导冻结策略的采样过程以满足新的空间和任务约束。
result: "在 CALVIN 和 LIBERO-PRO 基准测试中分别实现了 31% 和 13% 的性能提升，并在真实机器人上成功演示了鲁棒的自适应能力。"
conclusion: VLS 证明了通过推理时引导而非重新训练，可以有效解决预训练策略在分布外环境中的泛化难题。
---

## 摘要
为什么预训练的扩散或流匹配策略在障碍物附近、偏移的支撑面上或轻微杂乱的环境中执行相同任务时会失败？此类失败很少反映出运动技能的缺失；相反，它们暴露了模仿学习在训练-测试偏移下的局限性，即动作生成与训练特定的空间配置和任务规范紧密耦合。通过重新训练或微调来解决这些失败成本高昂且在概念上不一致，因为所需的行为已经存在，但无法在测试时进行选择性适配。我们提出了视觉语言引导（Vision-Language Steering, VLS），这是一个无需训练的框架，用于对冻结的生成式机器人策略进行推理时适配。VLS 将适配视为推理时控制问题，在不修改策略参数的情况下，根据分布外（OOD）的观察-语言输入引导预训练扩散或流匹配策略的采样过程。通过利用视觉语言模型合成轨迹可微的奖励函数，VLS 引导去噪过程朝着满足测试时空间和任务要求的动作轨迹进行。在仿真和真实世界的评估中，VLS 一贯优于先前的引导方法，在 CALVIN 上实现了 31% 的提升，在 LIBERO-PRO 上实现了 13% 的增益。在 Franka 机器人上的真实世界部署进一步证明了在测试时空间和语义偏移下稳健的推理时适配能力。项目页面：https://vision-language-steering.github.io/webpage/

## Abstract
Why do pretrained diffusion or flow-matching policies fail when the same task is performed near an obstacle, on a shifted support surface, or amid mild clutter? Such failures rarely reflect missing motor skills; instead, they expose a limitation of imitation learning under train-test shifts, where action generation is tightly coupled to training-specific spatial configurations and task specifications. Retraining or fine-tuning to address these failures is costly and conceptually misaligned, as the required behaviors already exist but cannot be selectively adapted at test time. We propose Vision-Language Steering (VLS), a training-free framework for inference-time adaptation of frozen generative robot policies. VLS treats adaptation as an inference-time control problem, steering the sampling process of a pretrained diffusion or flow-matching policy in response to out-of-distribution observation-language inputs without modifying policy parameters. By leveraging vision-language models to synthesize trajectory-differentiable reward functions, VLS guides denoising toward action trajectories that satisfy test-time spatial and task requirements. Across simulation and real-world evaluations, VLS consistently outperforms prior steering methods, achieving a 31% improvement on CALVIN and a 13% gain on LIBERO-PRO. Real-world deployment on a Franka robot further demonstrates robust inference-time adaptation under test-time spatial and semantic shifts. Project page: https://vision-language-steering.github.io/webpage/