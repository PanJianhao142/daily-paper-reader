Title: Dynamical Regimes of Multimodal Diffusion Models

URL Source: https://arxiv.org/pdf/2602.04780v1

Published Time: Thu, 05 Feb 2026 02:23:38 GMT

Number of Pages: 41

Markdown Content:
# Dynamical Regimes of Multimodal Diffusion Models 

Emil Albrychiewicz, a,b, 1 Andr´ es Franco Valiente, a,b,c, 1 and Li-Ching Chen d

> a

Leinweber Institute for Theoretical Physics and Department of Physics, University of California, Berkeley, CA, 94720-7300, USA 

> b

Theoretical Physics Group, Lawrence Berkeley National Laboratory, Berkeley, CA 94720-8162, USA 

> c

Department of Radiation Oncology, University of California, San Francisco 

> d

Computational Precision Health, University of California San Francisco, 2177 Hearst Ave, Berkeley, CA, 94709, USA 

> 1

These authors contributed equally. 

E-mail: ealbrych@berkeley.edu , andresfranco@berkeley.edu ,

liching chen@berkeley.edu 

Abstract: Diffusion based generative models have achieved unprecedented fidelity in syn-thesizing high dimensional data, yet the theoretical mechanisms governing multimodal gen-eration remain poorly understood. Here, we present a theoretical framework for coupled diffusion models, using coupled Ornstein-Uhlenbeck processes as a tractable model. By using the nonequilibrium statistical physics of dynamical phase transitions, we demonstrate that multimodal generation is governed by a spectral hierarchy of interaction timescales rather than simultaneous resolution. A key prediction is the “synchronization gap”, a temporal window during the reverse generative process where distinct eigenmodes stabilize at different rates, providing a theoretical explanation for common desynchronization artifacts. We derive analytical conditions for speciation and collapse times under both symmetric and anisotropic coupling regimes, establishing strict bounds for coupling strength to avoid unstable symmetry breaking. We show that the coupling strength acts as a spectral filter that enforces a tunable temporal hierarchy on generation. We support these predictions through controlled exper-iments with diffusion models trained on MNIST datasets and exact score samplers. These results motivate time dependent coupling schedules that target mode specific timescales, of-fering a potential alternative to ad hoc guidance tuning. 

> arXiv:2602.04780v1 [cs.LG] 4 Feb 2026

## Contents 

1. Introduction 12. Theoretical Framework of Coupled Diffusion Models 43. The Symmetric Relaxation Matrix 11 4. The Anisotropic Relaxation Matrix 17 5. MNIST Synchronization Experiment 21 

5.1. Protocol I: Deterministic Synchronization Diagnostics 23 5.2. Protocol II: Cloning Based Speciation Curves 24 5.3. Results 25 

6. Discussion and Future Directions 30 A. Derivation Of The Cumulant Generating Function For Symmetric Cou-pling 32 B. Explicit Form Of Diffusion Kernel For Anisotropic Coupling 33 C. Exact-score OU Toy Experiment For Anisotropic Relaxation Matrix 35 

## 1. Introduction 

The recent success of diffusion based generative models has fundamentally transformed the landscape of unsupervised learning, enabling the synthesis of high dimensional data with unprecedented fidelity across modalities such as image, audio, and video [1–15]. While the empirical performance of these models is well documented, the theoretical mechanisms gov-erning the dynamics of the reverse-time generative process remain an active area of inquiry [16–19]. Recent work by Biroli et al. (2024) [20] provides a rigorous statistical mechan-ics framework for understanding these dynamics in single-variable models, delineating three distinct dynamical regimes: (I) a noise regime, dominated by high-entropy disorder; (II) a speciation regime, where the generative trajectory converges toward the data manifold and samples from the underlying population distribution; and (III) a collapse regime, character-ized by memorization where the process concentrates onto the discrete empirical distribution of the training data. This dynamical description of the denoising process provides theoret-ical context for an important question when diffusion models generate new samples versus recreating memorized ones. – 1 – However, the extension of this framework to multimodal generation introduces nontrivial theoretical complexities, e.g., text-to-image, audio-video problems. Multimodality imposes additional degrees of freedom and necessitates the satisfaction of two distinct constraints: intra-modal content coherence i.e. the structural integrity of each modality, and cross modal alignment [7, 21, 22] i.e. the semantic synchronization between modalities. In this work, we address these constraints within the framework of coupled diffusion models. The coupled diffusion framework acts as the minimal candidate for a universality class for multimodal generation, explicitly representing the statistical dependencies between modalities as an in-teraction term that constrains the joint probability statistical manifold. We argue using the theoretical model that these constraints do not necessarily resolve simultaneously. We demon-strate that the coupling between modalities induces distinct convergence scales, creating a hierarchy of transition times where content formation and alignment stabilize at different stages of the reverse process. To formalize these dynamics, we introduce a framework based on coupled Ornstein-Uhlenbeck (OU) processes [23]. Consider a stochastic process driven purely by a Brownian motion, the variance would grow linearly with time, causing signal values to diverge to infinity and leading to numerical instability. In contrast, the OU process is characterized by a mean-reverting drift term that effectively dampens noise injection. This mean inversion ensures that the process remains within a bounded, numerically stable range and converges to a stationary distribution under specific conditions. Therefore, we choose to model the diffusion architecture via an OU process rather than a simple Brownian motion. Crucially, the existence of this stationary distribution provides a well defined, closed form prior, N (0 , I ), from which the reverse generation process can be initialized. Our approach aligns with the variance preserving formulation proposed by Song et al. (2021) [4], which carefully balances the decay rate and noise magnitude to ensure the total variance of the signal remains constant throughout the forward dynamics. In this work, we provide a comprehensive theoretical analysis of coupled diffusion models in §2. We extend work of [20] to apply statistical physics models, concretely random en-ergy model (REM) [24], to study the dynamical regimes of coupled diffusion processes. Our findings are the following. We derive a generalized speciation time argument as bifurcation point where deterministic drift field acquires additional fixed points (2.30) and review REM arguments for derivation of collapse time condition (2.48). Throughout this paper, we adopt the nomenclature of [20] and we refer to the transition time between regime I and regime II as a speciation time tS , for a transition between regime II and regime III we call this time a 

collapse time tC .In §3, we derive the analytical solution for the reverse process under symmetric linear coupling. By diagonalizing the system into common and difference eigenmodes, we show that speciation time condition can be written as a sum of signal to noise ratios (SNRs) for decoupled modes (3.14). Due to different eigenvalues these modes lead to a separation of time scales. We call this effect as synchronization gap , a temporal window during the reverse process when one eigenmode crossed regime but the other has not. This gap exists for both – 2 – speciation and collapse time and its size depends on the coupling strength g as can be seen on Figure 1 for speciation time and Figure 2 for collapse time. We suggest that this gap can be used to explain desynchronization artifacts often observed in multi modal generation. The coupling strength g acts as a spectral filter that enforces a temporal hierarchy on generation, ensuring that shared semantic structures emerge significantly earlier than modality-specific discrepancies. The transcendental equation for collapse time is given in (3.23). We confirm the curse of dimensionality findings of [20] i.e. if number of samples does not scale exponentially with sample dimension, the collapse time cannot be found. For a chosen set of parameters, the collapse time remains nearly constant when coupling strength g is increased in difference to speciation time that changes significantly. We also derive a strict bound for a coupling strength g (3.11) beyond which the model undergoes unstable symmetry breaking [25–27] and sampling trajectories diverge. A cumulant generating function for computation of collapse time is derive in Appendix A. In §4, we introduce an anisotropic coupling matrix, which is relevant for conditional generation tasks. In this case, information is flowing from one modality to another without a reciprocal feedback. We derive equations for speciation and collapse times and solve them numerically for particular choices of initial distributions. The closed form expressions are listed in Appendix B. As in the symmetric case, the speciation time is more dependent on the coupling strength Figure 3 whereas collapse time does not change much Figure 5. We plot the dependence of speciation time on the alignment angle between condition and target means in Figure 4, showing that large coupling can remove bifurcation points for aligned directions whereas the effect on misaligned directions is much smaller. We also show that conditional collapse time can push collapse time further, demonstrating that external guidance delays the transition to the collapse regime. Importantly, the collapse time does not depend on the angle between condition and target means. To provide evidence for the theory discussed in the paper, we conduct two experiments that we describe in §5 and Appendix C. In the former, we train a diffusion model on the MNIST image dataset [28] and we use deterministic Denoising Diffusion Implicit Model (DDIM) [3] and stochastic Denoising Diffusion Probabilistic Model (DDPM) [29]. This model is supposed to act as a proxy for a symmetric coupled OU discussed in §3. Although we do not change the architecture of the model by explicitly introducing the coupling, we construct pairs of samples that we diagonalize using common and difference eigenmodes. The cou-pling strength modifies diffusion noise covariance. We test whether such model exhibits a synchronization gap and how it changes when coupling strength is adjusted. First, using the experiment with DDIM sampler. We confirm that the synchronization gap cannot be attributed to fixed channel conventions or marginal statistics of the dataset Table 1. We also provide an evidence of a desynchronization effect Figure 8 and show that noise injection in the window when one mode stabilized and the other not affects the not yet stabilized mode more Figure 9. Since the speciation time is a point corresponding to branching of stochastic trajec-tories we employ DDPM sampler to study cloning samples and observing their trajectories in – 3 – the reverse time. By training an image classifier we can determine when clones agree at the final time of denoising process. With that metric one can determine whether the denoising process crossed from the regime I to regime II. Indeed we find that that the synchronization gap appears when the coupling is introduced and its width depends on the coupling strength size Figure 10. In the latter experiment Appendix C we design a conditional generation corresponding to anisotropic coupling discussed in §4. In this case we do not train a neural network, instead we use reverse time sampler with an exact score. We test different values of coupling, applied with different schedules and we find that coupling effect is angle dependent as expected from the theory. We report that small to moderate coupling is beneficial for misaligned modalities. However, constant coupling schedule has a detrimental effect for aligned modalities whereas late coupling has the least detrimental effect on the aligned modalities yet it ameliorates mis-aligned ones. This exact experiment provides an intuition for constructing coupling schedules in realistic examples. In summary, we believe this framework advances the theoretical understanding of diffu-sion models by establishing a direct link between cross modal interaction mechanisms and nonequilibrium phase transitions. By quantifying the synchronization gap, we provide a basis for moving beyond the heuristic tuning of guidance strengths toward the principled design of coupling schedules that respect the intrinsic timescales of semantic emergence across modal-ities. This perspective suggests that future multimodal diffusion architectures should be approached not merely as engineering black boxes, but as nonequilibrium statistical systems whose stability, convergence speed and quality is governed by the spectral hierarchy of their interactions. 

## 2. Theoretical Framework of Coupled Diffusion Models 

For the following sections, we will use uppercase for random variables and lowercase variables for their corresponding realizations. We begin by modeling a coupled diffusion model architecture via a coupled system of two 

d−dimensional Ornstein-Uhlenbeck stochastic processes Z(t) = ( X(t), Y (t)) ∈ R2d described by the Itˆ o stochastic differential equation 

dZ (t) = M Z (t) dt + Σ W dW (t), (2.1) driven by a R2d valued Wiener process W (t) with volatility matrix Σ W . For theoretical clarity, we keep dimensions of X(t) ∈ Rd and Y (t) ∈ Rd to be equal although typically the embedding spaces for different modes (e.g. image and video) have different dimensionality in practice. In what follows, we will discuss two different choices of the relaxation matrix 

M , which we set to be time independent. The intuition behind either choice will be how we wish to model the information flow, we will begin by investigating the case of a symmetric relaxation matrix where there is no preferred information flow between either modality. In – 4 – the second case, we will break this symmetry and introduce an anisotropic relaxation matrix where there is a clear directionality between the information flow between the two modalities. First, we discuss the case of an symmetric relaxation matrix with couplings g and β i.e. 

M = −β gg −β

!

⊗ Id, ΣW = σW 00 σW

!

⊗ Id, (2.2) with a stability condition β > |g| that ensures the eigenvalues have a negative real part. Id

is the d dimensional identity matrix. The case of an anisotropic relaxation matrix will be the choice of a lower triangular relaxation matrix where we explicitly have 

M = −β 0

g −β

!

⊗ Id, ΣW = σW 00 σW

!

⊗ Id, (2.3) in this case there is no stability restriction on the value of g coupling provided that β > 0. We note that this lower triangular case has an explicit decomposition where it can be written as a sum of a diagonal matrix βI 2 and a nilpotent matrix 

M = −βI 2 ⊗ Id + 0 0 

g 0

!

⊗ Id. (2.4) This linear system of SDEs can be explicitly solved through the use of Itˆ o’s lemma. The solution is described by a Gaussian process. In order to see this, we begin by writing the SDE as 

d(e−M t Z(t)) = e−M t ΣW dW (t), (2.5) which can be integrated, given initial conditions Z(0) to give the Gaussian process 

Z(t) = eM t Z(0) + eM t 

Z t

> 0

e−M s ΣW dW (s). (2.6) Note that in the lower triangular anisotropic case, the matrix exponential simplifies due to the nilpotent part of M giving us the useful identity e−M s = e−β(−s)(I − N s ). From this solution, we can then calculate correlation functions such as the mean 

μ(t) = E[Z(t)] = eM t μ(0) , (2.7) and the covariance matrix 

Q(t) = E [( Z(t) − μ(t))( Z(t) − μ(t)) ⊺] (2.8) =

Z t

> 0

eM τ ΣW ΣTW eM ⊺τ dτ. (2.9) – 5 – For the stochastic process described by (2.1) to admit a well-defined transition probability density with respect to the Lebesgue measure on R2d, the covariance matrix Q(t) must be invertible and hence positive definite. It is easy to show that a sufficient condition for this is that the matrix Σ W has full rank which ensures that the driving noise has full support on 

R2d and not just a subspace. In the construction of a diffusion model, we typically have a forward process which adds noise to a dataset given by (2.1). This forward process is typically chosen in such a way that it is converges to a well defined, easy to sample from distribution, e.g., a normal distribution 

N (0 , I d). We then use this stationary distribution as a prior for the reverse process. We use the same time coordinate t ∈ [0 , T ] for both processes, the forward noising process runs from 0 → T and sampling/ denoising process runs back from T → 0. For an Itˆ o diffusion 

dZ = b(Z, t ) dt + Σ W dW with drift term b(Z, t ), Anderson’s time reversal theorem [30] states that there exists a time-reversed process which satisfies 

d eZ(t) = 



b( eZ(t), t ) − σ ∇ eZ log p(n) 

> t

( eZ(t)) 



dt + Σ W dfW (t), (2.10) where p(n) 

> t

is the empirical density of Z(t) induced by the empirical initial distribution p(n)0

and σ is the diffusion matrix σ = Σ W ΣTW and dt refers to a negative time step. In contrast to the forward process, an additional term which is known as the score function ∇ eZ log pt

arises. In the context of score based diffusion models, the score ∇ log p(n) 

> t

is approximated by a neural network and has a loss function given by score matching [31–33]. In the analysis of this paper, we assume that one has access to the exact ∇ log p(n) 

> t

corresponding to p(n)0 . In the literature, this is referred to as exact empirical score [20, 34, 35]. As previously noted, for the linear SDE (2.1), the transition density is a Gaussian process: 

Kt(ez | z) = 1(2 π)dpdet Q(t) exp 



− 12 (ez − eM t z)⊺Q(t)−1(ez − eM t z)



, (2.11) where Z ∈ R2d and thus the normalization uses (2 π)d = (2 π)(2 d)/2, and Q(t) ∈ R2d×2d is the transition covariance (2.8). Accordingly, 

p(n) 

> t

(ez) = 

Z

Kt(ez | z) p(n)0 (z) dz. (2.12) For clarity of analysis, we consider training data that can be separated into different classes. Without loss of generality, we will limit the discussion to two distinct classes however this can be easily generalized to more classes. For the underlying initial population distribution, we choose a two component Gaussian mixture with equal weights, 

P0(z) = 12 N (z; μ(0) , Σ(0)) + 12 N (z; −μ(0) , Σ(0)) , (2.13) where μ ∈ R2d and 

μ(0) = μx(0) 

μy(0) 

!

, μx, μ y ∈ Rd, Σ(0) = σ2 

> x

00 σ2

> y

!

⊗ Id. (2.14) – 6 – The training data consists of n i.i.d. samples {z1, . . . , z n} ∼ P0, hence 

p(n)0 (z) = 1

n

> n

X

> i=1

δ(z − zi) (2.15) Since the forward process is a Gaussian process (2.11), each component remains Gaussian with mean drifted by (2.7) 

μ(t) = eM t μ(0) , (2.16) we define the drifted initial covariance 

S(t) = eM t Σ(0) eM ⊺t (2.17) while the process accumulates noise given by Q(t) (2.8). The empirical probability distribution becomes a mixture of drifted kernels with width 

Q(t)

p(n) 

> t

(z) = 1

n

> n

X

> i=1

N (z; eM t zi, Q (t)) . (2.18) By contrast, the population probability distribution combines the drifted width and the noise, with a diffusion kernel C(t) = S(t) + Q(t), 

Pt(z) = 12 N (z; μ(t), C (t)) + 12 N (z; −μ(t), C (t)) . (2.19) Depending on the regime of analysis we will either use the population or empirical distri-bution. In the speciation regime, thresholds are controlled primarily by the separation of the two population components and can therefore be expressed using the parametric form of 

Pt. In contrast, collapse corresponds to an extremal-statistics transition where p(n) 

> t

becomes dominated by a small number of mixture terms. Capturing this requires retaining the discrete empirical sum and the correct kernel width Q(t). We start with a discussion of the computation of speciation time. For the population mixture Pt in (2.19), completing the square gives 

Pt(z) = 1(2 π)dpdet C(t) exp 



− 12 z⊺C(t)−1z − 12 μ(t)⊺C(t)−1μ(t)



cosh  μ(t)⊺C(t)−1z ,

(2.20) hence log Pt(z) = const( t) − 12 z⊺C(t)−1z + log cosh  μ(t)⊺C(t)−1z , (2.21) where const( t) refers to z independent terms. Substituting (2.21) into the reverse drift in (2.10) (with a = σ2 

> W

I) yields 

brev (z, t ) = −M z + σ2 

> W

∇z log Pt(z)= −(M + σ2 

> W

C(t)−1)z + σ2 

> W

C(t)−1μ(t) tanh  μ(t)⊺C(t)−1z. (2.22) – 7 – If M is symmetric (as in (2.2)), then brev (z, t ) is an irrotational vector field. Consequently, the drift admits a scalar potential Vt which allows us to reformulate the reverse dynamics as a gradient flow brev = −∇ Vt. Up to z independent terms, one convenient choice is 

Vt(z) = 12 z⊺M z + σ2

> W

2 z⊺C(t)−1z − σ2 

> W

log cosh  μ(t)⊺C(t)−1z . (2.23) In the anisotropic case (2.3), the drift is generally non-conservative and no scalar potential exists. Therefore, we define speciation time in a potential independent way as a bifurcation point where the deterministic drift field brev (z, t ) acquires additional fixed points. In the symmetric case, this bifurcation coincides with the emergence of a double-well structure in Vt

as explored in [20, 27]. Therefore, this critical time corresponds to transition from the regime where trajectories are given by random Brownian motion to a regime where trajectories split into clusters. The fixed points of the reverse drift satisfy brev (z, t ) = 0, i.e., 

 M + σ2 

> W

C(t)−1z = σ2 

> W

C(t)−1μ(t) tanh  μ(t)⊺C(t)−1z. (2.24) We expect that for real data, the distribution is highly concentrated and hence the precision matrix has very large positive eigenvalues initially and hence  M + σ2 

> W

C(t)−1 can be ap-proximated by a positive definite matrix. As the diffusion time progresses, the OU process is chosen to reach a stationary process such that at any intermediate times, invertibility is ensured. This can enforced numerically provided that the data variance is smaller than the variance of the stationary distribution. We clean this equation up by writing 

A(t) :=  M + σ2 

> W

C(t)−1−1σ2 

> W

C(t)−1. (2.25) Then (2.24) is equivalent to 

z = A(t) μ(t) tanh( u), where u := μ(t)⊺C(t)−1z. (2.26) Multiplying by μ(t)⊺C(t)−1 yields a scalar self-consistency equation 

u = κ(t) tanh( u), (2.27) with 

κ(t) := μ(t)⊺C(t)−1A(t)μ(t). (2.28) Besides the trivial solution u = 0, non-zero solutions appear via a pitchfork bifurcation at 

κ(t) = 1. Expanding near u = 0 gives 

u − κ tanh( u) = u



1 − κ + κ

3 u2 + O(u4)



, (2.29) so additional stable fixed points exist if and only if κ(t) > 1. We therefore define the speciation time tS by 

κ(tS ) = 1 . (2.30) – 8 – Next, we discuss the derivation of the collapse time, which marks the transition to a regime where the diffusion model exhibits memorization. In this regime, the reverse time trajectories flow toward specific training data points, and the model can no longer generalize to unseen data. Mathematically, this corresponds to the point where the empirical distribution diverges from the underlying population distribution. To derive collapse time, we follow [20] and we employ techniques from the Random Energy Model (REM) [24, 36–38], which is a disordered statistical physics models known to exhibits phase transitions e.g., it was used for analysis of spin glasses. In this approach, the collapse time corresponds to the condensation transition time when the system freezes to its lowest energy states and the partition function is no longer dominated by the entropy of the population states but instead by the energy of the a few specific training examples. This memorization phenomenon can be clearly seen from empirical probability distribution. Using the diffusion kernel (2.11), the posterior weights over training indices can be expressed as 

wi(ez) = Kt(ez|zi)

Pnj=1 Kt(ez|zj ) , (2.31) where index i labels a training sample {zi}ni=1 and zi ∈ R2d. The model has an ability to generalize when all weights contribute comparably but once it localizes on particular index 

i⋆ i.e., wi⋆ (z) ≈ 1 it memorizes training point. If we denote εt(ez, z ) = − 12d log Kt(ez|z), then we can write the partition function as 

Zt(ez) = 

> n

X

> i=1

e−2dε t(ez,z i). (2.32) We will work in the thermodynamic limit where we have asymptotically large d and n with a fixed ratio 

α = 12d log n. (2.33) In addition to this, we will assume that {εt(ez, z i)}ni=1 will behave as independent and identi-cally distributed random variables. We introduce an inverse temperature β and we assume there exists a convex, differentiable function Λt(β) = lim 

> d→∞

12d log E[e−β2dε t ], (2.34) which is known as the scaled cumulant generating function of ϵt. By the G¨ artner-Ellis theo-rem, the rate function It is then given by the Legendre-Fenchel transform 

It(u) = sup 

> β∈R

(−uβ − Λt(β)) , (2.35) where the rate function by the large deviation principle is related to a probability distribution of energy levels 

P(εt ∈ [u, u + du ]) ≈ e−2dI t(u). (2.36) – 9 – Let nt(u)du = # {i : εi ∈ [u, u + du ]} denote the density of states. We can use rate function to obtain an expectation value of density of states 

E[nt(u)] = e2d(α−It(u)) . (2.37) The partition function can be written exactly as 

Z(β) = 

Z

> R

du n t(u)e−β2du . (2.38) The quenched free energy is then given by 

ϕt(β) = lim 

> d→∞

12d E[log Z(β)] = sup 

> u∈D ε

(α − It(u) − βu ), (2.39) where Dε is a set of available energy levels and we used the Laplace approximation to replace density of states with typical value (2.37). This set is bounded by a lower limit such that the expectation of number of states becomes of order 1. Since there n = e2dα samples, from (2.37) the lower bound is given by 

It(umin ) = α, (2.40) if a supremum u⋆ of (2.39), which is given by 

dI t

du (u⋆) = −β, (2.41) is above umin , then exponentially many states contribute to the partition function. From (2.35) we find 

ϕt(β) = α + Λ t(β). (2.42) However, for larger β (lower temperature), the energies will be fixed by a lower bound 

u⋆ = umin , (2.43) 

ϕt(β) = −βu min , (2.44) this is the frozen phase. The system exhibits phase transition and only a small set of config-urations is allowed. The condensation point βc is defined such that 

It(umin ) = α, dI t

du (umin ) = −βc, (2.45) from Legendre transformation umin = −Λ′

> t

(βc) where prime denotes differentiation. Since for the partition function (2.32), we have β = 1, we therefore have for a liquid phase 

ϕt = α + Λ t(1) , (2.46) – 10 – and for a condensation phase 

ϕt = −umin , (2.47) the collapse time corresponds to a moment when only a small set of states can be realized so it is given by a solution of βc(tC ) = 1 which is equivalent to 

ItC (umin ) = α, (2.48) 

umin = −Λ′ 

> tC

(1) . (2.49) Using the REM model, we transitioned from the computation of collapsed posterior weight to a discussion of energy landscape. At large time, many terms contribute and weights are spread. As we approach t = 0 the lowest energy dominate the sum and the model collapse to best matching training point. We now proceed to the discussion of particular choices of the relaxation matrix M .

## 3. The Symmetric Relaxation Matrix 

We now focus on the case of a symmetric relaxation matrix M . This choice will allow us to diagonalize the coupled system into orthogonal eigenmodes which offer a clear physical interpretation of the generation process. To visualize this spectral decomposition, consider the joint generation of text and images. Rather than viewing the processes as being separate, we can decompose their generating dynamics into common modes representing the shared semantic content/ alignment between the caption and the visual scene and a difference mode that represents the discrepancies between the modalities. Explicitly, we can diagonalize the (2.2) with the choice of normalized eigenvectors 

v+ = 1

√2

11

!

, v− = 1

√2

1

−1

!

, (3.1) and their respective eigenvalues 

λ+ = −β + g, and , λ − = −β − g. (3.2) We call v+ = 1√2 (X + Y ) a “common” mode and v− = 1√2 (X − Y ) a “difference” mode, which we will see have different decay rates. From the construction, we interpret common mode, denoted with + as a one that controls shared content, whereas a difference mode, denoted with −, controls disagreement between modalities. Since we require β > |g| for stability, the common mode has smaller decay rate and thus retains signal longer under forward noising process in comparison to the difference mode. Since the end of the generation process is at 

t → 0, this implies that the diffusion model generates a hierarchical emergence of features i.e. it determines the shared semantic content first, establishing a consistent global structure before resolving the independent, modality specific details via the difference mode. This – 11 – separation allows us to analyze the speciation and collapse times for each mode independently and study the corresponding synchronization gaps between the eigenmodes. Before we proceed, we will derive a formula for general speciation and collapse times in the case of symmetric M . We start with a computation of κ(t) = μ(t)⊺C(t)−1μ(t) using the diagonalizing basis. Let us define projection operators from the spectral decomposition (3.1) 

P+ = v+v⊺ 

> +

⊗ Id, P− = v−v⊺ 

> −

⊗ Id, (3.3) and decompose the initial Gaussian mean μ(0) as 

μ+(0) = v⊺

> +

μ(0) = 1

√2 (μx(0) + μy(0)) , μ−(0) = v⊺

> −

μ(0) = 1

√2 (μx(0) − μy(0)) , (3.4) then the drift equation (2.7) 

μ(t) = eM t μ(0) = 



eλ+tP+ + eλ−tP−



μ(0) = eλ+tμ+(0) ⊗ v+ + eλ−tμ−(0) ⊗ v−. (3.5) Similarly, we find the eigenvalues of the diffusion kernel 

c±(t) = σ2e2λ±t + σ2

> W

e2λ±t − 12λ±

, (3.6) where we also assume that σx = σy = σ in (2.14), so that we can decompose it with projection operators (3.3) 

C(t) = c+(t)P+ + c−(t)P−, (3.7) and find the inverse 

C(t)−1 = 1

c+(t) P+ + 1

c−(t) P−. (3.8) In the ± basis, 

 M + σ2 

> W

C(t)−1−1 = 1

λ+ + σ2 

> W

/c +(t) P+ + 1

λ− + σ2 

> W

/c −(t) P−. (3.9) Hence invertibility requires λ± + σ2 

> W

/c ±(t)̸ = 0. Moreover, in the symmetric case, the reverse potential (2.23) is confining at large ∥z∥ when 

λ± + σ2

> W

c±(t) > 0, (3.10) A sufficient condition ensuring (3.10) for all t ∈ [0 , T ] is 

σ2 < σ2

> W

β + |g| , (3.11) – 12 – since c±(t) ≥ σ2 and σ2 

> W

/c ±(t) is non-increasing in t. Violating (3.10) leads to a non-confining reverse potential tail which we call unstable symmetry breaking and can cause sampling trajectories to diverge [27]. Using the orthogonality of the eigenvectors, we obtain for κ (2.28) 

κ(t) = σ2

> W

 e2λ+t|| μ+(0) || 2

c+(t)( λ+c+(t) + σ2 

> W

) + e2λ−t|| μ−(0) || 2

c−(t)( λ−c−(t) + σ2 

> W

)



, (3.12) where we used (3.5). To analyze the system in the high dimension limit as d → ∞ , we introduce a per dimension norm m2 

> ±

= 1 

> d

|| μ±(0) || 2 and we rescale κ(t) accordingly by a factor of 1 /d to ensure it remains of order O(1). Then, we can rewrite the last equation as 

κ(t) = σ2

> W

" e2λ+tm2+

c+(t)( λ+c+(t) + σ2 

> W

) + e2λ−tm2

> −

c−(t)( λ−c−(t) + σ2 

> W

)

#

. (3.13) We can interpret this equation as a sum of signal to noise ratios for the common and difference modes 

κ(t) = σ2 

> W

(SNR + + SNR −). (3.14) The equation above reveals that the total signal driving the speciation is additive. However, due to the exponential separation of timescales, the contribution from the common mode dominates the early dynamics. If κ(t) < 1 for all t, the model loses the ability to distinguish between different classes and the system is stuck in the noise regime. In fact when (3.11) is satisfied then both SNR ± are strictly decreasing functions in time, therefore κ(t) achieves its maximum at t = 0. Therefore, the system will never leave the noise regime if 

κ(0) = σ2

> W

 m2+

σ2(λ+σ2 + σ2 

> W

) + m2

> −

σ2(λ−σ2 + σ2 

> W

)



< 1. (3.15) In the general case, we cannot solve (3.13) analytically for speciation time. Hence, we first analyze the two opposite cases when either the initial common or difference mode vanishes. For both, we can write analytic expression for speciation time tS (2.30) 1 = σ2 

> W

SNR ± = σ2

> W

e2λ±tm2

> ±

c±(t)( λ±c±(t) + σ2 

> W

) , (3.16) which gives a quadratic equation for e2λ±t, taking the positive root we get 

t = 12λ±

log 



σ2

> W



m2 

> ±

+

q

m4 

> ±

+ B2



2λ±B2

 , (3.17) where B = σ2 + σ2 

> W
> 2λ±

. We use this analytic form to plot speciation time tS versus coupling strength g on Figure 1 for common and difference mode cases. We also include a numerical solution for the mixtures mode cases. – 13 – Figure 1 : Impact of coupling strength g on speciation time ts. Analytic solutions (solid and dashed) show that the Common Mode only case exhibits a non-monotonic relationship, peaking near g = 0 .45, while the Difference Mode leads to a monotonic decrease in speciation time. Numerical results for mixtures (dotted/dash-dotted) demonstrate how intermediate modal configurations interpolate between these extremes. Parameters are set to β = 1 , σ 2 

> W

=2, and σ2 = 1. Clearly, the value of coupling strength g changes the speciation time tS and this change has a different characteristic for the common and difference mode. In the case of the analytic formula (3.17), one can find an optimal value of coupling strength g such that speciation time is maximal which corresponds to the earliest time in the generation process. The coupling induces a temporal splitting of the speciation transition. As expected, the common mode whose decay rate is slower has sooner speciation time than a difference mode, however the synchronization gap between these two shrinks as coupling strength grows to the point when strong coupling causes difference mode to speciates before the common one. From a genera-tive standpoint, this identifies a tunable synchronization regime. Coupling can either widen or shrink the time interval in which the global structure is decided while modality specific discrepancies are still unresolved. The mixture modes confirm that speciation time tS is not determined by a single dominant mode unless the initialization is strongly aligned with one eigenspace. For diffusion modeling, this supports the view that coupling acts like a spectral filter. The reverse process selects which collective coordinates become informative first, which organizes the generation based on how the signal projects onto the eigenspaces of the coupled dynamics. In addition, the bound (3.11) on the decay rate for the model to transition from the – 14 – noise regime provides a criterion for when a coupled diffusion model may become numerically unstable or explode in sampling, and it directly links that instability to kernel growth and coupling strength. In the discussion above, we only focused on nonnegative g since we are interested in the case where both modalities are aligned due to a coupling. In the case of negative g the role of the modes reverses and the difference mode dominates early dynamics. Now, we proceed with a discussion of the collapse time i.e. the transition time from regime II to regime III where the diffusion model loses the ability to generalize and instead starts a memorization process. We start with a calculation of cumulant generating function (2.34), where we leave the details of calculation for Appendix A. Denoting 

χ±(t) = σ2

σ2

> W

2λ±

1 − e−2λ±t , (3.18) we find Λt(β) = − 14 log(1 + βχ +) − 14 log(1 + βχ −) − 14

β(1 + χ+)1 + βχ +

− 14

β(1 + χ−)1 + βχ −

, (3.19) and the saddle point (2.48) of this particular form of Λ t(β) is given by 

−Λ′

> t

(1) = 12 . (3.20) Therefore, the collapse time can be found by solving 

α = ItC

 12



= −ΛtC (1) − 12 , (3.21) explicitly we get 

n2/d =



1 + σ2

σ2

> W

2λ+

1 − e−2λ+tC

  

1 + σ2

σ2

> W

2λ−

1 − e−2λ−tC



, (3.22) or if we use decay rate τn2/d =



1 + σ2

σ2

> W

τ+

eτ+tC − 1

  

1 + σ2

σ2

> W

τ−

eτ−tC − 1



, (3.23) again this is a transcendental equation that for general g needs to be solved numerically. Unlike speciation, which depends on the between-class separation encoded in μ, condensa-tion is controlled by the transition variance Q(t) and the number of training points. Using the diffusion kernel C(t), transition covariance Q(t) and (2.33) we can show that (3.23) is equivalent to 

α = 14 log 

 C(tC )

Q(tC )



(3.24) – 15 – Notice that, provided the system is in the stable regime, χ± is a strictly decreasing function in tC and τ . In fact lim   

> tC→0+

χ± = ∞, and lim   

> tC→∞

χ± = 0 . (3.25) Here, we clearly see the curse of dimensionality [20, 39] for diffusion models. If n2/d = 1, there is no finite collapse time and the model cannot generalize at all. For n2/d > 1, there is an unique collapse time. If we use the inequality ex − 1 ≥ x, we can construct an upper bound for the collapse time 

tC ≤ tmax = σ2/σ 2

> W

n1/d − 1 , (3.26) this bound is saturated in the case when coupling g vanishes. For a symmetric coupling, in a diagonal basis (3.1), we could factorize a transition kernel (2.11) 

Kt(ez|z) = K+,t (ez+|z+)K−,t (ez−|z−), (3.27) where z± are constructed using projection operators (3.3). Therefore, we can can construct partition functions for ± modes separately and introduce their respective collapse times. Formally, this transition corresponds to the moment when the posterior weights wi, ±(z±) for a particular training point i become of order O(1). In such case, we find tC± by solving 

n1/d = 1 + σ2

σ2

> W

τ±

eτ±tC± − 1 , (3.28) which can be analytically solved to give 

tC± = 1

τ±

log 



1 + σ2

σ2

> W

τ±

n1/d − 1



. (3.29) In Figure 2, we plot the collapse times for the common mode tC+ , the difference mode 

tC− and the collapse time of the joint system as a function of the coupling strength g. The graph shows a temporal splitting of the timescales that explains the hierarchical behavior of coupled generative models. Interestingly, tC remains nearly constant despite an increase of g.This stability arises because the contributions χ± effectively compensate for one another. As a practical guide, this shows that the coupling strength g serves as a robust control parameter which allows us to tune the generative hierarchy without risking a collapse of the entire joint system. Analogous to the speciation phase, there is a corresponding hierarchy in the memoriza-tion process. As the coupling strength g increases, we observe widening of the temporal gap between the modes. The collapse time of a common mode increases implying that the align-ment between modalities enters the memorization regime earlier in the generative process. – 16 – Figure 2 : Collapse time vs coupling strength g. We plot analytic solutions for the collapse time of common and difference modes and numerical solutions. For plotting and numerical evaluation, we set α = 1 and σ2/σ 2 

> W

= 1. In contrast, the difference mode collapse time decreases, indicating that the fine-grained, modality-specific details remain in the generalization regime until late times in the generative process. This separation creates a temporal window tC− < t < t C+ where the model exhibits hybrid behavior, i.e., the global structure is now memorized but there are still local details that are being memorized. This analysis suggests that the coupling strength g additionally acts as a control parameter for the generalization bandwidth. 

## 4. The Anisotropic Relaxation Matrix 

We now proceed with a discussion of the anisotropic relaxation matrix case defined in (2.3). This setup is particularly relevant for conditional generative tasks, such as text-to-image generation, where a fixed context modality X guides the generation of a target modality 

Y . In this model, there is a unidirectional information flow from X to Y without reciprocal feedback via the coupling g.We start with the computation of the speciation time tS using the condition κ(tS ) = 1 (2.30). For notational convenience, we define the operator 

K(t) = C(t)−1  M + σ2 

> W

C(t)−1 C(t)−1, (4.1) which is generally non-symmetric and where M is given by (2.3) and the explicit form of the matrix elements of the diffusion kernel C(t) is provided in Appendix B. In the appendix, we – 17 – also provide explicit formulas for elements of K(t). Solving the coupled drift dynamics yields the following explicit mean trajectories 

μx(t) = e−βt μx(0) , (4.2) 

μy(t) = e−βt (μy(0) + gtμ x(0)) . (4.3) Using the per-dimension norms m2 

> x,y

= 1 

> d

|| μx,y (0) || 2 and the alignment angle θ defined by cos θ = μx(0) · μy(0) 

|| μx(0) || || μy(0) || , (4.4) we can solve the speciation condition numerically. We analyze two distinct regimes. First, we consider an uninformative context scenario where the conditioning signal X has negligible between-class separation where μx(0) = 0, while the target Y carries the label information m2 

> y

> 0. This effectively models cases where the context provides general structure but cannot be used to distinguish between different class identities. The results are plotted in Figure 3 for the case when σ2 

> W

= 2, σ2 

> x

= σ2 

> y

= 1 and β = 1. As shown in Figure 3, the speciation time tS decreases monotonically with the 

Figure 3 : Numerical solution for speciation time vs. coupling strength g in the uninformative context regime ( μx(0) = 0 and m2 

> y

= 2). The monotonic decrease in tS indicates that stronger coupling delays class speciation toward the end of the reverse process (closer to t = 0). coupling strength g. Since sampling proceeds from T → 0, smaller tS means that speciation occurs later in the reverse process. In this uninformative context regime μx(0) = 0, the mean trajectory μy(t) = e−βt μy(0) is independent of g. Nevertheless, the coupling modifies the reverse time bifurcation through the covariance, g increases the effective uncertainty seen by – 18 – the reverse drift by first mixing X variance into the Y channel through the drifted initial co-variance S(t) = eM t Σ(0) eM ⊺t, and secondly, inducing correlated noise through the transition covariance Q(t). Both effects inflate the variance of Y and thereby reduce κ(t), delaying or completely preventing the onset of additional fixed points. In this regime, increasing g acts primarily as a noise drag. Next, we consider the general case where both modalities carry information with varying alignment angle θ. For simplicity, we consider the case where they both have the same norm 

m2 

> x

= m2 

> y

= 1. The phase diagram of speciation time tS (g, θ ) is presented in Figure 4. White color indicates the no-speciation regime sup  

> t∈[0 ,T ]

κ(t) ≤ 1, (4.5) in which the reverse drift field does not acquire additional fixed points and the dynamics remains effectively unimodal (i.e. noise-dominated) throughout the sampling. Unlike the 

Figure 4 : Numerical solution for speciation time vs. coupling constant g and angle θ in the case of m2 

> x

= m2 

> y

= 1. For plotting we set σ2 

> W

= 2, σ2 

> x

= σ2 

> y

= 1 and β = 1. White color labels region where κ(t) < 1 for all t. The blue dashed line indicates an approximate gcrit (θ). symmetric case, there is no additional regime where the coupling accelerates speciation by increasing tS . Instead, increasing g generally delays speciation. This effect is strongly depen-dent on alignment. When the means are aligned θ ≈ 0, the system is initially less sensitive to coupling. However, around g ≈ 1.0 tS drops rapidly from ≈ 0.6 to ≈ 0.1 and eventually enters an no-speciation regime for g ≳ 1.7. When the means are anti-aligned θ ≈ π, the initial speciation time is lower due to signal interference. However, the sensitivity to g is reduced, – 19 – the speciation time decreases more gradually, and the system avoids failure to bifurcate within the plotted range. In the symmetric case σ2 

> x

= σ2 

> y

= σ2, which we use for our experiments, one has C(0) = 

σ2I and hence 

A(0) =  M + rI −1 rI, r := σ2 

> W

/σ 2. (4.6) 

κ(0) = rσ2(r − β)

 m2 

> x

+ m2

> y

 − rg σ2(r − β)2 mxmy cos θ, (4.7) where m2 

> x,y

= 1 

> d

∥μx,y (0) ∥2. Equation (4.7) makes the alignment sensitivity explicit. For the case of aligned means wherecos θ > 0 , increasing g decreases κ(0), while for anti aligned means where cos θ < 0 , it increases κ(0). In practice we observe that κ(t) is maximized near 

t = 0 across the parameter ranges of Figure 4, so κ(0) ≤ 1 provides an accurate diagnostic for the no-speciation regime (4.5), and yields an explicit approximate phase boundary gcrit (θ)via κ(0) = 1, which on Figure 4 is marked with blue dashed line and for larger values of θ

correctly approximate the boundary of the white region. The phase diagram suggests that large effective coupling can suppress bifurcation when the conditional and unconditional directions are locally aligned, pushing the system into the no-speciation regime (4.5). This motivates treating the coupling strength as a sampling-time control, analogous to guidance scaling as for example in Classifier-Free Guidance (CFG) scales [40, 41]. In Appendix C we discuss an exact score numerical experiment in which we examine different scheduling patterns for coupling and tests their results with respect to θ. We show that moderate coupling provides better results in the misaligned phase ( θ > π/ 2). We now move on to the discussion of transition between regime II and regime III. In the asymmetric case, we are interested in two different collapse times. First we consider a joint collapse time as given by (3.24) 

α = 14 log 

 det C(tC )det Q(tC )



(4.8) but we can also consider conditional collapse time 

αC = 12 log 

 Cy|x(tC,y |x)

Qy|x(tC,y |x)



, (4.9) where the prefactor is twice since effective dimension is d and we compute conditional covari-ances using the Schur complement 

Cy|x(t) = C22 (t) − C12 (t)2

C11 (t) (4.10) 

Qy|x(t) = q22 (t) − q12 (t)2

q11 (t) . (4.11) We show the behavior of the joint collapse time tC and conditional collapse time tC,y |x on Figure 5. As in the case of symmetric coupling, the condensation time depends weakly on g.The conditional collapse time tC,y |x is smaller than the joint tC , reflecting that conditioning reduces the effective uncertainty in Y .– 20 – Figure 5 : Numerical solutions for joint collapse time tC and conditional collapse time tC,y |x.For plotting we set σ2 

> W

= 1, σ2 

> x

= σ2 

> y

= 1, β = 1 and α = 1. 

## 5. MNIST Synchronization Experiment 

Our analysis of the symmetric relaxation matrix in §3 reveals that the generation process undergoes two distinct transitions, i.e., speciation and collapse which occur at two distinct time scales. In the case of speciation, the common mode stabilizes first and is followed by the difference mode. Here, the stabilization meaning the transition from the high noise regime I into the clustered structure of regime II. This implies the existence of a temporal window which we refer to as a synchronization gap. When we introduced common and difference modes, we discussed that the information can be understood in a hierarchical fashion where the global structure is determined before resolving the specific, higher frequency signals between modalities i.e. the fine details of the generation. In this case, the synchronization gap can be understood as a period where the global structure is already decided while modality specific discrepancies remain unstable. In generative modeling, such a gap is expected to manifest as a transient misalignment and, crucially, as a selective susceptibility of the difference mode to perturbations during that window. To validate our theoretical framework, we construct a minimal image experiment to investigate the predictions in the case of the symmetric relaxation matrix. In order to do this, we do not directly sample the theoretical Ornstein-Uhlenbeck SDE but instead we will implement a standard diffusion model architecture whose data we can split into a two channel state. Our objective in this experiment is not about sample quality but instead about seeing the temporal ordering between modes. Let x ∈ [0 , 1] 28 ×28 be an MNIST image [28]. We define a deterministic, pixel aligned – 21 – modality transform T selected from a set of operations including edge mapping, inversion, morphological dilation or blur. From x, we form a two channel state 

z0 =

"

xA

xB

#

∈ R2×28 ×28 . (5.1) We introduce two different sample sets. First we introduce MAIN pairing . For each underlying digit image x, we set ( xA, x B ) = ( x, T (x)) such that they are both in the same label class and then randomly swap the channels with uniform probability. This enforces an explicit A/B exchange symmetry at the dataset level and prevents the model from relying on a fixed channel identity. Our second pairing will be called CTRL pairing where we break content alignment while preserving per channel marginals by sampling xA and xB from different MNIST indices with 

xA = xi and xB = T (xπ(i)), where π is a random permutation refreshed each epoch con-strained such that yi̸ = yπ(i) ensuring disjoint classes. We apply the same random A/B 

random swap as in the MAIN pairing. Consequently, any observed mode ordering cannot be attributed to fixed channel conventions or marginal statistics but strictly to the presence or absence of cross-channel semantic alignment. As in §3, we diagonalize the basis using the change of variables 

u = xA + xB

√2 , v = xA − xB

√2 . (5.2) Using the new basis, we denote stacked representation as z(uv ) = [ u, v ]⊤. By construction, the common mode u captures structure/content shared across channels while difference mode 

v isolates misalignment between channels. In the diagonal ( u, v ) basis, where components decouple, the scalar coupling parameter 

g ∈ [0 , 1) is implemented by modifying the diffusion noise covariance. Specifically, at each diffusion step, we draw 

εu ∼ N (0 , (1 − g) I), εv ∼ N (0 , (1 + g) I), (5.3) independently over pixels, and then map ( u, v ) back to ( xA, x B ) coordinates by the inverse change of variables. Equivalently, in ( xA, x B ) coordinates, the noise has unit per-channel variance but a tun-able cross channel correlation Var( εA) = Var( εB ) = 1 , Cov( εA, ε B ) = −g. (5.4) We employ a standard variance preserving discrete diffusion with T timesteps and linear β

schedule. Defining αt = 1 − βt and the cumulative product ¯ αt = Qts=0 αs. The forward noising process is given by 

zt = √¯αt z0 + √1 − ¯αtε, (5.5) – 22 – where ε is sampled with the anisotropic variance described above. When the coupling strength 

g = 0, this setup reduces down to standard isotropic Gaussian noise in both modes. Under this variance preserving formulation, the per mode noise variance for each mode at a time step t scales as Var( z(m) 

> t

|z(m)0 ) ∝ (1 − ¯αt)σ2

> m

, with σ2 

> u

= 1 − g and σ2 

> v

= 1 + g. Consequently, a convenient proxy for per-mode SNR therefore satisfies SNR u(t)SNR v(t) ∝ 1 + g

1 − g , (5.6) predicting that increasing g monotonically widens the ordering i.e. u stabilizes earlier than 

v. This is the minimal mechanism needed to test different speciation times for both modes and the synchronization gap hypothesis. We train an unconditional ε-prediction diffusion model on zt ∈ R2×28 ×28 . The architec-ture is a compact U-Net [42] with sinusoidal time embedding. It takes ( zt, t ) and outputs 

bεθ(zt, t ) ∈ R2×28 ×28 . The training minimizes the standard mean-squared error 

L(θ) = Ez0, t, ε 

hbεθ(zt, t ) − ε 22

i

, (5.7) with t sampled uniformly from {0, . . . , T − 1} and ε drawn from the mode-shaped noise law (5.3). We keep an exponential moving average of parameters for evaluation to reduce sampling variance. We note that because of our target ϵ is anisotropic in the variance, the squared magnitude of the errors will be inherently larger for the v modes since the target values are typically larger implying that the corresponding gradient will be dominated by errors in the 

v mode. 

5.1. Protocol I: Deterministic Synchronization Diagnostics 

To analyze mode resolved stabilization along the reverse process, we employ a DDIM deter-ministic sampling [3], initialized from zT −1 drawn from the same mode shaped noise distri-bution. At each reverse step t, we compute the predicted clean state in ( u, v ) coordinates: 

bz(uv )0 (t) = z(uv ) 

> t

− √1 − ¯αt bε(uv ) 

> θ

(zt, t )

√¯αt

. (5.8) We log ( xA, x B ) along the full time reversed trajectory with a chosen timestep and then project the logged predictions into u(t) and v(t) for mode resolved analysis. Let m(t) ∈ { u(t), v (t)}

denote a logged mode prediction at reverse time t. We quantify stabilization and observe the synchronization gap in two complementary ways. Let m⋆ = m(tfinal ) be the last logged prediction near t = 0. Flattening images into vectors, we may use the cosine similarity Cos m(t) = E

h

cos  m(t), m ⋆

i

. (5.9) This is metric is invariant to signal magnitude and consequently any value approaching 1 indicates that the mode vector has been aligned with the ground truth. For a threshold τ ∈

– 23 – {0.90 , 0.95 , 0.98 }, we define the crossing time as the earliest reverse step at which alignment exceeds τtu(τ ) := max {t : Cos u(t) ≥ τ }, tv(τ ) := max {t : Cos v(t) ≥ τ }. (5.10) We can then find a synchronization gap at τ

∆t(τ ) := tv(τ ) − tu(τ ). (5.11) Thus ∆ t(τ ) < 0 means the common mode u stabilizes earlier than the difference mode v by 

|∆t| reverse steps. To provide an interpretable counterpart to our metrics, we visualize for the channel images xA(t), xB (t), and the common-mode image u(t) along a fixed sample trajectory. If we assume that a synchronization gap exists, we expect that u(t) reveals a consistent digit structure significantly earlier than the resolution of the fine grained details required for pixel level agreement between xA(t) and xB (t). Finally, we perform a targeted causal test. At a chosen reverse timestep tint , we inject noise only into the difference mode 

v(tint ) ← v(tint ) + σξ, ξ ∼ N (0 , I ), (5.12) leaving u unchanged at that step, and then continue deterministic sampling. We compare the final outputs with and without intervention under identical initial noise. The existence of the synchronization gap predicts that perturbations within the window where u is stable but v is not, produce persistent desynchronization effects, whereas perturbations outside the window are largely corrected. 

5.2. Protocol II: Cloning Based Speciation Curves 

Deterministic traces characterize a single mean reverse trajectory, but the theory of speciation is fundamentally about branching of stochastic paths. We therefore implement a cloning based observation of the speciation time following a similar procedure as in [20]. In this case, we use DDPM [29] with anisotropic noise for the case of nonzero coupling strength g. Since DDPM is much slower in the second protocol, we only use MAIN samples. We also reduce the number of available classes to two for better comparison with theory where we have two clusters. To implement the standard DDPM reverse updates with unit variance noise, we work in rescaled coordinates 

yu = u

√1 − g , yv = v

√1 + g , (5.13) and perform the usual DDPM step in y-space, and then map back to ( u, v ) before finally using the change of variables map back to ( xA, x B ). This yields the correct stochastic reverse kernel for the mode shaped forward law (5.4). – 24 – We evaluate class identity using swap invariant images derived from the final sample (xA, x B ) as 

uimg = xA + xB

2 , vimg = xA − xB

√2 . (5.14) The factor 1 /2 in uimg keeps pixel values in [0 , 1] and does not affect binary classification. We train two classifiers Cu and Cv on uimg and vimg , respectively, with sign invariance enforced by using the symmetrized logits 12 (Cv(vimg ) + Cv(−vimg )). This yields predicted labels byu, byv ∈{0, 1}.Fix a set of scan times Tscan ⊂ { 0, . . . , T − 1}.For each run, we generate a master reverse trajectory and cache the intermediate states zt for all t ∈ T scan . At each cached time t,we create two independent clones that start from the same zt and continue to t → 0 with independent reverse noise. For each mode m ∈ { u, v } we define the cloning agreement 

ϕm(t) := P

by(1)  

> m

= by(2) 

> m



, m ∈ { u, v }. (5.15) Empirically, ϕm(t) is estimated as an average over batches and independent master trajecto-ries. Raw agreement scores can be misleadingly high due to classifier bias or marginal class imbalances. To correct for this, we report the baseline corrected agreement 

ϕex  

> m

(t) = ϕm(t) − ϕindep 

> m

1 − ϕindep 

> m

, (5.16) where ϕindep  

> m

is the agreement probability for two independent samples from the model. This maps independent behavior to 0 and perfect agreement to 1. For a threshold ϕ⋆ = 0 .55, we define the speciation time as the earliest reverse step at which the curve ϕm(t) crosses ϕ⋆,accounting for the reverse time orientation, this means we have 

tspec  

> m

(ϕ⋆) = sup {t ∈ T scan : ϕex  

> m

(t) ≥ ϕ⋆}, m ∈ { u, v }, (5.17) with a linear interpolation between adjacent scan points when reporting non-integer crossing times. Comparing tspec  

> u

and tspec  

> v

provides a reproducible test of the temporal ordering, independent of the deterministic metrics in Protocol I. To quantify uncertainty, we model the number of agreeing pairs as a binomial count aggregated over repeats and batch size. We compute the 95% Wilson score confidence intervals for the raw agreements ϕm(t) and since (5.16) is a monotonic transformation, we obtain confidence intervals for the corrected metric 

ϕex m (t) by directly applying the same transformation to the Wilson interval bounds. 

5.3. Results Protocol I Results 

We demonstrate that the synchronization gap is a robust phenomenon that is significantly diminished in the control setting. We compare samples from our MAIN against a matched CTRL sample which removes semantic pairing while preserving the systems dynamics. – 25 – For each coupling strength g ∈ { 0.0, 0.3, 0.5, 0.7}, we sweep four random seeds with 

T = 200 reverse steps, 20 training epochs, and evaluation batch size 16. Table 1 aggregates the resulting gaps, computed using (5.10). On Figure 6 we show an example of cosine metric evolution during denoising process for coupling strength g = 0 .3. One could question why there is a gap even for g = 0, u and v have equal noise, but the data geometry makes learning 

u easier, it retains digit like structure under averaging of correlated pairs in MAIN, while v

is dominated by transform specific residue. Hence, u aligns with its final state earlier even without dynamical coupling. In the second part of the experiment we will show that indeed for g = 0 the synchronization gap between speciation times (which we discussed in §3 is close to zero). Two robustness checks preserve the same qualitative conclusion: (i) increasing the                                                                                            

> MAIN: ∆ t(τ) (mean ±sd) CTRL: ∆ t(τ) (mean ±sd)
> gτ= 0 .90 τ= 0 .95 τ= 0 .98 τ= 0 .90 τ= 0 .95 τ= 0 .98 0.0 −64 .0±15 .4−57 .0±12 .1−43 .5±6.2−25 .3±6.3−20 .0±4.2−14 .0±2.20.3 −64 .5±6.8−56 .0±6.1−49 .0±5.2−29 .5±6.0−24 .3±3.3−18 .5±2.60.5 −77 .2±29 .9−64 .5±17 .5−53 .5±5.4−31 .2±2.9−26 .5±3.1−20 .2±2.20.7 −78 .0±26 .1−75 .5±18 .7−61 .0±13 .0−36 .0±3.6−32 .8±3.9−29 .0±2.2

Table 1 : Protocol I synchronization gap. Aggregate over four seeds with T = 200 time steps, 20 epochs, and evaluation batch size 16. Negative ∆ t(τ ) means the u-stream reaches the threshold earlier (at higher noise) than the v-stream. Across all ( g, τ ), the magnitude of the gap is substantially larger in MAIN than CTRL (typically by a factor ≈ 2–3), supporting that the effect is not explained by generic per-stream denoising dynamics alone. reverse horizon to T = 500 (e.g. g = 0 .3 gives MAIN ∆ t = −113 vs. CTRL ∆ t = −72 at 

τ = 0 .95; g = 0 .5 gives MAIN ∆ t = −103 vs. CTRL ∆ t = −76 at τ = 0 .95), and (ii) increasing evaluation batch size (e.g. at g = 0 .5, τ = 0 .95: MAIN ∆ t = −82 vs. CTRL ∆t = −30). Thus the synchronization gap is stable across seeds and evaluation settings, while remaining consistently smaller in the control. In the case of Protocol I, ghosting also appears in MAIN and is strongly suppressed in the CTRL sample. To quantify the qualitative ghosting effect, we use cosine similarity for the final frame, we use cosine similarity to the final frame (5.9): 

cu(t) = cos  u(t), u final 

, cA(t) = cos  xA(t), x A, final 

, cB (t) = cos  xB (t), x B, final 

, (5.18) and define the ghosting index 

GI (t) = 2 cu(t) − cA(t) − cB (t). (5.19) In MAIN, GI (t) is steady at high noise and decays toward 0 as t → 0, matching the visual observation that u(t) stabilizes into a recognizable structure earlier than either xA(t) or 

xB (t). This is also confirmed by the gap developing between u cosine metric and xA/B 

cosine metric e.g. on Figure 7a, where the u cosine metric curve in the middle of denoising – 26 – (a) MAIN (b) CTRL 

Figure 6 : Protocol I synchronization gap. We plot cosine similarity to final metrics for both modes with respect to a reserve timestep. The coupling strength is set to g = 0 .3. process overpasses xB cosine metric curve. In CTRL, as shown on Figure 7b, the ghosting index decreases steadily to 0 and there is no point where u cosine metric curve dominates, consistent with the absence of early common-mode stabilization under the control dynamics. In Figure 8, we show the full denoising trajectory to show visually the effect of ghosting. For all three figures, we used 500 timesteps for better resolution of the effect.  

> (a) MAIN (b) CTRL

Figure 7 : Protocol I ghosting index. We plot cosine similarity to final frame metrics for common mode u and xA/B as well as ghosting index with respect to reverse timestep. Plots were made for the coupling strength g = 0 .3 and trajectory length 500. We perform an intervention at reverse step tint = 260 by perturbing only the v-stream with Gaussian noise of scale σ = 0 .25, and measure the resulting RMS changes in the final outputs. An example is shown on Figure 9. For CTRL, the perturbation propagates broadly (RMS ∆ u ≈ 0.0708, RMS ∆ v ≈ 0.0851), whereas in MAIN the induced changes are markedly – 27 – Figure 8 : Protocol I generation. We show denoising trajectory for MAIN g = 0 .3, 500 timesteps. The first row is channel xA, the second is xB and the third is common channel u. 

> (a) MAIN (b) CTRL

Figure 9 : This figure shows the Protocol I intervention. We present intervention plots by injecting noise in v channel and measuring RMS with respect to base values. Plots were made for the coupling strength g = 0 .5 and 500 timesteps. smaller (RMS ∆ u ≈ 0.0247, RMS ∆ v ≈ 0.0274). This is consistent with MAIN exhibiting stronger stabilization of the common component against single-stream perturbations, in line with the ghosting and synchronization-gap signatures. 

Protocol II 

In this case, we directly visualize ϕex  

> u

(t) and ϕex  

> v

(t) (5.16) as functions of reverse time for varying coupling strengths g. We summarize an average over 5 trials with 128 batch size – 28 – for coupling strengths g ∈ { 0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6} in Figure 10. We also include two representative examples at g = 0 .0 Figure 11a and g = 0 .5 Figure 11b to show directly the emergence of the synchronization gap. As mentioned before in the cloning experiment, it is clear that the gap is coupling dependent and it almost disappears for g = 0 .0. Across the sweep, increasing coupling produces larger and more persistent separation between the 

u and v curves, supporting a genuine coupling-driven synchronization phenomenon rather than a thresholding artifact. We sweep up to g = 0 .6. For larger g, the rescaled DDPM coordinates yu = u/ √1 − g become numerically ill-conditioned, and empirically the v-mode agreement curve often fails to cross ϕ⋆ reliably within the finite reverse horizon, making tspec 

> v

ill-defined. We therefore restrict to a moderate-coupling regime where both modes admit stable, replicable threshold crossings. 

Figure 10 : Protocol II synchronization gap. Using cloning procedure we plot common and difference mode dependence on the coupling strength. The appearance of synchronization gap and different scaling of SNRs associated to both modes matches expectations discussed in the theory part. Collectively, these results support that synchronization gaps, ghosting, and selective in-tervention sensitivity are intrinsic signatures of the mode SNR split mechanism implemented here. This is consistent with the qualitative prediction of §3 that separating effective mode SNRs produces a temporal window in which global content stabilizes before fine cross-channel discrepancies. – 29 – (a) Speciation curves, g = 0 .0. (b) Speciation curves, g = 0 .5. 

Figure 11 : We show evolution of ϕex  

> u

and ϕex  

> v

(t) during denoising process for coupling strengths g = 0 .0 and g = 0 .5. We record time when they cross the threshold line corre-sponding to regime transition. For vanishing coupling the gap is almost non-existent. 

## 6. Discussion and Future Directions 

In this work, we have established a rigorous theoretical framework for multimodal generative dynamics by extending the statistical mechanics of diffusion models to coupled systems. By modeling the interaction between modalities as a coupled Ornstein Uhlenbeck process, we identified the thermodynamic constraints that govern the simultaneous emergence of content coherence and cross modal alignment. Our central theoretical contribution is the analytic derivation of speciation and collapse time for coupled diffusion model. In the symmetric coupling case we found the synchronization gap, a temporal window where the common eigenmode has transitioned into the speciation regime, while the difference eigenmode remains in the noise regime. In the anisotropic cou-pling case, we showed a dependence of speciation time on both coupling strength as well the alignment angle between the conditioning signal and the target mean. We checked these theoretical predictions through extensive experimentation using stan-dard diffusion model architectures the for symmetric coupling case and the exact score exper-iment for anisotropic coupling. We found the confirmation of the existence of the synchro-nization gap in a baseline dataset and showed its width dependence on the coupling strength. We also showed that different coupling strengths and schedules could improve misaligned generative processes. The implications of this framework extend beyond curiosity, offering actionable insights for the design of next generation multimodal diffusion architectures. Our findings advocate for adaptive coupling schedules that can accelerate speciation time without significant modi-fications to the collapse time. One also needs to consider the synchronization gap so that the model does not generate samples until both modalities stabilized into II regime. Several promising avenues for future research emerge from this study. While our analysis focused on dealing with the data space directly, it is a natural question to try to investigate – 30 – how the synchronization gap manifests under more recent architecture designs like those in Latent Diffusion Models [22] where the natural space to do the analysis in is the latent space. Our current model assumes a static coupling strength. Future work could explore time dependent couplings M (t) which could admit derivative expansions introducing additional time scales during the generation. Additionally, this framework would allow us to begin designing coupling schedules analogous to the noise schedules that we use for Σ W .Formally, this extends our framework to a non-autonomous stochastic system, modulo the noise term, of the form dZ (t) = M (t)Z(t)dt , we could begin to understand the structure of the time dependent case by integrating iteratively as we do with Dyson series, the result being 

Z(t) = 



I +

Z t

> 0

M (s1) ds 1 +

Z t

> 0

Z s1

> 0

M (s1) M (s2) ds 2ds 1 + . . . 



Z(0) , (6.1) which is effectively the signature transform [43]. The importance of this results lies in the fact that the signature transform encodes the noncommutativity of the underlying stochastic paths through the tensor algebra [44] which reveals that the time dependent coupling case imposes a specific chronological ordering on the information flow. The higher order terms of the signature should effectively capture the sequence in which the modalities interact, suggesting that the order of the cross modal diffusion is as critical as the coupling strength itself. The use of the signature transform in deep learning has been previously leveraged and is reviewed in [45]. Finally, we would like to point out that although the analysis has shown that coupled OU oscillators are incredibly useful in predicting several distinct phenomena in diffusion models, it is not necessarily a fundamental fact that all diffusion models would necessary fall into this linear description. We argued that the key property was that the SDE was mean reverting such that no numerical divergence appear. Let Xt ∈ Rd and x its realization, a natural nonlinear generalization would therefore be a cubic mean reverting SDE with additive noise of the form 

dX t =  aX t − bX 3

> t

 dt + σdW t, b > 0, σ > 0, a ∈ R (6.2) For such an SDE, we would still be able to find a stationary distribution for which we could condition the reverse process to, the Fokker Planck equation can be directly solved to give the Gibbs measure 

π(x) ∝ exp 

 α

2 ∥x∥2 − β

4 ∥x∥4



, (6.3) where Z is a normalization factor. In this case, the theoretical analysis suggests that we can no longer simply train a model with a nonlinear forward process and then take a simple Gaussian noise for the reverse process. The generation process would simply always output noise. From a physical point of view, it is now clear that the analysis of such systems can be aided by the techniques of nonequilibrium field theory [46]. We expect this to be an eventual necessary tool for the analysis of nonlinear theoretical constructions for diffusion models due to three key observations. Having nonlinear interaction terms allows us to begin modeling nonlinear – 31 – coupling architectures such as those that appear in cross attention [47] which is based on a nonlinear state dependent coupling i.e., the attention mechanism. Second, making the connection between nonlinear stochastic systems and nonequilibrium field theory naturally gives us an analytic method of trying to design coupling schedules for the parameters a

and b through standard renormalization group flow arguments [48]. Lastly, finding stationary distributions from which theoretical analysis can begin is one of the shining points of quantum field theory, in the simple example of the Gibbs measure, one can easily show that the prior is now bimodal noise in the statistics sense of the word modality. This effectively shifts our generative priors from a maximal entropy Gaussian to a Boltzmann distribution. Finally, testing these dynamics on large scale, heterogeneous datasets e.g. video-audio-text triplets is a natural extension. We hypothesize that as the number of modalities in-creases, the spectral gap between the fastest and slowest eigenmodes will widen, exacerbating desynchronization artifacts. Verifying the scaling laws of the collapse time tC in these hyper multimodal regimes will be crucial for the stability of future foundation models. 

## Acknowledgments 

We would like to thank Ori Ganor, David T. Limmer, Wojciech Musial, Edward Yam and, Viola Zixin Zhao for helpful discussions surrounding related nonequilibrium systems, machine learning and possible multi-agent reinforcement learning followups to this work. This work has been supported by the Leinweber Institute for Theoretical Physics at UC Berkeley. 

## A. Derivation Of The Cumulant Generating Function For Symmetric Cou-pling 

In this appendix, we derive the asymptotic limit of the Cumulant Generating Function (CGF) stated in (3.19). We begin with the finite-dimensional definition in (2.34) and utilize the diagonalized basis introduced in §3. If we denote 

q± = σ2

> W

e2λ±t − 12λ±

, (A.1) then the reduced energy of (2.34) can be decomposed as 

εt(ez, z ) = ε+,t (ez+, z +) + ε−,t (ez−, z −), ε±,t (ez, z ) = 14dq ±(t) || ez± − eλ±tz±|| 2, (A.2) where z± is a decomposition of z on the diagonal basis. In the random energy model for a fixed point ez, the energies {εt}ni=1 are treated as i.i.d. random variables. Therefore, we can write a conditional CGF Λt(β; ez) = lim 

> d→∞

12d log Ez [exp( −β2dε (ez, z ))] , (A.3) – 32 – where z ∼ N (0 , σ 2I2d). The Strong Law of Large Numbers implies that the normalized squared norms converge almost surely and we get 1

d ∥ez±∥2 a.s. 

−−−→ 

> d→∞

c±(t). (A.4) Since Λ t(β; ez) is a continuous function of the sufficient statistics 1 

> d

∥ez±∥2, the Continuous Mapping Theorem ensures that the random variable Λ t(β; ez) converges almost surely to a deterministic limit Λ t(β). Since the energy functional decomposes into independent terms for the + and − modes, the expectation factorizes. We may therefore compute the contribution of a single mode for a single mode and hence we drop the ± from the notation temporarily. Denoting a = e2λt , using the standard identity for the expectation of a quadratic expo-nential under a Gaussian measure z ∼ N (0 , σ 2Id), we have 

Ez

h

e− 12 z⊺Az +b⊺z i

= det( Id + σ2A)−1/2 exp 

 σ2

2 b⊺(Id + σ2A)−1b



, (A.5) where we used the fact that z± ∈ Rd, we find 

Ez



exp 



− β

2q ∥ez − az ∥2

=



1 + β σ2a2

q

−d/ 2

exp − β

2q

11 + β σ2a2

> q

∥ez∥2

!

. (A.6) We can use (3.18) to write 

β σ2a2

q = βχ ±, (A.7) hence Λ±,t (β) = lim 

> d→∞

12d log Ez±

h

exp 



− β 2d bε±,t (ez±, z ±)

i 

= lim 

> d→∞

12d



− d

2 log(1 + βχ ±) − β

2q±

11 + βχ ±

∥ez±∥2



= − 14 log(1 + βχ ±) − β

41 + χ±

1 + βχ ±

., (A.8) using (A.4). Summing over both + and − modes, we recover (3.19). 

## B. Explicit Form Of Diffusion Kernel For Anisotropic Coupling 

In this appendix, we derive the closed form expressions for the covariance matrix C(t) and the diffusion kernel K(t) in the asymmetric coupling regime. We consider the process governed by the drift matrix M ∈ R2×2 given by 

M = −β 0

g −β

!

. (B.1) – 33 – The associated matrix exponential is eM t = e−βt 1 0 

gt 1

!

which can be computed via the nilpotency identity mentioned in §2. The noise covariance matrix Q(t) is defined by the integral Q(t) = σ2

> W

R t 

> 0

eM s (eM s )⊤ds .To facilitate the integration, we define the following auxiliary functions 

u(t) = 1 − e−2βt , (B.2) 

k(t) = 1 − e−2βt (1 + 2 βt ), (B.3) 

h(t) = 1 − e−2βt (1 + 2 βt + 2 β2t2). (B.4) Computing the elementwise integrals of the matrix exponential yields the block structure 

Q(t) = q11 q12 

q12 q22 

!

⊗ Id, with components 

q11 (t) = σ2

> W

u(t)2β , (B.5) 

q12 (t) = σ2

> W

gk (t)4β2 , (B.6) 

q22 (t) = σ2

> W

 u(t)2β + g2h(t)4β3



. (B.7) The total state covariance C(t) evolves according to C(t) = eM t C(0) eM ⊤t + Q(t). Assuming an initial diagonal covariance C(0) = diag( σ2

> x

, σ 2 

> y

) ⊗ Id, we obtain the components 

C11 (t) = e−2βt σ2 

> x

+ q11 (t), (B.8) 

C12 (t) = e−2βt gtσ 2 

> x

+ q12 (t), (B.9) 

C22 (t) = e−2βt σ2 

> y

+ e−2βt g2t2σ2 

> x

+ q22 (t). (B.10) We now compute the auxiliary kernel defined as K(t) := C(t)−1(M +σ2 

> W

C(t)−1)−1C(t)−1.Let ∆( t) = det( C(t)) = C11 C22 − C212 . The term involving the drift is given by 

M + σ2 

> W

C(t)−1 = −β + σ2  

> WC22
> ∆

− σ2 

> WC12
> ∆

g − σ2  

> WC12
> ∆

−β + σ2 

> WC11
> ∆

!

. (B.11) The determinant of this matrix simplifies to det( M + σ2 

> W

C(t)−1) = D(t)∆( t) , (B.12) where we have defined the quantity D(t) as 

D(t) := β2∆( t) − βσ 2 

> W

(C11 (t) + C22 (t)) + gσ 2 

> W

C12 (t) + σ4 

> W

. (B.13) – 34 – Finally, by applying the standard inversion formula for 2 × 2 block matrices, the kernel K(t)takes the form 

K(t) = 1∆( t)D(t)

N11 (t) N12 (t)

N21 (t) N22 (t)

!

. (B.14) Algebraic manipulation yields the following expressions for the numerators 

N11 (t) = σ2 

> W

C22 (t) − β  C22 (t)2 + C12 (t)2 + gC 12 (t)C22 (t), (B.15) 

N12 (t) = C12 (t) β (C11 (t) + C22 (t)) − gC 12 (t) − σ2

> W

 , (B.16) 

N21 (t) = βC 12 (t) ( C11 (t) + C22 (t)) − σ2 

> W

C12 (t) − gC 11 (t)C22 (t), (B.17) 

N22 (t) = σ2 

> W

C11 (t) − β  C11 (t)2 + C12 (t)2 + gC 11 (t)C12 (t). (B.18) 

## C. Exact-score OU Toy Experiment For Anisotropic Relaxation Matrix 

We construct a minimal conditional generation experiment for anisotropic coupling discussed in §4 in order to observe the effect of coupling strength on the model. For simplicity, in the experiment, we use the reverse time sampler with an exact (population) conditional score. This removes the need for neural network to learn the score function and isolates the dynamical effect. Let us first briefly describe experimental setup. We work in dimension d = 32. The data distribution is a two-component Gaussian mixture for both source X and target Y :

x0 = s μ x + σdata εx, y0 = s μ y + σdata εy, (C.1) where σdata = 1, εx, ε y ∼ N (0 , I d), and the class label s is sampled uniformly from {+1 , −1}.To model geometric misalignment, we confine the mean vectors to a 2D signal plane spanned by deterministic orthonormal basis vectors u, v ∈ Rd. We fix the signal-to-noise ratio such that the per-dimension mean squared amplitude is m2. The means are parameterized by a relative angle θμx = √d m u, μy = √d m (cos θ u + sin θ v ). (C.2) We sweep θ ∈ [0 , π ] to transition from perfectly aligned domains ( θ = 0) to orthogonal (θ = π/ 2) and anti-correlated ( θ = π) domains and average metrics over 2000 Monte Carlo trials per θ.Using (2.1) and (2.3) we write asymmetric coupling OU process equations. In this case 

X(t) does not depend on Y (t), while Y (t) is driven by X(t) through a scalar coupling g(t), 

dX (t) = −βX (t) dt + σW dW x(t), (C.3) 

dY (t) =  −βY (t) + g(t) X(t) dt + σW dW y(t), t ∈ [0 , T ]. (C.4) In numerical experiment we set β = 1, σ2 

> W

= 2, and T = 2. The first and second moments (μ(t), C (t)) are computed exactly by integrating the corresponding linear ODEs. – 35 – Conditioned on a forward path X0: T , the exact conditional distribution Pt(y|x) at any time t remains a Gaussian mixture. Using the Schur complement of the joint covariance matrix C(t), the conditional score ∇y log Pt(y|x) is derived analytically. The conditional density is given by: 

Pt(y|x) = X

> k∈{ +,−}

wk(x, t ) N  y; mk(x, t ), C y|x(t)Id

, (C.5) where the component means m± shift based on the observed x, and the weights w± correspond to the posterior class probability given x.We simulate the reverse process Yt from T → 0 using the Euler Maruyama method with 

N = 800 steps. The reverse SDE includes the coupling drift term consistent with the forward process: 

d eYt =



−β eYt + g(t) Xt − σ2 

> W

∇y log Pt( eYt|Xt)



dt + σW dfWy,t . (C.6) We compare three simple schedules for coupling constant (defined over forward time 

t ∈ [0 , T ]): 

gconst (t) = g0, glate (t) = g0 1{t ≤ t0}, gearly (t) = g0 1{t ≥ t0}, (C.7) and sweep different coupling magnitudes g0 ∈ { 0.2, 0.5, 1.0}.To determine the effect of coupling and its schedule we plot at t = 0 observables and their difference wrt. the uncoupled baseline g0 = 0. We report alignment accuracy, signal MSE, and negative likelihood. In details 

• For alignment accuracy, we determine the sign of x0 data point s(x0) = sgn( ⟨x0, μ x⟩)and compare it to the sign of generated point s(ey0) = sgn( ⟨ey0, μ y⟩). We define the accuracy as a sample average of matching signs. 

• Next, we compute MSE 12 E || (ey0) − s(x0)( μy)|| 2 . (C.8) 

• We also calculate negative likelihood at t = 0 NLL = E[− log P0(ey0|x0)] . (C.9) In all registered metrics, we observe a clear regime transition as θ increases. For small angles (highly aligned modalities) coupling causes alignment accuracy decrease and signal-subspace MSE increase relative to baseline g0 = 0. For large angles (misaligned modalities) coupling produces alignment accuracy increase and signal-subspace MSE decrease, with a sign change near θ ≈ π/ 2–2 π/ 3 depending on the observable. Scheduling strongly modulates this trade-off. Constant coupling is typically the most harmful schedule in the aligned regime ( θ < π/ 2), while late coupling has the least detrimental – 36 – effect for aligned regime yet introduces a boost effect for misaligned one ( θ > π/ 2). The conditional NLL illustrates an over-guidance-like effect at large coupling: for g0 = 1 .0 the sampler consistently worsens NLL 0 under a fixed discretization budget, whereas for moderate coupling ( g0 = 0 .5) scheduled coupling can achieve near-neutral or improved NLL 0 at large 

θ. For weak coupling ( g0 = 0 .2) the NLL penalty disappears and improvements at large θ are visible across schedules, albeit with smaller alignment gains. Overall, this exact-score experiment confirms that cross-modal coupling is not uniformly beneficial: it induces a genuine phase structure controlled by the angle θ, and scheduling provides a practical handle to leverage performance while limiting distributional degradation under realistic sampling budgets.   

> (a) ∆ accuracy vs to baseline. (b) ∆ MSE vs to baseline. (c) ∆ NLL vs to baseline.

Figure 12 : Results of the OU experiment: ∆ of observable wrt. to baseline for a coupling strength g0 = 0 .2  

> (a) ∆ accuracy vs to baseline. (b) ∆ MSE vs to baseline. (c) ∆ NLL vs to baseline.

Figure 13 : Results of the OU experiment: ∆ of observable wrt. to baseline for a coupling strength g0 = 0 .5

## References      

> [1] J. Sohl-Dickstein, E. Weiss, N. Maheswaranathan and S. Ganguli, Deep unsupervised learning using nonequilibrium thermodynamics , in International conference on machine learning ,pp. 2256–2265, pmlr, 2015. [2] Y. Song and S. Ermon, Generative modeling by estimating gradients of the data distribution ,
> Advances in neural information processing systems 32 (2019) .

– 37 – (a) ∆ accuracy vs to baseline. (b) ∆ MSE vs to baseline. (c) ∆ NLL vs to baseline. 

Figure 14 : Results of the OU experiment: ∆ of observable wrt. to baseline for a coupling strength g0 = 1 .0

[3] J. Song, C. Meng and S. Ermon, Denoising diffusion implicit models , arXiv preprint arXiv:2010.02502 (2020) . [4] Y. Song, J. Sohl-Dickstein, D.P. Kingma, A. Kumar, S. Ermon and B. Poole, Score-based generative modeling through stochastic differential equations , arXiv preprint arXiv:2011.13456 

(2020) . [5] Z. Kong, W. Ping, J. Huang, K. Zhao and B. Catanzaro, Diffwave: A versatile diffusion model for audio synthesis , arXiv preprint arXiv:2009.09761 (2020) . [6] N. Chen, Y. Zhang, H. Zen, R.J. Weiss, M. Norouzi and W. Chan, Wavegrad: Estimating gradients for waveform generation , arXiv preprint arXiv:2009.00713 (2020) . [7] C. Saharia, W. Chan, S. Saxena, L. Li, J. Whang, E.L. Denton et al., Photorealistic text-to-image diffusion models with deep language understanding , Advances in neural information processing systems 35 (2022) 36479. [8] J. Ho, T. Salimans, A. Gritsenko, W. Chan, M. Norouzi and D.J. Fleet, Video diffusion models ,

arXiv preprint arXiv:2204.03458 (2022) . [9] J. Ho, W. Chan, C. Saharia, J. Whang, R. Gao, A. Gritsenko et al., Imagen video: High definition video generation with diffusion models , arXiv preprint arXiv:2210.02303 (2022) . [10] B. Poole, A. Jain, J.T. Barron and B. Mildenhall, Dreamfusion: Text-to-3d using 2d diffusion ,

arXiv preprint arXiv:2209.14988 (2022) . [11] L. Yang, Z. Zhang, Y. Song, S. Hong, R. Xu, Y. Zhao et al., Diffusion models: A comprehensive survey of methods and applications , ACM computing surveys 56 (2023) 1. [12] W. Peebles and S. Xie, Scalable diffusion models with transformers , in Proceedings of the IEEE/CVF international conference on computer vision , pp. 4195–4205, 2023. [13] C.-H. Lai, Y. Song, D. Kim, Y. Mitsufuji and S. Ermon, The principles of diffusion models ,

arXiv preprint arXiv:2510.21890 (2025) . [14] C.M. Bishop and H. Bishop, Deep Learning: Foundations and Concepts , Springer (2024). [15] K.P. Murphy, Probabilistic Machine Learning: Advanced Topics , MIT Press (2023). [16] L. Ambrogioni, The statistical thermodynamics of generative diffusion models: Phase transitions, symmetry breaking and critical instability , arXiv preprint arXiv:2310.17467 (2023) . 

– 38 – [17] Z. Kadkhodaie, F. Guth, E.P. Simoncelli and S. Mallat, Generalization in diffusion models arises from geometry-adaptive harmonic representations , arXiv preprint arXiv:2310.02557 

(2023) . [18] T. Yoon, J.Y. Choi, S. Kwon and E.K. Ryu, Diffusion probabilistic models generalize when they fail to memorize , in ICML 2023 workshop on structured probabilistic inference {\ &} generative modeling , 2023. [19] H. Cui, F. Krzakala, E. Vanden-Eijnden and L. Zdeborov´ a, Analysis of learning a flow-based generative model from limited sample complexity , arXiv preprint arXiv:2310.03575 (2023) . [20] G. Biroli, T. Bonnaire, V. De Bortoli and M. M´ ezard, Dynamical regimes of diffusion models ,

Nature Communications 15 (2024) 9957. [21] A. Radford, J.W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal et al., Learning transferable visual models from natural language supervision , in International conference on machine learning , pp. 8748–8763, PMLR, 2021. [22] R. Rombach, A. Blattmann, D. Lorenz, P. Esser and B. Ommer, High-resolution image synthesis with latent diffusion models , arXiv [cs.CV] (2021) . [23] G.E. Uhlenbeck and L.S. Ornstein, On the theory of the brownian motion , Physical review 36 

(1930) 823. [24] B. Derrida, Random-energy model: An exactly solvable model of disordered systems , Physical Review B 24 (1981) 2613. [25] G. Biroli and M. M´ ezard, Generative diffusion in very large dimensions , Journal of Statistical Mechanics: Theory and Experiment 2023 (2023) 093402. [26] G. Raya and L. Ambrogioni, Spontaneous symmetry breaking in generative diffusion models ,

Advances in Neural Information Processing Systems 36 (2023) 66377. [27] Z. Yu and H. Huang, Nonequilbrium physics of generative diffusion models , Physical Review E 

111 (2025) 014111. [28] Y. LeCun, L. Bottou, Y. Bengio and P. Haffner, Gradient-based learning applied to document recognition , Proceedings of the IEEE 86 (2002) 2278. [29] J. Ho, A. Jain and P. Abbeel, Denoising diffusion probabilistic models , Advances in neural information processing systems 33 (2020) 6840. [30] B.D.O. Anderson, Reverse-time diffusion equation models , Stoch. Process. Their Appl. 12 

(1982) 313. [31] A. Hyv¨ arinen and P. Dayan, Estimation of non-normalized statistical models by score matching. , Journal of Machine Learning Research 6 (2005) . [32] P. Vincent, A connection between score matching and denoising autoencoders , Neural computation 23 (2011) 1661. [33] V. De Bortoli, J. Thornton, J. Heng and A. Doucet, Diffusion schr¨ odinger bridges with applications to score-based generative modeling , in Advances in Neural Information Processing Systems , vol. 34, pp. 17695–17709, 2021. 

– 39 – [34] P. Cattiaux, G. Conforti, I. Gentil and C. L´ eonard, Time reversal of diffusion processes under a finite entropy condition , in Annales de l’Institut Henri Poincar´ e (B) Probabilit´ es et Statistiques ,vol. 59, pp. 1844–1881, Institut Henri Poincar´ e, 2023. [35] U.G. Haussmann and E. Pardoux, Time reversal of diffusions , The Annals of Probability (1986) 1188. [36] M. M´ ezard, G. Parisi and M.A. Virasoro, Spin glass theory and beyond: An Introduction to the Replica Method and Its Applications , vol. 9, World Scientific Publishing Company (1987). [37] D. Ruelle, A mathematical reformulation of derrida’s rem and grem , Communications in Mathematical Physics 108 (1987) 225. [38] M. Mezard and A. Montanari, Information, physics, and computation , Oxford University Press (2009). [39] D.L. Donoho et al., High-dimensional data analysis: The curses and blessings of dimensionality ,

AMS math challenges lecture 1 (2000) 32. [40] J. Ho and T. Salimans, Classifier-free diffusion guidance , in NeurIPS 2021 Workshop on Deep Generative Models and Downstream Applications , 2021. [41] H. Chung, J. Kim, G.Y. Park, H. Nam and J.C. Ye, Cfg++: Manifold-constrained classifier free guidance for diffusion models , arXiv preprint arXiv:2406.08070 (2024) . [42] O. Ronneberger, P. Fischer and T. Brox, U-net: Convolutional networks for biomedical image segmentation , in International Conference on Medical image computing and computer-assisted intervention , pp. 234–241, Springer, 2015. [43] K.-T. Chen, Iterated path integrals , Bulletin of the American Mathematical Society 83 (1977) 831. [44] T. Lyons, Differential equations driven by rough signals (i): An extension of an inequality of l. c. young , Mathematical Research Letters 1 (1994) 451. [45] I. Chevyrev and A. Kormilitzin, A primer on the signature method in machine learning , in 

Signature Methods in Finance , p. 3–64, Springer Nature Switzerland (2025), DOI. [46] J. Zinn-Justin, Quantum field theory and critical phenomena , vol. 171, Oxford university press (2021). [47] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A.N. Gomez et al., Attention is all you need , Advances in neural information processing systems 30 (2017) . [48] K.G. Wilson, The renormalization group: Critical phenomena and the kondo problem , Reviews of modern physics 47 (1975) 773. 

– 40 –