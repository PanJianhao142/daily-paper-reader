---
title: "DDiT: Dynamic Patch Scheduling for Efficient Diffusion Transformers"
title_zh: DDiT：面向高效扩散 Transformer 的动态补丁调度
authors: "Dahye Kim, Deepti Ghadiyaram, Raghudeep Gadde"
date: 2026-02-19
pdf: "https://arxiv.org/pdf/2602.16968v1"
tags: ["keyword:MDM", "query:课题"]
score: 7.0
evidence: 通过动态分块实现可变时空分辨率
tldr: 扩散 Transformer (DiT) 在图像和视频生成中表现卓越但计算开销巨大，主因是其在整个去噪过程中使用固定大小的 patch。本文提出 DDiT，一种动态分块调度策略，根据内容复杂度和去噪步数动态调整 patch 大小。该方法在初期使用粗粒度 patch 建模全局结构，后期使用细粒度 patch 完善细节。实验显示，在保持生成质量的前提下，该方法在 FLUX-1.Dev 和 Wan 2.1 上分别实现了 3.52 倍和 3.2 倍的加速。
motivation: 现有的 DiT 模型在整个去噪过程中采用固定尺寸的分块，导致在处理简单内容或早期全局建模阶段存在严重的计算冗余。
method: 提出动态分块（Dynamic Tokenization）策略，根据去噪时间步和内容复杂度动态调整 patch 大小，实现计算资源的按需分配。
result: 在 FLUX-1.Dev 和 Wan 2.1 模型上分别获得 3.52 倍和 3.2 倍的推理加速，且未牺牲图像质量和提示词匹配度。
conclusion: DDiT 证明了通过在推理阶段动态调整 token 粒度，可以大幅提升扩散 Transformer 的效率并保持高性能。
---

## 摘要
扩散 Transformer (DiTs) 在图像和视频生成领域取得了最先进的性能，但其成功是以高昂的计算成本为代价的。这种低效很大程度上归因于固定的分词（tokenization）过程，即在整个去噪阶段均使用固定大小的补丁（patches），而不考虑内容的复杂程度。我们提出了动态分词，这是一种高效的推理端策略，可根据内容复杂度和去噪时间步动态调整补丁大小。我们的核心见解是：早期的去噪步骤仅需较粗的补丁来建模全局结构，而后续迭代则需要更精细（更小尺寸）的补丁来优化局部细节。在推理过程中，我们的方法在图像和视频生成的去噪步骤中动态重新分配补丁大小，在保持感知生成质量的同时显著降低了计算开销。广泛的实验证明了该方法的有效性：在 FLUX-1.Dev 和 Wan 2.1 上分别实现了高达 3.52 倍和 3.2 倍的加速，且未损害生成质量和提示词遵循度。

## Abstract
Diffusion Transformers (DiTs) have achieved state-of-the-art performance in image and video generation, but their success comes at the cost of heavy computation. This inefficiency is largely due to the fixed tokenization process, which uses constant-sized patches throughout the entire denoising phase, regardless of the content's complexity. We propose dynamic tokenization, an efficient test-time strategy that varies patch sizes based on content complexity and the denoising timestep. Our key insight is that early timesteps only require coarser patches to model global structure, while later iterations demand finer (smaller-sized) patches to refine local details. During inference, our method dynamically reallocates patch sizes across denoising steps for image and video generation and substantially reduces cost while preserving perceptual generation quality. Extensive experiments demonstrate the effectiveness of our approach: it achieves up to $3.52\times$ and $3.2\times$ speedup on FLUX-1.Dev and Wan $2.1$, respectively, without compromising the generation quality and prompt adherence.