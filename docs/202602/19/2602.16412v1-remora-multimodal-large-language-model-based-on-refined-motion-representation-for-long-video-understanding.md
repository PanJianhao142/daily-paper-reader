---
title: "ReMoRa: Multimodal Large Language Model based on Refined Motion Representation for Long-Video Understanding"
title_zh: ReMoRa：基于精细化运动表示的长视频理解多模态大语言模型
authors: "Daichi Yashima, Shuhei Kurita, Yusuke Oda, Komei Sugiura"
date: 2026-02-18
pdf: "https://arxiv.org/pdf/2602.16412v1"
tags: ["keyword:FM", "query:课题"]
score: 6.0
evidence: 用于长视频理解的精细运动表示
tldr: 针对多模态大模型在长视频理解中面临的计算开销大和RGB帧冗余问题，本文提出ReMoRa模型。该模型直接在压缩表征上操作，利用稀疏RGB关键帧捕捉外观，并引入精炼的运动表征（替代光流）来编码时间动态。通过降噪和细化模块提升运动特征质量，并实现线性扩展的特征压缩。实验表明，ReMoRa在LongVideoBench等多个长视频基准测试中表现优异，为高效长视频理解提供了新方案。
motivation: 旨在解决长视频处理中全量RGB帧带来的计算复杂度高和信息冗余严重的问题。
method: 利用稀疏关键帧结合经过降噪细化的压缩域运动矢量，并采用线性扩展的特征压缩机制。
result: 在LongVideoBench、NExT-QA和MLVU等多个挑战性长视频基准测试中均取得了优于基准模型的效果。
conclusion: ReMoRa证明了通过精炼的运动表征可以高效且低成本地实现强大的长视频理解能力。
---

## 摘要
尽管多模态大语言模型（MLLMs）在广泛的任务中取得了显著成功，但长视频理解仍然是一个重大挑战。在本研究中，我们专注于利用 MLLMs 进行视频理解。这一任务具有挑战性，因为处理完整的 RGB 帧流在计算上是难以实现的，且存在高度冗余，因为自注意力机制的复杂度随序列长度呈二次方增长。在本文中，我们提出了 ReMoRa，这是一种直接在视频压缩表示上进行操作来处理视频的视频 MLLM。模型保留了一组稀疏的 RGB 关键帧以获取外观信息，同时将时间动态编码为运动表示，从而消除了对连续 RGB 帧的需求。这些运动表示充当了光流（optical flow）的紧凑代理，无需完整的帧解码即可捕捉时间动态。为了改进基于块的运动（block-based motions）中的噪声和低保真度，我们引入了一个模块来去噪并生成细粒度的运动表示。此外，我们的模型以一种随序列长度线性扩展的方式压缩这些特征。我们通过在全套长视频理解基准测试上进行的大量实验，证明了 ReMoRa 的有效性。ReMoRa 在包括 LongVideoBench、NExT-QA 和 MLVU 在内的多个具有挑战性的基准测试中优于基准方法。

## Abstract
While multimodal large language models (MLLMs) have shown remarkable success across a wide range of tasks, long-form video understanding remains a significant challenge. In this study, we focus on video understanding by MLLMs. This task is challenging because processing a full stream of RGB frames is computationally intractable and highly redundant, as self-attention have quadratic complexity with sequence length. In this paper, we propose ReMoRa, a video MLLM that processes videos by operating directly on their compressed representations. A sparse set of RGB keyframes is retained for appearance, while temporal dynamics are encoded as a motion representation, removing the need for sequential RGB frames. These motion representations act as a compact proxy for optical flow, capturing temporal dynamics without full frame decoding. To refine the noise and low fidelity of block-based motions, we introduce a module to denoise and generate a fine-grained motion representation. Furthermore, our model compresses these features in a way that scales linearly with sequence length. We demonstrate the effectiveness of ReMoRa through extensive experiments across a comprehensive suite of long-video understanding benchmarks. ReMoRa outperformed baseline methods on multiple challenging benchmarks, including LongVideoBench, NExT-QA, and MLVU.