Title: Constraining Streaming Flow Models for Adapting Learned Robot Trajectory Distributions

URL Source: https://arxiv.org/pdf/2602.15567v1

Published Time: Wed, 18 Feb 2026 01:55:44 GMT

Number of Pages: 8

Markdown Content:
# Constraining Streaming Flow Models for Adapting Learned Robot Trajectory Distributions 

Jieting Long 1 Dechuan Liu 2,3 Weidong Cai 1 Ian Manchester 2,3 Weiming Zhi 1,3,4∗Collision -Prone Policies Safe and Collision -Free Streaming Flow Policy 

> Constraining
> Post -training
> Metric Anisotropy (M -1)
> Sampled Body Points

Fig. 1: Overview of CASF and its effect. Left: collisions produced by the baseline SFP. Right: collision-avoiding behaviours under CASF. 

Middle: the proposed CASF framework, which introduces geometry- and distance-aware constraints as a post-training module. 

Abstract —Robot motion distributions often exhibit multi-modality and require flexible generative models for accurate representation. Streaming Flow Policies (SFPs) have recently emerged as a powerful paradigm for generating robot trajec-tories by integrating learned velocity fields directly in action space, enabling smooth and reactive control. However, existing formulations lack mechanisms for adapting trajectories post-training to enforce safety and task-specific constraints. We propose Constraint-Aware Streaming Flow (CASF), a framework that augments streaming flow policies with constraint-dependent metrics that reshape the learned velocity field during execution. CASF models each constraint, defined in either the robot’s workspace or configuration space, as a differentiable distance function that is converted into a local metric and pulled back into the robot’s control space. Far from restricted regions, the re-sulting metric reduces to the identity; near constraint boundaries, it smoothly attenuates or redirects motion, effectively deforming the underlying flow to maintain safety. This allows trajectories to be adapted in real time, ensuring that robot actions respect joint limits, avoid collisions, and remain within feasible workspaces, while preserving the multi-modal and reactive properties of streaming flow policies. We demonstrate CASF in simulated and real-world manipulation tasks, showing that it produces constraint-satisfying trajectories that remain smooth, feasible, and dynamically consistent, outperforming standard post-hoc projection baselines. 

> ∗

email: Weiming.Zhi@sydney.edu.au .

> 1

School of Computer Science, The University of Sydney, Australia. 

> 2

School of Aerospace, Mechanical and Mechatronic Engineering, The University of Sydney, Australia. 

> 3

Australian Center For Robotics, The University of Sydney, Australia. 

> 4

College of Connected Computing, Vanderbilt University, TN, USA. 

I. I NTRODUCTION 

Robots operating in complex environments must generate trajectories that are both expressive and reactive, often under multi-modal task distributions. Capturing this variability re-quires generative motion models capable of representing rich distributions over future trajectories while remaining suitable for real-time control. Recent progress in flexible generative models has enabled robot policies to incorporate complex trajectory distributions, including diffusion-based policies [1], [2], [3] and flow-matching models [4], [5], [6]. A key drawback of these models lies in their inference procedure, which requires numerically solving an integral over full trajectories, where each step jointly refines all future actions. This limitation was recently addressed by Streaming Flow Policies (SFPs) [4], [6], which reinterpret the generative process as a continuous-time flow directly in action space rather than in trajectory space. Instead of evolving a trajec-tory of trajectories, SFP learns a neural velocity field whose integration progressively refines the predicted action sequence. Each flow integration step updates the entire trajectory distri-bution, allowing actions to be streamed incrementally as they are generated. This formulation provides reduced inference latency compared to diffusion-based sampling, making flow-based generative control practical for closed-loop execution. However, real-world robots must respect diverse safety and feasibility constraints that may change or be partially unknown at training time. These include joint limits, self-collisions, 

> arXiv:2602.15567v1 [cs.RO] 17 Feb 2026

obstacle avoidance, and workspace boundaries, defined across both configuration and task spaces. Directly integrating the learned flow field can thus lead to infeasible or unsafe motions. To address this, we propose the Constraint-Aware Streaming Flow (CASF) framework, which enables the learned ODE to be reshaped online to account for dynamic constraints. CASF models each constraint as a differentiable distance function defining proximity to restricted regions [7], [8]. These distance functions are used to construct local constraint metrics that deform the geometry of the robot’s action space, scaling and reorienting the underlying flow field according to the local constraint influence. Constraints defined in the robot’s workspace are expressed through their distance fields and 

pulled back via the robot’s kinematics into the control or configuration space, allowing all constraints to be combined coherently. Figure 1 illustrates the induced metric ( M −1) and sampled body points used for metric pullback, together with representative failure and success cases under collisions. The resulting modular metric composition yields a continuously deformed vector field that adapts at runtime to environmental and kinematic changes. This approach enforces constraints di-rectly through the ODE integration process without retraining. Concretely, this paper makes the following contributions:  

> •

Constraint-Aware Streaming Flow (CASF), a framework for reshaping learned streaming flow policies through constraint-dependent metric fields, enabling continuous and differentiable enforcement of safety and feasibility constraints at runtime.  

> •

A modular constraint composition scheme, where con-straints defined in both workspace and configuration space are converted into local metrics, and pulled back through the robot’s kinematics to act coherently within a unified control-space geometry.  

> •

Rigorous empirical evaluations demonstrating the ca-pability of CASF to safely enforce constraints while remaining close to behaviours learned via flow-matching. II. R ELATED WORK 

Motion Policy Generation: Motion policy generation un-derpins robotic autonomy, mapping perception directly to closed-loop control. While classical methods primarily re-lied on model-based planning and optimisation [9], [10], [11], the field has increasingly shifted toward learning-based paradigms with imitation learning (IL) [12], [13], [14], [15] as a baseline for cloning expert demonstrations. Recently, generative imitation learning has progressed towards diffusion-based policies [1], [2], [16], [17], and most recently to flow-based formulations [18], [5], [19], [6], which retain the expressivity of diffusion while significantly reducing inference latency by replacing iterative denoising with straight-through probability transport along learned flows. Yet, these data-driven policies degrade under distribution shift and frequently collide in unseen environments, as geometric constraints are weakly encoded during training. 

Inference-time Constrained Policy Optimisation: Con-strained policy optimisation formalises motion generation by expressing obstacles as strict constraints, solving for safe trajectories that link the initial and target while respecting kinematic limits. Existing strategies typically fall into two categories. (1) Trajectory Optimisation and Post-hoc Filtering 

rectifies unconstrained rollouts using gradient-based planners (e.g., CHOMP [10], TrajOpt [20]) or control-theoretic safety filters [21] grounded in set invariance or reachability analysis . However, these decoupled overrides often induce out-of-distribution actions, suffer from local minima, and incur high computational overhead by separating generation from cor-rection. (2) Generative Guidance biases the sampling process directly, employing either soft constraints via classifier-based guidance [22], [23] which lack strict feasibility guarantees or hard constraints via projection [24] or reflected dynamics (e.g., mirror maps) [25], [26]. Notably, [27] constrains generative diffusion models with progressively enforced barriers, and JM2D [28] aligns diffusion planners with optimisation-based safety via joint sampling. Our approach (CASF) modulates the generative vector field onto flow models via geometry-aware metric shaping, enforcing safety constraints through smooth, reactive steering. By avoiding discontinuous hard projections or expensive retraining, CASF preserves trajectory continuity and imitation fidelity directly during inference. III. P RELIMINARIES : T RAJECTORY DISTRIBUTION 

LEARNING WITH FLOWS 

Flow Matching: Flow matching [4] is a continuous generative modeling framework that learns a time-dependent velocity field to transport samples from a simple base distribution to a complex data distribution via an ordinary differential equation (ODE). Given a sample a(t) ∈ A evolving under flow time 

t ∈ [0 , 1] , the flow dynamics are defined as: 

da (t)

dt = vθ (a(t), t ), (1) where vθ : A× [0 , 1] → T A is a neural network parameterising a velocity field. Integrating this ODE transforms an initial distribution p0(a) into a target distribution p1(a).The training objective minimises the discrepancy between the model-predicted velocity vθ (a, t ) and a target velocity 

v∗(a, t ) constructed from data trajectories: 

LFM = Et∼U [0 ,1] , a ∼pt(a)

 ∥vθ (a, t ) − v∗(a, t )∥22

. (2) At optimality, the induced marginal distribution of a(t) under 

vθ matches the data distribution at all intermediate timesteps, allowing the model to represent rich, multi-modal densities over continuous variables [13]. 

Streaming Flow Policy: The Streaming Flow Policy (SFP) 

simplifies diffusion and flow-matching policies by treating ac-tion trajectories as flow trajectories [6]. Traditional diffusion or flow policies generate a trajectory of trajectories . That is, they sample a full sequence of actions via a diffusion or flow process that must complete before any robot actions can be executed. This is computationally expensive and introduces latency. In contrast, SFP operates directly in action space A, defining a history-conditioned velocity field vθ (a, t | h) that evolves actions according to: 

da (t)

dt = vθ (a(t), t | h), a(0) ∼ N (aprev , σ 20 I), (3) where h denotes the observation history and aprev is the most recently executed action. By incrementally integrating this ODE, SFP generates a sequence of future actions whose 

flow time aligns with real execution time, enabling on-the-fly streaming of actions to the robot controller. During training, stabilising conditional flows are analyti-cally constructed around demonstration trajectories ξ(t) as: 

vξ (a, t ) = ˙ξ(t) − k (a − ξ(t)) , (4) whose induced marginals pξ (a | t) form narrow Gaussian tubes centered around the demonstrations. The model vθ

is then trained to match these conditional flows using the conditional flow-matching loss. The resulting learned velocity field produces per-timestep marginals that match the data distribution, preserving multi-modality while enabling low-latency, closed-loop control suit-able for real-time robotic policy execution. IV. C ONSTRAINT -A WARE STREAMING FLOW 

The Constraint-Aware Streaming Flow (CASF) framework reshapes the learned velocity field of a Streaming Flow Policy (SFP) to enforce safety and feasibility constraints during execution. Rather than retraining or projecting trajectories post hoc, CASF modifies the geometry of the flow ODE itself. It treats the robot’s action or configuration space as a deformable manifold whose local geometry adapts near constraint boundaries. As the robot approaches obstacles or joint limits, the local metric stretches unsafe directions and compresses tangential ones, naturally bending or slowing the flow. This is analogous to fluid motion around a solid object. Far from constraints, this metric smoothly reduces to the iden-tity, preserving the nominal behaviour. Through this metric-weighted deformation, CASF embeds constraint awareness directly into the ODE integration process, enabling smooth, real-time adaptation of streaming policies while maintaining their reactive, multi-modal character. In the rest of this section, we first describe how to construct metrics from distance functions to an infeasible region. We then outline how users can either craft or learn distance func-tions based on the constraints desired. Finally, we introduce how constraints defined in separate task-spaces (e.g. in the robot’s workspace and joint space) can be fused together by pulling the constraints to the robot’s configuration space. 

A. Distance-Induced Metrics and Metric-Weighted Streaming 

Metric Construction: We define a smooth Riemannian metric that increases motion cost near infeasible or unsafe regions of the action space. Intuitively, the metric acts as a local “resistance field” that slows or diverts motion in the direction of constraint violation while allowing tangential movement along constraint surfaces. Let F denote the set of infeasible states, and let dk(a) ≥ 0 be differentiable distances 

> Fig. 2: Visualisation of learned neural signed distance fields (Neural SDFs). Left: Robomimic simulation scene with a vase obstacle placed on the table. Middle: zero level-set surface reconstructions of the learned SDF from two viewpoints (camera-aligned and top-down). Right: corresponding 2D SDF slices.

from the current action a to each boundary Fk. With outward unit normals nk(a) = ∇adk(a)/∥∇ adk(a)∥, the local metric is constructed as: 

M (a) = I + X

> k

wk

 dk(a)h

αk

 dk(a) nkn⊤ 

> k

. . . 

+ βk

 dk(a) (I − nkn⊤ 

> k

)

i

, (5) where wk(d) is a smooth influence function (e.g., Gaussian), and αk(d), βk(d) control the stiffness along and tangent to constraint boundaries. As dk(a) → ∞ , wk(d) → 0 and 

M (a) → I, so the metric smoothly reverts to the identity far from constraints. 

Metric-Weight Streaming Flow: Given the original trained streaming flow vθ (a, t | h), which represents the learned veloc-ity field used to generate actions during execution, constraint adaptation is introduced at inference time by pre-multiplying the velocity with the inverse of the local constraint metric: 

da (t)

dt = ˜ v(a, t | h) = M (a)−1 vθ (a, t | h), (6) where M (a) ≻ 0 is a smoothly varying, geometry-induced metric constructed from obstacle distance and surface normals, and modulated by a distance-based decay so that shaping vanishes away from constraint boundaries. Equivalently, ˜v minimises the metric-weighted projection: 

˜v = arg min  

> ˙a
> 12

∥ ˙a − vθ ∥2 

> M(a)

, (7) which attenuates motion along constraint normals relative to tangential components, yielding a continuously deformed flow field that enforces constraint-awareness in real time, without retraining or altering the nominal policy. 

Connection to Control Barrier Functions (CBFs): The metric-weighted projection formulation can be viewed as a continuous and analytic approximation to safety-filter methods based on Control Barrier Functions (CBFs), which are widely used in constrained robot control. Classical CBF formulations compute a corrected control ˙a∗ at each timestep by solving a quadratic program of the form: 

˙a∗ = arg min  

> ˙a
> 12

∥ ˙a − vθ (a)∥22 s.t. gi(a, ˙a) ≥ 0, (8) where gi(a, ˙a) ≥ 0 represents a generalised set of feasibility constraints, such as joint limits or actuator saturation, ensuring that the resulting action ˙a∗ remains within the robot’s physical and operational capabilities. In contrast, CASF embeds an analogous correction directly into the streaming ODE by replacing explicit inequality con-straints with a continuously varying metric M (a) whose eigen-structure encodes direction-dependent penalties derived from local geometry. The resulting update ˜v = M (a)−1vθ (a) per-forms an implicit soft projection of the policy-induced velocity field, approximating the effect of CBF-based safety filtering in closed form without solving an optimization problem at each step. This yields a lightweight, differentiable alternative to CBF-QP filters, maintaining continuous deformation of the velocity field while retaining the interpretability of constrained optimisation. 

B. Training Distance Functions for Neural Metric Fields 

To construct constraint-aware metrics, CASF requires smooth distance functions dk(a) that encode the signed prox-imity of an action or configuration a to the corresponding constraint boundary Fk. In simple cases, analytic distance functions can be defined directly (e.g., distance to a box, sphere, or joint limit). However, for complex geometries or learned environment representations, these distances can instead be obtained from neural implicit fields trained from samples. Figure 2 visualises a learned distance field of a vase in our simulation environment, where no analytical SDF is available, illustrating both the reconstructed surface geometry and corresponding 2D SDF slices. 

Learning distance functions: Given a set of sampled points {ai}Ni=1 in the robot’s configuration or workspace, with associated ground-truth distances si to a constraint region (e.g. obstacles in workspace), we train a neural network 

ϕψ (a) : Rn → R to regress these distances via: 

Ldist (ψ) = E(ai,s i)

λmse (ϕψ (ai) − | si|)2 . . . 

+ λeik (∥∇ aϕψ (ai)∥2 − 1) 2. (9) where the first term enforces distance accuracy and the second imposes the Eikonal constraint ∥∇ aϕψ (a)∥2 = 1 to encour-age locally metric-consistent gradients. This loss formulation parallels those used in distance function learning for shape reconstruction [7], ensuring that ϕψ (a) behaves as a smooth distance field in the vicinity of constraint boundaries. 

Constraint encoding: Once trained, the neural field ϕψ (a)

serves directly as the differentiable distance function dk(a)

used for metric construction in Equation (5). Its gradient 

∇aϕψ (a) defines local surface normals, which are orthogonal to the iso-contour lines visualised in the 2D slices of Figure 2. These normals enable the computation of anisotropic metrics: 

M (a) = I + w(ϕψ (a)) 

h

α(ϕψ (a)) nn ⊤ . . . , 

+β(ϕψ (a))( I − nn ⊤)

i

, (10) where n = ∇aϕψ (a)/∥∇ aϕψ (a)∥ is the learned constraint normal. This yields a smooth neural metric field that remains differentiable. 

C. Pullback of Workspace Constraints to C-Space 

Robot motion is governed by forward kinematics that map joint configurations to workspace positions. Let q ∈ C ⊂ Rn

> Fig. 3: We sample body points on the robot. Left: The joints and links of the manipulator. Middle: dense surface sampling over the full arm mesh. Right: link-wise surface sampling, preserving local geometry per link and used in our pullback-based constraint formulation.

denote the configuration vector, and x = f (q) ∈ W ⊂ R3 the corresponding workspace point. The differential relation: 

˙x = J(q) ˙ q, (11) uses the Jacobian J(q) = ∂f (q)/∂q to map joint velocities to workspace velocities. This extends naturally to multiple body points fi(q), as illustrated in Figure 3, with multiple Jacobians Ji(q), allowing proximity and collision constraints to be enforced across the robot structure. 

Metric pullback: Workspace constraints are often repre-sented as distance fields ϕi(x) defining proximity to obstacles or boundaries in W, whereas streaming flow policies operate in configuration space C. To align these spaces, each workspace metric Mx,i (x) is pulled back via: 

Mq,i (q) = Ji(q)⊤ Mx,i 

 fi(q) Ji(q), (12) ensuring that penalised directions in workspace correspond to their joint-space counterparts under the robot’s kinemat-ics. Intuitively, if a workspace direction is heavily penalised (e.g., moving into an obstacle), the corresponding joint-space directions are also penalised in Mq,i (q).

Metric fusion: To account for collisions along the full robot geometry, we aggregate the pulled-back metrics of each body point sampled into a composite configuration-space metric 

Mfused (q). The fusion is anchored with an identity-based baseline to ensure the metric remains well-conditioned in free space: 

Mfused (q) = I + X

> i

wi(q) Mq,i (q), (13) where wi(q) = exp   − κidi(q)2 ∈ [0 , 1] is an SDF-based activation weight, modulating each constraint’s influence with the distance di(q) and decay rate κi.Near active constraints, their metrics dominate; far away, as the robot moves into free space, wi(q) → 0 and Mfused (q) →

I. During execution, the nominal streaming flow vθ is de-formed into a constraint-aware velocity field by solving the metric-weighted projection: 

dq (t)

dt = Mfused (q)−1 vθ (q, t | h), (14) blending the effects of joint-space and workspace constraints Obs S.R. G.C. A.P.L NoShaping State 0.479 0.836 193 Visual 0.469 0.819 193 Hard-Projection State 0.480 0.796 194 Visual 0.400 0.711 187 CBF State 0.780 0.899 183 Visual 0.600 0.805 185        

> CASF (Ours) State 0.813 0.961 168
> Visual 0.816 0.941 157

TABLE I: Push-T: At the last step of each episode, we measure the coverage (G.C.) of the block over the goal area, the success rate (S.R.), where success is defined as a higher coverage than the minimum in the demonstration dataset, and the average trajectory length (A.P.L.).                                                                                                                      

> Metric Line Khamesh N-Shape Sine R-Shape S-Shape W-Shape Worm Z-Shape SFP Masked F.D. NA NA NA NA NA NA NA NA NA M.P.D. 0.159 0.219 0.131 0.237 0.091 0.213 0.219 0.169 0.270 IntViolation 14.526 18.921 6.516 8.399 9.245 8.738 6.714 7.186 9.768 Projection Masked F.D. 0.139 0.163 0.156 0.294 0.077 0.199 0.385 0.285 0.418 M.P.D. 0.001 0.002 0.002 0.003 0.001 0.003 0.003 0.002 0.003 IntViolation 0.054 0.088 0.039 0.157 0.028 0.118 0.094 0.055 0.168 CBF Masked F.D 0.142 0.142 0.119 0.205 0.075 0.267 0.383 0.274 0.370 M.P.D. 0.000 0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.000
> IntViolation 0.000 0.037 0.000 0.000 0.000 0.000 0.000 0.000 0.000 CASF (Ours)
> Masked F.D 0.051 0.157 0.117 0.211 0.054 0.093 0.186 0.080 0.164
> M.P.D. 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000
> IntViolation 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000

TABLE II: Quantitative performance comparison of constraint-handling methods (raw SFP -no shaping, Hard-Projection, CBF, and CASF) on LASA obstacle-avoidance tasks [29]. Lower is better for all metrics: Masked Fr´ echet Distance (Masked F.D.) [30], Maximum Penetration Depth (M.P.D.) [31], and Integral Violation (IntViolation) [21]. Score: 0.841, Steps: 200 Score: 0.883, Steps: 200 Score: 0.968, Steps: 200 Score: 1.000 , Steps: 147 

(a) pushTstate Score: 0.732, Steps: 200 Score: 0.906, Steps: 200 Score: 0.929, Steps: 192 Score: 1.000 , Steps: 140 

(b) pushTvisual 

Fig. 4: Comparison of representative rollouts under different constraint-handling strategies: No Shaping(left), Hard-Projection (left-second), CBF (right-second), and CASF (right). Each panel reports the final task score and number of steps. 

into a unified, smooth constraint-aware flow. V. E XPERIMENTS 

We rigorously investigate the capabilities of Constraint-Aware Streaming Flow Policy (CASF), examining its abil-ity to enforce robust collision avoidance. CASF is bench-marked against hard projection and Control Barrier Functions (CBFs) [21] filtering. The empirical evaluations are conducted both in simulation and in the real-world on a Universal Robot (UR) manipulator. When training underlying streaming flow policies, we follow the hyperparameters and setup in [6]. 

Constraining the workspace: To first evaluate CASF’s abil-ity to enforce geometric constraints directly, we assess its global and local constraint awareness in the PushT [32] and LASA [29] environments, respectively, and further validate it in a 3D RoboMimic [33] setting. All experiments adopt a closed-loop, receding-horizon evaluation protocol, in which predicted velocity chunks are integrated forward and resulting states are fed back for subsequent actions. To assess policy fidelity under large-scale workspace con-straints, we evaluate performance in the 2-D PushT environ-ment. Policies are trained via imitation learning using 200 demonstrations for both state- and image-conditioned variants and evaluated over 50 closed-loop episodes. Quantitative eval-uations are conducted via the following metrics:  

> •

Success Rate (S.R.) : the proportion of episodes in which the object reaches the goal region, summarising overall task completion under a success criterion;  

> •

Goal Coverage (G.C.) : the averaged fraction of the goal region covered by the object at the final timestep, reflect-ing how well the task objective is ultimately achieved;  

> •

Average Path Length (A.R.L.) : the mean length of the executed end-effector trajectory, indicating execution ef-ficiency and detour severity under constraint enforcement. Quantitative results (Table I) show that CASF consistently outperforms the unconstrained SFP baseline and projection-based filters, achieving higher Success Rate and Goal Cov-erage while improving operational efficiency with a 15% reduction in path length. Qualitative inspection (Figure 4) con-firms that, unlike hard-projection and CBF-style corrections, which often induce oscillatory drift or blocking effects due to discontinuous or normal-only adjustments, CASF’s continuous metric shaping imparts global geometric awareness; this allows the policy to anticipate and deflect from boundaries smoothly, maintaining safer and more direct routes while preserving nominal behaviour in free space. To further investigate the behaviour under localised reactive constraints, we conduct experiments on the LASA benchmark [29]. We report three quantitative metrics:  

> •

Masked Fr´ echet Distance (Masked F.D.) [30] measures trajectory deviation, isolating how much the global shape changes from trajectories of the unshaped policy;  

> •

Maximum Penetration Depth (M.P.D.) [31] reports the worst-case constraint violation, capturing peak failures;  

> •

Integral Violation (IntViolation) [21] accumulates vio-lations over time, reflecting the overall severity and duration of unsafe behaviour. As shown in Table II, CASF achieves near-zero safety vio-lations across all tasks, while consistently attaining the lowest Masked F.D., demonstrating that it preserves global trajectory structure substantially better than projection-based baselines while maintaining strict constraint satisfaction. While the Fig. 5: Qualitative evaluation of reactive obstacle avoidance on four LASA tasks (Line, Worm, Z-shape, and W-shape). Each task compares the raw policy, Hard-Projection, CBF, and CASF. Grey streamlines visualize the induced velocity fields, while orange curves show rollout trajectories. The blue dashed curve denotes the unshaped predicted trajectory, and the red curve in the first column indicates the ground-truth demonstration. Transparent reddish overlays highlight the correction masks introduced by each shaping method. 

> Fig. 6: Whole robot collision avoidance. Each group demonstrates avoidance behaviour induced by collisions at body points along the links (yellow dot markers). Left: rollouts of the baseline imitation policy. Right: CASF with collision-avoidance over the body of the robot.

unshaped SFP exhibits substantial violations (large M.P.D. and IntViolation), indicating frequent and deep obstacle intrusions. Hard-Projection and CBF both enforce strict safety, driving M.P.D. and IntViolation close to or equal to zero, but at the cost of markedly increased Masked F.D., revealing significant distortion of the nominal trajectory due to abrupt or piecewise corrections. Note that Masked F.D. for the SFP baseline is reported as NA, since the metric measures distortion induced by shaping relative to the raw policy and is thus not meaningful when no shaping is applied. Qualitative results (Figure 5) corroborate this finding: CASF induces fluid, anticipatory deviations that minimally perturb the global trajectory shape, in contrast to the abrupt directional changes or piecewise-linear detours produced by hard-projection and CBF corrections. Correction mask overlaid highlights this distinction: CASF induces a spatially graded, distance-modulated shaping of the velocity field, whereas projection-based methods apply discontinuous or boundary-concentrated adjustments. Further qualitative validation in the 3D Robomimic en-vironment (Figure 8) corroborates these findings within a higher-dimensional workspace. The overlaid trajectories and translucent body volumes demonstrate how CASF produces smooth, anticipatory deviations of the end-effector motion around cylindrical obstacles while preserving a coherent ap-proach toward the task goal. In contrast, baseline methods (top row) result in task failure, succumbing to collisions or deadlocks near the obstacle. This performance highlights how the induced Riemannian metric effectively warps the 3D vector field, guiding the end-effector along a fluid, collision-free trajectory without sacrificing task progress. Overall, these results demonstrate that CASF enforces workspace-level safety without sacrificing trajectory fidelity or efficiency. By reshaping the local geometry of the workspace through a distance-modulated Riemannian metric, CASF en-ables anticipatory avoidance behaviour that preserves the ex-pressive structure learned by the streaming flow policy. 

Whole Robot Collision Avoidance: Under the 3D Robomimic manipulation environment, we next evaluate CASF in a more challenging setting that requires whole-robot collision avoid-ance in high-dimensional configuration space, where obsta-cles are introduced into the workspace, positioned to cover intermediate links of the manipulator (e.g., elbow, forearm) rather than the end-effector. These scenarios induce collisions that cannot be resolved by task-space corrections alone. Here, we sample up to 15 body points on each of the robot links to enable whole-robot collision avoidance. Figure 6 presents qualitative rollouts under multiple obstacle placements, each targeting a distinct region of the arm (First Column). Baseline policies, which only consider end-effector safety, consistently fail (Second Column): when the end-effector itself is not threatened, task-space safety filters remain inactive, causing intermediate links to drive directly into obstacles. In con-trast, CASF (Third Column) successfully adapts the motion by redistributing avoidance behaviour across relevant joints. This produces smooth, coordinated rotations that steer the threatened link clear of the hazard while maintaining task progression. The overlaid translucent body volumes in Figure 6 illus-trate the efficacy of configuration-space metric pullback. By defining distance-modulated metrics at multiple control points along the kinematic link and aggregating their contributions actively via the Jacobian, CASF induces joint-level velocity shaping that reflects the global geometry of the arm–obstacle interaction. Consequently, avoidance emerges as a cohesive whole-robot response: upstream joints adjust preemptively to Sawing actions:        

> Moving forward
> Collision
> Avoided!
> Raise up
> the joint
> to avoid
> Sawing actions:
> Moving forward
> Collision!
> Hit the vase down
> Collison
> Avoided!
> Collision!
> Keep
> moving
> Collision
> Avoided!
> Going up
> to avoid
> Long -arm
> Collision !
> Bending
> the rose
> Bypass the
> rose :keep
> moving
> towards
> the chair
> Task Completed:
> Put chair upright
> Task Completed:
> Put chair upright
> Collision !
> Hit the vase
> next to the box
> Collision Avoided!
> Go around the vase
> Collision !
> Hit the vase down
> Collision Avoided!
> Go around the vase
> Task Completed:
> Tool in the box
> Task Completed:
> Tool in the box
> Collision Avoided!
> Avoided the vase
> Collision !
> Move the tool and
> hit the vase mouth
> Bypass vase mouth :
> keep turning
> Collision !
> keep turning but
> trapped in mouth
> Task Failed!!!
> Vase down and
> arm stopped
> Task Completed:
> Hammer hit the screw

Fig. 7: CASF deployed in the real-world. Across four manipulation tasks, policies without CASF collide with obstacles (top), whereas CASF enables collision-aware motion generation that avoids contact while completing the tasks (bottom). 

Fig. 8: Workspace collision avoidance in the 3D Robomimic environ-ment. Left: policy executions with obstacles (green cylinders), with translucent robot and object meshes illustrating the swept motion volume (first column: baseline policy; second column: CASF). Right: 3D end-effector trajectories, comparing raw policy rollouts (orange) with CASF-shaped trajectories (blue) 

retract the threatened link, exploiting the kinematic null space to ensure safe clearance without disrupting the end-effector’s path toward the goal. Importantly, these corrections remain continuous and task-consistent, avoiding the abrupt halting or oscillatory behaviour commonly observed with projection-based filtering methods. Collectively, these results demonstrate that CASF extends beyond end-effector safety to enable robust, anticipatory whole-robot collision avoidance in complex 3D manipulation scenarios. By shaping the policy’s velocity field directly in configuration space through metric pullback, CASF preserves the expressive structure of the learned motion while ensuring safety under diverse, previously unseen obstacle interactions. 

Real Robot Execution: We further assess the performance of CASF on a real robotic platform using four representative manipulation tasks, each featuring distinct obstacle placements that induce contacts with different parts of the arm. The evaluated tasks are: 1) Tidy Up: Picking up a fallen chair and placing it upright on the target area, with an obstacle blocking the end-effector’s direct path to the goal. 2) Pick & Place: Retrieving a wrench from the tool shelf and placing it into a storage box, with an obstacle positioned to interfere with the upper arm along the reaching motion. 3) Sawing: Grasping a hand saw from the tool shelf and executing sawing motions, with an obstacle repeatedly contacting the wrist during the action. 4) Hammer Hitting: Picking up a hammer from the tool shelf and hammering a nail, where collisions occur right after grasping the tool. For each task, we collect 50 demonstration trajectories for each task and train neural SDFs of the environments. We visualise qualitative comparisons between executions with and without collision avoidance in Figure 7, illustrating the effectiveness of CASF under different obstacle configurations. Across all tasks, CASF consistently enables collision-aware motion generation under diverse contact scenarios, demon-strating robust obstacle avoidance behaviours while preserving task completion. These results highlight the ability of CASF to generalise across heterogeneous manipulation skills and obstacle configurations on a real robotic platform, despite being trained on relatively small datasets. VI. C ONCLUSIONS AND FUTURE WORK 

We introduced Constraint-Aware Streaming Flow (CASF), a constraint-aware shaping mechanism for streaming flow poli-cies that embeds geometric safety constraints directly into the policy’s inference-time dynamics. By coupling signed distance fields with metric shaping of streaming flow dynamics, CASF provides a principled mechanism to steer learned behaviours away from obstacles and boundaries without altering the underlying policy distribution. Experiments in both simulation and real-robot settings show that CASF produces smooth, stable trajectories that remain faithful to demonstrations. Future work will explore integrating perception-driven dis-tance fields to support deployment in unstructured scenes. A key theoretical extension is to relax the symmetry of the shaping metric by considering direction-dependent or non-reversible geometric structures (e.g., Finsler or Randers met-rics), which can introduce asymmetric modulation of the flow field and explicitly bias motion away from constraint bound-aries rather than merely attenuating velocities along surface normals. Such formulations may provide stronger guarantees in tight, non-convex corridors and near-contact scenarios. REFERENCES [1] M. Janner, Y. Du, J. Tenenbaum, and S. Levine, “Planning with diffusion for flexible behavior synthesis,” in International Conference on Machine Learning (ICML) , 2022. [2] C. Chi, S. Feng, Y. Du, Z. Xu, E. Cousineau, B. Burchfiel, and S. Song, “Diffusion policy: Visuomotor policy learning via action diffusion,” in 

Proceedings of Robotics: Science and Systems (RSS) , 2023. [3] S. H. Høeg, Y. Du, and O. Egeland, “Fast policy synthesis with variable noise diffusion models,” in IEEE International Conference on Robotics and Automation (ICRA) . IEEE, 2025. [4] Y. Lipman, R. T. Q. Chen, H. Ben-Hamu, M. Nickel, and M. Le, “Flow matching for generative modeling,” in International Conference on Learning Representations (ICLR) , 2023. [5] S. Ye and M. C. Gombolay, “Efficient trajectory forecasting and generation with conditional flow matching,” in IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) . IEEE, 2024. [6] S. Jiang, X. Fang, N. Roy, T. Lozano-P´ erez, L. P. Kaelbling, and S. An-cha, “Streaming flow policy: Simplifying diffusion / flow-matching policies by treating action trajectories as flow trajectories,” in Conference on Robot Learning (CoRL) , 2025. [7] J. J. Park, P. Florence, J. Straub, R. Newcombe, and S. Lovegrove, “Deepsdf: Learning continuous signed distance functions for shape representation,” in The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , June 2019. [8] M. Koptev, N. Figueroa, and A. Billard, “Neural joint space implicit signed distance functions for reactive robot manipulator control,” IEEE Robotics and Automation Letters , 2023. [9] J. F. P. Kooij, F. Flohr, E. A. I. Pool, and D. Gavrila, “Context-based path prediction for targets with switching dynamics,” International Journal of Computer Vision , 2018. [10] N. Ratliff, M. Zucker, J. A. Bagnell, and S. Srinivasa, “Chomp: Gra-dient optimization techniques for efficient motion planning,” in IEEE International Conference on Robotics and Automation (ICRA) . IEEE, 2009. [11] G. Williams, N. Wagener, B. Goldfain, P. Drews, J. M. Rehg, B. Boots, and E. A. Theodorou, “Information theoretic mpc for model-based reinforcement learning,” in IEEE International Conference on Robotics and Automation (ICRA) . IEEE, 2017. [12] H. Ravichandar, A. S. Polydoros, S. Chernova, and A. Billard, “Recent advances in robot learning from demonstration,” Annual review of control, robotics, and autonomous systems , 2020. [13] P. Florence, C. Lynch, A. Zeng, O. A. Ramirez, A. Wahid, L. Downs, A. Wong, J. Lee, I. Mordatch, and J. Tompson, “Implicit behavioral cloning,” in Proceedings of the 5th Conference on Robot Learning .PMLR, 2022. [14] W. Zhi, I. Akinola, K. Van Wyk, N. D. Ratliff, and F. Ramos, “Global and reactive motion generation with geometric fabric command se-quences,” in IEEE International Conference on Robotics and Automation (ICRA) , 2023. [15] W. Zhi, T. Lai, L. Ott, and F. Ramos, “Diffeomorphic transforms for generalised imitation learning,” in Learning for Dynamics and Control Conference, L4DC , 2022. [16] C. Pan, Z. Yi, G. Shi, and G. Qu, “Model-based diffusion for trajectory optimization,” Advances in Neural Information Processing Systems (NeurIPS) , 2024. [17] H. Xue, C. Pan, Z. Yi, G. Qu, and G. Shi, “Full-order sampling-based mpc for torque-level locomotion control via diffusion-style annealing,” in IEEE International Conference on Robotics and Automation (ICRA) .IEEE, 2025. [18] C.-A. Cheng, M. Mukadam, J. Issac, S. Birchfield, D. Fox, B. Boots, and N. Ratliff, “Rmpflow: A computational graph for automatic motion pol-icy generation,” in International Workshop on Algorithmic Foundations of Robotics (WAFR) , 2018. [19] M. Braun, N. Jaquier, L. Rozo, and T. Asfour, “Riemannian flow matching policy for robot motion learning,” in IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) . IEEE, 2024. [20] J. Schulman, J. Ho, A. X. Lee, I. Awwal, H. Bradlow, and P. Abbeel, “Finding locally optimal, collision-free trajectories with sequential con-vex optimization.” in Robotics: science and systems , 2013. [21] A. D. Ames, S. Coogan, M. Egerstedt, G. Notomista, K. Sreenath, and P. Tabuada, “Control barrier functions: Theory and applications,” in 18th European Control Conference (ECC) , 2019. [22] P. Dhariwal and A. Nichol, “Diffusion models beat gans on image syn-thesis,” Advances in Neural Information Processing Systems (NeurIPS) ,2021. [23] W. Xiao, T.-H. Wang, C. Gan, R. Hasani, M. Lechner, and D. Rus, “Safediffuser: Safe planning with diffusion probabilistic models,” in 

The Thirteenth International Conference on Learning Representations (ICLR) , 2023. [24] R. R¨ omer, A. v. Rohr, and A. Schoellig, “Diffusion predictive control with constraints,” in Proceedings of the 7th Annual Learning for Dynam-ics &amp; Control Conference , ser. Proceedings of Machine Learning Research, 2025. [25] A. Lou and S. Ermon, “Reflected diffusion models,” in International Conference on Machine Learning (ICML) . PMLR, 2023. [26] G.-H. Liu, T. Chen, E. Theodorou, and M. Tao, “Mirror diffusion mod-els for constrained and watermarked generation,” Advances in Neural Information Processing Systems (NeurIPS) , 2023. [27] R. Mishra and I. R. Manchester, “Eb-mbd: Emerging-barrier model-based diffusion for safe trajectory optimization in highly constrained environments,” in IEEE International Conference on Robotics and Automation (ICRA) . IEEE, 2026. [28] W. Jung, U. A. Mishra, N. R. Arachchige, Y. Chen, D. Xu, and S. Kousik, “Joint model-based model-free diffusion for planning with constraints,” in Proceedings of The 9th Conference on Robot Learning ,ser. Proceedings of Machine Learning Research. PMLR, 2025. [29] S. M. Khansari-Zadeh and A. Billard, “Learning stable nonlinear dy-namical systems with gaussian mixture models,” IEEE Transactions on Robotics , 2011. [30] T. Eiter and H. Mannila, “Computing discrete fr´ echet distance,” Tech-nische Universitat Wien, Tech. Rep., 1994. [31] G. Van Den Bergen, Collision detection in interactive 3D environments .CRC Press, 2003. [32] P. Florence, C. Lynch, A. Zeng, O. Ramirez, A. Wahid, L. Downs, A. Wong, J. Lee, I. Mordatch, and J. Tompson, “Implicit behavioral cloning,” in Conference on Robot Learning (CoRL) , 2021. [33] A. Mandlekar, D. Xu, J. Wong, S. Nasiriany, C. Wang, R. Kulkarni, L. Fei-Fei, S. Savarese, Y. Zhu, and R. Mart´ ın-Mart´ ın, “What matters in learning from offline human demonstrations for robot manipulation,” in Proceedings of the 5th Conference on Robot Learning (CoRL) , ser. Proceedings of Machine Learning Research. PMLR, 2021.