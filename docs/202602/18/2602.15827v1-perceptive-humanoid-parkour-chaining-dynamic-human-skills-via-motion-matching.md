---
title: "Perceptive Humanoid Parkour: Chaining Dynamic Human Skills via Motion Matching"
title_zh: 感知型人形机器人跑酷：通过运动匹配链接动态人类技能
authors: "Zhen Wu, Xiaoyu Huang, Lujie Yang, Yuanhang Zhang, Koushil Sreenath, Xi Chen, Pieter Abbeel, Rocky Duan, Angjoo Kanazawa, Carmelo Sferrazza, Guanya Shi, C. Karen Liu"
date: 2026-02-17
pdf: "https://arxiv.org/pdf/2602.15827v1"
tags: ["query:课题"]
score: 6.0
evidence: 人形机器人的长时程技能组合与运动匹配
tldr: 本研究提出Perceptive Humanoid Parkour (PHP)框架，旨在提升人形机器人在复杂环境中的灵活性与适应性。通过运动匹配技术将人类原子技能组合成连贯的长程轨迹，并利用强化学习与知识蒸馏训练出具备视觉感知能力的控制策略。该方法使Unitree G1机器人能自主识别并跨越多种障碍，实现了如攀爬1.25米高台等高动态跑酷动作，显著增强了机器人的运动表现力与闭环决策能力。
motivation: 旨在解决人形机器人在复杂动态环境中缺乏类人运动灵活性、长程技能组合及感知驱动决策能力的问题。
method: 利用运动匹配技术在特征空间中组合人类技能轨迹，并通过强化学习将专家策略蒸馏为基于深度视觉的多技能学生策略。
result: 在Unitree G1机器人上成功实现了攀爬高达1.25米障碍物及长程多障碍物自主穿越，并展现出对实时环境扰动的强鲁棒性。
conclusion: 该框架证明了结合运动匹配与感知强化学习能有效提升人形机器人的动态跑酷性能，实现了高度类人且灵活的自主运动控制。
---

## 摘要
尽管人形机器人足式移动的最新进展已实现在各种地形上的稳定行走，但捕捉高动态人类运动的敏捷性和适应性仍然是一个公开挑战。特别是，复杂环境中的敏捷跑酷不仅需要底层鲁棒性，还需要类人的运动表现力、长时程技能组合以及感知驱动的决策。在本文中，我们提出了感知型人形机器人跑酷（PHP），这是一个模块化框架，使人形机器人能够在具有挑战性的障碍训练场中自主执行基于视觉的长时程跑酷。我们的方法首先利用运动匹配（公式化为特征空间中的最近邻搜索），将重定向的原子人类技能组合成长时程运动学轨迹。该框架实现了复杂技能链的灵活组合和平滑过渡，同时保留了动态人类运动的优雅和流畅。接下来，我们为这些组合运动训练运动追踪强化学习（RL）专家策略，并结合使用 DAgger 和 RL 将其蒸馏为单一的基于深度的多技能学生策略。至关重要的是，感知与技能组合的结合实现了自主的上下文感知决策：仅使用机载深度传感和离散的二维速度指令，机器人即可选择并执行是跨越、爬上、翻越还是滚下不同几何形状和高度的障碍物。我们在 Unitree G1 人形机器人上通过广泛的真实世界实验验证了我们的框架，展示了高度动态的跑酷技能，例如攀爬高达 1.25 米（机器人高度的 96%）的高大障碍物，以及对实时障碍物扰动具有闭环适应性的长时程多障碍物穿越。

## Abstract
While recent advances in humanoid locomotion have achieved stable walking on varied terrains, capturing the agility and adaptivity of highly dynamic human motions remains an open challenge. In particular, agile parkour in complex environments demands not only low-level robustness, but also human-like motion expressiveness, long-horizon skill composition, and perception-driven decision-making. In this paper, we present Perceptive Humanoid Parkour (PHP), a modular framework that enables humanoid robots to autonomously perform long-horizon, vision-based parkour across challenging obstacle courses. Our approach first leverages motion matching, formulated as nearest-neighbor search in a feature space, to compose retargeted atomic human skills into long-horizon kinematic trajectories. This framework enables the flexible composition and smooth transition of complex skill chains while preserving the elegance and fluidity of dynamic human motions. Next, we train motion-tracking reinforcement learning (RL) expert policies for these composed motions, and distill them into a single depth-based, multi-skill student policy, using a combination of DAgger and RL. Crucially, the combination of perception and skill composition enables autonomous, context-aware decision-making: using only onboard depth sensing and a discrete 2D velocity command, the robot selects and executes whether to step over, climb onto, vault or roll off obstacles of varying geometries and heights. We validate our framework with extensive real-world experiments on a Unitree G1 humanoid robot, demonstrating highly dynamic parkour skills such as climbing tall obstacles up to 1.25m (96% robot height), as well as long-horizon multi-obstacle traversal with closed-loop adaptation to real-time obstacle perturbations.