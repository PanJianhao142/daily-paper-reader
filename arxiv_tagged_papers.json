{
  "top_k": 100,
  "generated_at": "2026-01-05T09:32:37.941715+00:00",
  "queries": [
    {
      "type": "keyword",
      "alias": "符号回归（示例）",
      "tag": "符号回归（示例）",
      "query_text": "symbolic regression",
      "top_ids": [
        "2512.25023v1",
        "2512.24669v1",
        "2601.00737v1",
        "2512.24680v1",
        "2512.25042v1",
        "2512.25027v1",
        "2512.24642v1",
        "2601.00225v1",
        "2601.00368v1",
        "2601.00125v1",
        "2601.00570v1",
        "2601.00175v1",
        "2601.00728v1",
        "2601.00781v1",
        "2601.00136v1",
        "2601.00200v1",
        "2512.24564v1",
        "2601.00773v1",
        "2512.25014v1",
        "2512.24748v1",
        "2601.00237v1",
        "2512.24639v1",
        "2512.25063v1",
        "2601.00604v1",
        "2601.00388v1",
        "2601.00680v1",
        "2512.25032v1",
        "2601.00457v1",
        "2512.24847v1",
        "2601.00603v1",
        "2601.00307v1",
        "2601.00317v1",
        "2601.00147v1",
        "2512.24920v1",
        "2601.00041v1",
        "2512.24533v1",
        "2601.00189v1",
        "2601.00284v1",
        "2601.00513v1",
        "2601.00264v1",
        "2601.00422v1",
        "2601.00553v1",
        "2512.24977v1",
        "2601.00310v1",
        "2601.00578v1",
        "2601.00776v1",
        "2601.00677v1",
        "2601.00146v1",
        "2601.00329v1",
        "2512.24852v1",
        "2512.25045v1",
        "2512.24527v1",
        "2601.00141v1",
        "2601.00142v1",
        "2601.00290v1",
        "2601.00428v1",
        "2601.00743v1",
        "2512.24747v1",
        "2601.00656v1",
        "2512.24862v1",
        "2512.24611v1",
        "2601.00423v1",
        "2601.00613v1",
        "2512.24948v1",
        "2601.00171v1",
        "2601.00461v1",
        "2601.00328v1",
        "2601.00212v1",
        "2601.00757v1",
        "2512.24768v1",
        "2601.00279v1",
        "2512.24532v1",
        "2601.00309v1",
        "2601.00531v1",
        "2512.24643v1",
        "2512.24772v1",
        "2512.24588v1",
        "2601.00186v1",
        "2512.24971v1",
        "2601.00354v1",
        "2512.24888v1",
        "2512.24860v1",
        "2512.24966v1",
        "2512.24898v1",
        "2601.00176v1",
        "2601.00199v1",
        "2512.24529v1",
        "2601.00514v1",
        "2512.24696v1",
        "2601.00281v1",
        "2512.24816v1",
        "2601.00608v1",
        "2512.24587v1",
        "2512.24655v1",
        "2512.25074v1",
        "2512.24959v1",
        "2601.00478v1",
        "2601.00188v1",
        "2601.00455v1",
        "2601.00172v1"
      ]
    },
    {
      "type": "keyword",
      "alias": "大语言模型",
      "tag": "大语言模型",
      "query_text": "transformer",
      "top_ids": [
        "2512.25063v1",
        "2601.00189v1",
        "2601.00359v1",
        "2512.24782v1",
        "2601.00167v1",
        "2601.00143v1",
        "2601.00127v1",
        "2512.24657v1",
        "2601.00129v1",
        "2512.25061v1",
        "2601.00180v1",
        "2601.00197v1",
        "2512.24816v1",
        "2601.00230v1",
        "2601.00681v1",
        "2601.00670v1",
        "2601.00444v1",
        "2601.00237v1",
        "2512.24760v1",
        "2601.00354v1",
        "2512.24567v1",
        "2601.00692v1",
        "2601.00656v1",
        "2601.00066v1",
        "2601.00761v1",
        "2512.24846v2",
        "2601.00117v1",
        "2512.24559v1",
        "2512.25021v1",
        "2512.25069v1",
        "2601.00065v1",
        "2512.24641v1",
        "2512.24749v1",
        "2512.24740v1",
        "2601.00415v1",
        "2601.00492v1",
        "2512.24757v1",
        "2512.24677v1",
        "2512.25024v1",
        "2601.00742v1",
        "2512.24764v1",
        "2601.00666v1",
        "2601.00535v1",
        "2601.00161v1",
        "2512.24698v1",
        "2601.00780v1",
        "2512.24786v1",
        "2512.25038v1",
        "2512.24670v1",
        "2512.25035v1",
        "2601.00595v1",
        "2601.00096v1",
        "2601.00130v1",
        "2601.00774v1",
        "2601.00483v1",
        "2601.00398v1",
        "2601.00194v1",
        "2601.00242v1",
        "2601.00518v1",
        "2601.00302v1",
        "2601.00719v1",
        "2601.00787v1",
        "2512.24965v1",
        "2512.24743v1",
        "2601.00645v1",
        "2601.00505v1",
        "2512.24663v1",
        "2512.24983v1",
        "2512.24946v1",
        "2512.25054v1",
        "2601.00064v1",
        "2601.00384v1",
        "2512.24758v1",
        "2601.00288v1",
        "2512.24823v1",
        "2601.00295v1",
        "2601.00397v1",
        "2512.25048v1",
        "2512.24589v1",
        "2512.24937v1",
        "2601.00284v1",
        "2601.00434v1",
        "2601.00174v1",
        "2601.00417v1",
        "2601.00133v1",
        "2601.00791v1",
        "2601.00236v1",
        "2512.24770v1",
        "2512.24713v1",
        "2512.24775v1",
        "2512.24752v1",
        "2512.24804v1",
        "2601.00698v1",
        "2512.24812v1",
        "2601.00619v1",
        "2601.00582v1",
        "2601.00071v1",
        "2512.24575v1",
        "2601.00069v1",
        "2601.00726v1"
      ]
    },
    {
      "type": "llm_query",
      "alias": "sr-bench",
      "tag": "sr-bench",
      "query_text": "我希望找一些跟符号回归相关的论文，我是做benchmark的希望找一些benchmark和符号回归结合的论文",
      "top_ids": [
        "2601.00588v1",
        "2601.00535v1",
        "2601.00500v1",
        "2512.24943v1",
        "2512.24733v1",
        "2601.00573v1",
        "2601.00461v1",
        "2601.00575v1",
        "2601.00116v1",
        "2601.00167v1",
        "2512.24903v1",
        "2512.24527v1",
        "2601.00371v1",
        "2512.24591v1",
        "2601.00773v1",
        "2601.00186v1",
        "2512.24762v1",
        "2601.00143v1",
        "2601.00225v1",
        "2512.25010v1",
        "2601.00388v1",
        "2601.00436v1",
        "2512.24753v1",
        "2512.24637v2",
        "2601.00284v1",
        "2512.24800v1",
        "2512.24969v1",
        "2512.24617v1",
        "2512.24824v1",
        "2601.00761v1",
        "2601.00150v1",
        "2512.24660v1",
        "2512.24702v1",
        "2601.00423v1",
        "2601.00281v1",
        "2601.00095v1",
        "2512.24580v1",
        "2512.24743v1",
        "2601.00503v1",
        "2512.24643v1",
        "2512.24927v1",
        "2601.00082v1",
        "2601.00058v1",
        "2601.00395v1",
        "2601.00512v1",
        "2512.24991v1",
        "2601.00728v1",
        "2601.00730v1",
        "2601.00787v1",
        "2601.00209v1",
        "2512.24565v1",
        "2601.00758v1",
        "2512.24972v1",
        "2512.25042v1",
        "2601.00596v1",
        "2601.00537v1",
        "2512.24831v1",
        "2512.24545v1",
        "2512.24999v1",
        "2512.25019v1",
        "2601.00594v1",
        "2601.00656v1",
        "2512.24669v1",
        "2512.24562v1",
        "2512.24649v1",
        "2512.24807v1",
        "2601.00223v1",
        "2601.00603v1",
        "2601.00048v1",
        "2512.24581v1",
        "2512.24977v1",
        "2601.00364v1",
        "2601.00611v1",
        "2601.00403v1",
        "2512.24843v1",
        "2601.00777v1",
        "2512.24570v1",
        "2512.24533v1",
        "2512.25038v1",
        "2512.25023v1",
        "2601.00216v1",
        "2512.24713v1",
        "2601.00151v1",
        "2601.00454v1",
        "2512.24864v1",
        "2601.00717v1",
        "2512.24549v1",
        "2601.00288v1",
        "2512.25069v1",
        "2512.24772v1",
        "2512.24849v1",
        "2512.24695v1",
        "2512.24532v1",
        "2512.24615v1",
        "2601.00584v1",
        "2512.24667v1",
        "2601.00675v1",
        "2512.24551v1",
        "2601.00624v1",
        "2601.00447v1"
      ]
    },
    {
      "type": "llm_query",
      "alias": "大厂llm",
      "tag": "大厂llm",
      "query_text": "我希望找一些大厂出的大模型技术论文或者技术报告",
      "top_ids": [
        "2601.00535v1",
        "2512.24762v1",
        "2512.24946v1",
        "2512.24615v1",
        "2601.00777v1",
        "2512.24551v1",
        "2512.24724v1",
        "2601.00090v1",
        "2601.00512v1",
        "2601.00044v1",
        "2601.00167v1",
        "2601.00526v1",
        "2601.00588v1",
        "2512.24695v1",
        "2601.00504v1",
        "2601.00281v1",
        "2601.00129v1",
        "2512.24903v1",
        "2512.24617v1",
        "2512.25075v1",
        "2601.00288v1",
        "2601.00403v1",
        "2512.24757v1",
        "2601.00372v1",
        "2601.00730v1",
        "2512.25035v1",
        "2512.24969v1",
        "2512.24667v1",
        "2512.24713v1",
        "2601.00371v1",
        "2601.00610v1",
        "2601.00082v1",
        "2512.24740v1",
        "2512.25059v1",
        "2601.00373v1",
        "2601.00444v1",
        "2601.00581v1",
        "2601.00064v1",
        "2512.24562v1",
        "2512.24743v1",
        "2601.00675v1",
        "2512.24965v1",
        "2601.00237v1",
        "2512.24991v1",
        "2601.00328v1",
        "2512.24804v1",
        "2512.25073v1",
        "2512.24643v1",
        "2601.00469v1",
        "2601.00359v1",
        "2601.00423v1",
        "2512.24816v1",
        "2601.00503v1",
        "2512.25070v1",
        "2601.00059v1",
        "2601.00051v1",
        "2601.00130v1",
        "2601.00623v1",
        "2512.24963v1",
        "2512.24594v1",
        "2512.25038v1",
        "2512.24766v1",
        "2601.00145v1",
        "2512.25022v1",
        "2512.24927v1",
        "2512.25069v1",
        "2601.00454v1",
        "2512.24812v1",
        "2512.24943v1",
        "2512.25065v1",
        "2601.00197v1",
        "2512.24532v1",
        "2512.24888v1",
        "2601.00536v1",
        "2512.24824v1",
        "2601.00670v1",
        "2512.24653v1",
        "2601.00055v1",
        "2601.00143v1",
        "2512.25064v2",
        "2512.24968v1",
        "2512.24618v1",
        "2601.00787v1",
        "2512.25019v1",
        "2601.00742v1",
        "2601.00647v1",
        "2512.24868v1",
        "2512.24711v1",
        "2601.00213v1",
        "2601.00284v1",
        "2512.24972v1",
        "2601.00395v1",
        "2601.00058v1",
        "2601.00189v1",
        "2512.24775v1",
        "2601.00439v1",
        "2512.24865v1",
        "2512.24560v1",
        "2601.00245v1",
        "2601.00260v1"
      ]
    }
  ],
  "papers": [
    {
      "id": "2601.00791v1",
      "title": "Geometry of Reason: Spectral Signatures of Valid Mathematical Reasoning",
      "abstract": "We present a training-free method for detecting valid mathematical reasoning in large language models through spectral analysis of attention patterns. By treating attention matrices as adjacency matrices of dynamic graphs over tokens, we extract four interpretable spectral diagnostics, the Fiedler value (algebraic connectivity), high-frequency energy ratio (HFER), graph signal smoothness, and spectral entropy, that exhibit statistically significant differences between valid and invalid mathematical proofs. Experiments across seven transformer models from four independent architectural families (Meta Llama, Alibaba Qwen, Microsoft Phi, and Mistral AI) demonstrate that this spectral signature produces effect sizes up to Cohen's $d = 3.30$ ($p < 10^{-116}$), enabling 85.0--95.6\\% classification accuracy under rigorous evaluation, with calibrated thresholds reaching 93--95\\% on the full dataset. The method requires no training data, fine-tuning, or learned classifiers: a single threshold on a spectral metric suffices for high accuracy. Through systematic label correction, we discover that the spectral method detects logical coherence rather than compiler acceptance, identifying mathematically valid proofs that formal verifiers reject due to technical failures. We further identify an architectural dependency: Mistral-7B's Sliding Window Attention shifts the discriminative signal from HFER to late-layer Smoothness ($d = 2.09$, $p_{\\text{MW}} = 1.16 \\times 10^{-48}$), revealing that attention mechanism design affects which spectral features capture reasoning validity. These findings establish spectral graph analysis as a principled framework for reasoning verification with immediate applications to hallucination detection and AI safety monitoring.",
      "authors": [
        "Valentin Noël"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.LO"
      ],
      "published": "2026-01-02 18:49:37+00:00",
      "link": "https://arxiv.org/pdf/2601.00791v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2601.00787v1",
      "title": "Adapting Natural Language Processing Models Across Jurisdictions: A pilot Study in Canadian Cancer Registries",
      "abstract": "Population-based cancer registries depend on pathology reports as their primary diagnostic source, yet manual abstraction is resource-intensive and contributes to delays in cancer data. While transformer-based NLP systems have improved registry workflows, their ability to generalize across jurisdictions with differing reporting conventions remains poorly understood. We present the first cross-provincial evaluation of adapting BCCRTron, a domain-adapted transformer model developed at the British Columbia Cancer Registry, alongside GatorTron, a biomedical transformer model, for cancer surveillance in Canada. Our training dataset consisted of approximately 104,000 and 22,000 de-identified pathology reports from the Newfoundland & Labrador Cancer Registry (NLCR) for Tier 1 (cancer vs. non-cancer) and Tier 2 (reportable vs. non-reportable) tasks, respectively. Both models were fine-tuned using complementary synoptic and diagnosis focused report section input pipelines. Across NLCR test sets, the adapted models maintained high performance, demonstrating transformers pretrained in one jurisdiction can be localized to another with modest fine-tuning. To improve sensitivity, we combined the two models using a conservative OR-ensemble achieving a Tier 1 recall of 0.99 and reduced missed cancers to 24, compared with 48 and 54 for the standalone models. For Tier 2, the ensemble achieved 0.99 recall and reduced missed reportable cancers to 33, compared with 54 and 46 for the individual models. These findings demonstrate that an ensemble combining complementary text representations substantially reduce missed cancers and improve error coverage in cancer-registry NLP. We implement a privacy-preserving workflow in which only model weights are shared between provinces, supporting interoperable NLP infrastructure and a future pan-Canadian foundation model for cancer pathology and registry workflows.",
      "authors": [
        "Jonathan Simkin",
        "Lovedeep Gondara",
        "Zeeshan Rizvi",
        "Gregory Doyle",
        "Jeff Dowden",
        "Dan Bond",
        "Desmond Martin",
        "Raymond Ng"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-02 18:46:19+00:00",
      "link": "https://arxiv.org/pdf/2601.00787v1",
      "tags": [
        "sr-bench",
        "大厂llm",
        "大语言模型"
      ]
    },
    {
      "id": "2601.00781v1",
      "title": "Categorical Reparameterization with Denoising Diffusion models",
      "abstract": "Gradient-based optimization with categorical variables typically relies on score-function estimators, which are unbiased but noisy, or on continuous relaxations that replace the discrete distribution with a smooth surrogate admitting a pathwise (reparameterized) gradient, at the cost of optimizing a biased, temperature-dependent objective. In this paper, we extend this family of relaxations by introducing a diffusion-based soft reparameterization for categorical distributions. For these distributions, the denoiser under a Gaussian noising process admits a closed form and can be computed efficiently, yielding a training-free diffusion sampler through which we can backpropagate. Our experiments show that the proposed reparameterization trick yields competitive or improved optimization performance on various benchmarks.",
      "authors": [
        "Samson Gourevitch",
        "Alain Durmus",
        "Eric Moulines",
        "Jimmy Olsson",
        "Yazid Janati"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "published": "2026-01-02 18:30:05+00:00",
      "link": "https://arxiv.org/pdf/2601.00781v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00777v1",
      "title": "Investigating the Viability of Employing Multi-modal Large Language Models in the Context of Audio Deepfake Detection",
      "abstract": "While Vision-Language Models (VLMs) and Multimodal Large Language Models (MLLMs) have shown strong generalisation in detecting image and video deepfakes, their use for audio deepfake detection remains largely unexplored. In this work, we aim to explore the potential of MLLMs for audio deepfake detection. Combining audio inputs with a range of text prompts as queries to find out the viability of MLLMs to learn robust representations across modalities for audio deepfake detection. Therefore, we attempt to explore text-aware and context-rich, question-answer based prompts with binary decisions. We hypothesise that such a feature-guided reasoning will help in facilitating deeper multimodal understanding and enable robust feature learning for audio deepfake detection. We evaluate the performance of two MLLMs, Qwen2-Audio-7B-Instruct and SALMONN, in two evaluation modes: (a) zero-shot and (b) fine-tuned. Our experiments demonstrate that combining audio with a multi-prompt approach could be a viable way forward for audio deepfake detection. Our experiments show that the models perform poorly without task-specific training and struggle to generalise to out-of-domain data. However, they achieve good performance on in-domain data with minimal supervision, indicating promising potential for audio deepfake detection.",
      "authors": [
        "Akanksha Chuchra",
        "Shukesh Reddy",
        "Sudeepta Mishra",
        "Abhijit Das",
        "Abhinav Dhall"
      ],
      "primary_category": "cs.SD",
      "categories": [
        "cs.SD",
        "cs.CV"
      ],
      "published": "2026-01-02 18:17:22+00:00",
      "link": "https://arxiv.org/pdf/2601.00777v1",
      "tags": [
        "sr-bench",
        "大厂llm"
      ]
    },
    {
      "id": "2601.00757v1",
      "title": "Modeling Epidemic Dynamics of Mutant Strains with Evolutionary Game-based Vaccination Behavior",
      "abstract": "The outbreak of mutant strains and vaccination behaviors have been the focus of recent epidemiological research, but most existing epidemic models failed to simultaneously capture viral mutation and consider the complexity and behavioral dynamics of vaccination. To address this gap, we develop an extended SIRS model that distinguishes infections with the original strain and a mutant strain, and explicitly introduces a vaccinated compartment state. At the behavioral level, we employ evolutionary game theory to model individual vaccination decisions, where strategies are determined by both neighbors' choices and the current epidemiological situation. This process corresponds to the time-varying vaccination rate of susceptible individuals transitioning to vaccinated individuals at the epidemic spreading level. We then couple the epidemic and vaccination behavioral processes through the microscopic Markov chain approach (MMCA) and finally investigate the evolutionary dynamics via numerical simulations. The results show that our framework can effectively mitigate outbreaks across different disease scenarios. Sensitivity analysis further reveals that vaccination uptake is most strongly influenced by vaccine cost, efficacy, and perceived risk of side effects. Overall, this behavior-aware modeling framework captures the co-evolution of viral mutation and vaccination behavior, providing quantitative and theoretical support for designing effective public health vaccination policies.",
      "authors": [
        "Wenjie Zhang",
        "Yusheng Li",
        "Qin Li",
        "Guojun Huang",
        "Minyu Feng"
      ],
      "primary_category": "q-bio.PE",
      "categories": [
        "q-bio.PE",
        "cs.SI",
        "physics.soc-ph"
      ],
      "published": "2026-01-02 17:22:58+00:00",
      "link": "https://arxiv.org/pdf/2601.00757v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00743v1",
      "title": "An Agentic Framework for Neuro-Symbolic Programming",
      "abstract": "Integrating symbolic constraints into deep learning models could make them more robust, interpretable, and data-efficient. Still, it remains a time-consuming and challenging task. Existing frameworks like DomiKnowS help this integration by providing a high-level declarative programming interface, but they still assume the user is proficient with the library's specific syntax. We propose AgenticDomiKnowS (ADS) to eliminate this dependency. ADS translates free-form task descriptions into a complete DomiKnowS program using an agentic workflow that creates and tests each DomiKnowS component separately. The workflow supports optional human-in-the-loop intervention, enabling users familiar with DomiKnowS to refine intermediate outputs. We show how ADS enables experienced DomiKnowS users and non-users to rapidly construct neuro-symbolic programs, reducing development time from hours to 10-15 minutes.",
      "authors": [
        "Aliakbar Nafar",
        "Chetan Chigurupati",
        "Danial Kamali",
        "Hamid Karimian",
        "Parisa Kordjamshidi"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-02 16:59:39+00:00",
      "link": "https://arxiv.org/pdf/2601.00743v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00737v1",
      "title": "Stochastic Actor-Critic: Mitigating Overestimation via Temporal Aleatoric Uncertainty",
      "abstract": "Off-policy actor-critic methods in reinforcement learning train a critic with temporal-difference updates and use it as a learning signal for the policy (actor). This design typically achieves higher sample efficiency than purely on-policy methods. However, critic networks tend to overestimate value estimates systematically. This is often addressed by introducing a pessimistic bias based on uncertainty estimates. Current methods employ ensembling to quantify the critic's epistemic uncertainty-uncertainty due to limited data and model ambiguity-to scale pessimistic updates. In this work, we propose a new algorithm called Stochastic Actor-Critic (STAC) that incorporates temporal (one-step) aleatoric uncertainty-uncertainty arising from stochastic transitions, rewards, and policy-induced variability in Bellman targets-to scale pessimistic bias in temporal-difference updates, rather than relying on epistemic uncertainty. STAC uses a single distributional critic network to model the temporal return uncertainty, and applies dropout to both the critic and actor networks for regularization. Our results show that pessimism based on a distributional critic alone suffices to mitigate overestimation, and naturally leads to risk-averse behavior in stochastic environments. Introducing dropout further improves training stability and performance by means of regularization. With this design, STAC achieves improved computational efficiency using a single distributional critic network.",
      "authors": [
        "Uğurcan Özalp"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SY"
      ],
      "published": "2026-01-02 16:33:17+00:00",
      "link": "https://arxiv.org/pdf/2601.00737v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00730v1",
      "title": "Grading Handwritten Engineering Exams with Multimodal Large Language Models",
      "abstract": "Handwritten STEM exams capture open-ended reasoning and diagrams, but manual grading is slow and difficult to scale. We present an end-to-end workflow for grading scanned handwritten engineering quizzes with multimodal large language models (LLMs) that preserves the standard exam process (A4 paper, unconstrained student handwriting). The lecturer provides only a handwritten reference solution (100%) and a short set of grading rules; the reference is converted into a text-only summary that conditions grading without exposing the reference scan. Reliability is achieved through a multi-stage design with a format/presence check to prevent grading blank answers, an ensemble of independent graders, supervisor aggregation, and rigid templates with deterministic validation to produce auditable, machine-parseable reports. We evaluate the frozen pipeline in a clean-room protocol on a held-out real course quiz in Slovenian, including hand-drawn circuit schematics. With state-of-the-art backends (GPT-5.2 and Gemini-3 Pro), the full pipeline achieves $\\approx$8-point mean absolute difference to lecturer grades with low bias and an estimated manual-review trigger rate of $\\approx$17% at $D_{\\max}=40$. Ablations show that trivial prompting and removing the reference solution substantially degrade accuracy and introduce systematic over-grading, confirming that structured prompting and reference grounding are essential.",
      "authors": [
        "Janez Perš",
        "Jon Muhovič",
        "Andrej Košir",
        "Boštjan Murovec"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-02 16:10:08+00:00",
      "link": "https://arxiv.org/pdf/2601.00730v1",
      "tags": [
        "sr-bench",
        "大厂llm"
      ]
    },
    {
      "id": "2601.00728v1",
      "title": "Precision Autotuning for Linear Solvers via Contextual Bandit-Based RL",
      "abstract": "We propose a reinforcement learning (RL) framework for adaptive precision tuning of linear solvers, and can be extended to general algorithms. The framework is formulated as a contextual bandit problem and solved using incremental action-value estimation with a discretized state space to select optimal precision configurations for computational steps, balancing precision and computational efficiency. To verify its effectiveness, we apply the framework to iterative refinement for solving linear systems $Ax = b$. In this application, our approach dynamically chooses precisions based on calculated features from the system. In detail, a Q-table maps discretized features (e.g., approximate condition number and matrix norm)to actions (chosen precision configurations for specific steps), optimized via an epsilon-greedy strategy to maximize a multi-objective reward balancing accuracy and computational cost. Empirical results demonstrate effective precision selection, reducing computational cost while maintaining accuracy comparable to double-precision baselines. The framework generalizes to diverse out-of-sample data and offers insight into utilizing RL precision selection for other numerical algorithms, advancing mixed-precision numerical methods in scientific computing. To the best of our knowledge, this is the first work on precision autotuning with RL and verified on unseen datasets.",
      "authors": [
        "Erin Carson",
        "Xinye Chen"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "math.NA"
      ],
      "published": "2026-01-02 15:59:42+00:00",
      "link": "https://arxiv.org/pdf/2601.00728v1",
      "tags": [
        "sr-bench",
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00698v1",
      "title": "BSAT: B-Spline Adaptive Tokenizer for Long-Term Time Series Forecasting",
      "abstract": "Long-term time series forecasting using transformers is hampered by the quadratic complexity of self-attention and the rigidity of uniform patching, which may be misaligned with the data's semantic structure. In this paper, we introduce the \\textit{B-Spline Adaptive Tokenizer (BSAT)}, a novel, parameter-free method that adaptively segments a time series by fitting it with B-splines. BSAT algorithmically places tokens in high-curvature regions and represents each variable-length basis function as a fixed-size token, composed of its coefficient and position. Further, we propose a hybrid positional encoding that combines a additive learnable positional encoding with Rotary Positional Embedding featuring a layer-wise learnable base: L-RoPE. This allows each layer to attend to different temporal dependencies. Our experiments on several public benchmarks show that our model is competitive with strong performance at high compression rates. This makes it particularly well-suited for use cases with strong memory constraints.",
      "authors": [
        "Maximilian Reinwardt",
        "Michael Eichelbeck",
        "Matthias Althoff"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-02 14:27:54+00:00",
      "link": "https://arxiv.org/pdf/2601.00698v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2601.00680v1",
      "title": "Sigmoid Head for Quality Estimation under Language Ambiguity",
      "abstract": "Language model (LM) probability is not a reliable quality estimator, as natural language is ambiguous. When multiple output options are valid, the model's probability distribution is spread across them, which can misleadingly indicate low output quality. This issue is caused by two reasons: (1) LMs' final output activation is softmax, which does not allow multiple correct options to receive high probabilities simultaneuously and (2) LMs' training data is single, one-hot encoded references, indicating that there is only one correct option at each output step. We propose training a module for Quality Estimation on top of pre-trained LMs to address these limitations. The module, called Sigmoid Head, is an extra unembedding head with sigmoid activation to tackle the first limitation. To tackle the second limitation, during the negative sampling process to train the Sigmoid Head, we use a heuristic to avoid selecting potentially alternative correct tokens. Our Sigmoid Head is computationally efficient during training and inference. The probability from Sigmoid Head is notably better quality signal compared to the original softmax head. As the Sigmoid Head does not rely on human-annotated quality data, it is more robust to out-of-domain settings compared to supervised QE.",
      "authors": [
        "Tu Anh Dinh",
        "Jan Niehues"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-02 13:12:28+00:00",
      "link": "https://arxiv.org/pdf/2601.00680v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00677v1",
      "title": "IRPO: Scaling the Bradley-Terry Model via Reinforcement Learning",
      "abstract": "Generative Reward Models (GRMs) have attracted considerable research interest in reward modeling due to their interpretability, inference-time scalability, and potential for refinement through reinforcement learning (RL). However, widely used pairwise GRMs create a computational bottleneck when integrated with RL algorithms such as Group Relative Policy Optimization (GRPO). This bottleneck arises from two factors: (i) the O(n^2) time complexity of pairwise comparisons required to obtain relative scores, and (ii) the computational overhead of repeated sampling or additional chain-of-thought (CoT) reasoning to improve performance. To address the first factor, we propose Intergroup Relative Preference Optimization (IRPO), a novel RL framework that incorporates the well-established Bradley-Terry model into GRPO. By generating a pointwise score for each response, IRPO enables efficient evaluation of arbitrarily many candidates during RL training while preserving interpretability and fine-grained reward signals. Experimental results demonstrate that IRPO achieves state-of-the-art (SOTA) performance among pointwise GRMs across multiple benchmarks, with performance comparable to that of current leading pairwise GRMs. Furthermore, we show that IRPO significantly outperforms pairwise GRMs in post-training evaluations.",
      "authors": [
        "Haonan Song",
        "Qingchen Xie",
        "Huan Zhu",
        "Feng Xiao",
        "Luxi Xing",
        "Fuzhen Li",
        "Liu Kang",
        "Feng Jiang",
        "Zhiyong Zheng",
        "Fan Yang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-02 12:57:06+00:00",
      "link": "https://arxiv.org/pdf/2601.00677v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00675v1",
      "title": "RoboReward: General-Purpose Vision-Language Reward Models for Robotics",
      "abstract": "A well-designed reward is critical for effective reinforcement learning-based policy improvement. In real-world robotic domains, obtaining such rewards typically requires either labor-intensive human labeling or brittle, handcrafted objectives. Vision-language models (VLMs) have shown promise as automatic reward models, yet their effectiveness on real robot tasks is poorly understood. In this work, we aim to close this gap by introducing (1) \\textbf{RoboReward}, a robotics reward dataset and benchmark built on large-scale real-robot corpora from Open X-Embodiment (OXE) and RoboArena, and (2) vision-language reward models trained on this dataset (RoboReward 4B/8B). Because OXE is success-heavy and lacks failure examples, we propose a \\emph{negative examples data augmentation} pipeline that generates calibrated \\emph{negatives} and \\emph{near-misses} via counterfactual relabeling of successful episodes and temporal clipping to create partial-progress outcomes from the same videos. Using this framework, we produce an extensive training and evaluation dataset that spans diverse tasks and embodiments and enables systematic evaluation of whether state-of-the-art VLMs can reliably provide rewards for robotics. Our evaluation of leading open-weight and proprietary VLMs reveals that no model excels across all tasks, underscoring substantial room for improvement. We then train general-purpose 4B- and 8B-parameter models that outperform much larger VLMs in assigning rewards for short-horizon robotic tasks. Finally, we deploy the 8B-parameter reward VLM in real-robot reinforcement learning and find that it improves policy learning over Gemini Robotics-ER 1.5, a frontier physical reasoning VLM trained on robotics data, by a large margin, while substantially narrowing the gap to RL training with human-provided rewards.",
      "authors": [
        "Tony Lee",
        "Andrew Wagenmaker",
        "Karl Pertsch",
        "Percy Liang",
        "Sergey Levine",
        "Chelsea Finn"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-01-02 12:47:34+00:00",
      "link": "https://arxiv.org/pdf/2601.00675v1",
      "tags": [
        "sr-bench",
        "大厂llm"
      ]
    },
    {
      "id": "2601.00670v1",
      "title": "Wave2Word: A Multimodal Transformer Framework for Joint EEG-Text Alignment and Multi-Task Representation Learning in Neurocritical Care",
      "abstract": "Continuous electroencephalography (EEG) is routinely used in neurocritical care to monitor seizures and other harmful brain activity, including rhythmic and periodic patterns that are clinically significant. Although deep learning methods have achieved high accuracy in seizure detection, most existing approaches remain seizure-centric, rely on discrete-label supervision, and are primarily evaluated using accuracy-based metrics. A central limitation of current EEG modeling practice is the weak correspondence between learned representations and how EEG findings are interpreted and summarized in clinical workflows. Harmful EEG activity exhibits overlapping patterns, graded expert agreement, and temporal persistence, which are not well captured by classification objectives alone. This work proposes a multimodal EEG representation learning framework that integrates signal-domain modeling with structured clinical language supervision. First, raw EEG is transformed into a longitudinal bipolar montage and time-frequency representations. Second, dual transformer-based encoders model complementary temporal and frequency-centric dependencies and are fused using an adaptive gating mechanism. Third, EEG embeddings are aligned with structured expert consensus descriptions through a contrastive objective. Finally, an EEG-conditioned text reconstruction loss is introduced as a representation-level constraint alongside standard classification loss. Experimental evaluation using a controlled train-validation-test split achieves a six-class test accuracy of 0.9797. Ablation analyses show that removing contrastive alignment reduces cross-modal retrieval performance from Recall@10 of 0.3390 to 0.0045, despite minimal change in classification accuracy. These findings demonstrate that discriminative accuracy does not reliably reflect representation quality for clinically meaningful EEG modeling.",
      "authors": [
        "Argha Kamal Samanta",
        "Deepak Mewada",
        "Monalisa Sarma",
        "Debasis Samanta"
      ],
      "primary_category": "cs.HC",
      "categories": [
        "cs.HC"
      ],
      "published": "2026-01-02 12:35:12+00:00",
      "link": "https://arxiv.org/pdf/2601.00670v1",
      "tags": [
        "大厂llm",
        "大语言模型"
      ]
    },
    {
      "id": "2601.00656v1",
      "title": "Quantum Simulation of Protein Fragment Electronic Structure Using Moment-based Adaptive Variational Quantum Algorithms",
      "abstract": "Background: Understanding electronic interactions in protein active sites is fundamental to drug discovery and enzyme engineering, but remains computationally challenging due to exponential scaling of quantum mechanical calculations.   Results: We present a quantum-classical hybrid framework for simulating protein fragment electronic structure using variational quantum algorithms. We construct fermionic Hamiltonians from experimentally determined protein structures, map them to qubits via Jordan-Wigner transformation, and optimize ground state energies using the Variational Quantum Eigensolver implemented in pure Python. For a 4-orbital serine protease fragment, we achieve chemical accuracy (< 1.6 mHartree) with 95.3% correlation energy recovery. Systematic analysis reveals three-phase convergence behaviour with exponential decay (α = 0.95), power law optimization (γ = 1.21), and asymptotic approach. Application to SARS-CoV-2 protease inhibition demonstrates predictive accuracy (MAE=0.25 kcal/mol), while cytochrome P450 metabolism predictions achieve 85% site accuracy.   Conclusions: This work establishes a pathway for quantum-enhanced biomolecular simulations on near-term quantum hardware, bridging quantum algorithm development with practical biological applications.",
      "authors": [
        "Biraja Ghoshal"
      ],
      "primary_category": "q-bio.QM",
      "categories": [
        "q-bio.QM",
        "cs.ET"
      ],
      "published": "2026-01-02 11:33:09+00:00",
      "link": "https://arxiv.org/pdf/2601.00656v1",
      "tags": [
        "sr-bench",
        "大语言模型",
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00647v1",
      "title": "Physio-DPO: Aligning Large Language Models with the Protein Energy Landscape to Eliminate Structural Hallucinations",
      "abstract": "Large Protein Language Models have shown strong potential for generative protein design, yet they frequently produce structural hallucinations, generating sequences with high linguistic likelihood that fold into thermodynamically unstable conformations. Existing alignment approaches such as Direct Preference Optimization are limited in this setting, as they model preferences as binary labels and ignore the continuous structure of the physical energy landscape. We propose Physio-DPO, a physics informed alignment framework that grounds protein language models in thermodynamic stability. Physio-DPO introduces a magnitude aware objective that scales optimization updates according to the energy gap between native structures and physics perturbed hard negatives. Experiments show that Physio-DPO consistently outperforms strong baselines including SFT, PPO, and standard DPO, reducing self consistency RMSD to 1.28 Å and increasing foldability to 92.8%. Qualitative analysis further demonstrates that Physio-DPO effectively mitigates structural hallucinations by recovering biophysical interactions such as hydrophobic core packing and hydrogen bond networks.",
      "authors": [
        "QiWei Meng"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.CE",
        "q-bio.QM"
      ],
      "published": "2026-01-02 11:16:52+00:00",
      "link": "https://arxiv.org/pdf/2601.00647v1",
      "tags": [
        "大厂llm"
      ]
    },
    {
      "id": "2601.00645v1",
      "title": "Quality Detection of Stored Potatoes via Transfer Learning: A CNN and Vision Transformer Approach",
      "abstract": "Image-based deep learning provides a non-invasive, scalable solution for monitoring potato quality during storage, addressing key challenges such as sprout detection, weight loss estimation, and shelf-life prediction. In this study, images and corresponding weight data were collected over a 200-day period under controlled temperature and humidity conditions. Leveraging powerful pre-trained architectures of ResNet, VGG, DenseNet, and Vision Transformer (ViT), we designed two specialized models: (1) a high-precision binary classifier for sprout detection, and (2) an advanced multi-class predictor to estimate weight loss and forecast remaining shelf-life with remarkable accuracy. DenseNet achieved exceptional performance, with 98.03% accuracy in sprout detection. Shelf-life prediction models performed best with coarse class divisions (2-5 classes), achieving over 89.83% accuracy, while accuracy declined for finer divisions (6-8 classes) due to subtle visual differences and limited data per class. These findings demonstrate the feasibility of integrating image-based models into automated sorting and inventory systems, enabling early identification of sprouted potatoes and dynamic categorization based on storage stage. Practical implications include improved inventory management, differential pricing strategies, and reduced food waste across supply chains. While predicting exact shelf-life intervals remains challenging, focusing on broader class divisions ensures robust performance. Future research should aim to develop generalized models trained on diverse potato varieties and storage conditions to enhance adaptability and scalability. Overall, this approach offers a cost-effective, non-destructive method for quality assessment, supporting efficiency and sustainability in potato storage and distribution.",
      "authors": [
        "Shrikant Kapse",
        "Priyankkumar Dhrangdhariya",
        "Priya Kedia",
        "Manasi Patwardhan",
        "Shankar Kausley",
        "Soumyadipta Maiti",
        "Beena Rai",
        "Shirish Karande"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-02 11:10:55+00:00",
      "link": "https://arxiv.org/pdf/2601.00645v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2601.00624v1",
      "title": "Do Chatbot LLMs Talk Too Much? The YapBench Benchmark",
      "abstract": "Large Language Models (LLMs) such as ChatGPT, Claude, and Gemini increasingly act as general-purpose copilots, yet they often respond with unnecessary length on simple requests, adding redundant explanations, hedging, or boilerplate that increases cognitive load and inflates token-based inference cost. Prior work suggests that preference-based post-training and LLM-judged evaluations can induce systematic length bias, where longer answers are rewarded even at comparable quality.   We introduce YapBench, a lightweight benchmark for quantifying user-visible over-generation on brevity-ideal prompts. Each item consists of a single-turn prompt, a curated minimal-sufficient baseline answer, and a category label. Our primary metric, YapScore, measures excess response length beyond the baseline in characters, enabling comparisons across models without relying on any specific tokenizer. We summarize model performance via the YapIndex, a uniformly weighted average of category-level median YapScores.   YapBench contains over three hundred English prompts spanning three common brevity-ideal settings: (A) minimal or ambiguous inputs where the ideal behavior is a short clarification, (B) closed-form factual questions with short stable answers, and (C) one-line coding tasks where a single command or snippet suffices. Evaluating 76 assistant LLMs, we observe an order-of-magnitude spread in median excess length and distinct category-specific failure modes, including vacuum-filling on ambiguous inputs and explanation or formatting overhead on one-line technical requests. We release the benchmark and maintain a live leaderboard for tracking verbosity behavior over time.",
      "authors": [
        "Vadim Borisov",
        "Michael Gröger",
        "Mina Mikhael",
        "Richard H. Schreiber"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-02 09:43:52+00:00",
      "link": "https://arxiv.org/pdf/2601.00624v1",
      "tags": [
        "sr-bench"
      ]
    },
    {
      "id": "2601.00623v1",
      "title": "DA-DPO: Cost-efficient Difficulty-aware Preference Optimization for Reducing MLLM Hallucinations",
      "abstract": "Direct Preference Optimization (DPO) has shown strong potential for mitigating hallucinations in Multimodal Large Language Models (MLLMs). However, existing multimodal DPO approaches often suffer from overfitting due to the difficulty imbalance in preference data. Our analysis shows that MLLMs tend to overemphasize easily distinguishable preference pairs, which hinders fine-grained hallucination suppression and degrades overall performance. To address this issue, we propose Difficulty-Aware Direct Preference Optimization (DA-DPO), a cost-effective framework designed to balance the learning process. DA-DPO consists of two main components: (1) Difficulty Estimation leverages pre-trained vision--language models with complementary generative and contrastive objectives, whose outputs are integrated via a distribution-aware voting strategy to produce robust difficulty scores without additional training; and (2) Difficulty-Aware Training reweights preference pairs based on their estimated difficulty, down-weighting easy samples while emphasizing harder ones to alleviate overfitting. This framework enables more effective preference optimization by prioritizing challenging examples, without requiring new data or extra fine-tuning stages. Extensive experiments demonstrate that DA-DPO consistently improves multimodal preference optimization, yielding stronger robustness to hallucinations and better generalization across standard benchmarks, while remaining computationally efficient. The project page is available at https://artanic30.github.io/project_pages/DA-DPO/.",
      "authors": [
        "Longtian Qiu",
        "Shan Ning",
        "Chuyu Zhang",
        "Jiaxuan Sun",
        "Xuming He"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-02 09:41:54+00:00",
      "link": "https://arxiv.org/pdf/2601.00623v1",
      "tags": [
        "大厂llm"
      ]
    },
    {
      "id": "2601.00611v1",
      "title": "Stronger Approximation Guarantees for Non-Monotone γ-Weakly DR-Submodular Maximization",
      "abstract": "Maximizing submodular objectives under constraints is a fundamental problem in machine learning and optimization. We study the maximization of a nonnegative, non-monotone $γ$-weakly DR-submodular function over a down-closed convex body. Our main result is an approximation algorithm whose guarantee depends smoothly on $γ$; in particular, when $γ=1$ (the DR-submodular case) our bound recovers the $0.401$ approximation factor, while for $γ<1$ the guarantee degrades gracefully and, it improves upon previously reported bounds for $γ$-weakly DR-submodular maximization under the same constraints. Our approach combines a Frank-Wolfe-guided continuous-greedy framework with a $γ$-aware double-greedy step, yielding a simple yet effective procedure for handling non-monotonicity. This results in state-of-the-art guarantees for non-monotone $γ$-weakly DR-submodular maximization over down-closed convex bodies.",
      "authors": [
        "Hareshkumar Jadav",
        "Ranveer Singh",
        "Vaneet Aggarwal"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CC",
        "math.OC"
      ],
      "published": "2026-01-02 08:44:10+00:00",
      "link": "https://arxiv.org/pdf/2601.00611v1",
      "tags": [
        "sr-bench"
      ]
    },
    {
      "id": "2601.00610v1",
      "title": "Vision-based Goal-Reaching Control for Mobile Robots Using a Hierarchical Learning Framework",
      "abstract": "Reinforcement learning (RL) is effective in many robotic applications, but it requires extensive exploration of the state-action space, during which behaviors can be unsafe. This significantly limits its applicability to large robots with complex actuators operating on unstable terrain. Hence, to design a safe goal-reaching control framework for large-scale robots, this paper decomposes the whole system into a set of tightly coupled functional modules. 1) A real-time visual pose estimation approach is employed to provide accurate robot states to 2) an RL motion planner for goal-reaching tasks that explicitly respects robot specifications. The RL module generates real-time smooth motion commands for the actuator system, independent of its underlying dynamic complexity. 3) In the actuation mechanism, a supervised deep learning model is trained to capture the complex dynamics of the robot and provide this model to 4) a model-based robust adaptive controller that guarantees the wheels track the RL motion commands even on slip-prone terrain. 5) Finally, to reduce human intervention, a mathematical safety supervisor monitors the robot, stops it on unsafe faults, and autonomously guides it back to a safe inspection area. The proposed framework guarantees uniform exponential stability of the actuation system and safety of the whole operation. Experiments on a 6,000 kg robot in different scenarios confirm the effectiveness of the proposed framework.",
      "authors": [
        "Mehdi Heydari Shahna",
        "Pauli Mustalahti",
        "Jouni Mattila"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-01-02 08:41:47+00:00",
      "link": "https://arxiv.org/pdf/2601.00610v1",
      "tags": [
        "大厂llm"
      ]
    },
    {
      "id": "2601.00604v1",
      "title": "Cycling Race Time Prediction: A Personalized Machine Learning Approach Using Route Topology and Training Load",
      "abstract": "Predicting cycling duration for a given route is essential for training planning and event preparation. Existing solutions rely on physics-based models that require extensive parameterization, including aerodynamic drag coefficients and real-time wind forecasts, parameters impractical for most amateur cyclists. This work presents a machine learning approach that predicts ride duration using route topology features combined with the athlete's current fitness state derived from training load metrics. The model learns athlete-specific performance patterns from historical data, substituting complex physical measurements with historical performance proxies. We evaluate the approach using a single-athlete dataset (N=96 rides) in an N-of-1 study design. After rigorous feature engineering to eliminate data leakage, we find that Lasso regression with Topology + Fitness features achieves MAE=6.60 minutes and R2=0.922. Notably, integrating fitness metrics (CTL, ATL) reduces error by 14% compared to topology alone (MAE=7.66 min), demonstrating that physiological state meaningfully constrains performance even in self-paced efforts. Progressive checkpoint predictions enable dynamic race planning as route difficulty becomes apparent.",
      "authors": [
        "Francisco Aguilera Moreno"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-02 08:19:26+00:00",
      "link": "https://arxiv.org/pdf/2601.00604v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00596v1",
      "title": "Beyond IVR: Benchmarking Customer Support LLM Agents for Business-Adherence",
      "abstract": "Traditional customer support systems, such as Interactive Voice Response (IVR), rely on rigid scripts and lack the flexibility required for handling complex, policy-driven tasks. While large language model (LLM) agents offer a promising alternative, evaluating their ability to act in accordance with business rules and real-world support workflows remains an open challenge. Existing benchmarks primarily focus on tool usage or task completion, overlooking an agent's capacity to adhere to multi-step policies, navigate task dependencies, and remain robust to unpredictable user or environment behavior. In this work, we introduce JourneyBench, a benchmark designed to assess policy-aware agents in customer support. JourneyBench leverages graph representations to generate diverse, realistic support scenarios and proposes the User Journey Coverage Score, a novel metric to measure policy adherence. We evaluate multiple state-of-the-art LLMs using two agent designs: a Static-Prompt Agent (SPA) and a Dynamic-Prompt Agent (DPA) that explicitly models policy control. Across 703 conversations in three domains, we show that DPA significantly boosts policy adherence, even allowing smaller models like GPT-4o-mini to outperform more capable ones like GPT-4o. Our findings demonstrate the importance of structured orchestration and establish JourneyBench as a critical resource to advance AI-driven customer support beyond IVR-era limitations.",
      "authors": [
        "Sumanth Balaji",
        "Piyush Mishra",
        "Aashraya Sachdeva",
        "Suraj Agrawal"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-02 07:21:23+00:00",
      "link": "https://arxiv.org/pdf/2601.00596v1",
      "tags": [
        "sr-bench"
      ]
    },
    {
      "id": "2601.00588v1",
      "title": "CSSBench: Evaluating the Safety of Lightweight LLMs against Chinese-Specific Adversarial Patterns",
      "abstract": "Large language models (LLMs) are increasingly deployed in cost-sensitive and on-device scenarios, and safety guardrails have advanced mainly in English. However, real-world Chinese malicious queries typically conceal intent via homophones, pinyin, symbol-based splitting, and other Chinese-specific patterns. These Chinese-specific adversarial patterns create the safety evaluation gap that is not well captured by existing benchmarks focused on English. This gap is particularly concerning for lightweight models, which may be more vulnerable to such specific adversarial perturbations. To bridge this gap, we introduce the Chinese-Specific Safety Benchmark (CSSBench) that emphasizes these adversarial patterns and evaluates the safety of lightweight LLMs in Chinese. Our benchmark covers six domains that are common in real Chinese scenarios, including illegal activities and compliance, privacy leakage, health and medical misinformation, fraud and hate, adult content, and public and political safety, and organizes queries into multiple task types. We evaluate a set of popular lightweight LLMs and measure over-refusal behavior to assess safety-induced performance degradation. Our results show that the Chinese-specific adversarial pattern is a critical challenge for lightweight LLMs. This benchmark offers a comprehensive evaluation of LLM safety in Chinese, assisting robust deployments in practice.",
      "authors": [
        "Zhenhong Zhou",
        "Shilinlu Yan",
        "Chuanpu Liu",
        "Qiankun Li",
        "Kun Wang",
        "Zhigang Zeng"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-02 06:21:41+00:00",
      "link": "https://arxiv.org/pdf/2601.00588v1",
      "tags": [
        "sr-bench",
        "大厂llm"
      ]
    },
    {
      "id": "2601.00584v1",
      "title": "GranAlign: Granularity-Aware Alignment Framework for Zero-Shot Video Moment Retrieval",
      "abstract": "Zero-shot video moment retrieval (ZVMR) is the task of localizing a temporal moment within an untrimmed video using a natural language query without relying on task-specific training data. The primary challenge in this setting lies in the mismatch in semantic granularity between textual queries and visual content. Previous studies in ZVMR have attempted to achieve alignment by leveraging high-quality pre-trained knowledge that represents video and language in a joint space. However, these approaches failed to balance the semantic granularity between the pre-trained knowledge provided by each modality for a given scene. As a result, despite the high quality of each modality's representations, the mismatch in granularity led to inaccurate retrieval. In this paper, we propose a training-free framework, called Granularity-Aware Alignment (GranAlign), that bridges this gap between coarse and fine semantic representations. Our approach introduces two complementary techniques: granularity-based query rewriting to generate varied semantic granularities, and query-aware caption generation to embed query intent into video content. By pairing multi-level queries with both query-agnostic and query-aware captions, we effectively resolve semantic mismatches. As a result, our method sets a new state-of-the-art across all three major benchmarks (QVHighlights, Charades-STA, ActivityNet-Captions), with a notable 3.23% mAP@avg improvement on the challenging QVHighlights dataset.",
      "authors": [
        "Mingyu Jeon",
        "Sunjae Yoon",
        "Jonghee Kim",
        "Junyeoung Kim"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-02 06:04:58+00:00",
      "link": "https://arxiv.org/pdf/2601.00584v1",
      "tags": [
        "sr-bench"
      ]
    },
    {
      "id": "2601.00581v1",
      "title": "AceFF: A State-of-the-Art Machine Learning Potential for Small Molecules",
      "abstract": "We introduce AceFF, a pre-trained machine learning interatomic potential (MLIP) optimized for small molecule drug discovery. While MLIPs have emerged as efficient alternatives to Density Functional Theory (DFT), generalizability across diverse chemical spaces remains difficult. AceFF addresses this via a refined TensorNet2 architecture trained on a comprehensive dataset of drug-like compounds. This approach yields a force field that balances high-throughput inference speed with DFT-level accuracy. AceFF fully supports the essential medicinal chemistry elements (H, B, C, N, O, F, Si, P, S, Cl, Br, I) and is explicitly trained to handle charged states. Validation against rigorous benchmarks, including complex torsional energy scans, molecular dynamics trajectories, batched minimizations, and forces and anergy accuracy demonstrates that AceFF establishes a new state-of-the-art for organic molecules. The AceFF-2 model weights and inference code are available at https://huggingface.co/Acellera/AceFF-2.0.",
      "authors": [
        "Stephen E. Farr",
        "Stefan Doerr",
        "Antonio Mirarchi",
        "Francesc Sabanes Zariquiey",
        "Gianni De Fabritiis"
      ],
      "primary_category": "physics.chem-ph",
      "categories": [
        "physics.chem-ph",
        "cs.LG"
      ],
      "published": "2026-01-02 05:47:37+00:00",
      "link": "https://arxiv.org/pdf/2601.00581v1",
      "tags": [
        "大厂llm"
      ]
    },
    {
      "id": "2601.00578v1",
      "title": "Learning to be Reproducible: Custom Loss Design for Robust Neural Networks",
      "abstract": "To enhance the reproducibility and reliability of deep learning models, we address a critical gap in current training methodologies: the lack of mechanisms that ensure consistent and robust performance across runs. Our empirical analysis reveals that even under controlled initialization and training conditions, the accuracy of the model can exhibit significant variability. To address this issue, we propose a Custom Loss Function (CLF) that reduces the sensitivity of training outcomes to stochastic factors such as weight initialization and data shuffling. By fine-tuning its parameters, CLF explicitly balances predictive accuracy with training stability, leading to more consistent and reliable model performance. Extensive experiments across diverse architectures for both image classification and time series forecasting demonstrate that our approach significantly improves training robustness without sacrificing predictive performance. These results establish CLF as an effective and efficient strategy for developing more stable, reliable and trustworthy neural networks.",
      "authors": [
        "Waqas Ahmed",
        "Sheeba Samuel",
        "Kevin Coakley",
        "Birgitta Koenig-Ries",
        "Odd Erik Gundersen"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-02 05:31:08+00:00",
      "link": "https://arxiv.org/pdf/2601.00578v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00575v1",
      "title": "InfoSynth: Information-Guided Benchmark Synthesis for LLMs",
      "abstract": "Large language models (LLMs) have demonstrated significant advancements in reasoning and code generation. However, efficiently creating new benchmarks to evaluate these capabilities remains a challenge. Traditional benchmark creation relies on manual human effort, a process that is both expensive and time-consuming. Furthermore, existing benchmarks often contaminate LLM training data, necessitating novel and diverse benchmarks to accurately assess their genuine capabilities. This work introduces InfoSynth, a novel framework for automatically generating and evaluating reasoning benchmarks guided by information-theoretic principles. We propose metrics based on KL-divergence and entropy to quantify benchmark novelty and diversity without relying on costly model evaluations. Building on this framework, we develop an end-to-end pipeline that synthesizes robust Python coding problems from seed datasets using genetic algorithms and iterative code feedback. Our method generates accurate test cases and solutions to new problems 97% of the time, and the synthesized benchmarks consistently exhibit higher novelty and diversity compared to their seed datasets. Moreover, our algorithm provides a method for controlling the novelty/diversity and difficulty of generated problems. InfoSynth offers a scalable, self-verifying pipeline for constructing high-quality, novel and diverse benchmarks for LLMs. Project Page: https://ishirgarg.github.io/infosynth_web/",
      "authors": [
        "Ishir Garg",
        "Neel Kolhe",
        "Xuandong Zhao",
        "Dawn Song"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-02 05:26:27+00:00",
      "link": "https://arxiv.org/pdf/2601.00575v1",
      "tags": [
        "sr-bench"
      ]
    },
    {
      "id": "2601.00573v1",
      "title": "Benchmarking ERP Analysis: Manual Features, Deep Learning, and Foundation Models",
      "abstract": "Event-related potential (ERP), a specialized paradigm of electroencephalographic (EEG), reflects neurological responses to external stimuli or events, generally associated with the brain's processing of specific cognitive tasks. ERP plays a critical role in cognitive analysis, the detection of neurological diseases, and the assessment of psychological states. Recent years have seen substantial advances in deep learning-based methods for spontaneous EEG and other non-time-locked task-related EEG signals. However, their effectiveness on ERP data remains underexplored, and many existing ERP studies still rely heavily on manually extracted features. In this paper, we conduct a comprehensive benchmark study that systematically compares traditional manual features (followed by a linear classifier), deep learning models, and pre-trained EEG foundation models for ERP analysis. We establish a unified data preprocessing and training pipeline and evaluate these approaches on two representative tasks, ERP stimulus classification and ERP-based brain disease detection, across 12 publicly available datasets. Furthermore, we investigate various patch-embedding strategies within advanced Transformer architectures to identify embedding designs that better suit ERP data. Our study provides a landmark framework to guide method selection and tailored model design for future ERP analysis. The code is available at https://github.com/DL4mHealth/ERP-Benchmark.",
      "authors": [
        "Yihe Wang",
        "Zhiqiao Kang",
        "Bohan Chen",
        "Yu Zhang",
        "Xiang Zhang"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE",
        "cs.CE"
      ],
      "published": "2026-01-02 05:19:39+00:00",
      "link": "https://arxiv.org/pdf/2601.00573v1",
      "tags": [
        "sr-bench"
      ]
    },
    {
      "id": "2601.00570v1",
      "title": "User Perceptions of an LLM-Based Chatbot for Cognitive Reappraisal of Stress: Feasibility Study",
      "abstract": "Cognitive reappraisal is a well-studied emotion regulation strategy that helps individuals reinterpret stressful situations to reduce their impact. Many digital mental health tools struggle to support this process because rigid scripts fail to accommodate how users naturally describe stressors. This study examined the feasibility of an LLM-based single-session intervention (SSI) for workplace stress reappraisal. We assessed short-term changes in stress-related outcomes and examined design tensions during use. We conducted a feasibility study with 100 employees at a large technology company who completed a structured cognitive reappraisal session delivered by a GPT-4o-based chatbot. Pre-post measures included perceived stress intensity, stress mindset, perceived demand, and perceived resources. These outcomes were analyzed using paired Wilcoxon signed-rank tests with correction for multiple comparisons. We also examined sentiment and stress trajectories across conversation quartiles using two RoBERTa-based classifiers and an LLM-based stress rater. Open-ended responses were analyzed using thematic analysis. Results showed significant reductions in perceived stress intensity and significant improvements in stress mindset. Changes in perceived resources and perceived demand trended in expected directions but were not statistically significant. Automated analyses indicated consistent declines in negative sentiment and stress over the course of the interaction. Qualitative findings suggested that participants valued the structured prompts for organizing thoughts, gaining perspective, and feeling acknowledged. Participants also reported tensions around scriptedness, preferred interaction length, and reactions to AI-driven empathy. These findings highlight both the promise and the design constraints of integrating LLMs into DMH interventions for workplace settings.",
      "authors": [
        "Ananya Bhattacharjee",
        "Jina Suh",
        "Mohit Chandra",
        "Javier Hernandez"
      ],
      "primary_category": "cs.HC",
      "categories": [
        "cs.HC"
      ],
      "published": "2026-01-02 05:13:44+00:00",
      "link": "https://arxiv.org/pdf/2601.00570v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00553v1",
      "title": "A Comprehensive Dataset for Human vs. AI Generated Image Detection",
      "abstract": "Multimodal generative AI systems like Stable Diffusion, DALL-E, and MidJourney have fundamentally changed how synthetic images are created. These tools drive innovation but also enable the spread of misleading content, false information, and manipulated media. As generated images become harder to distinguish from photographs, detecting them has become an urgent priority. To combat this challenge, We release MS COCOAI, a novel dataset for AI generated image detection consisting of 96000 real and synthetic datapoints, built using the MS COCO dataset. To generate synthetic images, we use five generators: Stable Diffusion 3, Stable Diffusion 2.1, SDXL, DALL-E 3, and MidJourney v6. Based on the dataset, we propose two tasks: (1) classifying images as real or generated, and (2) identifying which model produced a given synthetic image. The dataset is available at https://huggingface.co/datasets/Rajarshi-Roy-research/Defactify_Image_Dataset.",
      "authors": [
        "Rajarshi Roy",
        "Nasrin Imanpour",
        "Ashhar Aziz",
        "Shashwat Bajpai",
        "Gurpreet Singh",
        "Shwetangshu Biswas",
        "Kapil Wanaskar",
        "Parth Patwa",
        "Subhankar Ghosh",
        "Shreyas Dixit",
        "Nilesh Ranjan Pal",
        "Vipula Rawte",
        "Ritvik Garimella",
        "Gaytri Jena",
        "Vasu Sharma",
        "Vinija Jain",
        "Aman Chadha",
        "Aishwarya Naresh Reganti",
        "Amitava Das"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-01-02 03:58:18+00:00",
      "link": "https://arxiv.org/pdf/2601.00553v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00537v1",
      "title": "Boosting Segment Anything Model to Generalize Visually Non-Salient Scenarios",
      "abstract": "Segment Anything Model (SAM), known for its remarkable zero-shot segmentation capabilities, has garnered significant attention in the community. Nevertheless, its performance is challenged when dealing with what we refer to as visually non-salient scenarios, where there is low contrast between the foreground and background. In these cases, existing methods often cannot capture accurate contours and fail to produce promising segmentation results. In this paper, we propose Visually Non-Salient SAM (VNS-SAM), aiming to enhance SAM's perception of visually non-salient scenarios while preserving its original zero-shot generalizability. We achieve this by effectively exploiting SAM's low-level features through two designs: Mask-Edge Token Interactive decoder and Non-Salient Feature Mining module. These designs help the SAM decoder gain a deeper understanding of non-salient characteristics with only marginal parameter increments and computational requirements. The additional parameters of VNS-SAM can be optimized within 4 hours, demonstrating its feasibility and practicality. In terms of data, we established VNS-SEG, a unified dataset for various VNS scenarios, with more than 35K images, in contrast to previous single-task adaptations. It is designed to make the model learn more robust VNS features and comprehensively benchmark the model's segmentation performance and generalizability on VNS scenarios. Extensive experiments across various VNS segmentation tasks demonstrate the superior performance of VNS-SAM, particularly under zero-shot settings, highlighting its potential for broad real-world applications. Codes and datasets are publicly available at https://guangqian-guo.github.io/VNS-SAM.",
      "authors": [
        "Guangqian Guo",
        "Pengfei Chen",
        "Yong Guo",
        "Huafeng Chen",
        "Boqiang Zhang",
        "Shan Gao"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-02 02:42:04+00:00",
      "link": "https://arxiv.org/pdf/2601.00537v1",
      "tags": [
        "sr-bench"
      ]
    },
    {
      "id": "2601.00536v1",
      "title": "Retrieval--Reasoning Processes for Multi-hop Question Answering: A Four-Axis Design Framework and Empirical Trends",
      "abstract": "Multi-hop question answering (QA) requires systems to iteratively retrieve evidence and reason across multiple hops. While recent RAG and agentic methods report strong results, the underlying retrieval--reasoning \\emph{process} is often left implicit, making procedural choices hard to compare across model families. This survey takes the execution procedure as the unit of analysis and introduces a four-axis framework covering (A) overall execution plan, (B) index structure, (C) next-step control (strategies and triggers), and (D) stop/continue criteria. Using this schema, we map representative multi-hop QA systems and synthesize reported ablations and tendencies on standard benchmarks (e.g., HotpotQA, 2WikiMultiHopQA, MuSiQue), highlighting recurring trade-offs among effectiveness, efficiency, and evidence faithfulness. We conclude with open challenges for retrieval--reasoning agents, including structure-aware planning, transferable control policies, and robust stopping under distribution shift.",
      "authors": [
        "Yuelyu Ji",
        "Zhuochun Li",
        "Rui Meng",
        "Daqing He"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-02 02:38:01+00:00",
      "link": "https://arxiv.org/pdf/2601.00536v1",
      "tags": [
        "大厂llm"
      ]
    },
    {
      "id": "2601.00535v1",
      "title": "FreeText: Training-Free Text Rendering in Diffusion Transformers via Attention Localization and Spectral Glyph Injection",
      "abstract": "Large-scale text-to-image (T2I) diffusion models excel at open-domain synthesis but still struggle with precise text rendering, especially for multi-line layouts, dense typography, and long-tailed scripts such as Chinese. Prior solutions typically require costly retraining or rigid external layout constraints, which can degrade aesthetics and limit flexibility. We propose \\textbf{FreeText}, a training-free, plug-and-play framework that improves text rendering by exploiting intrinsic mechanisms of \\emph{Diffusion Transformer (DiT)} models. \\textbf{FreeText} decomposes the problem into \\emph{where to write} and \\emph{what to write}. For \\emph{where to write}, we localize writing regions by reading token-wise spatial attribution from endogenous image-to-text attention, using sink-like tokens as stable spatial anchors and topology-aware refinement to produce high-confidence masks. For \\emph{what to write}, we introduce Spectral-Modulated Glyph Injection (SGMI), which injects a noise-aligned glyph prior with frequency-domain band-pass modulation to strengthen glyph structure and suppress semantic leakage (rendering the concept instead of the word). Extensive experiments on Qwen-Image, FLUX.1-dev, and SD3 variants across longText-Benchmark, CVTG, and our CLT-Bench show consistent gains in text readability while largely preserving semantic alignment and aesthetic quality, with modest inference overhead.",
      "authors": [
        "Ruiqiang Zhang",
        "Hengyi Wang",
        "Chang Liu",
        "Guanjie Wang",
        "Zehua Ma",
        "Weiming Zhang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-02 02:36:48+00:00",
      "link": "https://arxiv.org/pdf/2601.00535v1",
      "tags": [
        "sr-bench",
        "大厂llm",
        "大语言模型"
      ]
    },
    {
      "id": "2601.00526v1",
      "title": "Federated Customization of Large Models: Approaches, Experiments, and Insights",
      "abstract": "In this article, we explore federated customization of large models and highlight the key challenges it poses within the federated learning framework. We review several popular large model customization techniques, including full fine-tuning, efficient fine-tuning, prompt engineering, prefix-tuning, knowledge distillation, and retrieval-augmented generation. Then, we discuss how these techniques can be implemented within the federated learning framework. Moreover, we conduct experiments on federated prefix-tuning, which, to the best of our knowledge, is the first trial to apply prefix-tuning in the federated learning setting. The conducted experiments validate its feasibility with performance close to centralized approaches. Further comparison with three other federated customization methods demonstrated its competitive performance, satisfactory efficiency, and consistent robustness.",
      "authors": [
        "Yuchuan Ye",
        "Ming Ding",
        "Youjia Chen",
        "Peng Cheng",
        "Dusit Niyato"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.DC"
      ],
      "published": "2026-01-02 01:45:52+00:00",
      "link": "https://arxiv.org/pdf/2601.00526v1",
      "tags": [
        "大厂llm"
      ]
    },
    {
      "id": "2601.00514v1",
      "title": "The Illusion of Insight in Reasoning Models",
      "abstract": "Do reasoning models have \"Aha!\" moments? Prior work suggests that models like DeepSeek-R1-Zero undergo sudden mid-trace realizations that lead to accurate outputs, implying an intrinsic capacity for self-correction. Yet, it remains unclear whether such intrinsic shifts in reasoning strategy actually improve performance. Here, we study mid-reasoning shifts and instrument training runs to detect them. Our analysis spans 1M+ reasoning traces, hundreds of training checkpoints, three reasoning domains, and multiple decoding temperatures and model architectures. We find that reasoning shifts are rare, do not become more frequent with training, and seldom improve accuracy, indicating that they do not correspond to prior perceptions of model insight. However, their effect varies with model uncertainty. Building on this finding, we show that artificially triggering extrinsic shifts under high entropy reliably improves accuracy. Our results show that mid-reasoning shifts are symptoms of unstable inference behavior rather than an intrinsic mechanism for self-correction.",
      "authors": [
        "Liv G. d'Aliberti",
        "Manoel Horta Ribeiro"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-02 00:12:13+00:00",
      "link": "https://arxiv.org/pdf/2601.00514v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00513v1",
      "title": "When Small Models Are Right for Wrong Reasons: Process Verification for Trustworthy Agents",
      "abstract": "Deploying small language models (7-9B parameters) as autonomous agents requires trust in their reasoning, not just their outputs. We reveal a critical reliability crisis: 50-69\\% of correct answers from these models contain fundamentally flawed reasoning -- a ``Right-for-Wrong-Reasons'' phenomenon invisible to standard accuracy metrics. Through analysis of 10,734 reasoning traces across three models and diverse tasks, we introduce the Reasoning Integrity Score (RIS), a process-based metric validated with substantial inter-rater agreement ($κ=0.657$). Conventional practices are challenged by our findings: while retrieval-augmented generation (RAG) significantly improves reasoning integrity (Cohen's $d=0.23$--$0.93$), meta-cognitive interventions like self-critique often harm performance ($d=-0.14$ to $-0.33$) in small models on the evaluated tasks. Mechanistic analysis reveals RAG succeeds by grounding calculations in external evidence, reducing errors by 7.6\\%, while meta-cognition amplifies confusion without sufficient model capacity. To enable deployment, verification capabilities are distilled into a neural classifier achieving 0.86 F1-score with 100$\\times$ speedup. These results underscore the necessity of process-based verification for trustworthy agents: accuracy alone is dangerously insufficient when models can be right for entirely wrong reasons.",
      "authors": [
        "Laksh Advani"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-01 23:54:15+00:00",
      "link": "https://arxiv.org/pdf/2601.00513v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00505v1",
      "title": "Effect of Electric Charge on Biotherapeutic Transport, Binding and Absorption: A Computational Study",
      "abstract": "This study explores the effects of electric charge on the dynamics of drug transport and absorption in subcutaneous injections of monoclonal antibodies (mAbs). We develop a novel mathematical and computational model, based on the Nernst-Planck equations and porous media flow theory, to investigate the complex interactions between mAbs and charged species in subcutaneous tissue. The model enables us to study short-term transport dynamics and long-term binding and absorption for two mAbs with different electric properties. We examine the influence of buffer pH, body mass index, injection depth, and formulation concentration on drug distribution and compare our numerical results with experimental data from the literature.",
      "authors": [
        "Mario de Lucio",
        "Pavlos P. Vlachos",
        "Hector Gomez"
      ],
      "primary_category": "cs.CE",
      "categories": [
        "cs.CE"
      ],
      "published": "2026-01-01 23:11:29+00:00",
      "link": "https://arxiv.org/pdf/2601.00505v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2601.00504v1",
      "title": "MotionPhysics: Learnable Motion Distillation for Text-Guided Simulation",
      "abstract": "Accurately simulating existing 3D objects and a wide variety of materials often demands expert knowledge and time-consuming physical parameter tuning to achieve the desired dynamic behavior. We introduce MotionPhysics, an end-to-end differentiable framework that infers plausible physical parameters from a user-provided natural language prompt for a chosen 3D scene of interest, removing the need for guidance from ground-truth trajectories or annotated videos. Our approach first utilizes a multimodal large language model to estimate material parameter values, which are constrained to lie within plausible ranges. We further propose a learnable motion distillation loss that extracts robust motion priors from pretrained video diffusion models while minimizing appearance and geometry inductive biases to guide the simulation. We evaluate MotionPhysics across more than thirty scenarios, including real-world, human-designed, and AI-generated 3D objects, spanning a wide range of materials such as elastic solids, metals, foams, sand, and both Newtonian and non-Newtonian fluids. We demonstrate that MotionPhysics produces visually realistic dynamic simulations guided by natural language, surpassing the state of the art while automatically determining physically plausible parameters. The code and project page are available at: https://wangmiaowei.github.io/MotionPhysics.github.io/.",
      "authors": [
        "Miaowei Wang",
        "Jakub Zadrożny",
        "Oisin Mac Aodha",
        "Amir Vaxman"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "published": "2026-01-01 22:56:37+00:00",
      "link": "https://arxiv.org/pdf/2601.00504v1",
      "tags": [
        "大厂llm"
      ]
    },
    {
      "id": "2601.00503v1",
      "title": "Interpretable Machine Learning for Quantum-Informed Property Predictions in Artificial Sensing Materials",
      "abstract": "Digital sensing faces challenges in developing sustainable methods to extend the applicability of customized e-noses to complex body odor volatilome (BOV). To address this challenge, we developed MORE-ML, a computational framework that integrates quantum-mechanical (QM) property data of e-nose molecular building blocks with machine learning (ML) methods to predict sensing-relevant properties. Within this framework, we expanded our previous dataset, MORE-Q, to MORE-QX by sampling a larger conformational space of interactions between BOV molecules and mucin-derived receptors. This dataset provides extensive electronic binding features (BFs) computed upon BOV adsorption. Analysis of MORE-QX property space revealed weak correlations between QM properties of building blocks and resulting BFs. Leveraging this observation, we defined electronic descriptors of building blocks as inputs for tree-based ML models to predict BFs. Benchmarking showed CatBoost models outperform alternatives, especially in transferability to unseen compounds. Explainable AI methods further highlighted which QM properties most influence BF predictions. Collectively, MORE-ML combines QM insights with ML to provide mechanistic understanding and rational design principles for molecular receptors in BOV sensing. This approach establishes a foundation for advancing artificial sensing materials capable of analyzing complex odor mixtures, bridging the gap between molecular-level computations and practical e-nose applications.",
      "authors": [
        "Li Chen",
        "Leonardo Medrano Sandonas",
        "Shirong Huang",
        "Alexander Croy",
        "Gianaurelio Cuniberti"
      ],
      "primary_category": "physics.chem-ph",
      "categories": [
        "physics.chem-ph",
        "cs.LG"
      ],
      "published": "2026-01-01 22:56:07+00:00",
      "link": "https://arxiv.org/pdf/2601.00503v1",
      "tags": [
        "sr-bench",
        "大厂llm"
      ]
    },
    {
      "id": "2601.00469v1",
      "title": "DSL or Code? Evaluating the Quality of LLM-Generated Algebraic Specifications: A Case Study in Optimization at Kinaxis",
      "abstract": "Model-driven engineering (MDE) provides abstraction and analytical rigour, but industrial adoption in many domains has been limited by the cost of developing and maintaining models. Large language models (LLMs) can help shift this cost balance by supporting direct generation of models from natural-language (NL) descriptions. For domain-specific languages (DSLs), however, LLM-generated models may be less accurate than LLM-generated code in mainstream languages such as Python, due to the latter's dominance in LLM training corpora. We investigate this issue in mathematical optimization, with AMPL, a DSL with established industrial use. We introduce EXEOS, an LLM-based approach that derives AMPL models and Python code from NL problem descriptions and iteratively refines them with solver feedback. Using a public optimization dataset and real-world supply-chain cases from our industrial partner Kinaxis, we evaluate generated AMPL models against Python code in terms of executability and correctness. An ablation study with two LLM families shows that AMPL is competitive with, and sometimes better than, Python, and that our design choices in EXEOS improve the quality of generated specifications.",
      "authors": [
        "Negin Ayoughi",
        "David Dewar",
        "Shiva Nejati",
        "Mehrdad Sabetzadeh"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE"
      ],
      "published": "2026-01-01 20:48:15+00:00",
      "link": "https://arxiv.org/pdf/2601.00469v1",
      "tags": [
        "大厂llm"
      ]
    },
    {
      "id": "2601.00461v1",
      "title": "Laplacian Kernelized Bandit",
      "abstract": "We study multi-user contextual bandits where users are related by a graph and their reward functions exhibit both non-linear behavior and graph homophily. We introduce a principled joint penalty for the collection of user reward functions $\\{f_u\\}$, combining a graph smoothness term based on RKHS distances with an individual roughness penalty. Our central contribution is proving that this penalty is equivalent to the squared norm within a single, unified \\emph{multi-user RKHS}. We explicitly derive its reproducing kernel, which elegantly fuses the graph Laplacian with the base arm kernel. This unification allows us to reframe the problem as learning a single ''lifted'' function, enabling the design of principled algorithms, \\texttt{LK-GP-UCB} and \\texttt{LK-GP-TS}, that leverage Gaussian Process posteriors over this new kernel for exploration. We provide high-probability regret bounds that scale with an \\emph{effective dimension} of the multi-user kernel, replacing dependencies on user count or ambient dimension. Empirically, our methods outperform strong linear and non-graph-aware baselines in non-linear settings and remain competitive even when the true rewards are linear. Our work delivers a unified, theoretically grounded, and practical framework that bridges Laplacian regularization with kernelized bandits for structured exploration.",
      "authors": [
        "Shuang Wu",
        "Arash A. Amini"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "published": "2026-01-01 20:09:23+00:00",
      "link": "https://arxiv.org/pdf/2601.00461v1",
      "tags": [
        "sr-bench",
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00457v1",
      "title": "Geometric Regularization in Mixture-of-Experts: The Disconnect Between Weights and Activations",
      "abstract": "Mixture-of-Experts (MoE) models achieve efficiency through sparse activation, but the role of geometric regularization in expert specialization remains unclear. We apply orthogonality loss to enforce expert diversity and find it fails on multiple fronts: it does not reduce weight-space overlap (MSO actually increases by up to 114%), activation-space overlap remains high (~0.6) regardless of regularization, and effects on performance are inconsistent -- marginal improvement on WikiText-103 (-0.9%), slight degradation on TinyStories (+0.9%), and highly variable results on PTB (std > 1.0). Our analysis across 7 regularization strengths reveals no significant correlation (r = -0.293, p = 0.523) between weight and activation orthogonality. These findings demonstrate that weight-space regularization neither achieves its geometric goal nor reliably improves performance, making it unsuitable for MoE diversity.",
      "authors": [
        "Hyunjun Kim"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-01 19:53:01+00:00",
      "link": "https://arxiv.org/pdf/2601.00457v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00455v1",
      "title": "Deep Networks Learn Deep Hierarchical Models",
      "abstract": "We consider supervised learning with $n$ labels and show that layerwise SGD on residual networks can efficiently learn a class of hierarchical models. This model class assumes the existence of an (unknown) label hierarchy $L_1 \\subseteq L_2 \\subseteq \\dots \\subseteq L_r = [n]$, where labels in $L_1$ are simple functions of the input, while for $i > 1$, labels in $L_i$ are simple functions of simpler labels.   Our class surpasses models that were previously shown to be learnable by deep learning algorithms, in the sense that it reaches the depth limit of efficient learnability. That is, there are models in this class that require polynomial depth to express, whereas previous models can be computed by log-depth circuits.   Furthermore, we suggest that learnability of such hierarchical models might eventually form a basis for understanding deep learning. Beyond their natural fit for domains where deep learning excels, we argue that the mere existence of human ``teachers\" supports the hypothesis that hierarchical structures are inherently available. By providing granular labels, teachers effectively reveal ``hints'' or ``snippets'' of the internal algorithms used by the brain. We formalize this intuition, showing that in a simplified model where a teacher is partially aware of their internal logic, a hierarchical structure emerges that facilitates efficient learnability.",
      "authors": [
        "Amit Daniely"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-01 19:44:53+00:00",
      "link": "https://arxiv.org/pdf/2601.00455v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00454v1",
      "title": "Defensive M2S: Training Guardrail Models on Compressed Multi-turn Conversations",
      "abstract": "Guardrail models are essential for ensuring the safety of Large Language Model (LLM) deployments, but processing full multi-turn conversation histories incurs significant computational cost. We propose Defensive M2S, a training paradigm that fine-tunes guardrail models on Multi-turn to Single-turn (M2S) compressed conversations rather than complete dialogue histories. We provide a formal complexity analysis showing that M2S reduces training cost from $O(n^2)$ to $O(n)$ for $n$-turn conversations. Empirically, on our training dataset (779 samples, avg. 10.6 turns), M2S requires only 169K tokens compared to 15.7M tokens for the multi-turn baseline -- a 93$\\times$ reduction. We evaluate Defensive M2S across three guardrail model families (LlamaGuard, Nemotron, Qwen3Guard) and three compression templates (hyphenize, numberize, pythonize) on SafeDialBench, a comprehensive multi-turn jailbreak benchmark. Our best configuration, Qwen3Guard with hyphenize compression, achieves 93.8% attack detection recall while reducing inference tokens by 94.6% (from 3,231 to 173 tokens per conversation). This represents a 38.9 percentage point improvement over the baseline while dramatically reducing both training and inference costs. Our findings demonstrate that M2S compression can serve as an effective efficiency technique for guardrail deployment, enabling scalable safety screening of long multi-turn conversations.",
      "authors": [
        "Hyunjun Kim"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-01 19:42:08+00:00",
      "link": "https://arxiv.org/pdf/2601.00454v1",
      "tags": [
        "sr-bench",
        "大厂llm"
      ]
    },
    {
      "id": "2601.00447v1",
      "title": "Unifying Proportional Fairness in Centroid and Non-Centroid Clustering",
      "abstract": "Proportional fairness criteria inspired by democratic ideals of proportional representation have received growing attention in the clustering literature. Prior work has investigated them in two separate paradigms. Chen et al. [ICML 2019] study centroid clustering, in which each data point's loss is determined by its distance to a representative point (centroid) chosen in its cluster. Caragiannis et al. [NeurIPS 2024] study non-centroid clustering, in which each data point's loss is determined by its maximum distance to any other data point in its cluster.   We generalize both paradigms to introduce semi-centroid clustering, in which each data point's loss is a combination of its centroid and non-centroid losses, and study two proportional fairness criteria -- the core and, its relaxation, fully justified representation (FJR). Our main result is a novel algorithm which achieves a constant approximation to the core, in polynomial time, even when the distance metrics used for centroid and non-centroid loss measurements are different. We also derive improved results for more restricted loss functions and the weaker FJR criterion, and establish lower bounds in each case.",
      "authors": [
        "Benjamin Cookson",
        "Nisarg Shah",
        "Ziqi Yu"
      ],
      "primary_category": "cs.GT",
      "categories": [
        "cs.GT"
      ],
      "published": "2026-01-01 19:12:35+00:00",
      "link": "https://arxiv.org/pdf/2601.00447v1",
      "tags": [
        "sr-bench"
      ]
    },
    {
      "id": "2601.00444v1",
      "title": "Comparative Efficiency Analysis of Lightweight Transformer Models: A Multi-Domain Empirical Benchmark for Enterprise NLP Deployment",
      "abstract": "In the rapidly evolving landscape of enterprise natural language processing (NLP), the demand for efficient, lightweight models capable of handling multi-domain text automation tasks has intensified. This study conducts a comparative analysis of three prominent lightweight Transformer models - DistilBERT, MiniLM, and ALBERT - across three distinct domains: customer sentiment classification, news topic classification, and toxicity and hate speech detection. Utilizing datasets from IMDB, AG News, and the Measuring Hate Speech corpus, we evaluated performance using accuracy-based metrics including accuracy, precision, recall, and F1-score, as well as efficiency metrics such as model size, inference time, throughput, and memory usage. Key findings reveal that no single model dominates all performance dimensions. ALBERT achieves the highest task-specific accuracy in multiple domains, MiniLM excels in inference speed and throughput, and DistilBERT demonstrates the most consistent accuracy across tasks while maintaining competitive efficiency. All results reflect controlled fine-tuning under fixed enterprise-oriented constraints rather than exhaustive hyperparameter optimization. These results highlight trade-offs between accuracy and efficiency, recommending MiniLM for latency-sensitive enterprise applications, DistilBERT for balanced performance, and ALBERT for resource-constrained environments.",
      "authors": [
        "Muhammad Shahmeer Khan"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-01 19:05:25+00:00",
      "link": "https://arxiv.org/pdf/2601.00444v1",
      "tags": [
        "大厂llm",
        "大语言模型"
      ]
    },
    {
      "id": "2601.00428v1",
      "title": "A Comparative Analysis of Interpretable Machine Learning Methods",
      "abstract": "In recent years, Machine Learning (ML) has seen widespread adoption across a broad range of sectors, including high-stakes domains such as healthcare, finance, and law. This growing reliance has raised increasing concerns regarding model interpretability and accountability, particularly as legal and regulatory frameworks place tighter constraints on using black-box models in critical applications. Although interpretable ML has attracted substantial attention, systematic evaluations of inherently interpretable models, especially for tabular data, remain relatively scarce and often focus primarily on aggregated performance outcomes.   To address this gap, we present a large-scale comparative evaluation of 16 inherently interpretable methods, ranging from classical linear models and decision trees to more recent approaches such as Explainable Boosting Machines (EBMs), Symbolic Regression (SR), and Generalized Optimal Sparse Decision Trees (GOSDT). Our study spans 216 real-world tabular datasets and goes beyond aggregate rankings by stratifying performance according to structural dataset characteristics, including dimensionality, sample size, linearity, and class imbalance. In addition, we assess training time and robustness under controlled distributional shifts. Our results reveal clear performance hierarchies, especially for regression tasks, where EBMs consistently achieve strong predictive accuracy. At the same time, we show that performance is highly context-dependent: SR and Interpretable Generalized Additive Neural Networks (IGANNs) perform particularly well in non-linear regimes, while GOSDT models exhibit pronounced sensitivity to class imbalance. Overall, these findings provide practical guidance for practitioners seeking a balance between interpretability and predictive performance, and contribute to a deeper empirical understanding of interpretable modeling for tabular data.",
      "authors": [
        "Mattia Billa",
        "Giovanni Orlandi",
        "Veronica Guidetti",
        "Federica Mandreoli"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-01 18:39:05+00:00",
      "link": "https://arxiv.org/pdf/2601.00428v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00423v1",
      "title": "E-GRPO: High Entropy Steps Drive Effective Reinforcement Learning for Flow Models",
      "abstract": "Recent reinforcement learning has enhanced the flow matching models on human preference alignment. While stochastic sampling enables the exploration of denoising directions, existing methods which optimize over multiple denoising steps suffer from sparse and ambiguous reward signals. We observe that the high entropy steps enable more efficient and effective exploration while the low entropy steps result in undistinguished roll-outs. To this end, we propose E-GRPO, an entropy aware Group Relative Policy Optimization to increase the entropy of SDE sampling steps. Since the integration of stochastic differential equations suffer from ambiguous reward signals due to stochasticity from multiple steps, we specifically merge consecutive low entropy steps to formulate one high entropy step for SDE sampling, while applying ODE sampling on other steps. Building upon this, we introduce multi-step group normalized advantage, which computes group-relative advantages within samples sharing the same consolidated SDE denoising step. Experimental results on different reward settings have demonstrated the effectiveness of our methods.",
      "authors": [
        "Shengjun Zhang",
        "Zhang Zhang",
        "Chensheng Dai",
        "Yueqi Duan"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "published": "2026-01-01 18:27:32+00:00",
      "link": "https://arxiv.org/pdf/2601.00423v1",
      "tags": [
        "sr-bench",
        "大厂llm",
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00422v1",
      "title": "Robust Assembly Progress Estimation via Deep Metric Learning",
      "abstract": "In recent years, the advancement of AI technologies has accelerated the development of smart factories. In particular, the automatic monitoring of product assembly progress is crucial for improving operational efficiency, minimizing the cost of discarded parts, and maximizing factory productivity. However, in cases where assembly tasks are performed manually over multiple days, implementing smart factory systems remains a challenge. Previous work has proposed Anomaly Triplet-Net, which estimates assembly progress by applying deep metric learning to the visual features of products. Nevertheless, when visual changes between consecutive tasks are subtle, misclassification often occurs. To address this issue, this paper proposes a robust system for estimating assembly progress, even in cases of occlusion or minimal visual change, using a small-scale dataset. Our method leverages a Quadruplet Loss-based learning approach for anomaly images and introduces a custom data loader that strategically selects training samples to enhance estimation accuracy. We evaluated our approach using a image datasets: captured during desktop PC assembly. The proposed Anomaly Quadruplet-Net outperformed existing methods on the dataset. Specifically, it improved the estimation accuracy by 1.3% and reduced misclassification between adjacent tasks by 1.9% in the desktop PC dataset and demonstrating the effectiveness of the proposed method.",
      "authors": [
        "Kazuma Miura",
        "Sarthak Pathak",
        "Kazunori Umeda"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-01 18:26:17+00:00",
      "link": "https://arxiv.org/pdf/2601.00422v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00417v1",
      "title": "Deep Delta Learning",
      "abstract": "The efficacy of deep residual networks is fundamentally predicated on the identity shortcut connection. While this mechanism effectively mitigates the vanishing gradient problem, it imposes a strictly additive inductive bias on feature transformations, thereby limiting the network's capacity to model complex state transitions. In this paper, we introduce Deep Delta Learning (DDL), a novel architecture that generalizes the standard residual connection by modulating the identity shortcut with a learnable, data-dependent geometric transformation. This transformation, termed the Delta Operator, constitutes a rank-1 perturbation of the identity matrix, parameterized by a reflection direction vector $\\mathbf{k}(\\mathbf{X})$ and a gating scalar $β(\\mathbf{X})$. We provide a spectral analysis of this operator, demonstrating that the gate $β(\\mathbf{X})$ enables dynamic interpolation between identity mapping, orthogonal projection, and geometric reflection. Furthermore, we restructure the residual update as a synchronous rank-1 injection, where the gate acts as a dynamic step size governing both the erasure of old information and the writing of new features. This unification empowers the network to explicitly control the spectrum of its layer-wise transition operator, enabling the modeling of complex, non-monotonic dynamics while preserving the stable training characteristics of gated residual architectures.",
      "authors": [
        "Yifan Zhang",
        "Yifeng Liu",
        "Mengdi Wang",
        "Quanquan Gu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "published": "2026-01-01 18:11:38+00:00",
      "link": "https://arxiv.org/pdf/2601.00417v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2601.00398v1",
      "title": "RoLID-11K: A Dashcam Dataset for Small-Object Roadside Litter Detection",
      "abstract": "Roadside litter poses environmental, safety and economic challenges, yet current monitoring relies on labour-intensive surveys and public reporting, providing limited spatial coverage. Existing vision datasets for litter detection focus on street-level still images, aerial scenes or aquatic environments, and do not reflect the unique characteristics of dashcam footage, where litter appears extremely small, sparse and embedded in cluttered road-verge backgrounds. We introduce RoLID-11K, the first large-scale dataset for roadside litter detection from dashcams, comprising over 11k annotated images spanning diverse UK driving conditions and exhibiting pronounced long-tail and small-object distributions. We benchmark a broad spectrum of modern detectors, from accuracy-oriented transformer architectures to real-time YOLO models, and analyse their strengths and limitations on this challenging task. Our results show that while CO-DETR and related transformers achieve the best localisation accuracy, real-time models remain constrained by coarse feature hierarchies. RoLID-11K establishes a challenging benchmark for extreme small-object detection in dynamic driving scenes and aims to support the development of scalable, low-cost systems for roadside-litter monitoring. The dataset is available at https://github.com/xq141839/RoLID-11K.",
      "authors": [
        "Tao Wu",
        "Qing Xu",
        "Xiangjian He",
        "Oakleigh Weekes",
        "James Brown",
        "Wenting Duan"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-01 17:22:44+00:00",
      "link": "https://arxiv.org/pdf/2601.00398v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2601.00397v1",
      "title": "Revati: Transparent GPU-Free Time-Warp Emulation for LLM Serving",
      "abstract": "Deploying LLMs efficiently requires testing hundreds of serving configurations, but evaluating each one on a GPU cluster takes hours and costs thousands of dollars. Discrete-event simulators are faster and cheaper, but they require re-implementing the serving system's control logic -- a burden that compounds as frameworks evolve.   We present Revati, a time-warp emulator that enables performance modeling by directly executing real serving system code at simulation-like speed. The system intercepts CUDA API calls to virtualize device management, allowing serving frameworks to run without physical GPUs. Instead of executing GPU kernels, it performs time jumps -- fast-forwarding virtual time by predicted kernel durations. We propose a coordination protocol that synchronizes these jumps across distributed processes while preserving causality. On vLLM and SGLang, Revati achieves less than 5% prediction error across multiple models and parallelism configurations, while running 5-17x faster than real GPU execution.",
      "authors": [
        "Amey Agrawal",
        "Mayank Yadav",
        "Sukrit Kumar",
        "Anirudha Agrawal",
        "Garv Ghai",
        "Souradeep Bera",
        "Elton Pinto",
        "Sirish Gambhira",
        "Mohammad Adain",
        "Kasra Sohrab",
        "Chus Antonanzas",
        "Alexey Tumanov"
      ],
      "primary_category": "cs.DC",
      "categories": [
        "cs.DC",
        "cs.LG"
      ],
      "published": "2026-01-01 17:19:58+00:00",
      "link": "https://arxiv.org/pdf/2601.00397v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2601.00388v1",
      "title": "Vision-Language Reasoning for Geolocalization: A Reinforcement Learning Approach",
      "abstract": "Recent advances in vision-language models have opened up new possibilities for reasoning-driven image geolocalization. However, existing approaches often rely on synthetic reasoning annotations or external image retrieval, which can limit interpretability and generalizability. In this paper, we present Geo-R, a retrieval-free framework that uncovers structured reasoning paths from existing ground-truth coordinates and optimizes geolocation accuracy via reinforcement learning. We propose the Chain of Region, a rule-based hierarchical reasoning paradigm that generates precise, interpretable supervision by mapping GPS coordinates to geographic entities (e.g., country, province, city) without relying on model-generated or synthetic labels. Building on this, we introduce a lightweight reinforcement learning strategy with coordinate-aligned rewards based on Haversine distance, enabling the model to refine predictions through spatially meaningful feedback. Our approach bridges structured geographic reasoning with direct spatial supervision, yielding improved localization accuracy, stronger generalization, and more transparent inference. Experimental results across multiple benchmarks confirm the effectiveness of Geo-R, establishing a new retrieval-free paradigm for scalable and interpretable image geolocalization. To facilitate further research and ensure reproducibility, both the model and code will be made publicly available.",
      "authors": [
        "Biao Wu",
        "Meng Fang",
        "Ling Chen",
        "Ke Xu",
        "Tao Cheng",
        "Jun Wang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-01 16:51:41+00:00",
      "link": "https://arxiv.org/pdf/2601.00388v1",
      "tags": [
        "sr-bench",
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00384v1",
      "title": "Engineering Attack Vectors and Detecting Anomalies in Additive Manufacturing",
      "abstract": "Additive manufacturing (AM) is rapidly integrating into critical sectors such as aerospace, automotive, and healthcare. However, this cyber-physical convergence introduces new attack surfaces, especially at the interface between computer-aided design (CAD) and machine execution layers. In this work, we investigate targeted cyberattacks on two widely used fused deposition modeling (FDM) systems, Creality's flagship model K1 Max, and Ender 3. Our threat model is a multi-layered Man-in-the-Middle (MitM) intrusion, where the adversary intercepts and manipulates G-code files during upload from the user interface to the printer firmware. The MitM intrusion chain enables several stealthy sabotage scenarios. These attacks remain undetectable by conventional slicer software or runtime interfaces, resulting in structurally defective yet externally plausible printed parts. To counter these stealthy threats, we propose an unsupervised Intrusion Detection System (IDS) that analyzes structured machine logs generated during live printing. Our defense mechanism uses a frozen Transformer-based encoder (a BERT variant) to extract semantic representations of system behavior, followed by a contrastively trained projection head that learns anomaly-sensitive embeddings. Later, a clustering-based approach and a self-attention autoencoder are used for classification. Experimental results demonstrate that our approach effectively distinguishes between benign and compromised executions.",
      "authors": [
        "Md Mahbub Hasan",
        "Marcus Sternhagen",
        "Krishna Chandra Roy"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-01 16:27:52+00:00",
      "link": "https://arxiv.org/pdf/2601.00384v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2601.00372v1",
      "title": "LLM-Powered Analysis of IoT User Reviews: Tracking and Ranking Security and Privacy Concerns",
      "abstract": "Being able to understand the security and privacy (S&P) concerns of IoT users brings benefits to both developers and users. To learn about users' views, we examine Amazon IoT reviews - one of the biggest IoT markets. This work presents a state-of-the-art methodology to identify and categorize reviews in which users express S&P concerns. We developed an automated pipeline by fine-tuning GPT-3.5-Turbo to build two models: the Classifier-Rationalizer-Categorizer and the Thematic Mapper. By leveraging dynamic few-shot prompting and the model's large context size, our pipeline achieved over 97% precision and recall, significantly outperforming keyword-based and classical ML methods. We applied our pipeline to 91K Amazon reviews about fitness trackers, smart speakers and cameras, over multiple years. We found that on average 5% contained S&P concerns, while security camera exhibited the highest prevalence at 10%. Our method detected significantly more S&P-relevant reviews than prior works: 15x more for fitness trackers, 29% more for smart speakers, and 70% more for cameras. Our longitudinal analysis reveals that concerns like surveillance and data control have persisted for years, suggesting limited industry progress. We demonstrate that across all device types, users consistently demand more precise control over what data is collected and shared. We uncover challenges in multi-user and multi-device interactions, identifying two previously unreported themes concerning inadequate controls for account separation and data access. These findings, ranging from broad persistent trends to specific instances of customer loss, offer actionable insights for developers to improve user satisfaction and trust.",
      "authors": [
        "Taufiq Islam Protick",
        "Sai Teja Peddinti",
        "Nina Taft",
        "Anupam Das"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR"
      ],
      "published": "2026-01-01 15:24:21+00:00",
      "link": "https://arxiv.org/pdf/2601.00372v1",
      "tags": [
        "大厂llm"
      ]
    },
    {
      "id": "2601.00368v1",
      "title": "Mask-Conditioned Voxel Diffusion for Joint Geometry and Color Inpainting",
      "abstract": "We present a lightweight two-stage framework for joint geometry and color inpainting of damaged 3D objects, motivated by the digital restoration of cultural heritage artifacts. The pipeline separates damage localization from reconstruction. In the first stage, a 2D convolutional network predicts damage masks on RGB slices extracted from a voxelized object, and these predictions are aggregated into a volumetric mask. In the second stage, a diffusion-based 3D U-Net performs mask-conditioned inpainting directly on voxel grids, reconstructing geometry and color while preserving observed regions. The model jointly predicts occupancy and color using a composite objective that combines occupancy reconstruction with masked color reconstruction and perceptual regularization. We evaluate the approach on a curated set of textured artifacts with synthetically generated damage using standard geometric and color metrics. Compared to symmetry-based baselines, our method produces more complete geometry and more coherent color reconstructions at a fixed 32^3 resolution. Overall, the results indicate that explicit mask conditioning is a practical way to guide volumetric diffusion models for joint 3D geometry and color inpainting.",
      "authors": [
        "Aarya Sumuk"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-01 15:11:55+00:00",
      "link": "https://arxiv.org/pdf/2601.00368v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00364v1",
      "title": "The Role of Mixed-Language Documents for Multilingual Large Language Model Pretraining",
      "abstract": "Multilingual large language models achieve impressive cross-lingual performance despite largely monolingual pretraining. While bilingual data in pretraining corpora is widely believed to enable these abilities, details of its contributions remain unclear. We investigate this question by pretraining models from scratch under controlled conditions, comparing the standard web corpus with a monolingual-only version that removes all multilingual documents. Despite constituting only 2% of the corpus, removing bilingual data causes translation performance to drop 56% in BLEU, while behaviour on cross-lingual QA and general reasoning tasks remains stable, with training curves largely overlapping the baseline. To understand this asymmetry, we categorize bilingual data into parallel (14%), code-switching (72%), and miscellaneous documents (14%) based on the semantic relevance of content in different languages. We then conduct granular ablations by reintroducing parallel or code-switching data into the monolingual-only corpus. Our experiments reveal that parallel data almost fully restores translation performance (91% of the unfiltered baseline), whereas code-switching contributes minimally. Other cross-lingual tasks remain largely unaffected by either type. These findings reveal that translation critically depends on systematic token-level alignments from parallel data, whereas cross-lingual understanding and reasoning appear to be achievable even without bilingual data.",
      "authors": [
        "Jiandong Shao",
        "Raphael Tang",
        "Crystina Zhang",
        "Karin Sevegnani",
        "Pontus Stenetorp",
        "Jianfei Yang",
        "Yao Lu"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-01 14:52:06+00:00",
      "link": "https://arxiv.org/pdf/2601.00364v1",
      "tags": [
        "sr-bench"
      ]
    },
    {
      "id": "2601.00359v1",
      "title": "Efficient Prediction of Dense Visual Embeddings via Distillation and RGB-D Transformers",
      "abstract": "In domestic environments, robots require a comprehensive understanding of their surroundings to interact effectively and intuitively with untrained humans. In this paper, we propose DVEFormer - an efficient RGB-D Transformer-based approach that predicts dense text-aligned visual embeddings (DVE) via knowledge distillation. Instead of directly performing classical semantic segmentation with fixed predefined classes, our method uses teacher embeddings from Alpha-CLIP to guide our efficient student model DVEFormer in learning fine-grained pixel-wise embeddings. While this approach still enables classical semantic segmentation, e.g., via linear probing, it further enables flexible text-based querying and other applications, such as creating comprehensive 3D maps. Evaluations on common indoor datasets demonstrate that our approach achieves competitive performance while meeting real-time requirements, operating at 26.3 FPS for the full model and 77.0 FPS for a smaller variant on an NVIDIA Jetson AGX Orin. Additionally, we show qualitative results that highlight the effectiveness and possible use cases in real-world applications. Overall, our method serves as a drop-in replacement for traditional segmentation approaches while enabling flexible natural-language querying and seamless integration into 3D mapping pipelines for mobile robotics.",
      "authors": [
        "Söhnke Benedikt Fischedick",
        "Daniel Seichter",
        "Benedict Stephan",
        "Robin Schmidt",
        "Horst-Michael Gross"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.RO"
      ],
      "published": "2026-01-01 14:29:31+00:00",
      "link": "https://arxiv.org/pdf/2601.00359v1",
      "tags": [
        "大厂llm",
        "大语言模型"
      ]
    },
    {
      "id": "2601.00329v1",
      "title": "Sparse Probabilistic Coalition Structure Generation: Bayesian Greedy Pursuit and $\\ell_1$ Relaxations",
      "abstract": "We study coalition structure generation (CSG) when coalition values are not given but must be learned from episodic observations. We model each episode as a sparse linear regression problem, where the realised payoff \\(Y_t\\) is a noisy linear combination of a small number of coalition contributions. This yields a probabilistic CSG framework in which the planner first estimates a sparse value function from \\(T\\) episodes, then runs a CSG solver on the inferred coalition set. We analyse two estimation schemes. The first, Bayesian Greedy Coalition Pursuit (BGCP), is a greedy procedure that mimics orthogonal matching pursuit. Under a coherence condition and a minimum signal assumption, BGCP recovers the true set of profitable coalitions with high probability once \\(T \\gtrsim K \\log m\\), and hence yields welfare-optimal structures. The second scheme uses an \\(\\ell_1\\)-penalised estimator; under a restricted eigenvalue condition, we derive \\(\\ell_1\\) and prediction error bounds and translate them into welfare gap guarantees. We compare both methods to probabilistic baselines and identify regimes where sparse probabilistic CSG is superior, as well as dense regimes where classical least-squares approaches are competitive.",
      "authors": [
        "Angshul Majumdar"
      ],
      "primary_category": "cs.GT",
      "categories": [
        "cs.GT",
        "cs.AI"
      ],
      "published": "2026-01-01 12:50:56+00:00",
      "link": "https://arxiv.org/pdf/2601.00329v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00328v1",
      "title": "Joint Geometry-Appearance Human Reconstruction in a Unified Latent Space via Bridge Diffusion",
      "abstract": "Achieving consistent and high-fidelity geometry and appearance reconstruction of 3D digital humans from a single RGB image is inherently a challenging task. Existing studies typically resort to decoupled pipelines for geometry estimation and appearance synthesis, often hindering unified reconstruction and causing inconsistencies. This paper introduces \\textbf{JGA-LBD}, a novel framework that unifies the modeling of geometry and appearance into a joint latent representation and formulates the generation process as bridge diffusion. Observing that directly integrating heterogeneous input conditions (e.g., depth maps, SMPL models) leads to substantial training difficulties, we unify all conditions into the 3D Gaussian representations, which can be further compressed into a unified latent space through a shared sparse variational autoencoder (VAE). Subsequently, the specialized form of bridge diffusion enables to start with a partial observation of the target latent code and solely focuses on inferring the missing components. Finally, a dedicated decoding module extracts the complete 3D human geometric structure and renders novel views from the inferred latent representation. Experiments demonstrate that JGA-LBD outperforms current state-of-the-art approaches in terms of both geometry fidelity and appearance quality, including challenging in-the-wild scenarios. Our code will be made publicly available at https://github.com/haiantyz/JGA-LBD.",
      "authors": [
        "Yingzhi Tang",
        "Qijian Zhang",
        "Junhui Hou"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-01 12:48:56+00:00",
      "link": "https://arxiv.org/pdf/2601.00328v1",
      "tags": [
        "大厂llm",
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00317v1",
      "title": "On the Error Floor Evaluation of NOMA-Irregular Repetition Slotted ALOHA",
      "abstract": "In this work, we provide a simple yet tight analytical approximation of the packet loss rate in the error floor region for a non-orthogonal multiple access (NOMA)-based irregular repetition slotted ALOHA (IRSA) scheme. Considering an Internet of Things (IoT) scenario, users randomly select both the number of replicas based on a designed degree distribution and the transmission power from predetermined levels, while successive interference cancellation (SIC) is performed at the receiver. Our derived packet loss rate expression in the finite length regime is promptly evaluated. Its accuracy is validated through Monte-Carlo simulations, demonstrating a strong match across channel loads, including those beyond the low load regime",
      "authors": [
        "Estefanía Recayte"
      ],
      "primary_category": "cs.ET",
      "categories": [
        "cs.ET",
        "cs.NI"
      ],
      "published": "2026-01-01 11:59:30+00:00",
      "link": "https://arxiv.org/pdf/2601.00317v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00309v1",
      "title": "Can Optimal Transport Improve Federated Inverse Reinforcement Learning?",
      "abstract": "In robotics and multi-agent systems, fleets of autonomous agents often operate in subtly different environments while pursuing a common high-level objective. Directly pooling their data to learn a shared reward function is typically impractical due to differences in dynamics, privacy constraints, and limited communication bandwidth. This paper introduces an optimal transport-based approach to federated inverse reinforcement learning (IRL). Each client first performs lightweight Maximum Entropy IRL locally, adhering to its computational and privacy limitations. The resulting reward functions are then fused via a Wasserstein barycenter, which considers their underlying geometric structure. We further prove that this barycentric fusion yields a more faithful global reward estimate than conventional parameter averaging methods in federated learning. Overall, this work provides a principled and communication-efficient framework for deriving a shared reward that generalizes across heterogeneous agents and environments.",
      "authors": [
        "David Millard",
        "Ali Baheri"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "eess.SY"
      ],
      "published": "2026-01-01 11:13:34+00:00",
      "link": "https://arxiv.org/pdf/2601.00309v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00307v1",
      "title": "VisNet: Efficient Person Re-Identification via Alpha-Divergence Loss, Feature Fusion and Dynamic Multi-Task Learning",
      "abstract": "Person re-identification (ReID) is an extremely important area in both surveillance and mobile applications, requiring strong accuracy with minimal computational cost. State-of-the-art methods give good accuracy but with high computational budgets. To remedy this, this paper proposes VisNet, a computationally efficient and effective re-identification model suitable for real-world scenarios. It is the culmination of conceptual contributions, including feature fusion at multiple scales with automatic attention on each, semantic clustering with anatomical body partitioning, a dynamic weight averaging technique to balance classification semantic regularization, and the use of loss function FIDI for improved metric learning tasks. The multiple scales fuse ResNet50's stages 1 through 4 without the use of parallel paths, with semantic clustering introducing spatial constraints through the use of rule-based pseudo-labeling. VisNet achieves 87.05% Rank-1 and 77.65% mAP on the Market-1501 dataset, having 32.41M parameters and 4.601 GFLOPs, hence, proposing a practical approach for real-time deployment in surveillance and mobile applications where computational resources are limited.",
      "authors": [
        "Anns Ijaz",
        "Muhammad Azeem Javed"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-01-01 11:06:11+00:00",
      "link": "https://arxiv.org/pdf/2601.00307v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00290v1",
      "title": "ClinicalReTrial: A Self-Evolving AI Agent for Clinical Trial Protocol Optimization",
      "abstract": "Clinical trial failure remains a central bottleneck in drug development, where minor protocol design flaws can irreversibly compromise outcomes despite promising therapeutics. Although cutting-edge AI methods achieve strong performance in predicting trial success, they are inherently reactive for merely diagnosing risk without offering actionable remedies once failure is anticipated. To fill this gap, this paper proposes ClinicalReTrial, a self-evolving AI agent framework that addresses this gap by casting clinical trial reasoning as an iterative protocol redesign problem. Our method integrates failure diagnosis, safety-aware modification, and candidate evaluation in a closed-loop, reward-driven optimization framework. Serving the outcome prediction model as a simulation environment, ClinicalReTrial enables low-cost evaluation of protocol modifications and provides dense reward signals for continuous self-improvement. To support efficient exploration, the framework maintains hierarchical memory that captures iteration-level feedback within trials and distills transferable redesign patterns across trials. Empirically, ClinicalReTrial improves 83.3% of trial protocols with a mean success probability gain of 5.7%, and retrospective case studies demonstrate strong alignment between the discovered redesign strategies and real-world clinical trial modifications.",
      "authors": [
        "Sixue Xing",
        "Xuanye Xia",
        "Kerui Wu",
        "Meng Jiang",
        "Jintai Chen",
        "Tianfan Fu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "published": "2026-01-01 10:11:58+00:00",
      "link": "https://arxiv.org/pdf/2601.00290v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00264v1",
      "title": "S1-MMAlign: A Large-Scale, Multi-Disciplinary Dataset for Scientific Figure-Text Understanding",
      "abstract": "Multimodal learning has revolutionized general domain tasks, yet its application in scientific discovery is hindered by the profound semantic gap between complex scientific imagery and sparse textual descriptions. We present S1-MMAlign, a large-scale, multi-disciplinary multimodal dataset comprising over 15.5 million high-quality image-text pairs derived from 2.5 million open-access scientific papers. Spanning disciplines from physics and biology to engineering, the dataset captures diverse visual modalities including experimental setups, heatmaps, and microscopic imagery. To address the pervasive issue of weak alignment in raw scientific captions, we introduce an AI-ready semantic enhancement pipeline that utilizes the Qwen-VL multimodal large model series to recaption images by synthesizing context from paper abstracts and citation contexts. Technical validation demonstrates that this enhancement significantly improves data quality: SciBERT-based pseudo-perplexity metrics show reduced semantic ambiguity, while CLIP scores indicate an 18.21% improvement in image-text alignment. S1-MMAlign provides a foundational resource for advancing scientific reasoning and cross-modal understanding in the era of AI for Science. The dataset is publicly available at https://huggingface.co/datasets/ScienceOne-AI/S1-MMAlign.",
      "authors": [
        "He Wang",
        "Longteng Guo",
        "Pengkang Huo",
        "Xuanxu Lin",
        "Yichen Yuan",
        "Jie Jiang",
        "Jing Liu"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-01 08:54:51+00:00",
      "link": "https://arxiv.org/pdf/2601.00264v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00260v1",
      "title": "TotalFM: An Organ-Separated Framework for 3D-CT Vision Foundation Models",
      "abstract": "While foundation models in radiology are expected to be applied to various clinical tasks, computational cost constraints remain a major challenge when training on 3D-CT volumetric data. In this study, we propose TotalFM, a radiological foundation model that efficiently learns the correspondence between 3D-CT images and linguistic expressions based on the concept of organ separation, utilizing a large-scale dataset of 140,000 series. By automating the creation of organ volume and finding-sentence pairs through segmentation techniques and Large Language Model (LLM)-based radiology report processing, and by combining self-supervised pre-training via VideoMAE with contrastive learning using volume-text pairs, we aimed to balance computational efficiency and representation capability. In zero-shot organ-wise lesion classification tasks, the proposed model achieved higher F1 scores in 83% (5/6) of organs compared to CT-CLIP and 64% (9/14) of organs compared to Merlin. These results suggest that the proposed model exhibits high generalization performance in a clinical evaluation setting using actual radiology report sentences. Furthermore, in zero-shot finding-wise lesion classification tasks, our model achieved a higher AUROC in 83% (25/30) of finding categories compared to Merlin. We also confirmed performance comparable to existing Vision-Language Models (VLMs) in radiology report generation tasks. Our results demonstrate that the organ-separated learning framework can serve as a realistic and effective design guideline for the practical implementation of 3D-CT foundation models.",
      "authors": [
        "Kohei Yamamoto",
        "Tomohiro Kikuchi"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-01 08:27:01+00:00",
      "link": "https://arxiv.org/pdf/2601.00260v1",
      "tags": [
        "大厂llm"
      ]
    },
    {
      "id": "2601.00245v1",
      "title": "Modern Neuromorphic AI: From Intra-Token to Inter-Token Processing",
      "abstract": "The rapid growth of artificial intelligence (AI) has brought novel data processing and generative capabilities but also escalating energy requirements. This challenge motivates renewed interest in neuromorphic computing principles, which promise brain-like efficiency through discrete and sparse activations, recurrent dynamics, and non-linear feedback. In fact, modern AI architectures increasingly embody neuromorphic principles through heavily quantized activations, state-space dynamics, and sparse attention mechanisms. This paper elaborates on the connections between neuromorphic models, state-space models, and transformer architectures through the lens of the distinction between intra-token processing and inter-token processing. Most early work on neuromorphic AI was based on spiking neural networks (SNNs) for intra-token processing, i.e., for transformations involving multiple channels, or features, of the same vector input, such as the pixels of an image. In contrast, more recent research has explored how neuromorphic principles can be leveraged to design efficient inter-token processing methods, which selectively combine different information elements depending on their contextual relevance. Implementing associative memorization mechanisms, these approaches leverage state-space dynamics or sparse self-attention. Along with a systematic presentation of modern neuromorphic AI models through the lens of intra-token and inter-token processing, training methodologies for neuromorphic AI models are also reviewed. These range from surrogate gradients leveraging parallel convolutional processing to local learning rules based on reinforcement learning mechanisms.",
      "authors": [
        "Osvaldo Simeone"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE",
        "cs.IT",
        "cs.LG"
      ],
      "published": "2026-01-01 07:38:07+00:00",
      "link": "https://arxiv.org/pdf/2601.00245v1",
      "tags": [
        "大厂llm"
      ]
    },
    {
      "id": "2601.00242v1",
      "title": "Neural Minimum Weight Perfect Matching for Quantum Error Codes",
      "abstract": "Realizing the full potential of quantum computation requires Quantum Error Correction (QEC). QEC reduces error rates by encoding logical information across redundant physical qubits, enabling errors to be detected and corrected. A common decoder used for this task is Minimum Weight Perfect Matching (MWPM) a graph-based algorithm that relies on edge weights to identify the most likely error chains. In this work, we propose a data-driven decoder named Neural Minimum Weight Perfect Matching (NMWPM). Our decoder utilizes a hybrid architecture that integrates Graph Neural Networks (GNNs) to extract local syndrome features and Transformers to capture long-range global dependencies, which are then used to predict dynamic edge weights for the MWPM decoder. To facilitate training through the non-differentiable MWPM algorithm, we formulate a novel proxy loss function that enables end-to-end optimization. Our findings demonstrate significant performance reduction in the Logical Error Rate (LER) over standard baselines, highlighting the advantage of hybrid decoders that combine the predictive capabilities of neural networks with the algorithmic structure of classical matching.",
      "authors": [
        "Yotam Peled",
        "David Zenati",
        "Eliya Nachmani"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.IT",
        "cs.LG"
      ],
      "published": "2026-01-01 07:25:51+00:00",
      "link": "https://arxiv.org/pdf/2601.00242v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2601.00237v1",
      "title": "Application Research of a Deep Learning Model Integrating CycleGAN and YOLO in PCB Infrared Defect Detection",
      "abstract": "This paper addresses the critical bottleneck of infrared (IR) data scarcity in Printed Circuit Board (PCB) defect detection by proposing a cross-modal data augmentation framework integrating CycleGAN and YOLOv8. Unlike conventional methods relying on paired supervision, we leverage CycleGAN to perform unpaired image-to-image translation, mapping abundant visible-light PCB images into the infrared domain. This generative process synthesizes high-fidelity pseudo-IR samples that preserve the structural semantics of defects while accurately simulating thermal distribution patterns. Subsequently, we construct a heterogeneous training strategy that fuses generated pseudo-IR data with limited real IR samples to train a lightweight YOLOv8 detector. Experimental results demonstrate that this method effectively enhances feature learning under low-data conditions. The augmented detector significantly outperforms models trained on limited real data alone and approaches the performance benchmarks of fully supervised training, proving the efficacy of pseudo-IR synthesis as a robust augmentation strategy for industrial inspection.",
      "authors": [
        "Chao Yang",
        "Haoyuan Zheng",
        "Yue Ma"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.LG",
        "cs.RO"
      ],
      "published": "2026-01-01 07:01:47+00:00",
      "link": "https://arxiv.org/pdf/2601.00237v1",
      "tags": [
        "大厂llm",
        "大语言模型",
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00225v1",
      "title": "Towards Syn-to-Real IQA: A Novel Perspective on Reshaping Synthetic Data Distributions",
      "abstract": "Blind Image Quality Assessment (BIQA) has advanced significantly through deep learning, but the scarcity of large-scale labeled datasets remains a challenge. While synthetic data offers a promising solution, models trained on existing synthetic datasets often show limited generalization ability. In this work, we make a key observation that representations learned from synthetic datasets often exhibit a discrete and clustered pattern that hinders regression performance: features of high-quality images cluster around reference images, while those of low-quality images cluster based on distortion types. Our analysis reveals that this issue stems from the distribution of synthetic data rather than model architecture. Consequently, we introduce a novel framework SynDR-IQA, which reshapes synthetic data distribution to enhance BIQA generalization. Based on theoretical derivations of sample diversity and redundancy's impact on generalization error, SynDR-IQA employs two strategies: distribution-aware diverse content upsampling, which enhances visual diversity while preserving content distribution, and density-aware redundant cluster downsampling, which balances samples by reducing the density of densely clustered areas. Extensive experiments across three cross-dataset settings (synthetic-to-authentic, synthetic-to-algorithmic, and synthetic-to-synthetic) demonstrate the effectiveness of our method. The code is available at https://github.com/Li-aobo/SynDR-IQA.",
      "authors": [
        "Aobo Li",
        "Jinjian Wu",
        "Yongxu Liu",
        "Leida Li",
        "Weisheng Dong"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-01 06:11:16+00:00",
      "link": "https://arxiv.org/pdf/2601.00225v1",
      "tags": [
        "sr-bench",
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00223v1",
      "title": "JP-TL-Bench: Anchored Pairwise LLM Evaluation for Bidirectional Japanese-English Translation",
      "abstract": "We introduce JP-TL-Bench, a lightweight, open benchmark designed to guide the iterative development of Japanese-English translation systems. In this context, the challenge is often \"which of these two good translations is better?\" rather than \"is this translation acceptable?\" This distinction matters for Japanese-English, where subtle choices in politeness, implicature, ellipsis, and register strongly affect perceived naturalness. JP-TL-Bench uses a protocol built to make LLM judging both reliable and affordable: it evaluates a candidate model via reference-free, pairwise LLM comparisons against a fixed, versioned anchor set. Pairwise results are aggregated with a Bradley-Terry model and reported as win rates plus a normalized 0-10 \"LT\" score derived from a logistic transform of fitted log-strengths. Because each candidate is scored against the same frozen anchor set, scores are structurally stable given the same base set, judge, and aggregation code.",
      "authors": [
        "Leonard Lin",
        "Adam Lensenmayer"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-01 06:09:45+00:00",
      "link": "https://arxiv.org/pdf/2601.00223v1",
      "tags": [
        "sr-bench"
      ]
    },
    {
      "id": "2601.00216v1",
      "title": "From Evidence-Based Medicine to Knowledge Graph: Retrieval-Augmented Generation for Sports Rehabilitation and a Domain Benchmark",
      "abstract": "In medicine, large language models (LLMs) increasingly rely on retrieval-augmented generation (RAG) to ground outputs in up-to-date external evidence. However, current RAG approaches focus primarily on performance improvements while overlooking evidence-based medicine (EBM) principles. This study addresses two key gaps: (1) the lack of PICO alignment between queries and retrieved evidence, and (2) the absence of evidence hierarchy considerations during reranking. We present a generalizable strategy for adapting EBM to graph-based RAG, integrating the PICO framework into knowledge graph construction and retrieval, and proposing a Bayesian-inspired reranking algorithm to calibrate ranking scores by evidence grade without introducing predefined weights. We validated this framework in sports rehabilitation, a literature-rich domain currently lacking RAG systems and benchmarks. We released a knowledge graph (357,844 nodes and 371,226 edges) and a reusable benchmark of 1,637 QA pairs. The system achieved 0.830 nugget coverage, 0.819 answer faithfulness, 0.882 semantic similarity, and 0.788 PICOT match accuracy. In a 5-point Likert evaluation, five expert clinicians rated the system 4.66-4.84 across factual accuracy, faithfulness, relevance, safety, and PICO alignment. These findings demonstrate that the proposed EBM adaptation strategy improves retrieval and answer quality and is transferable to other clinical domains. The released resources also help address the scarcity of RAG datasets in sports rehabilitation.",
      "authors": [
        "Jinning Zhang",
        "Jie Song",
        "Wenhui Tu",
        "Zecheng Li",
        "Jingxuan Li",
        "Jin Li",
        "Xuan Liu",
        "Taole Sha",
        "Zichen Wei",
        "Yan Li"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-01 05:20:54+00:00",
      "link": "https://arxiv.org/pdf/2601.00216v1",
      "tags": [
        "sr-bench"
      ]
    },
    {
      "id": "2601.00213v1",
      "title": "Overlooked Safety Vulnerability in LLMs: Malicious Intelligent Optimization Algorithm Request and its Jailbreak",
      "abstract": "The widespread deployment of large language models (LLMs) has raised growing concerns about their misuse risks and associated safety issues. While prior studies have examined the safety of LLMs in general usage, code generation, and agent-based applications, their vulnerabilities in automated algorithm design remain underexplored. To fill this gap, this study investigates this overlooked safety vulnerability, with a particular focus on intelligent optimization algorithm design, given its prevalent use in complex decision-making scenarios. We introduce MalOptBench, a benchmark consisting of 60 malicious optimization algorithm requests, and propose MOBjailbreak, a jailbreak method tailored for this scenario. Through extensive evaluation of 13 mainstream LLMs including the latest GPT-5 and DeepSeek-V3.1, we reveal that most models remain highly susceptible to such attacks, with an average attack success rate of 83.59% and an average harmfulness score of 4.28 out of 5 on original harmful prompts, and near-complete failure under MOBjailbreak. Furthermore, we assess state-of-the-art plug-and-play defenses that can be applied to closed-source models, and find that they are only marginally effective against MOBjailbreak and prone to exaggerated safety behaviors. These findings highlight the urgent need for stronger alignment techniques to safeguard LLMs against misuse in algorithm design.",
      "authors": [
        "Haoran Gu",
        "Handing Wang",
        "Yi Mei",
        "Mengjie Zhang",
        "Yaochu Jin"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR",
        "cs.CL"
      ],
      "published": "2026-01-01 05:14:32+00:00",
      "link": "https://arxiv.org/pdf/2601.00213v1",
      "tags": [
        "大厂llm"
      ]
    },
    {
      "id": "2601.00212v1",
      "title": "IntraStyler: Exemplar-based Style Synthesis for Cross-modality Domain Adaptation",
      "abstract": "Image-level domain alignment is the de facto approach for unsupervised domain adaptation, where unpaired image translation is used to minimize the domain gap. Prior studies mainly focus on the domain shift between the source and target domains, whereas the intra-domain variability remains under-explored. To address the latter, an effective strategy is to diversify the styles of the synthetic target domain data during image translation. However, previous methods typically require intra-domain variations to be pre-specified for style synthesis, which may be impractical. In this paper, we propose an exemplar-based style synthesis method named IntraStyler, which can capture diverse intra-domain styles without any prior knowledge. Specifically, IntraStyler uses an exemplar image to guide the style synthesis such that the output style matches the exemplar style. To extract the style-only features, we introduce a style encoder to learn styles discriminatively based on contrastive learning. We evaluate the proposed method on the largest public dataset for cross-modality domain adaptation, CrossMoDA 2023. Our experiments show the efficacy of our method in controllable style synthesis and the benefits of diverse synthetic data for downstream segmentation. Code is available at https://github.com/han-liu/IntraStyler.",
      "authors": [
        "Han Liu",
        "Yubo Fan",
        "Hao Li",
        "Dewei Hu",
        "Daniel Moyer",
        "Zhoubing Xu",
        "Benoit M. Dawant",
        "Ipek Oguz"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-01 05:04:36+00:00",
      "link": "https://arxiv.org/pdf/2601.00212v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00200v1",
      "title": "Detecting Unobserved Confounders: A Kernelized Regression Approach",
      "abstract": "Detecting unobserved confounders is crucial for reliable causal inference in observational studies. Existing methods require either linearity assumptions or multiple heterogeneous environments, limiting applicability to nonlinear single-environment settings. To bridge this gap, we propose Kernel Regression Confounder Detection (KRCD), a novel method for detecting unobserved confounding in nonlinear observational data under single-environment conditions. KRCD leverages reproducing kernel Hilbert spaces to model complex dependencies. By comparing standard and higherorder kernel regressions, we derive a test statistic whose significant deviation from zero indicates unobserved confounding. Theoretically, we prove two key results: First, in infinite samples, regression coefficients coincide if and only if no unobserved confounders exist. Second, finite-sample differences converge to zero-mean Gaussian distributions with tractable variance. Extensive experiments on synthetic benchmarks and the Twins dataset demonstrate that KRCD not only outperforms existing baselines but also achieves superior computational efficiency.",
      "authors": [
        "Yikai Chen",
        "Yunxin Mao",
        "Chunyuan Zheng",
        "Hao Zou",
        "Shanzhi Gu",
        "Shixuan Liu",
        "Yang Shi",
        "Wenjing Yang",
        "Kun Kuang",
        "Haotian Wang"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "published": "2026-01-01 04:26:02+00:00",
      "link": "https://arxiv.org/pdf/2601.00200v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00197v1",
      "title": "StockBot 2.0: Vanilla LSTMs Outperform Transformer-based Forecasting for Stock Prices",
      "abstract": "Accurate forecasting of financial markets remains a long-standing challenge due to complex temporal and often latent dependencies, non-linear dynamics, and high volatility. Building on our earlier recurrent neural network framework, we present an enhanced StockBot architecture that systematically evaluates modern attention-based, convolutional, and recurrent time-series forecasting models within a unified experimental setting. While attention-based and transformer-inspired models offer increased modeling flexibility, extensive empirical evaluation reveals that a carefully constructed vanilla LSTM consistently achieves superior predictive accuracy and more stable buy/sell decision-making when trained under a common set of default hyperparameters. These results highlight the robustness and data efficiency of recurrent sequence models for financial time-series forecasting, particularly in the absence of extensive hyperparameter tuning or the availability of sufficient data when discretized to single-day intervals. Additionally, these results underscore the importance of architectural inductive bias in data-limited market prediction tasks.",
      "authors": [
        "Shaswat Mohanty"
      ],
      "primary_category": "cs.CE",
      "categories": [
        "cs.CE",
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-01-01 04:09:51+00:00",
      "link": "https://arxiv.org/pdf/2601.00197v1",
      "tags": [
        "大厂llm",
        "大语言模型"
      ]
    },
    {
      "id": "2601.00194v1",
      "title": "DichroGAN: Towards Restoration of in-air Colours of Seafloor from Satellite Imagery",
      "abstract": "Recovering the in-air colours of seafloor from satellite imagery is a challenging task due to the exponential attenuation of light with depth in the water column. In this study, we present DichroGAN, a conditional generative adversarial network (cGAN) designed for this purpose. DichroGAN employs a two-steps simultaneous training: first, two generators utilise a hyperspectral image cube to estimate diffuse and specular reflections, thereby obtaining atmospheric scene radiance. Next, a third generator receives as input the generated scene radiance containing the features of each spectral band, while a fourth generator estimates the underwater light transmission. These generators work together to remove the effects of light absorption and scattering, restoring the in-air colours of seafloor based on the underwater image formation equation. DichroGAN is trained on a compact dataset derived from PRISMA satellite imagery, comprising RGB images paired with their corresponding spectral bands and masks. Extensive experiments on both satellite and underwater datasets demonstrate that DichroGAN achieves competitive performance compared to state-of-the-art underwater restoration techniques.",
      "authors": [
        "Salma Gonzalez-Sabbagh",
        "Antonio Robles-Kelly",
        "Shang Gao"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-01 04:03:30+00:00",
      "link": "https://arxiv.org/pdf/2601.00194v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2601.00189v1",
      "title": "SSI-GAN: Semi-Supervised Swin-Inspired Generative Adversarial Networks for Neuronal Spike Classification",
      "abstract": "Mosquitos are the main transmissive agents of arboviral diseases. Manual classification of their neuronal spike patterns is very labor-intensive and expensive. Most available deep learning solutions require fully labeled spike datasets and highly preprocessed neuronal signals. This reduces the feasibility of mass adoption in actual field scenarios. To address the scarcity of labeled data problems, we propose a new Generative Adversarial Network (GAN) architecture that we call the Semi-supervised Swin-Inspired GAN (SSI-GAN). The Swin-inspired, shifted-window discriminator, together with a transformer-based generator, is used to classify neuronal spike trains and, consequently, detect viral neurotropism. We use a multi-head self-attention model in a flat, window-based transformer discriminator that learns to capture sparser high-frequency spike features. Using just 1 to 3% labeled data, SSI-GAN was trained with more than 15 million spike samples collected at five-time post-infection and recording classification into Zika-infected, dengue-infected, or uninfected categories. Hyperparameters were optimized using the Bayesian Optuna framework, and performance for robustness was validated under fivefold Monte Carlo cross-validation. SSI-GAN reached 99.93% classification accuracy on the third day post-infection with only 3% labeled data. It maintained high accuracy across all stages of infection with just 1% supervision. This shows a 97-99% reduction in manual labeling effort relative to standard supervised approaches at the same performance level. The shifted-window transformer design proposed here beat all baselines by a wide margin and set new best marks in spike-based neuronal infection classification.",
      "authors": [
        "Danial Sharifrazi",
        "Nouman Javed",
        "Mojtaba Mohammadi",
        "Seyede Sana Salehi",
        "Roohallah Alizadehsani",
        "Prasad N. Paradkar",
        "U. Rajendra Acharya",
        "Asim Bhatti"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-01 03:34:00+00:00",
      "link": "https://arxiv.org/pdf/2601.00189v1",
      "tags": [
        "大厂llm",
        "大语言模型",
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00186v1",
      "title": "Reinforcement-Learned Unequal Error Protection for Quantized Semantic Embeddings",
      "abstract": "This paper tackles the pressing challenge of preserving semantic meaning in communication systems constrained by limited bandwidth. We introduce a novel reinforcement learning framework that achieves per-dimension unequal error protection via adaptive repetition coding. Central to our approach is a composite semantic distortion metric that balances global embedding similarity with entity-level preservation, empowering the reinforcement learning agent to allocate protection in a context-aware manner. Experiments show statistically significant gains over uniform protection, achieving 6.8% higher chrF scores and 9.3% better entity preservation at 1 dB SNR. The key innovation of our framework is the demonstration that simple, intelligently allocated repetition coding enables fine-grained semantic protection -- an advantage unattainable with conventional codes such as LDPC or Reed-Solomon. Our findings challenge traditional channel coding paradigms by establishing that code structure must align with semantic granularity. This approach is particularly suited to edge computing and IoT scenarios, where bandwidth is scarce, but semantic fidelity is critical, providing a practical pathway for next-generation semantic-aware networks.",
      "authors": [
        "Moirangthem Tiken Singh",
        "Adnan Arif"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.IR",
        "cs.NI"
      ],
      "published": "2026-01-01 03:14:50+00:00",
      "link": "https://arxiv.org/pdf/2601.00186v1",
      "tags": [
        "sr-bench",
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00175v1",
      "title": "Early Prediction of Liver Cirrhosis Up to Three Years in Advance: A Machine Learning Study Benchmarking Against the FIB-4 Score",
      "abstract": "Objective: Develop and evaluate machine learning (ML) models for predicting incident liver cirrhosis one, two, and three years prior to diagnosis using routinely collected electronic health record (EHR) data, and to benchmark their performance against the FIB-4 score. Methods: We conducted a retrospective cohort study using de-identified EHR data from a large academic health system. Patients with fatty liver disease were identified and categorized into cirrhosis and non-cirrhosis cohorts based on ICD-9/10 codes. Prediction scenarios were constructed using observation and prediction windows to emulate real-world clinical use. Demographics, diagnoses, laboratory results, vital signs, and comorbidity indices were aggregated from the observation window. XGBoost models were trained for 1-, 2-, and 3-year prediction horizons and evaluated on held-out test sets. Model performance was compared with FIB-4 using area under the receiver operating characteristic curve (AUC). Results: Final cohorts included 3,043 patients for the 1-year prediction, 1,981 for the 2-year prediction, and 1,470 for the 3-year prediction. Across all prediction windows, ML models consistently outperformed FIB-4. The XGBoost models achieved AUCs of 0.81, 0.73, and 0.69 for 1-, 2-, and 3-year predictions, respectively, compared with 0.71, 0.63, and 0.57 for FIB-4. Performance gains persisted with longer prediction horizons, indicating improved early risk discrimination. Conclusions: Machine learning models leveraging routine EHR data substantially outperform the traditional FIB-4 score for early prediction of liver cirrhosis. These models enable earlier and more accurate risk stratification and can be integrated into clinical workflows as automated decision-support tools to support proactive cirrhosis prevention and management.",
      "authors": [
        "Zhuqi Miao",
        "Sujan Ravi",
        "Abdulaziz Ahmed"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-01 02:33:16+00:00",
      "link": "https://arxiv.org/pdf/2601.00175v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00172v1",
      "title": "Sequential Reservoir Computing for Efficient High-Dimensional Spatiotemporal Forecasting",
      "abstract": "Forecasting high-dimensional spatiotemporal systems remains computationally challenging for recurrent neural networks (RNNs) and long short-term memory (LSTM) models due to gradient-based training and memory bottlenecks. Reservoir Computing (RC) mitigates these challenges by replacing backpropagation with fixed recurrent layers and a convex readout optimization, yet conventional RC architectures still scale poorly with input dimensionality. We introduce a Sequential Reservoir Computing (Sequential RC) architecture that decomposes a large reservoir into a series of smaller, interconnected reservoirs. This design reduces memory and computational costs while preserving long-term temporal dependencies. Using both low-dimensional chaotic systems (Lorenz63) and high-dimensional physical simulations (2D vorticity and shallow-water equations), Sequential RC achieves 15-25% longer valid forecast horizons, 20-30% lower error metrics (SSIM, RMSE), and up to three orders of magnitude lower training cost compared to LSTM and standard RNN baselines. The results demonstrate that Sequential RC maintains the simplicity and efficiency of conventional RC while achieving superior scalability for high-dimensional dynamical systems. This approach provides a practical path toward real-time, energy-efficient forecasting in scientific and engineering applications.",
      "authors": [
        "Ata Akbari Asanjan",
        "Filip Wudarski",
        "Daniel O'Connor",
        "Shaun Geaney",
        "Elena Strbac",
        "P. Aaron Lott",
        "Davide Venturelli"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.NE"
      ],
      "published": "2026-01-01 02:24:56+00:00",
      "link": "https://arxiv.org/pdf/2601.00172v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00167v1",
      "title": "Online Finetuning Decision Transformers with Pure RL Gradients",
      "abstract": "Decision Transformers (DTs) have emerged as a powerful framework for sequential decision making by formulating offline reinforcement learning (RL) as a sequence modeling problem. However, extending DTs to online settings with pure RL gradients remains largely unexplored, as existing approaches continue to rely heavily on supervised sequence-modeling objectives during online finetuning. We identify hindsight return relabeling -- a standard component in online DTs -- as a critical obstacle to RL-based finetuning: while beneficial for supervised learning, it is fundamentally incompatible with importance sampling-based RL algorithms such as GRPO, leading to unstable training. Building on this insight, we propose new algorithms that enable online finetuning of Decision Transformers using pure reinforcement learning gradients. We adapt GRPO to DTs and introduce several key modifications, including sub-trajectory optimization for improved credit assignment, sequence-level likelihood objectives for enhanced stability and efficiency, and active sampling to encourage exploration in uncertain regions. Through extensive experiments, we demonstrate that our methods outperform existing online DT baselines and achieve new state-of-the-art performance across multiple benchmarks, highlighting the effectiveness of pure-RL-based online finetuning for Decision Transformers.",
      "authors": [
        "Junkai Luo",
        "Yinglun Zhu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-01 02:17:18+00:00",
      "link": "https://arxiv.org/pdf/2601.00167v1",
      "tags": [
        "sr-bench",
        "大厂llm",
        "大语言模型"
      ]
    },
    {
      "id": "2601.00151v1",
      "title": "Reinforcement Learning with Function Approximation for Non-Markov Processes",
      "abstract": "We study reinforcement learning methods with linear function approximation under non-Markov state and cost processes. We first consider the policy evaluation method and show that the algorithm converges under suitable ergodicity conditions on the underlying non-Markov processes. Furthermore, we show that the limit corresponds to the fixed point of a joint operator composed of an orthogonal projection and the Bellman operator of an auxiliary \\emph{Markov} decision process.   For Q-learning with linear function approximation, as in the Markov setting, convergence is not guaranteed in general. We show, however, that for the special case where the basis functions are chosen based on quantization maps, the convergence can be shown under similar ergodicity conditions. Finally, we apply our results to partially observed Markov decision processes, where finite-memory variables are used as state representations, and we derive explicit error bounds for the limits of the resulting learning algorithms.",
      "authors": [
        "Ali Devran Kara"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "math.OC"
      ],
      "published": "2026-01-01 00:56:18+00:00",
      "link": "https://arxiv.org/pdf/2601.00151v1",
      "tags": [
        "sr-bench"
      ]
    },
    {
      "id": "2601.00150v1",
      "title": "FCMBench: A Comprehensive Financial Credit Multimodal Benchmark for Real-world Applications",
      "abstract": "As multimodal AI becomes widely used for credit risk assessment and document review, a domain-specific benchmark is urgently needed that (1) reflects documents and workflows specific to financial credit applications, (2) includes credit-specific understanding and real-world robustness, and (3) preserves privacy compliance without sacrificing practical utility. Here, we introduce FCMBench-V1.0 -- a large-scale financial credit multimodal benchmark for real-world applications, covering 18 core certificate types, with 4,043 privacy-compliant images and 8,446 QA samples. The FCMBench evaluation framework consists of three dimensions: Perception, Reasoning, and Robustness, including 3 foundational perception tasks, 4 credit-specific reasoning tasks that require decision-oriented understanding of visual evidence, and 10 real-world acquisition artifact types for robustness stress testing. To reconcile compliance with realism, we construct all samples via a closed synthesis-capture pipeline: we manually synthesize document templates with virtual content and capture scenario-aware images in-house. This design also mitigates pre-training data leakage by avoiding web-sourced or publicly released images. FCMBench can effectively discriminate performance disparities and robustness across modern vision-language models. Extensive experiments were conducted on 23 state-of-the-art vision-language models (VLMs) from 14 top AI companies and research institutes. Among them, Gemini 3 Pro achieves the best F1(\\%) score as a commercial model (64.61), Qwen3-VL-235B achieves the best score as an open-source baseline (57.27), and our financial credit-specific model, Qfin-VL-Instruct, achieves the top overall score (64.92). Robustness evaluations show that even top-performing models suffer noticeable performance drops under acquisition artifacts.",
      "authors": [
        "Yehui Yang",
        "Dalu Yang",
        "Wenshuo Zhou",
        "Fangxin Shang",
        "Yifan Liu",
        "Jie Ren",
        "Haojun Fei",
        "Qing Yang",
        "Tao Chen"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CE",
        "cs.MM"
      ],
      "published": "2026-01-01 00:42:54+00:00",
      "link": "https://arxiv.org/pdf/2601.00150v1",
      "tags": [
        "sr-bench"
      ]
    },
    {
      "id": "2601.00146v1",
      "title": "Combining datasets with different ground truths using Low-Rank Adaptation to generalize image-based CNN models for photometric redshift prediction",
      "abstract": "In this work, we demonstrate how Low-Rank Adaptation (LoRA) can be used to combine different galaxy imaging datasets to improve redshift estimation with CNN models for cosmology. LoRA is an established technique for large language models that adds adapter networks to adjust model weights and biases to efficiently fine-tune large base models without retraining. We train a base model using a photometric redshift ground truth dataset, which contains broad galaxy types but is less accurate. We then fine-tune using LoRA on a spectroscopic redshift ground truth dataset. These redshifts are more accurate but limited to bright galaxies and take orders of magnitude more time to obtain, so are less available for large surveys. Ideally, the combination of the two datasets would yield more accurate models that generalize well. The LoRA model performs better than a traditional transfer learning method, with $\\sim2.5\\times$ less bias and $\\sim$2.2$\\times$ less scatter. Retraining the model on a combined dataset yields a model that generalizes better than LoRA but at a cost of greater computation time. Our work shows that LoRA is useful for fine-tuning regression models in astrophysics by providing a middle ground between full retraining and no retraining. LoRA shows potential in allowing us to leverage existing pretrained astrophysical models, especially for data sparse tasks.",
      "authors": [
        "Vikram Seenivasan",
        "Srinath Saikrishnan",
        "Andrew Lizarraga",
        "Jonathan Soriano",
        "Bernie Boscoe",
        "Tuan Do"
      ],
      "primary_category": "astro-ph.IM",
      "categories": [
        "astro-ph.IM",
        "cs.LG"
      ],
      "published": "2026-01-01 00:26:10+00:00",
      "link": "https://arxiv.org/pdf/2601.00146v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00143v1",
      "title": "MethConvTransformer: A Deep Learning Framework for Cross-Tissue Alzheimer's Disease Detection",
      "abstract": "Alzheimer's disease (AD) is a multifactorial neurodegenerative disorder characterized by progressive cognitive decline and widespread epigenetic dysregulation in the brain. DNA methylation, as a stable yet dynamic epigenetic modification, holds promise as a noninvasive biomarker for early AD detection. However, methylation signatures vary substantially across tissues and studies, limiting reproducibility and translational utility. To address these challenges, we develop MethConvTransformer, a transformer-based deep learning framework that integrates DNA methylation profiles from both brain and peripheral tissues to enable biomarker discovery. The model couples a CpG-wise linear projection with convolutional and self-attention layers to capture local and long-range dependencies among CpG sites, while incorporating subject-level covariates and tissue embeddings to disentangle shared and region-specific methylation effects. In experiments across six GEO datasets and an independent ADNI validation cohort, our model consistently outperforms conventional machine-learning baselines, achieving superior discrimination and generalization. Moreover, interpretability analyses using linear projection, SHAP, and Grad-CAM++ reveal biologically meaningful methylation patterns aligned with AD-associated pathways, including immune receptor signaling, glycosylation, lipid metabolism, and endomembrane (ER/Golgi) organization. Together, these results indicate that MethConvTransformer delivers robust, cross-tissue epigenetic biomarkers for AD while providing multi-resolution interpretability, thereby advancing reproducible methylation-based diagnostics and offering testable hypotheses on disease mechanisms.",
      "authors": [
        "Gang Qu",
        "Guanghao Li",
        "Zhongming Zhao"
      ],
      "primary_category": "q-bio.GN",
      "categories": [
        "q-bio.GN",
        "cs.AI"
      ],
      "published": "2026-01-01 00:18:33+00:00",
      "link": "https://arxiv.org/pdf/2601.00143v1",
      "tags": [
        "sr-bench",
        "大厂llm",
        "大语言模型"
      ]
    },
    {
      "id": "2601.00142v1",
      "title": "An AI Monkey Gets Grapes for Sure -- Sphere Neural Networks for Reliable Decision-Making",
      "abstract": "This paper compares three methodological categories of neural reasoning: LLM reasoning, supervised learning-based reasoning, and explicit model-based reasoning. LLMs remain unreliable and struggle with simple decision-making that animals can master without extensive corpora training. Through disjunctive syllogistic reasoning testing, we show that reasoning via supervised learning is less appealing than reasoning via explicit model construction. Concretely, we show that an Euler Net trained to achieve 100.00% in classic syllogistic reasoning can be trained to reach 100.00% accuracy in disjunctive syllogistic reasoning. However, the retrained Euler Net suffers severely from catastrophic forgetting (its performance drops to 6.25% on already-learned classic syllogistic reasoning), and its reasoning competence is limited to the pattern level. We propose a new version of Sphere Neural Networks that embeds concepts as circles on the surface of an n-dimensional sphere. These Sphere Neural Networks enable the representation of the negation operator via complement circles and achieve reliable decision-making by filtering out illogical statements that form unsatisfiable circular configurations. We demonstrate that the Sphere Neural Network can master 16 syllogistic reasoning tasks, including rigorous disjunctive syllogistic reasoning, while preserving the rigour of classical syllogistic reasoning. We conclude that neural reasoning with explicit model construction is the most reliable among the three methodological categories of neural reasoning.",
      "authors": [
        "Tiansi Dong",
        "Henry He",
        "Pietro Liò",
        "Mateja Jamnik"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-01 00:07:37+00:00",
      "link": "https://arxiv.org/pdf/2601.00142v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00141v1",
      "title": "Attention to Detail: Global-Local Attention for High-Resolution AI-Generated Image Detection",
      "abstract": "The rapid development of generative AI has made AI-generated images increasingly realistic and high-resolution. Most AI-generated image detection architectures typically downsample images before inputting them into models, risking the loss of fine-grained details. This paper presents GLASS (Global-Local Attention with Stratified Sampling), an architecture that combines a globally resized view with multiple randomly sampled local crops. These crops are original-resolution regions efficiently selected through spatially stratified sampling and aggregated using attention-based scoring. GLASS can be integrated into vision models to leverage both global and local information in images of any size. Vision Transformer, ResNet, and ConvNeXt models are used as backbones, and experiments show that GLASS outperforms standard transfer learning by achieving higher predictive performance within feasible computational constraints.",
      "authors": [
        "Lawrence Han"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-01 00:00:07+00:00",
      "link": "https://arxiv.org/pdf/2601.00141v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00130v1",
      "title": "Democratizing Electronic-Photonic AI Systems: An Open-Source AI-Infused Cross-Layer Co-Design and Design Automation Toolflow",
      "abstract": "Photonics is becoming a cornerstone technology for high-performance AI systems and scientific computing, offering unparalleled speed, parallelism, and energy efficiency. Despite this promise, the design and deployment of electronic-photonic AI systems remain highly challenging due to a steep learning curve across multiple layers, spanning device physics, circuit design, system architecture, and AI algorithms. The absence of a mature electronic-photonic design automation (EPDA) toolchain leads to long, inefficient design cycles and limits cross-disciplinary innovation and co-evolution. In this work, we present a cross-layer co-design and automation framework aimed at democratizing photonic AI system development. We begin by introducing our architecture designs for scalable photonic edge AI and Transformer inference, followed by SimPhony, an open-source modeling tool for rapid EPIC AI system evaluation and design-space exploration. We then highlight advances in AI-enabled photonic design automation, including physical AI-based Maxwell solvers, a fabrication-aware inverse design framework, and a scalable inverse training algorithm for meta-optical neural networks, enabling a scalable EPDA stack for next-generation electronic-photonic AI systems.",
      "authors": [
        "Hongjian Zhou",
        "Ziang Yin",
        "Jiaqi Gu"
      ],
      "primary_category": "physics.optics",
      "categories": [
        "physics.optics",
        "cs.AI",
        "cs.AR",
        "cs.ET"
      ],
      "published": "2025-12-31 22:22:29+00:00",
      "link": "https://arxiv.org/pdf/2601.00130v1",
      "tags": [
        "大厂llm",
        "大语言模型"
      ]
    },
    {
      "id": "2601.00129v1",
      "title": "Toward Large-Scale Photonics-Empowered AI Systems: From Physical Design Automation to System-Algorithm Co-Exploration",
      "abstract": "In this work, we identify three considerations that are essential for realizing practical photonic AI systems at scale: (1) dynamic tensor operation support for modern models rather than only weight-static kernels, especially for attention/Transformer-style workloads; (2) systematic management of conversion, control, and data-movement overheads, where multiplexing and dataflow must amortize electronic costs instead of letting ADC/DAC and I/O dominate; and (3) robustness under hardware non-idealities that become more severe as integration density grows. To study these coupled tradeoffs quantitatively, and to ensure they remain meaningful under real implementation constraints, we build a cross-layer toolchain that supports photonic AI design from early exploration to physical realization. SimPhony provides implementation-aware modeling and rapid cross-layer evaluation, translating physical costs into system-level metrics so architectural decisions are grounded in realistic assumptions. ADEPT and ADEPT-Z enable end-to-end circuit and topology exploration, connecting system objectives to feasible photonic fabrics under practical device and circuit constraints. Finally, Apollo and LiDAR provide scalable photonic physical design automation, turning candidate circuits into manufacturable layouts while accounting for routing, thermal, and crosstalk constraints.",
      "authors": [
        "Ziang Yin",
        "Hongjian Zhou",
        "Nicholas Gangi",
        "Meng Zhang",
        "Jeff Zhang",
        "Zhaoran Rena Huang",
        "Jiaqi Gu"
      ],
      "primary_category": "physics.optics",
      "categories": [
        "physics.optics",
        "cs.AI",
        "cs.AR",
        "cs.ET"
      ],
      "published": "2025-12-31 22:21:42+00:00",
      "link": "https://arxiv.org/pdf/2601.00129v1",
      "tags": [
        "大厂llm",
        "大语言模型"
      ]
    },
    {
      "id": "2601.00125v1",
      "title": "Constructing a Neuro-Symbolic Mathematician from First Principles",
      "abstract": "Large Language Models (LLMs) exhibit persistent logical failures in complex reasoning due to the lack of an internal axiomatic framework. We propose Mathesis, a neuro-symbolic architecture that encodes mathematical states as higher-order hypergraphs and uses a Symbolic Reasoning Kernel (SRK)--a differentiable logic engine that maps constraints to a continuous energy landscape. By defining a global energy function E(G), where zero energy implies logical consistency, the SRK yields gradient-based signals to train a Hypergraph Transformer Brain, turning proof search into energy minimization. Multi-step deduction is enabled via Monte Carlo Tree Search and Evolutionary Proof Search, guided by learned value functions and semantic unification.",
      "authors": [
        "Keqin Xie"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2025-12-31 22:02:02+00:00",
      "link": "https://arxiv.org/pdf/2601.00125v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00116v1",
      "title": "GRL-SNAM: Geometric Reinforcement Learning with Path Differential Hamiltonians for Simultaneous Navigation and Mapping in Unknown Environments",
      "abstract": "We present GRL-SNAM, a geometric reinforcement learning framework for Simultaneous Navigation and Mapping(SNAM) in unknown environments. A SNAM problem is challenging as it needs to design hierarchical or joint policies of multiple agents that control the movement of a real-life robot towards the goal in mapless environment, i.e. an environment where the map of the environment is not available apriori, and needs to be acquired through sensors. The sensors are invoked from the path learner, i.e. navigator, through active query responses to sensory agents, and along the motion path. GRL-SNAM differs from preemptive navigation algorithms and other reinforcement learning methods by relying exclusively on local sensory observations without constructing a global map. Our approach formulates path navigation and mapping as a dynamic shortest path search and discovery process using controlled Hamiltonian optimization: sensory inputs are translated into local energy landscapes that encode reachability, obstacle barriers, and deformation constraints, while policies for sensing, planning, and reconfiguration evolve stagewise via updating Hamiltonians. A reduced Hamiltonian serves as an adaptive score function, updating kinetic/potential terms, embedding barrier constraints, and continuously refining trajectories as new local information arrives. We evaluate GRL-SNAM on two different 2D navigation tasks. Comparing against local reactive baselines and global policy learning references under identical stagewise sensing constraints, it preserves clearance, generalizes to unseen layouts, and demonstrates that Geometric RL learning via updating Hamiltonians enables high-quality navigation through minimal exploration via local energy refinement rather than extensive global mapping. The code is publicly available on \\href{https://github.com/CVC-Lab/GRL-SNAM}{Github}.",
      "authors": [
        "Aditya Sai Ellendula",
        "Yi Wang",
        "Minh Nguyen",
        "Chandrajit Bajaj"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.RO"
      ],
      "published": "2025-12-31 21:27:20+00:00",
      "link": "https://arxiv.org/pdf/2601.00116v1",
      "tags": [
        "sr-bench"
      ]
    },
    {
      "id": "2601.00095v1",
      "title": "Universal Adaptive Constraint Propagation: Scaling Structured Inference for Large Language Models via Meta-Reinforcement Learning",
      "abstract": "Large language models increasingly require structured inference, from JSON schema enforcement to multi-lingual parsing, where outputs must satisfy complex constraints. We introduce MetaJuLS, a meta-reinforcement learning approach that learns universal constraint propagation policies applicable across languages and tasks without task-specific retraining. By formulating structured inference as adaptive constraint propagation and training a Graph Attention Network with meta-learning, MetaJuLS achieves 1.5--2.0$\\times$ speedups over GPU-optimized baselines while maintaining within 0.2\\% accuracy of state-of-the-art parsers. On Universal Dependencies across 10 languages and LLM-constrained generation (LogicBench, GSM8K-Constrained), MetaJuLS demonstrates rapid cross-domain adaptation: a policy trained on English parsing adapts to new languages and tasks with 5--10 gradient steps (5--15 seconds) rather than requiring hours of task-specific training. Mechanistic analysis reveals the policy discovers human-like parsing strategies (easy-first) and novel non-intuitive heuristics. By reducing propagation steps in LLM deployments, MetaJuLS contributes to Green AI by directly reducing inference carbon footprint.",
      "authors": [
        "Ibne Farabi Shihab",
        "Sanjeda Akter",
        "Anuj Sharma"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2025-12-31 20:03:49+00:00",
      "link": "https://arxiv.org/pdf/2601.00095v1",
      "tags": [
        "sr-bench"
      ]
    },
    {
      "id": "2601.00090v1",
      "title": "It's Never Too Late: Noise Optimization for Collapse Recovery in Trained Diffusion Models",
      "abstract": "Contemporary text-to-image models exhibit a surprising degree of mode collapse, as can be seen when sampling several images given the same text prompt. While previous work has attempted to address this issue by steering the model using guidance mechanisms, or by generating a large pool of candidates and refining them, in this work we take a different direction and aim for diversity in generations via noise optimization. Specifically, we show that a simple noise optimization objective can mitigate mode collapse while preserving the fidelity of the base model. We also analyze the frequency characteristics of the noise and show that alternative noise initializations with different frequency profiles can improve both optimization and search. Our experiments demonstrate that noise optimization yields superior results in terms of generation quality and variety.",
      "authors": [
        "Anne Harrington",
        "A. Sophia Koepke",
        "Shyamgopal Karthik",
        "Trevor Darrell",
        "Alexei A. Efros"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "published": "2025-12-31 19:47:49+00:00",
      "link": "https://arxiv.org/pdf/2601.00090v1",
      "tags": [
        "大厂llm"
      ]
    },
    {
      "id": "2601.00065v1",
      "title": "The Trojan in the Vocabulary: Stealthy Sabotage of LLM Composition",
      "abstract": "The open-weight LLM ecosystem is increasingly defined by model composition techniques (such as weight merging, speculative decoding, and vocabulary expansion) that remix capabilities from diverse sources. A critical prerequisite for applying these methods across different model families is tokenizer transplant, which aligns incompatible vocabularies to a shared embedding space. We demonstrate that this essential interoperability step introduces a supply-chain vulnerability: we engineer a single \"breaker token\" that is functionally inert in a donor model yet reliably reconstructs into a high-salience malicious feature after transplant into a base model. By exploiting the geometry of coefficient reuse, our attack creates an asymmetric realizability gap that sabotages the base model's generation while leaving the donor's utility statistically indistinguishable from nominal behavior. We formalize this as a dual-objective optimization problem and instantiate the attack using a sparse solver. Empirically, the attack is training-free and achieves spectral mimicry to evade outlier detection, while demonstrating structural persistence against fine-tuning and weight merging, highlighting a hidden risk in the pipeline of modular AI composition. Code is available at https://github.com/xz-liu/tokenforge",
      "authors": [
        "Xiaoze Liu",
        "Weichen Yu",
        "Matt Fredrikson",
        "Xiaoqian Wang",
        "Jing Gao"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CL",
        "cs.CR"
      ],
      "published": "2025-12-31 19:00:03+00:00",
      "link": "https://arxiv.org/pdf/2601.00065v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2512.25075v1",
      "title": "SpaceTimePilot: Generative Rendering of Dynamic Scenes Across Space and Time",
      "abstract": "We present SpaceTimePilot, a video diffusion model that disentangles space and time for controllable generative rendering. Given a monocular video, SpaceTimePilot can independently alter the camera viewpoint and the motion sequence within the generative process, re-rendering the scene for continuous and arbitrary exploration across space and time. To achieve this, we introduce an effective animation time-embedding mechanism in the diffusion process, allowing explicit control of the output video's motion sequence with respect to that of the source video. As no datasets provide paired videos of the same dynamic scene with continuous temporal variations, we propose a simple yet effective temporal-warping training scheme that repurposes existing multi-view datasets to mimic temporal differences. This strategy effectively supervises the model to learn temporal control and achieve robust space-time disentanglement. To further enhance the precision of dual control, we introduce two additional components: an improved camera-conditioning mechanism that allows altering the camera from the first frame, and CamxTime, the first synthetic space-and-time full-coverage rendering dataset that provides fully free space-time video trajectories within a scene. Joint training on the temporal-warping scheme and the CamxTime dataset yields more precise temporal control. We evaluate SpaceTimePilot on both real-world and synthetic data, demonstrating clear space-time disentanglement and strong results compared to prior work. Project page: https://zheninghuang.github.io/Space-Time-Pilot/ Code: https://github.com/ZheningHuang/spacetimepilot",
      "authors": [
        "Zhening Huang",
        "Hyeonho Jeong",
        "Xuelin Chen",
        "Yulia Gryaditskaya",
        "Tuanfeng Y. Wang",
        "Joan Lasenby",
        "Chun-Hao Huang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "published": "2025-12-31 18:59:57+00:00",
      "link": "https://arxiv.org/pdf/2512.25075v1",
      "tags": [
        "大厂llm"
      ]
    },
    {
      "id": "2512.25073v1",
      "title": "GaMO: Geometry-aware Multi-view Diffusion Outpainting for Sparse-View 3D Reconstruction",
      "abstract": "Recent advances in 3D reconstruction have achieved remarkable progress in high-quality scene capture from dense multi-view imagery, yet struggle when input views are limited. Various approaches, including regularization techniques, semantic priors, and geometric constraints, have been implemented to address this challenge. Latest diffusion-based methods have demonstrated substantial improvements by generating novel views from new camera poses to augment training data, surpassing earlier regularization and prior-based techniques. Despite this progress, we identify three critical limitations in these state-of-the-art approaches: inadequate coverage beyond known view peripheries, geometric inconsistencies across generated views, and computationally expensive pipelines. We introduce GaMO (Geometry-aware Multi-view Outpainter), a framework that reformulates sparse-view reconstruction through multi-view outpainting. Instead of generating new viewpoints, GaMO expands the field of view from existing camera poses, which inherently preserves geometric consistency while providing broader scene coverage. Our approach employs multi-view conditioning and geometry-aware denoising strategies in a zero-shot manner without training. Extensive experiments on Replica and ScanNet++ demonstrate state-of-the-art reconstruction quality across 3, 6, and 9 input views, outperforming prior methods in PSNR and LPIPS, while achieving a $25\\times$ speedup over SOTA diffusion-based methods with processing time under 10 minutes. Project page: https://yichuanh.github.io/GaMO/",
      "authors": [
        "Yi-Chuan Huang",
        "Hao-Jen Chien",
        "Chin-Yang Lin",
        "Ying-Huan Chen",
        "Yu-Lun Liu"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2025-12-31 18:59:55+00:00",
      "link": "https://arxiv.org/pdf/2512.25073v1",
      "tags": [
        "大厂llm"
      ]
    },
    {
      "id": "2512.25070v1",
      "title": "Scaling Open-Ended Reasoning to Predict the Future",
      "abstract": "High-stakes decision making involves reasoning under uncertainty about the future. In this work, we train language models to make predictions on open-ended forecasting questions. To scale up training data, we synthesize novel forecasting questions from global events reported in daily news, using a fully automated, careful curation recipe. We train the Qwen3 thinking models on our dataset, OpenForesight. To prevent leakage of future information during training and evaluation, we use an offline news corpus, both for data generation and retrieval in our forecasting system. Guided by a small validation set, we show the benefits of retrieval, and an improved reward function for reinforcement learning (RL). Once we obtain our final forecasting system, we perform held-out testing between May to August 2025. Our specialized model, OpenForecaster 8B, matches much larger proprietary models, with our training improving the accuracy, calibration, and consistency of predictions. We find calibration improvements from forecasting training generalize across popular benchmarks. We open-source all our models, code, and data to make research on language model forecasting broadly accessible.",
      "authors": [
        "Nikhil Chandak",
        "Shashwat Goel",
        "Ameya Prabhu",
        "Moritz Hardt",
        "Jonas Geiping"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "published": "2025-12-31 18:59:51+00:00",
      "link": "https://arxiv.org/pdf/2512.25070v1",
      "tags": [
        "大厂llm"
      ]
    },
    {
      "id": "2512.25065v1",
      "title": "Vulcan: Instance-Optimal Systems Heuristics Through LLM-Driven Search",
      "abstract": "Resource-management tasks in modern operating and distributed systems continue to rely primarily on hand-designed heuristics for tasks such as scheduling, caching, or active queue management. Designing performant heuristics is an expensive, time-consuming process that we are forced to continuously go through due to the constant flux of hardware, workloads and environments.   We propose a new alternative: synthesizing instance-optimal heuristics -- specialized for the exact workloads and hardware where they will be deployed -- using code-generating large language models (LLMs). To make this synthesis tractable, Vulcan separates policy and mechanism through LLM-friendly, task-agnostic interfaces. With these interfaces, users specify the inputs and objectives of their desired policy, while Vulcan searches for performant policies via evolutionary search over LLM-generated code. This interface is expressive enough to capture a wide range of system policies, yet sufficiently constrained to allow even small, inexpensive LLMs to generate correct and executable code.   We use Vulcan to synthesize performant heuristics for cache eviction and memory tiering, and find that these heuristics outperform all human-designed state-of-the-art algorithms by upto 69% and 7.9% in performance for each of these tasks respectively.",
      "authors": [
        "Rohit Dwivedula",
        "Divyanshu Saxena",
        "Sujay Yadalam",
        "Daehyeok Kim",
        "Aditya Akella"
      ],
      "primary_category": "cs.OS",
      "categories": [
        "cs.OS",
        "cs.AI",
        "cs.DC"
      ],
      "published": "2025-12-31 18:58:19+00:00",
      "link": "https://arxiv.org/pdf/2512.25065v1",
      "tags": [
        "大厂llm"
      ]
    },
    {
      "id": "2512.25063v1",
      "title": "Many Minds from One Model: Bayesian Transformers for Population Intelligence",
      "abstract": "Despite their scale and success, modern transformers are almost universally trained as single-minded systems: optimization produces one deterministic set of parameters, representing a single functional hypothesis about the data. Motivated by the idea that intelligence emerge from many minds, we propose Population Bayesian Transformers (B-Trans), which transform a standard Large Language Model into a Bayesian Transformer model to supports sampling diverse yet coherent model instances from a single set of pre-trained weights.   B-Trans introduces a Bayesian-motivated posterior proxy by treating the bias-like offsets in normalization layers as stochastic variables with a Gaussian variational approximation, inducing a distribution over model behavior without the cost of training full Bayesian neural networks. Sampling from this proxy yields a set of model instances with diverse behaviors while maintaining general competence. To preserve coherence within each generation, we freeze the sampled noise at the sequence level, enforcing temporal consistency across tokens. B-Trans allows for population-level decision-making, where aggregating predictions across sampled individuals significantly enhances exploration. Experiments across zero-shot generation, Reinforcement Learning with Verifiable Rewards (RLVR), and RL without explicit labels demonstrate that B-Trans effectively leverage the wisdom of crowds, yielding superior semantic diversity while achieving better task performance compared to deterministic baselines.",
      "authors": [
        "Diji Yang",
        "Yi Zhang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "published": "2025-12-31 18:56:02+00:00",
      "link": "https://arxiv.org/pdf/2512.25063v1",
      "tags": [
        "大语言模型",
        "符号回归（示例）"
      ]
    },
    {
      "id": "2512.25059v1",
      "title": "Reliable and Resilient Collective Communication Library for LLM Training and Serving",
      "abstract": "Modern ML training and inference now span tens to tens of thousands of GPUs, where network faults can waste 10--15\\% of GPU hours due to slow recovery. Common network errors and link fluctuations trigger timeouts that often terminate entire jobs, forcing expensive checkpoint rollback during training and request reprocessing during inference. We present R$^2$CCL, a fault-tolerant communication library that provides lossless, low-overhead failover by exploiting multi-NIC hardware. R$^2$CCL performs rapid connection migration, bandwidth-aware load redistribution, and resilient collective algorithms to maintain progress under failures. We evaluate R$^2$CCL on two 8-GPU H100 InfiniBand servers and via large-scale ML simulators modeling hundreds of GPUs with diverse failure patterns. Experiments show that R$^2$CCL is highly robust to NIC failures, incurring less than 1\\% training and less than 3\\% inference overheads. R$^2$CCL outperforms baselines AdapCC and DejaVu by 12.18$\\times$ and 47$\\times$, respectively.",
      "authors": [
        "Wei Wang",
        "Nengneng Yu",
        "Sixian Xiong",
        "Zaoxing Liu"
      ],
      "primary_category": "cs.DC",
      "categories": [
        "cs.DC",
        "cs.LG",
        "cs.NI"
      ],
      "published": "2025-12-31 18:53:11+00:00",
      "link": "https://arxiv.org/pdf/2512.25059v1",
      "tags": [
        "大厂llm"
      ]
    },
    {
      "id": "2601.00051v1",
      "title": "TeleWorld: Towards Dynamic Multimodal Synthesis with a 4D World Model",
      "abstract": "World models aim to endow AI systems with the ability to represent, generate, and interact with dynamic environments in a coherent and temporally consistent manner. While recent video generation models have demonstrated impressive visual quality, they remain limited in real-time interaction, long-horizon consistency, and persistent memory of dynamic scenes, hindering their evolution into practical world models. In this report, we present TeleWorld, a real-time multimodal 4D world modeling framework that unifies video generation, dynamic scene reconstruction, and long-term world memory within a closed-loop system. TeleWorld introduces a novel generation-reconstruction-guidance paradigm, where generated video streams are continuously reconstructed into a dynamic 4D spatio-temporal representation, which in turn guides subsequent generation to maintain spatial, temporal, and physical consistency. To support long-horizon generation with low latency, we employ an autoregressive diffusion-based video model enhanced with Macro-from-Micro Planning (MMPL)--a hierarchical planning method that reduces error accumulation from frame-level to segment-level-alongside efficient Distribution Matching Distillation (DMD), enabling real-time synthesis under practical computational budgets. Our approach achieves seamless integration of dynamic object modeling and static scene representation within a unified 4D framework, advancing world models toward practical, interactive, and computationally accessible systems. Extensive experiments demonstrate that TeleWorld achieves strong performance in both static and dynamic world understanding, long-term consistency, and real-time generation efficiency, positioning it as a practical step toward interactive, memory-enabled world models for multimodal generation and embodied intelligence.",
      "authors": [
        "Yabo Chen",
        "Yuanzhi Liang",
        "Jiepeng Wang",
        "Tingxi Chen",
        "Junfei Cheng",
        "Zixiao Gu",
        "Yuyang Huang",
        "Zicheng Jiang",
        "Wei Li",
        "Tian Li",
        "Weichen Li",
        "Zuoxin Li",
        "Guangce Liu",
        "Jialun Liu",
        "Junqi Liu",
        "Haoyuan Wang",
        "Qizhen Weng",
        "Xuan'er Wu",
        "Xunzhi Xiang",
        "Xiaoyan Yang",
        "Xin Zhang",
        "Shiwen Zhang",
        "Junyu Zhou",
        "Chengcheng Zhou",
        "Haibin Huang",
        "Chi Zhang",
        "Xuelong Li"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2025-12-31 18:31:46+00:00",
      "link": "https://arxiv.org/pdf/2601.00051v1",
      "tags": [
        "大厂llm"
      ]
    },
    {
      "id": "2512.25023v1",
      "title": "ResponseRank: Data-Efficient Reward Modeling through Preference Strength Learning",
      "abstract": "Binary choices, as often used for reinforcement learning from human feedback (RLHF), convey only the direction of a preference. A person may choose apples over oranges and bananas over grapes, but which preference is stronger? Strength is crucial for decision-making under uncertainty and generalization of preference models, but hard to measure reliably. Metadata such as response times and inter-annotator agreement can serve as proxies for strength, but are often noisy and confounded. We propose ResponseRank to address the challenge of learning from noisy strength signals. Our method uses relative differences in proxy signals to rank responses to pairwise comparisons by their inferred preference strength. To control for systemic variation, we compare signals only locally within carefully constructed strata. This enables robust learning of utility differences consistent with strength-derived rankings while making minimal assumptions about the strength signal. Our contributions are threefold: (1) ResponseRank, a novel method that robustly learns preference strength by leveraging locally valid relative strength signals; (2) empirical evidence of improved sample efficiency and robustness across diverse tasks: synthetic preference learning (with simulated response times), language modeling (with annotator agreement), and RL control tasks (with simulated episode returns); and (3) the Pearson Distance Correlation (PDC), a novel metric that isolates cardinal utility learning from ordinal accuracy.",
      "authors": [
        "Timo Kaufmann",
        "Yannick Metz",
        "Daniel Keim",
        "Eyke Hüllermeier"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2025-12-31 18:21:52+00:00",
      "link": "https://arxiv.org/pdf/2512.25023v1",
      "tags": [
        "sr-bench",
        "符号回归（示例）"
      ]
    },
    {
      "id": "2512.25014v1",
      "title": "Diffusion Language Models are Provably Optimal Parallel Samplers",
      "abstract": "Diffusion language models (DLMs) have emerged as a promising alternative to autoregressive models for faster inference via parallel token generation. We provide a rigorous foundation for this advantage by formalizing a model of parallel sampling and showing that DLMs augmented with polynomial-length chain-of-thought (CoT) can simulate any parallel sampling algorithm using an optimal number of sequential steps. Consequently, whenever a target distribution can be generated using a small number of sequential steps, a DLM can be used to generate the distribution using the same number of optimal sequential steps. However, without the ability to modify previously revealed tokens, DLMs with CoT can still incur large intermediate footprints. We prove that enabling remasking (converting unmasked tokens to masks) or revision (converting unmasked tokens to other unmasked tokens) together with CoT further allows DLMs to simulate any parallel sampling algorithm with optimal space complexity. We further justify the advantage of revision by establishing a strict expressivity gap: DLMs with revision or remasking are strictly more expressive than those without. Our results not only provide a theoretical justification for the promise of DLMs as the most efficient parallel sampler, but also advocate for enabling revision in DLMs.",
      "authors": [
        "Haozhe Jiang",
        "Nika Haghtalab",
        "Lijie Chen"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CC"
      ],
      "published": "2025-12-31 18:03:05+00:00",
      "link": "https://arxiv.org/pdf/2512.25014v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2512.24999v1",
      "title": "Basic Inequalities for First-Order Optimization with Applications to Statistical Risk Analysis",
      "abstract": "We introduce \\textit{basic inequalities} for first-order iterative optimization algorithms, forming a simple and versatile framework that connects implicit and explicit regularization. While related inequalities appear in the literature, we isolate and highlight a specific form and develop it as a well-rounded tool for statistical analysis. Let $f$ denote the objective function to be optimized. Given a first-order iterative algorithm initialized at $θ_0$ with current iterate $θ_T$, the basic inequality upper bounds $f(θ_T)-f(z)$ for any reference point $z$ in terms of the accumulated step sizes and the distances between $θ_0$, $θ_T$, and $z$. The bound translates the number of iterations into an effective regularization coefficient in the loss function. We demonstrate this framework through analyses of training dynamics and prediction risk bounds. In addition to revisiting and refining known results on gradient descent, we provide new results for mirror descent with Bregman divergence projection, for generalized linear models trained by gradient descent and exponentiated gradient descent, and for randomized predictors. We illustrate and supplement these theoretical findings with experiments on generalized linear models.",
      "authors": [
        "Seunghoon Paik",
        "Kangjie Zhou",
        "Matus Telgarsky",
        "Ryan J. Tibshirani"
      ],
      "primary_category": "math.ST",
      "categories": [
        "math.ST",
        "cs.LG",
        "math.NA",
        "math.OC",
        "stat.ML"
      ],
      "published": "2025-12-31 17:49:37+00:00",
      "link": "https://arxiv.org/pdf/2512.24999v1",
      "tags": [
        "sr-bench"
      ]
    },
    {
      "id": "2512.24991v1",
      "title": "Efficiently Estimating Data Efficiency for Language Model Fine-tuning",
      "abstract": "While large language models (LLMs) demonstrate reasonable zero-shot capability across many downstream tasks, fine-tuning is a common practice to improve their performance. However, a task's data efficiency--i.e., the number of fine-tuning examples needed to achieve a desired level of performance--is often unknown, resulting in costly cycles of incremental annotation and retraining. Indeed, we demonstrate across a curated set of 30 specialized tasks that performant LLMs may struggle zero-shot but can attain stronger performance after fine-tuning. This motivates the need for methods to predict a task's data efficiency without requiring incremental annotation. After introducing a concrete metric that quantifies a task's data efficiency, we propose using the gradient cosine similarity of low-confidence examples to predict data efficiency based on a small number of labeled samples. We validate our approach on a diverse set of tasks with varying data efficiencies, attaining 8.6% error in overall data efficiency prediction and typically eliminating hundreds of unnecessary annotations on each task. Our experiment results and implementation code are available on GitHub.",
      "authors": [
        "Gyung Hyun Je",
        "Colin Raffel"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2025-12-31 17:37:29+00:00",
      "link": "https://arxiv.org/pdf/2512.24991v1",
      "tags": [
        "sr-bench",
        "大厂llm"
      ]
    },
    {
      "id": "2512.24977v1",
      "title": "SymSeqBench: a unified framework for the generation and analysis of rule-based symbolic sequences and datasets",
      "abstract": "Sequential structure is a key feature of multiple domains of natural cognition and behavior, such as language, movement and decision-making. Likewise, it is also a central property of tasks to which we would like to apply artificial intelligence. It is therefore of great importance to develop frameworks that allow us to evaluate sequence learning and processing in a domain agnostic fashion, whilst simultaneously providing a link to formal theories of computation and computability. To address this need, we introduce two complementary software tools: SymSeq, designed to rigorously generate and analyze structured symbolic sequences, and SeqBench, a comprehensive benchmark suite of rule-based sequence processing tasks to evaluate the performance of artificial learning systems in cognitively relevant domains. In combination, SymSeqBench offers versatility in investigating sequential structure across diverse knowledge domains, including experimental psycholinguistics, cognitive psychology, behavioral analysis, neuromorphic computing and artificial intelligence. Due to its basis in Formal Language Theory (FLT), SymSeqBench provides researchers in multiple domains with a convenient and practical way to apply the concepts of FLT to conceptualize and standardize their experiments, thus advancing our understanding of cognition and behavior through shared computational frameworks and formalisms. The tool is modular, openly available and accessible to the research community.",
      "authors": [
        "Barna Zajzon",
        "Younes Bouhadjar",
        "Maxime Fabre",
        "Felix Schmidt",
        "Noah Ostendorf",
        "Emre Neftci",
        "Abigail Morrison",
        "Renato Duarte"
      ],
      "primary_category": "q-bio.NC",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "published": "2025-12-31 17:18:26+00:00",
      "link": "https://arxiv.org/pdf/2512.24977v1",
      "tags": [
        "sr-bench",
        "符号回归（示例）"
      ]
    },
    {
      "id": "2512.24971v1",
      "title": "Evaluating the Impact of Compression Techniques on the Robustness of CNNs under Natural Corruptions",
      "abstract": "Compressed deep learning models are crucial for deploying computer vision systems on resource-constrained devices. However, model compression may affect robustness, especially under natural corruption. Therefore, it is important to consider robustness evaluation while validating computer vision systems. This paper presents a comprehensive evaluation of compression techniques - quantization, pruning, and weight clustering applied individually and in combination to convolutional neural networks (ResNet-50, VGG-19, and MobileNetV2). Using the CIFAR-10-C and CIFAR 100-C datasets, we analyze the trade-offs between robustness, accuracy, and compression ratio. Our results show that certain compression strategies not only preserve but can also improve robustness, particularly on networks with more complex architectures. Utilizing multiobjective assessment, we determine the best configurations, showing that customized technique combinations produce beneficial multi-objective results. This study provides insights into selecting compression methods for robust and efficient deployment of models in corrupted real-world environments.",
      "authors": [
        "Itallo Patrick Castro Alves Da Silva",
        "Emanuel Adler Medeiros Pereira",
        "Erick de Andrade Barboza",
        "Baldoino Fonseca dos Santos Neto",
        "Marcio de Medeiros Ribeiro"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2025-12-31 17:00:01+00:00",
      "link": "https://arxiv.org/pdf/2512.24971v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2512.24969v1",
      "title": "Large language models and the entropy of English",
      "abstract": "We use large language models (LLMs) to uncover long-ranged structure in English texts from a variety of sources. The conditional entropy or code length in many cases continues to decrease with context length at least to $N\\sim 10^4$ characters, implying that there are direct dependencies or interactions across these distances. A corollary is that there are small but significant correlations between characters at these separations, as we show from the data independent of models. The distribution of code lengths reveals an emergent certainty about an increasing fraction of characters at large $N$. Over the course of model training, we observe different dynamics at long and short context lengths, suggesting that long-ranged structure is learned only gradually. Our results constrain efforts to build statistical physics models of LLMs or language itself.",
      "authors": [
        "Colin Scheibner",
        "Lindsay M. Smith",
        "William Bialek"
      ],
      "primary_category": "cond-mat.stat-mech",
      "categories": [
        "cond-mat.stat-mech",
        "cs.CL",
        "physics.bio-ph",
        "q-bio.NC"
      ],
      "published": "2025-12-31 16:54:44+00:00",
      "link": "https://arxiv.org/pdf/2512.24969v1",
      "tags": [
        "sr-bench",
        "大厂llm"
      ]
    },
    {
      "id": "2512.24968v1",
      "title": "The Impact of LLMs on Online News Consumption and Production",
      "abstract": "Large language models (LLMs) change how consumers acquire information online; their bots also crawl news publishers' websites for training data and to answer consumer queries; and they provide tools that can lower the cost of content creation. These changes lead to predictions of adverse impact on news publishers in the form of lowered consumer demand, reduced demand for newsroom employees, and an increase in news \"slop.\" Consequently, some publishers strategically responded by blocking LLM access to their websites using the robots.txt file standard.   Using high-frequency granular data, we document four effects related to the predicted shifts in news publishing following the introduction of generative AI (GenAI). First, we find a consistent and moderate decline in traffic to news publishers occurring after August 2024. Second, using a difference-in-differences approach, we find that blocking GenAI bots can have adverse effects on large publishers by reducing total website traffic by 23% and real consumer traffic by 14% compared to not blocking. Third, on the hiring side, we do not find evidence that LLMs are replacing editorial or content-production jobs yet. The share of new editorial and content-production job listings increases over time. Fourth, regarding content production, we find no evidence that large publishers increased text volume; instead, they significantly increased rich content and use more advertising and targeting technologies.   Together, these findings provide early evidence of some unforeseen impacts of the introduction of LLMs on news production and consumption.",
      "authors": [
        "Hangcheng Zhao",
        "Ron Berman"
      ],
      "primary_category": "econ.GN",
      "categories": [
        "econ.GN",
        "cs.AI",
        "cs.CY",
        "stat.AP"
      ],
      "published": "2025-12-31 16:54:29+00:00",
      "link": "https://arxiv.org/pdf/2512.24968v1",
      "tags": [
        "大厂llm"
      ]
    },
    {
      "id": "2512.24965v1",
      "title": "ShowUI-$π$: Flow-based Generative Models as GUI Dexterous Hands",
      "abstract": "Building intelligent agents capable of dexterous manipulation is essential for achieving human-like automation in both robotics and digital environments. However, existing GUI agents rely on discrete click predictions (x,y), which prohibits free-form, closed-loop trajectories (e.g. dragging a progress bar) that require continuous, on-the-fly perception and adjustment. In this work, we develop ShowUI-$π$, the first flow-based generative model as GUI dexterous hand, featuring the following designs: (i) Unified Discrete-Continuous Actions, integrating discrete clicks and continuous drags within a shared model, enabling flexible adaptation across diverse interaction modes; (ii) Flow-based Action Generation for drag modeling, which predicts incremental cursor adjustments from continuous visual observations via a lightweight action expert, ensuring smooth and stable trajectories; (iii) Drag Training data and Benchmark, where we manually collect and synthesize 20K drag trajectories across five domains (e.g. PowerPoint, Adobe Premiere Pro), and introduce ScreenDrag, a benchmark with comprehensive online and offline evaluation protocols for assessing GUI agents' drag capabilities. Our experiments show that proprietary GUI agents still struggle on ScreenDrag (e.g. Operator scores 13.27, and the best Gemini-2.5-CUA reaches 22.18). In contrast, ShowUI-$π$ achieves 26.98 with only 450M parameters, underscoring both the difficulty of the task and the effectiveness of our approach. We hope this work advances GUI agents toward human-like dexterous control in digital world. The code is available at https://github.com/showlab/showui-pi.",
      "authors": [
        "Siyuan Hu",
        "Kevin Qinghong Lin",
        "Mike Zheng Shou"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC"
      ],
      "published": "2025-12-31 16:51:14+00:00",
      "link": "https://arxiv.org/pdf/2512.24965v1",
      "tags": [
        "大厂llm",
        "大语言模型"
      ]
    },
    {
      "id": "2512.24959v1",
      "title": "Semi-overlapping Multi-bandit Best Arm Identification for Sequential Support Network Learning",
      "abstract": "Many modern AI and ML problems require evaluating partners' contributions through shared yet asymmetric, computationally intensive processes and the simultaneous selection of the most beneficial candidates. Sequential approaches to these problems can be unified under a new framework, Sequential Support Network Learning (SSNL), in which the goal is to select the most beneficial candidate set of partners for all participants using trials; that is, to learn a directed graph that represents the highest-performing contributions. We demonstrate that a new pure-exploration model, the semi-overlapping multi-(multi-armed) bandit (SOMMAB), in which a single evaluation provides distinct feedback to multiple bandits due to structural overlap among their arms, can be used to learn a support network from sparse candidate lists efficiently.   We develop a generalized GapE algorithm for SOMMABs and derive new exponential error bounds that improve the best known constant in the exponent for multi-bandit best-arm identification. The bounds scale linearly with the degree of overlap, revealing significant sample-complexity gains arising from shared evaluations.   From an application point of view, this work provides a theoretical foundation and improved performance guarantees for sequential learning tools for identifying support networks from sparse candidates in multiple learning problems, such as in multi-task learning (MTL), auxiliary task learning (ATL), federated learning (FL), and in multi-agent systems (MAS).",
      "authors": [
        "András Antos",
        "András Millinghoffer",
        "Péter Antal"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2025-12-31 16:42:00+00:00",
      "link": "https://arxiv.org/pdf/2512.24959v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2512.24948v1",
      "title": "ProDM: Synthetic Reality-driven Property-aware Progressive Diffusion Model for Coronary Calcium Motion Correction in Non-gated Chest CT",
      "abstract": "Coronary artery calcium (CAC) scoring from chest CT is a well-established tool to stratify and refine clinical cardiovascular disease risk estimation. CAC quantification relies on the accurate delineation of calcified lesions, but is oftentimes affected by artifacts introduced by cardiac and respiratory motion. ECG-gated cardiac CTs substantially reduce motion artifacts, but their use in population screening and routine imaging remains limited due to gating requirements and lack of insurance coverage. Although identification of incidental CAC from non-gated chest CT is increasingly considered for it offers an accessible and widely available alternative, this modality is limited by more severe motion artifacts. We present ProDM (Property-aware Progressive Correction Diffusion Model), a generative diffusion framework that restores motion-free calcified lesions from non-gated CTs. ProDM introduces three key components: (1) a CAC motion simulation data engine that synthesizes realistic non-gated acquisitions with diverse motion trajectories directly from cardiac-gated CTs, enabling supervised training without paired data; (2) a property-aware learning strategy incorporating calcium-specific priors through a differentiable calcium consistency loss to preserve lesion integrity; and (3) a progressive correction scheme that reduces artifacts gradually across diffusion steps to enhance stability and calcium fidelity. Experiments on real patient datasets show that ProDM significantly improves CAC scoring accuracy, spatial lesion fidelity, and risk stratification performance compared with several baselines. A reader study on real non-gated scans further confirms that ProDM suppresses motion artifacts and improves clinical usability. These findings highlight the potential of progressive, property-aware frameworks for reliable CAC quantification from routine chest CT imaging.",
      "authors": [
        "Xinran Gong",
        "Gorkem Durak",
        "Halil Ertugrul Aktas",
        "Vedat Cicek",
        "Jinkui Hao",
        "Ulas Bagci",
        "Nilay S. Shah",
        "Bo Zhou"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "published": "2025-12-31 16:29:05+00:00",
      "link": "https://arxiv.org/pdf/2512.24948v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2512.24946v1",
      "title": "HaineiFRDM: Explore Diffusion to Restore Defects in Fast-Movement Films",
      "abstract": "Existing open-source film restoration methods show limited performance compared to commercial methods due to training with low-quality synthetic data and employing noisy optical flows. In addition, high-resolution films have not been explored by the open-source methods.We propose HaineiFRDM(Film Restoration Diffusion Model), a film restoration framework, to explore diffusion model's powerful content-understanding ability to help human expert better restore indistinguishable film defects.Specifically, we employ a patch-wise training and testing strategy to make restoring high-resolution films on one 24GB-VRAMR GPU possible and design a position-aware Global Prompt and Frame Fusion Modules.Also, we introduce a global-local frequency module to reconstruct consistent textures among different patches. Besides, we firstly restore a low-resolution result and use it as global residual to mitigate blocky artifacts caused by patching process.Furthermore, we construct a film restoration dataset that contains restored real-degraded films and realistic synthetic data.Comprehensive experimental results conclusively demonstrate the superiority of our model in defect restoration ability over existing open-source methods. Code and the dataset will be released.",
      "authors": [
        "Rongji Xun",
        "Junjie Yuan",
        "Zhongjie Wang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "published": "2025-12-31 16:18:07+00:00",
      "link": "https://arxiv.org/pdf/2512.24946v1",
      "tags": [
        "大厂llm",
        "大语言模型"
      ]
    },
    {
      "id": "2512.24943v1",
      "title": "RAIR: A Rule-Aware Benchmark Uniting Challenging Long-Tail and Visual Salience Subset for E-commerce Relevance Assessment",
      "abstract": "Search relevance plays a central role in web e-commerce. While large language models (LLMs) have shown significant results on relevance task, existing benchmarks lack sufficient complexity for comprehensive model assessment, resulting in an absence of standardized relevance evaluation metrics across the industry. To address this limitation, we propose Rule-Aware benchmark with Image for Relevance assessment(RAIR), a Chinese dataset derived from real-world scenarios. RAIR established a standardized framework for relevance assessment and provides a set of universal rules, which forms the foundation for standardized evaluation. Additionally, RAIR analyzes essential capabilities required for current relevance models and introduces a comprehensive dataset consists of three subset: (1) a general subset with industry-balanced sampling to evaluate fundamental model competencies; (2) a long-tail hard subset focus on challenging cases to assess performance limits; (3) a visual salience subset for evaluating multimodal understanding capabilities. We conducted experiments on RAIR using 14 open and closed-source models. The results demonstrate that RAIR presents sufficient challenges even for GPT-5, which achieved the best performance. RAIR data are now available, serving as an industry benchmark for relevance assessment while providing new insights into general LLM and Visual Language Model(VLM) evaluation.",
      "authors": [
        "Chenji Lu",
        "Zhuo Chen",
        "Hui Zhao",
        "Zhenyi Wang",
        "Pengjie Wang",
        "Jian Xu",
        "Bo Zheng"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "published": "2025-12-31 16:09:08+00:00",
      "link": "https://arxiv.org/pdf/2512.24943v1",
      "tags": [
        "sr-bench",
        "大厂llm"
      ]
    },
    {
      "id": "2512.24927v1",
      "title": "Are First-Order Diffusion Samplers Really Slower? A Fast Forward-Value Approach",
      "abstract": "Higher-order ODE solvers have become a standard tool for accelerating diffusion probabilistic model (DPM) sampling, motivating the widespread view that first-order methods are inherently slower and that increasing discretization order is the primary path to faster generation. This paper challenges this belief and revisits acceleration from a complementary angle: beyond solver order, the placement of DPM evaluations along the reverse-time dynamics can substantially affect sampling accuracy in the low-neural function evaluation (NFE) regime.   We propose a novel training-free, first-order sampler whose leading discretization error has the opposite sign to that of DDIM. Algorithmically, the method approximates the forward-value evaluation via a cheap one-step lookahead predictor. We provide theoretical guarantees showing that the resulting sampler provably approximates the ideal forward-value trajectory while retaining first-order convergence. Empirically, across standard image generation benchmarks (CIFAR-10, ImageNet, FFHQ, and LSUN), the proposed sampler consistently improves sample quality under the same NFE budget and can be competitive with, and sometimes outperform, state-of-the-art higher-order samplers. Overall, the results suggest that the placement of DPM evaluations provides an additional and largely independent design angle for accelerating diffusion sampling.",
      "authors": [
        "Yuchen Jiao",
        "Na Li",
        "Changxiao Cai",
        "Gen Li"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.LG",
        "math.ST"
      ],
      "published": "2025-12-31 15:35:53+00:00",
      "link": "https://arxiv.org/pdf/2512.24927v1",
      "tags": [
        "sr-bench",
        "大厂llm"
      ]
    },
    {
      "id": "2512.24903v1",
      "title": "FinMMDocR: Benchmarking Financial Multimodal Reasoning with Scenario Awareness, Document Understanding, and Multi-Step Computation",
      "abstract": "We introduce FinMMDocR, a novel bilingual multimodal benchmark for evaluating multimodal large language models (MLLMs) on real-world financial numerical reasoning. Compared to existing benchmarks, our work delivers three major advancements. (1) Scenario Awareness: 57.9% of 1,200 expert-annotated problems incorporate 12 types of implicit financial scenarios (e.g., Portfolio Management), challenging models to perform expert-level reasoning based on assumptions; (2) Document Understanding: 837 Chinese/English documents spanning 9 types (e.g., Company Research) average 50.8 pages with rich visual elements, significantly surpassing existing benchmarks in both breadth and depth of financial documents; (3) Multi-Step Computation: Problems demand 11-step reasoning on average (5.3 extraction + 5.7 calculation steps), with 65.0% requiring cross-page evidence (2.4 pages average). The best-performing MLLM achieves only 58.0% accuracy, and different retrieval-augmented generation (RAG) methods show significant performance variations on this task. We expect FinMMDocR to drive improvements in MLLMs and reasoning-enhanced methods on complex multimodal reasoning tasks in real-world scenarios.",
      "authors": [
        "Zichen Tang",
        "Haihong E",
        "Rongjin Li",
        "Jiacheng Liu",
        "Linwei Jia",
        "Zhuodi Hao",
        "Zhongjun Yang",
        "Yuanze Li",
        "Haolin Tian",
        "Xinyi Hu",
        "Peizhi Zhao",
        "Yuan Liu",
        "Zhengyu Wang",
        "Xianghe Wang",
        "Yiling Huang",
        "Xueyuan Lin",
        "Ruofei Bai",
        "Zijian Xie",
        "Qian Huang",
        "Ruining Cao",
        "Haocheng Gao"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.CE"
      ],
      "published": "2025-12-31 15:00:03+00:00",
      "link": "https://arxiv.org/pdf/2512.24903v1",
      "tags": [
        "sr-bench",
        "大厂llm"
      ]
    },
    {
      "id": "2512.24898v1",
      "title": "PRISM: A hierarchical multiscale approach for time series forecasting",
      "abstract": "Forecasting is critical in areas such as finance, biology, and healthcare. Despite the progress in the field, making accurate forecasts remains challenging because real-world time series contain both global trends, local fine-grained structure, and features on multiple scales in between. Here, we present a new forecasting method, PRISM (Partitioned Representation for Iterative Sequence Modeling), that addresses this challenge through a learnable tree-based partitioning of the signal. At the root of the tree, a global representation captures coarse trends in the signal, while recursive splits reveal increasingly localized views of the signal. At each level of the tree, data are projected onto a time-frequency basis (e.g., wavelets or exponential moving averages) to extract scale-specific features, which are then aggregated across the hierarchy. This design allows the model to jointly capture global structure and local dynamics of the signal, enabling accurate forecasting. Experiments across benchmark datasets show that our method outperforms state-of-the-art methods for forecasting. Overall, these results demonstrate that our hierarchical approach provides a lightweight and flexible framework for forecasting multivariate time series. The code is available at https://github.com/nerdslab/prism.",
      "authors": [
        "Zihao Chen",
        "Alexandre Andre",
        "Wenrui Ma",
        "Ian Knight",
        "Sergey Shuvaev",
        "Eva Dyer"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2025-12-31 14:51:12+00:00",
      "link": "https://arxiv.org/pdf/2512.24898v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2512.24888v1",
      "title": "SoK: Web3 RegTech for Cryptocurrency VASP AML/CFT Compliance",
      "abstract": "The decentralized architecture of Web3 technologies creates fundamental challenges for Anti-Money Laundering and Counter-Financing of Terrorism compliance. Traditional regulatory technology solutions designed for centralized financial systems prove inadequate for blockchain's transparent yet pseudonymous networks. This systematization examines how blockchain-native RegTech solutions leverage distributed ledger properties to enable novel compliance capabilities.   We develop three taxonomies organizing the Web3 RegTech domain: a regulatory paradigm evolution framework across ten dimensions, a compliance protocol taxonomy encompassing five verification layers, and a RegTech lifecycle framework spanning preventive, real-time, and investigative phases. Through analysis of 41 operational commercial platforms and 28 academic prototypes selected from systematic literature review (2015-2025), we demonstrate that Web3 RegTech enables transaction graph analysis, real-time risk assessment, cross-chain analytics, and privacy-preserving verification approaches that are difficult to achieve or less commonly deployed in traditional centralized systems.   Our analysis reveals critical gaps between academic innovation and industry deployment, alongside persistent challenges in cross-chain tracking, DeFi interaction analysis, privacy protocol monitoring, and scalability. We synthesize architectural best practices and identify research directions addressing these gaps while respecting Web3's core principles of decentralization, transparency, and user sovereignty.",
      "authors": [
        "Qian'ang Mao",
        "Jiaxin Wang",
        "Ya Liu",
        "Li Zhu",
        "Jiaman Chen",
        "Jiaqi Yan"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR",
        "cs.SE"
      ],
      "published": "2025-12-31 14:31:29+00:00",
      "link": "https://arxiv.org/pdf/2512.24888v1",
      "tags": [
        "大厂llm",
        "符号回归（示例）"
      ]
    },
    {
      "id": "2512.24864v1",
      "title": "On Prime Matrix Product Factorizations",
      "abstract": "A graph $G$ factors into graphs $H$ and $K$ via a matrix product if $A = BC$, where $A$, $B$, and $C$ are the adjacency matrices of $G$, $H$, and $K$, respectively. The graph $G$ is prime if, in every such factorization, one of the factors is a perfect matching that is, it corresponds to a permutation matrix. We characterize all prime graphs, then using this result we classify all factorable forests, answering a question of Akbari et al. [\\emph{Linear Algebra and its Applications} (2025)]. We prove that every torus is factorable, and we characterize all possible factorizations of grids, addressing two questions posed by Maghsoudi et al. [\\emph{Journal of Algebraic Combinatorics} (2025)].",
      "authors": [
        "Saieed Akbari",
        "Mohamad Parsa Elahimanes",
        "Bobby Miraftab"
      ],
      "primary_category": "math.CO",
      "categories": [
        "math.CO",
        "cs.DM"
      ],
      "published": "2025-12-31 13:53:32+00:00",
      "link": "https://arxiv.org/pdf/2512.24864v1",
      "tags": [
        "sr-bench"
      ]
    },
    {
      "id": "2512.24860v1",
      "title": "Approximate Computation via Le Cam Simulability",
      "abstract": "We propose a decision-theoretic framework for computational complexity, complementary to classical theory: moving from syntactic exactness (Turing / Shannon) to semantic simulability (Le Cam). While classical theory classifies problems by the cost of exact solution, modern computation often seeks only decision-valid approximations. We introduce a framework where \"computation\" is viewed as the efficient simulation of a target statistical experiment within a bounded risk distortion (Le Cam deficiency).   We formally define computational deficiency ($δ_{\\text{poly}}$) and use it to construct the complexity class LeCam-P (Decision-Robust Polynomial Time), characterizing problems that may be syntactically hard but semantically easy to approximate. We show that classical Karp reductions can be viewed as zero-deficiency simulations, and that approximate reductions correspond to bounded deficiency. Furthermore, we establish the No-Free-Transfer Inequality, showing that strictly invariant representations inevitably destroy decision-relevant information. This framework offers a statistical perspective on approximation theory, bridging the gap between algorithmic complexity and decision theory.",
      "authors": [
        "Deniz Akdemir"
      ],
      "primary_category": "math.ST",
      "categories": [
        "math.ST",
        "cs.CC",
        "cs.IT"
      ],
      "published": "2025-12-31 13:40:02+00:00",
      "link": "https://arxiv.org/pdf/2512.24860v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2512.24847v1",
      "title": "AODDiff: Probabilistic Reconstruction of Aerosol Optical Depth via Diffusion-based Bayesian Inference",
      "abstract": "High-quality reconstruction of Aerosol Optical Depth (AOD) fields is critical for Atmosphere monitoring, yet current models remain constrained by the scarcity of complete training data and a lack of uncertainty quantification.To address these limitations, we propose AODDiff, a probabilistic reconstruction framework based on diffusion-based Bayesian inference. By leveraging the learned spatiotemporal probability distribution of the AOD field as a generative prior, this framework can be flexibly adapted to various reconstruction tasks without requiring task-specific retraining. We first introduce a corruption-aware training strategy to learns a spatiotemporal AOD prior solely from naturally incomplete data. Subsequently, we employ a decoupled annealing posterior sampling strategy that enables the more effective and integration of heterogeneous observations as constraints to guide the generation process. We validate the proposed framework through extensive experiments on Reanalysis data. Results across downscaling and inpainting tasks confirm the efficacy and robustness of AODDiff, specifically demonstrating its advantage in maintaining high spatial spectral fidelity. Furthermore, as a generative model, AODDiff inherently enables uncertainty quantification via multiple sampling, offering critical confidence metrics for downstream applications.",
      "authors": [
        "Linhao Fan",
        "Hongqiang Fang",
        "Jingyang Dai",
        "Yong Jiang",
        "Qixing Zhang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "physics.ao-ph"
      ],
      "published": "2025-12-31 13:16:10+00:00",
      "link": "https://arxiv.org/pdf/2512.24847v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2512.24824v1",
      "title": "LMG Index: A Robust Learned Index for Multi-Dimensional Performance Balance",
      "abstract": "Index structures are fundamental for efficient query processing on large-scale datasets. Learned indexes model the indexing process as a prediction problem to overcome the inherent trade-offs of traditional indexes. However, most existing learned indexes optimize only for limited objectives like query latency or space usage, neglecting other practical evaluation dimensions such as update efficiency and stability. Moreover, many learned indexes rely on assumptions about data distributions or workloads, lacking theoretical guarantees when facing unknown or evolving scenarios, which limits their generality in real-world systems.   In this paper, we propose LMIndex, a robust framework for learned indexing that leverages a efficient query/update top-layer structure (theoretically $O(1)$ when the key type is fixed) and a efficient optimal error threshold training algorithm (approach $O(1)$ in practice). Building upon this, we develop LMG (LMIndex with gaps), a variant employing a novel gap allocation strategy to enhance update performance and maintain stability under dynamic workloads. Extensive evaluations show that LMG achieves competitive or leading performance, including bulk loading (up to 8.25$\\times$ faster), point queries (up to 1.49$\\times$ faster), range queries (up to 4.02$\\times$ faster than B+Tree), update (up to 1.5$\\times$ faster on read-write workloads), stability (up to 82.59$\\times$ lower coefficient of variation), and space usage (up to 1.38$\\times$ smaller). These results demonstrate that LMG effectively breaks the multi-dimensional performance trade-offs inherent in state-of-the-art approaches, offering a balanced and versatile framework.",
      "authors": [
        "Yuzhen Chen",
        "Bin Yao"
      ],
      "primary_category": "cs.DB",
      "categories": [
        "cs.DB"
      ],
      "published": "2025-12-31 12:25:12+00:00",
      "link": "https://arxiv.org/pdf/2512.24824v1",
      "tags": [
        "sr-bench",
        "大厂llm"
      ]
    },
    {
      "id": "2512.24772v1",
      "title": "Uncertainty-aware Semi-supervised Ensemble Teacher Framework for Multilingual Depression Detection",
      "abstract": "Detecting depression from social media text is still a challenging task. This is due to different language styles, informal expression, and the lack of annotated data in many languages. To tackle these issues, we propose, Semi-SMDNet, a strong Semi-Supervised Multilingual Depression detection Network. It combines teacher-student pseudo-labelling, ensemble learning, and augmentation of data. Our framework uses a group of teacher models. Their predictions come together through soft voting. An uncertainty-based threshold filters out low-confidence pseudo-labels to reduce noise and improve learning stability. We also use a confidence-weighted training method that focuses on reliable pseudo-labelled samples. This greatly boosts robustness across languages. Tests on Arabic, Bangla, English, and Spanish datasets show that our approach consistently beats strong baselines. It significantly reduces the performance gap between settings that have plenty of resources and those that do not. Detailed experiments and studies confirm that our framework is effective and can be used in various situations. This shows that it is suitable for scalable, cross-language mental health monitoring where labelled resources are limited.",
      "authors": [
        "Mohammad Zia Ur Rehman",
        "Velpuru Navya",
        "Sanskar",
        "Shuja Uddin Qureshi",
        "Nagendra Kumar"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2025-12-31 10:35:59+00:00",
      "link": "https://arxiv.org/pdf/2512.24772v1",
      "tags": [
        "sr-bench",
        "符号回归（示例）"
      ]
    },
    {
      "id": "2512.24768v1",
      "title": "Sparse Offline Reinforcement Learning with Corruption Robustness",
      "abstract": "We investigate robustness to strong data corruption in offline sparse reinforcement learning (RL). In our setting, an adversary may arbitrarily perturb a fraction of the collected trajectories from a high-dimensional but sparse Markov decision process, and our goal is to estimate a near optimal policy. The main challenge is that, in the high-dimensional regime where the number of samples $N$ is smaller than the feature dimension $d$, exploiting sparsity is essential for obtaining non-vacuous guarantees but has not been systematically studied in offline RL. We analyse the problem under uniform coverage and sparse single-concentrability assumptions. While Least Square Value Iteration (LSVI), a standard approach for robust offline RL, performs well under uniform coverage, we show that integrating sparsity into LSVI is unnatural, and its analysis may break down due to overly pessimistic bonuses. To overcome this, we propose actor-critic methods with sparse robust estimator oracles, which avoid the use of pointwise pessimistic bonuses and provide the first non-vacuous guarantees for sparse offline RL under single-policy concentrability coverage. Moreover, we extend our results to the contaminated setting and show that our algorithm remains robust under strong contamination. Our results provide the first non-vacuous guarantees in high-dimensional sparse MDPs with single-policy concentrability coverage and corruption, showing that learning a near-optimal policy remains possible in regimes where traditional robust offline RL techniques may fail.",
      "authors": [
        "Nam Phuong Tran",
        "Andi Nika",
        "Goran Radanovic",
        "Long Tran-Thanh",
        "Debmalya Mandal"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "published": "2025-12-31 10:28:25+00:00",
      "link": "https://arxiv.org/pdf/2512.24768v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2512.24766v1",
      "title": "Dream2Flow: Bridging Video Generation and Open-World Manipulation with 3D Object Flow",
      "abstract": "Generative video modeling has emerged as a compelling tool to zero-shot reason about plausible physical interactions for open-world manipulation. Yet, it remains a challenge to translate such human-led motions into the low-level actions demanded by robotic systems. We observe that given an initial image and task instruction, these models excel at synthesizing sensible object motions. Thus, we introduce Dream2Flow, a framework that bridges video generation and robotic control through 3D object flow as an intermediate representation. Our method reconstructs 3D object motions from generated videos and formulates manipulation as object trajectory tracking. By separating the state changes from the actuators that realize those changes, Dream2Flow overcomes the embodiment gap and enables zero-shot guidance from pre-trained video models to manipulate objects of diverse categories-including rigid, articulated, deformable, and granular. Through trajectory optimization or reinforcement learning, Dream2Flow converts reconstructed 3D object flow into executable low-level commands without task-specific demonstrations. Simulation and real-world experiments highlight 3D object flow as a general and scalable interface for adapting video generation models to open-world robotic manipulation. Videos and visualizations are available at https://dream2flow.github.io/.",
      "authors": [
        "Karthik Dharmarajan",
        "Wenlong Huang",
        "Jiajun Wu",
        "Li Fei-Fei",
        "Ruohan Zhang"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "published": "2025-12-31 10:25:24+00:00",
      "link": "https://arxiv.org/pdf/2512.24766v1",
      "tags": [
        "大厂llm"
      ]
    },
    {
      "id": "2512.24762v1",
      "title": "OpenOneRec Technical Report",
      "abstract": "While the OneRec series has successfully unified the fragmented recommendation pipeline into an end-to-end generative framework, a significant gap remains between recommendation systems and general intelligence. Constrained by isolated data, they operate as domain specialists-proficient in pattern matching but lacking world knowledge, reasoning capabilities, and instruction following. This limitation is further compounded by the lack of a holistic benchmark to evaluate such integrated capabilities. To address this, our contributions are: 1) RecIF Bench & Open Data: We propose RecIF-Bench, a holistic benchmark covering 8 diverse tasks that thoroughly evaluate capabilities from fundamental prediction to complex reasoning. Concurrently, we release a massive training dataset comprising 96 million interactions from 160,000 users to facilitate reproducible research. 2) Framework & Scaling: To ensure full reproducibility, we open-source our comprehensive training pipeline, encompassing data processing, co-pretraining, and post-training. Leveraging this framework, we demonstrate that recommendation capabilities can scale predictably while mitigating catastrophic forgetting of general knowledge. 3) OneRec-Foundation: We release OneRec Foundation (1.7B and 8B), a family of models establishing new state-of-the-art (SOTA) results across all tasks in RecIF-Bench. Furthermore, when transferred to the Amazon benchmark, our models surpass the strongest baselines with an average 26.8% improvement in Recall@10 across 10 diverse datasets (Figure 1). This work marks a step towards building truly intelligent recommender systems. Nonetheless, realizing this vision presents significant technical and theoretical challenges, highlighting the need for broader research engagement in this promising direction.",
      "authors": [
        "Guorui Zhou",
        "Honghui Bao",
        "Jiaming Huang",
        "Jiaxin Deng",
        "Jinghao Zhang",
        "Junda She",
        "Kuo Cai",
        "Lejian Ren",
        "Lu Ren",
        "Qiang Luo",
        "Qianqian Wang",
        "Qigen Hu",
        "Rongzhou Zhang",
        "Ruiming Tang",
        "Shiyao Wang",
        "Wuchao Li",
        "Xiangyu Wu",
        "Xinchen Luo",
        "Xingmei Wang",
        "Yifei Hu",
        "Yunfan Wu",
        "Zhanyu Liu",
        "Zhiyang Zhang",
        "Zixing Zhang",
        "Bo Chen",
        "Bin Wen",
        "Chaoyi Ma",
        "Chengru Song",
        "Chenglong Chu",
        "Defu Lian",
        "Fan Yang",
        "Feng Jiang",
        "Hongtao Cheng",
        "Huanjie Wang",
        "Kun Gai",
        "Pengfei Zheng",
        "Qiang Wang",
        "Rui Huang",
        "Siyang Mao",
        "Tingting Gao",
        "Wei Yuan",
        "Yan Wang",
        "Yang Zhou",
        "Yi Su",
        "Zexuan Cheng",
        "Zhixin Ling",
        "Ziming Li"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2025-12-31 10:15:53+00:00",
      "link": "https://arxiv.org/pdf/2512.24762v1",
      "tags": [
        "sr-bench",
        "大厂llm"
      ]
    },
    {
      "id": "2512.24747v1",
      "title": "Fairness-Aware Insurance Pricing: A Multi-Objective Optimization Approach",
      "abstract": "Machine learning improves predictive accuracy in insurance pricing but exacerbates trade-offs between competing fairness criteria across different discrimination measures, challenging regulators and insurers to reconcile profitability with equitable outcomes. While existing fairness-aware models offer partial solutions under GLM and XGBoost estimation methods, they remain constrained by single-objective optimization, failing to holistically navigate a conflicting landscape of accuracy, group fairness, individual fairness, and counterfactual fairness. To address this, we propose a novel multi-objective optimization framework that jointly optimizes all four criteria via the Non-dominated Sorting Genetic Algorithm II (NSGA-II), generating a diverse Pareto front of trade-off solutions. We use a specific selection mechanism to extract a premium on this front. Our results show that XGBoost outperforms GLM in accuracy but amplifies fairness disparities; the Orthogonal model excels in group fairness, while Synthetic Control leads in individual and counterfactual fairness. Our method consistently achieves a balanced compromise, outperforming single-model approaches.",
      "authors": [
        "Tim J. Boonen",
        "Xinyue Fan",
        "Zixiao Quan"
      ],
      "primary_category": "q-fin.RM",
      "categories": [
        "q-fin.RM",
        "cs.LG"
      ],
      "published": "2025-12-31 09:42:03+00:00",
      "link": "https://arxiv.org/pdf/2512.24747v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2512.24740v1",
      "title": "Control of Microrobots with Reinforcement Learning under On-Device Compute Constraints",
      "abstract": "An important function of autonomous microrobots is the ability to perform robust movement over terrain. This paper explores an edge ML approach to microrobot locomotion, allowing for on-device, lower latency control under compute, memory, and power constraints. This paper explores the locomotion of a sub-centimeter quadrupedal microrobot via reinforcement learning (RL) and deploys the resulting controller on an ultra-small system-on-chip (SoC), SC$μ$M-3C, featuring an ARM Cortex-M0 microcontroller running at 5 MHz. We train a compact FP32 multilayer perceptron (MLP) policy with two hidden layers ($[128, 64]$) in a massively parallel GPU simulation and enhance robustness by utilizing domain randomization over simulation parameters. We then study integer (Int8) quantization (per-tensor and per-feature) to allow for higher inference update rates on our resource-limited hardware, and we connect hardware power budgets to achievable update frequency via a cycles-per-update model for inference on our Cortex-M0. We propose a resource-aware gait scheduling viewpoint: given a device power budget, we can select the gait mode (trot/intermediate/gallop) that maximizes expected RL reward at a corresponding feasible update frequency. Finally, we deploy our MLP policy on a real-world large-scale robot on uneven terrain, qualitatively noting that domain-randomized training can improve out-of-distribution stability. We do not claim real-world large-robot empirical zero-shot transfer in this work.",
      "authors": [
        "Yichen Liu",
        "Kesava Viswanadha",
        "Zhongyu Li",
        "Nelson Lojo",
        "Kristofer S. J. Pister"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "eess.SY"
      ],
      "published": "2025-12-31 09:18:36+00:00",
      "link": "https://arxiv.org/pdf/2512.24740v1",
      "tags": [
        "大厂llm",
        "大语言模型"
      ]
    },
    {
      "id": "2512.24733v1",
      "title": "BIOME-Bench: A Benchmark for Biomolecular Interaction Inference and Multi-Omics Pathway Mechanism Elucidation from Scientific Literature",
      "abstract": "Multi-omics studies often rely on pathway enrichment to interpret heterogeneous molecular changes, but pathway enrichment (PE)-based workflows inherit structural limitations of pathway resources, including curation lag, functional redundancy, and limited sensitivity to molecular states and interventions. Although recent work has explored using large language models (LLMs) to improve PE-based interpretation, the lack of a standardized benchmark for end-to-end multi-omics pathway mechanism elucidation has largely confined evaluation to small, manually curated datasets or ad hoc case studies, hindering reproducible progress. To address this issue, we introduce BIOME-Bench, constructed via a rigorous four-stage workflow, to evaluate two core capabilities of LLMs in multi-omics analysis: Biomolecular Interaction Inference and end-to-end Multi-Omics Pathway Mechanism Elucidation. We develop evaluation protocols for both tasks and conduct comprehensive experiments across multiple strong contemporary models. Experimental results demonstrate that existing models still exhibit substantial deficiencies in multi-omics analysis, struggling to reliably distinguish fine-grained biomolecular relation types and to generate faithful, robust pathway-level mechanistic explanations.",
      "authors": [
        "Sibo Wei",
        "Peng Chen",
        "Lifeng Dong",
        "Yin Luo",
        "Lei Wang",
        "Peng Zhang",
        "Wenpeng Lu",
        "Jianbin Guo",
        "Hongjun Yang",
        "Dajun Zeng"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2025-12-31 09:01:27+00:00",
      "link": "https://arxiv.org/pdf/2512.24733v1",
      "tags": [
        "sr-bench"
      ]
    },
    {
      "id": "2512.24724v1",
      "title": "FlowBlending: Stage-Aware Multi-Model Sampling for Fast and High-Fidelity Video Generation",
      "abstract": "In this work, we show that the impact of model capacity varies across timesteps: it is crucial for the early and late stages but largely negligible during the intermediate stage. Accordingly, we propose FlowBlending, a stage-aware multi-model sampling strategy that employs a large model and a small model at capacity-sensitive stages and intermediate stages, respectively. We further introduce simple criteria to choose stage boundaries and provide a velocity-divergence analysis as an effective proxy for identifying capacity-sensitive regions. Across LTX-Video (2B/13B) and WAN 2.1 (1.3B/14B), FlowBlending achieves up to 1.65x faster inference with 57.35% fewer FLOPs, while maintaining the visual fidelity, temporal coherence, and semantic alignment of the large models. FlowBlending is also compatible with existing sampling-acceleration techniques, enabling up to 2x additional speedup. Project page is available at: https://jibin86.github.io/flowblending_project_page.",
      "authors": [
        "Jibin Song",
        "Mingi Kwon",
        "Jaeseok Jeong",
        "Youngjung Uh"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2025-12-31 08:41:27+00:00",
      "link": "https://arxiv.org/pdf/2512.24724v1",
      "tags": [
        "大厂llm"
      ]
    },
    {
      "id": "2512.24713v1",
      "title": "FPGA Co-Design for Efficient N:M Sparse and Quantized Model Inference",
      "abstract": "Large language models (LLMs) have demonstrated remarkable performance across a wide range of language processing tasks. However, this success comes at the cost of substantial computation and memory requirements, which significantly impedes their deployment in resource-constrained environments. To address this challenge, this work introduces an automation framework that leverages weight pruning and low-bit quantization, and presents a hardware-software co-design method that generates accelerators on the Field-Programmable Gate Array (FPGA) platform. In particular, we implement a unified pipeline that applies N:M structured pruning and 4-bit integer quantization to reduce the memory footprint, followed by optimized dequantization and matrix multiplication to enhance LLM inference on several hardware platforms, including CPUs, NVIDIA GPUs with Dense and 2:4 Sparse Tensor Cores, and a custom systolic-array-based FPGA accelerator. Utilizing 2:4 sparsity combined with quantization on $4096 \\times 4096$ matrices, our approach achieves a reduction of up to $4\\times$ in weight storage and a $1.71\\times$ speedup in matrix multiplication, yielding a $1.29\\times$ end-to-end latency reduction compared to dense GPU baselines. Scaling analysis on the LLaMA-7B model further shows that structured sparsity enhances the throughput per token by $1.36\\times$. These results demonstrate the synergy of fine-grained N:M sparsity and quantization for enabling efficient and deployable LLM inference, while the proposed FPGA accelerator offers a flexible architectural path for supporting a broader class of sparsity patterns beyond the fixed 2:4 hardware constraints.",
      "authors": [
        "Fen-Yu Hsieh",
        "Yun-Chang Teng",
        "Ding-Yong Hong",
        "Jan-Jan Wu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AR"
      ],
      "published": "2025-12-31 08:27:40+00:00",
      "link": "https://arxiv.org/pdf/2512.24713v1",
      "tags": [
        "sr-bench",
        "大厂llm",
        "大语言模型"
      ]
    },
    {
      "id": "2512.24711v1",
      "title": "MEIC-DT: Memory-Efficient Incremental Clustering for Long-Text Coreference Resolution with Dual-Threshold Constraints",
      "abstract": "In the era of large language models (LLMs), supervised neural methods remain the state-of-the-art (SOTA) for Coreference Resolution. Yet, their full potential is underexplored, particularly in incremental clustering, which faces the critical challenge of balancing efficiency with performance for long texts. To address the limitation, we propose \\textbf{MEIC-DT}, a novel dual-threshold, memory-efficient incremental clustering approach based on a lightweight Transformer. MEIC-DT features a dual-threshold constraint mechanism designed to precisely control the Transformer's input scale within a predefined memory budget. This mechanism incorporates a Statistics-Aware Eviction Strategy (\\textbf{SAES}), which utilizes distinct statistical profiles from the training and inference phases for intelligent cache management. Furthermore, we introduce an Internal Regularization Policy (\\textbf{IRP}) that strategically condenses clusters by selecting the most representative mentions, thereby preserving semantic integrity. Extensive experiments on common benchmarks demonstrate that MEIC-DT achieves highly competitive coreference performance under stringent memory constraints.",
      "authors": [
        "Kangyang Luo",
        "Shuzheng Si",
        "Yuzhuo Bai",
        "Cheng Gao",
        "Zhitong Wang",
        "Cheng Huang",
        "Yingli Shen",
        "Yufeng Han",
        "Wenhao Li",
        "Cunliang Kong",
        "Maosong Sun"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2025-12-31 08:26:34+00:00",
      "link": "https://arxiv.org/pdf/2512.24711v1",
      "tags": [
        "大厂llm"
      ]
    },
    {
      "id": "2512.24702v1",
      "title": "Evolving, Not Training: Zero-Shot Reasoning Segmentation via Evolutionary Prompting",
      "abstract": "Reasoning Segmentation requires models to interpret complex, context-dependent linguistic queries to achieve pixel-level localization. Current dominant approaches rely heavily on Supervised Fine-Tuning (SFT) or Reinforcement Learning (RL). However, SFT suffers from catastrophic forgetting and domain dependency, while RL is often hindered by training instability and rigid reliance on predefined reward functions. Although recent training-free methods circumvent these training burdens, they are fundamentally limited by a static inference paradigm. These methods typically rely on a single-pass \"generate-then-segment\" chain, which suffers from insufficient reasoning depth and lacks the capability to self-correct linguistic hallucinations or spatial misinterpretations. In this paper, we challenge these limitations and propose EVOL-SAM3, a novel zero-shot framework that reformulates reasoning segmentation as an inference-time evolutionary search process. Instead of relying on a fixed prompt, EVOL-SAM3 maintains a population of prompt hypotheses and iteratively refines them through a \"Generate-Evaluate-Evolve\" loop. We introduce a Visual Arena to assess prompt fitness via reference-free pairwise tournaments, and a Semantic Mutation operator to inject diversity and correct semantic errors. Furthermore, a Heterogeneous Arena module integrates geometric priors with semantic reasoning to ensure robust final selection. Extensive experiments demonstrate that EVOL-SAM3 not only substantially outperforms static baselines but also significantly surpasses fully supervised state-of-the-art methods on the challenging ReasonSeg benchmark in a zero-shot setting. The code is available at https://github.com/AHideoKuzeA/Evol-SAM3.",
      "authors": [
        "Kai Ye",
        "Xiaotong You",
        "Jianghang Lin",
        "Jiayi Ji",
        "Pingyang Dai",
        "Liujuan Cao"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2025-12-31 08:10:03+00:00",
      "link": "https://arxiv.org/pdf/2512.24702v1",
      "tags": [
        "sr-bench"
      ]
    },
    {
      "id": "2512.24698v1",
      "title": "Dynamic Policy Learning for Legged Robot with Simplified Model Pretraining and Model Homotopy Transfer",
      "abstract": "Generating dynamic motions for legged robots remains a challenging problem. While reinforcement learning has achieved notable success in various legged locomotion tasks, producing highly dynamic behaviors often requires extensive reward tuning or high-quality demonstrations. Leveraging reduced-order models can help mitigate these challenges. However, the model discrepancy poses a significant challenge when transferring policies to full-body dynamics environments. In this work, we introduce a continuation-based learning framework that combines simplified model pretraining and model homotopy transfer to efficiently generate and refine complex dynamic behaviors. First, we pretrain the policy using a single rigid body model to capture core motion patterns in a simplified environment. Next, we employ a continuation strategy to progressively transfer the policy to the full-body environment, minimizing performance loss. To define the continuation path, we introduce a model homotopy from the single rigid body model to the full-body model by gradually redistributing mass and inertia between the trunk and legs. The proposed method not only achieves faster convergence but also demonstrates superior stability during the transfer process compared to baseline methods. Our framework is validated on a range of dynamic tasks, including flips and wall-assisted maneuvers, and is successfully deployed on a real quadrupedal robot.",
      "authors": [
        "Dongyun Kang",
        "Min-Gyu Kim",
        "Tae-Gyu Song",
        "Hajun Kim",
        "Sehoon Ha",
        "Hae-Won Park"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2025-12-31 08:04:22+00:00",
      "link": "https://arxiv.org/pdf/2512.24698v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2512.24696v1",
      "title": "Causal Discovery with Mixed Latent Confounding via Precision Decomposition",
      "abstract": "We study causal discovery from observational data in linear Gaussian systems affected by \\emph{mixed latent confounding}, where some unobserved factors act broadly across many variables while others influence only small subsets. This setting is common in practice and poses a challenge for existing methods: differentiable and score-based DAG learners can misinterpret global latent effects as causal edges, while latent-variable graphical models recover only undirected structure.   We propose \\textsc{DCL-DECOR}, a modular, precision-led pipeline that separates these roles. The method first isolates pervasive latent effects by decomposing the observed precision matrix into a structured component and a low-rank component. The structured component corresponds to the conditional distribution after accounting for pervasive confounders and retains only local dependence induced by the causal graph and localized confounding. A correlated-noise DAG learner is then applied to this deconfounded representation to recover directed edges while modeling remaining structured error correlations, followed by a simple reconciliation step to enforce bow-freeness.   We provide identifiability results that characterize the recoverable causal target under mixed confounding and show how the overall problem reduces to well-studied subproblems with modular guarantees. Synthetic experiments that vary the strength and dimensionality of pervasive confounding demonstrate consistent improvements in directed edge recovery over applying correlated-noise DAG learning directly to the confounded data.",
      "authors": [
        "Amir Asiaee",
        "Samhita Pal",
        "James O'quinn",
        "James P. Long"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2025-12-31 08:03:41+00:00",
      "link": "https://arxiv.org/pdf/2512.24696v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2512.24695v1",
      "title": "Nested Learning: The Illusion of Deep Learning Architectures",
      "abstract": "Despite the recent progresses, particularly in developing Language Models, there are fundamental challenges and unanswered questions about how such models can continually learn/memorize, self-improve, and find effective solutions. In this paper, we present a new learning paradigm, called Nested Learning (NL), that coherently represents a machine learning model with a set of nested, multi-level, and/or parallel optimization problems, each of which with its own context flow. Through the lenses of NL, existing deep learning methods learns from data through compressing their own context flow, and in-context learning naturally emerges in large models. NL suggests a philosophy to design more expressive learning algorithms with more levels, resulting in higher-order in-context learning and potentially unlocking effective continual learning capabilities. We advocate for NL by presenting three core contributions: (1) Expressive Optimizers: We show that known gradient-based optimizers, such as Adam, SGD with Momentum, etc., are in fact associative memory modules that aim to compress the gradients' information (by gradient descent). Building on this insight, we present other more expressive optimizers with deep memory and/or more powerful learning rules; (2) Self-Modifying Learning Module: Taking advantage of NL's insights on learning algorithms, we present a sequence model that learns how to modify itself by learning its own update algorithm; and (3) Continuum Memory System: We present a new formulation for memory system that generalizes the traditional viewpoint of long/short-term memory. Combining our self-modifying sequence model with the continuum memory system, we present a continual learning module, called Hope, showing promising results in language modeling, knowledge incorporation, and few-shot generalization tasks, continual learning, and long-context reasoning tasks.",
      "authors": [
        "Ali Behrouz",
        "Meisam Razaviyayn",
        "Peilin Zhong",
        "Vahab Mirrokni"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2025-12-31 07:59:43+00:00",
      "link": "https://arxiv.org/pdf/2512.24695v1",
      "tags": [
        "sr-bench",
        "大厂llm"
      ]
    },
    {
      "id": "2512.24680v1",
      "title": "ReSPIRe: Informative and Reusable Belief Tree Search for Robot Probabilistic Search and Tracking in Unknown Environments",
      "abstract": "Target search and tracking (SAT) is a fundamental problem for various robotic applications such as search and rescue and environmental exploration. This paper proposes an informative trajectory planning approach, namely ReSPIRe, for SAT in unknown cluttered environments under considerably inaccurate prior target information and limited sensing field of view. We first develop a novel sigma point-based approximation approach to fast and accurately estimate mutual information reward under non-Gaussian belief distributions, utilizing informative sampling in state and observation spaces to mitigate the computational intractability of integral calculation. To tackle significant uncertainty associated with inadequate prior target information, we propose the hierarchical particle structure in ReSPIRe, which not only extracts critical particles for global route guidance, but also adjusts the particle number adaptively for planning efficiency. Building upon the hierarchical structure, we develop the reusable belief tree search approach to build a policy tree for online trajectory planning under uncertainty, which reuses rollout evaluation to improve planning efficiency. Extensive simulations and real-world experiments demonstrate that ReSPIRe outperforms representative benchmark methods with smaller MI approximation error, higher search efficiency, and more stable tracking performance, while maintaining outstanding computational efficiency.",
      "authors": [
        "Kangjie Zhou",
        "Zhaoyang Li",
        "Han Gao",
        "Yao Su",
        "Hangxin Liu",
        "Junzhi Yu",
        "Chang Liu"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2025-12-31 07:13:14+00:00",
      "link": "https://arxiv.org/pdf/2512.24680v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2512.24667v1",
      "title": "Distributed Bilevel Optimization with Dual Pruning for Resource-limited Clients",
      "abstract": "With the development of large-scale models, traditional distributed bilevel optimization algorithms cannot be applied directly in low-resource clients. The key reason lies in the excessive computation involved in optimizing both the lower- and upper-level functions. Thus, we present the first resource-adaptive distributed bilevel optimization framework with a second-order free hypergradient estimator, which allows each client to optimize the submodels adapted to the available resources. Due to the coupled influence of partial outer parameters x and inner parameters y, it's challenging to theoretically analyze the upper bound regarding the globally averaged hypergradient for full model parameters. The error bound of inner parameter also needs to be reformulated since the local partial training. The provable theorems show that both RABO and RAFBO can achieve an asymptotically optimal convergence rate of $O(1/\\sqrt{C_x^{\\ast}Q})$, which is dominated by the minimum coverage of the outer parameter $C_x^{\\ast}$. Extensive experiments on two different tasks demonstrate the effectiveness and computation efficiency of our proposed methods.",
      "authors": [
        "Mingyi Li",
        "Xiao Zhang",
        "Ruisheng Zheng",
        "Hongjian Shi",
        "Yuan Yuan",
        "Xiuzhen Cheng",
        "Dongxiao Yu"
      ],
      "primary_category": "cs.DC",
      "categories": [
        "cs.DC"
      ],
      "published": "2025-12-31 06:43:31+00:00",
      "link": "https://arxiv.org/pdf/2512.24667v1",
      "tags": [
        "sr-bench",
        "大厂llm"
      ]
    },
    {
      "id": "2512.24663v1",
      "title": "Renormalization Group Guided Tensor Network Structure Search",
      "abstract": "Tensor network structure search (TN-SS) aims to automatically discover optimal network topologies and rank configurations for efficient tensor decomposition in high-dimensional data representation. Despite recent advances, existing TN-SS methods face significant limitations in computational tractability, structure adaptivity, and optimization robustness across diverse tensor characteristics. They struggle with three key challenges: single-scale optimization missing multi-scale structures, discrete search spaces hindering smooth structure evolution, and separated structure-parameter optimization causing computational inefficiency. We propose RGTN (Renormalization Group guided Tensor Network search), a physics-inspired framework transforming TN-SS via multi-scale renormalization group flows. Unlike fixed-scale discrete search methods, RGTN uses dynamic scale-transformation for continuous structure evolution across resolutions. Its core innovation includes learnable edge gates for optimization-stage topology modification and intelligent proposals based on physical quantities like node tension measuring local stress and edge information flow quantifying connectivity importance. Starting from low-complexity coarse scales and refining to finer ones, RGTN finds compact structures while escaping local minima via scale-induced perturbations. Extensive experiments on light field data, high-order synthetic tensors, and video completion tasks show RGTN achieves state-of-the-art compression ratios and runs 4-600$\\times$ faster than existing methods, validating the effectiveness of our physics-inspired approach.",
      "authors": [
        "Maolin Wang",
        "Bowen Yu",
        "Sheng Zhang",
        "Linjie Mi",
        "Wanyu Wang",
        "Yiqi Wang",
        "Pengyue Jia",
        "Xuetao Wei",
        "Zenglin Xu",
        "Ruocheng Guo",
        "Xiangyu Zhao"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2025-12-31 06:31:43+00:00",
      "link": "https://arxiv.org/pdf/2512.24663v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2512.24657v1",
      "title": "Antagonistic Bowden-Cable Actuation of a Lightweight Robotic Hand: Toward Dexterous Manipulation for Payload Constrained Humanoids",
      "abstract": "Humanoid robots toward human-level dexterity require robotic hands capable of simultaneously providing high grasping force, rapid actuation speeds, multiple degrees of freedom, and lightweight structures within human-like size constraints. Meeting these conflicting requirements remains challenging, as satisfying this combination typically necessitates heavier actuators and bulkier transmission systems, significantly restricting the payload capacity of robot arms. In this letter, we present a lightweight anthropomorphic hand actuated by Bowden cables, which uniquely combines rolling-contact joint optimization with antagonistic cable actuation, enabling single-motor-per-joint control with negligible cable-length deviation. By relocating the actuator module to the torso, the design substantially reduces distal mass while maintaining anthropomorphic scale and dexterity. Additionally, this antagonistic cable actuation eliminates the need for synchronization between motors. Using the proposed methods, the hand assembly with a distal mass of 236g (excluding remote actuators and Bowden sheaths) demonstrated reliable execution of dexterous tasks, exceeding 18N fingertip force and lifting payloads over one hundred times its own mass. Furthermore, robustness was validated through Cutkosky taxonomy grasps and trajectory consistency under perturbed actuator-hand transformations.",
      "authors": [
        "Sungjae Min",
        "Hyungjoo Kim",
        "David Hyunchul Shim"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2025-12-31 06:07:11+00:00",
      "link": "https://arxiv.org/pdf/2512.24657v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2512.24653v1",
      "title": "RoboMIND 2.0: A Multimodal, Bimanual Mobile Manipulation Dataset for Generalizable Embodied Intelligence",
      "abstract": "While data-driven imitation learning has revolutionized robotic manipulation, current approaches remain constrained by the scarcity of large-scale, diverse real-world demonstrations. Consequently, the ability of existing models to generalize across long-horizon bimanual tasks and mobile manipulation in unstructured environments remains limited. To bridge this gap, we present RoboMIND 2.0, a comprehensive real-world dataset comprising over 310K dual-arm manipulation trajectories collected across six distinct robot embodiments and 739 complex tasks. Crucially, to support research in contact-rich and spatially extended tasks, the dataset incorporates 12K tactile-enhanced episodes and 20K mobile manipulation trajectories. Complementing this physical data, we construct high-fidelity digital twins of our real-world environments, releasing an additional 20K-trajectory simulated dataset to facilitate robust sim-to-real transfer. To fully exploit the potential of RoboMIND 2.0, we propose MIND-2 system, a hierarchical dual-system frame-work optimized via offline reinforcement learning. MIND-2 integrates a high-level semantic planner (MIND-2-VLM) to decompose abstract natural language instructions into grounded subgoals, coupled with a low-level Vision-Language-Action executor (MIND-2-VLA), which generates precise, proprioception-aware motor actions.",
      "authors": [
        "Chengkai Hou",
        "Kun Wu",
        "Jiaming Liu",
        "Zhengping Che",
        "Di Wu",
        "Fei Liao",
        "Guangrun Li",
        "Jingyang He",
        "Qiuxuan Feng",
        "Zhao Jin",
        "Chenyang Gu",
        "Zhuoyang Liu",
        "Nuowei Han",
        "Xiangju Mi",
        "Yaoxu Lv",
        "Yankai Fu",
        "Gaole Dai",
        "Langzhe Gu",
        "Tao Li",
        "Yuheng Zhang",
        "Yixue Zhang",
        "Xinhua Wang",
        "Shichao Fan",
        "Meng Li",
        "Zhen Zhao",
        "Ning Liu",
        "Zhiyuan Xu",
        "Pei Ren",
        "Junjie Ji",
        "Haonan Liu",
        "Kuan Cheng",
        "Shanghang Zhang",
        "Jian Tang"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2025-12-31 05:59:40+00:00",
      "link": "https://arxiv.org/pdf/2512.24653v1",
      "tags": [
        "大厂llm"
      ]
    },
    {
      "id": "2512.24643v1",
      "title": "A Scalable Framework for logP Prediction: From Terabyte-Scale Data Integration to Interpretable Ensemble Modeling",
      "abstract": "This study presents a large-scale predictive modeling framework for logP prediction using 426850 bioactive compounds rigorously curated from the intersection of three authoritative chemical databases: PubChem, ChEMBL, and eMolecules. We developed a novel computational infrastructure to address the data integration challenge, reducing processing time from a projected over 100 days to 3.2 hours through byte-offset indexing architecture, a 740-fold improvement. Our comprehensive analysis revealed critical insights into the multivariate nature of lipophilicity: while molecular weight exhibited weak bivariate correlation with logP, SHAP analysis on ensemble models identified it as the single most important predictor globally. We systematically evaluated multiple modeling approaches, discovering that linear models suffered from inherent heteroskedasticity that classical remediation strategies, including weighted least squares and Box-Cox transformation, failed to address. Tree-based ensemble methods, including Random Forest and XGBoost, proved inherently robust to this violation, achieving an R-squared of 0.765 and RMSE of 0.731 logP units on the test set. Furthermore, a stratified modeling strategy, employing specialized models for drug-like molecules (91 percent of dataset) and extreme cases (nine percent), achieved optimal performance: an RMSE of 0.838 for the drug-like subset and an R-squared of 0.767 for extreme molecules, the highest of all evaluated approaches. These findings provide actionable guidance for molecular design, establish robust baselines for lipophilicity prediction using only 2D descriptors, and demonstrate that well-curated, descriptor-based ensemble models remain competitive with state-of-the-art graph neural network architectures.",
      "authors": [
        "Malikussaid",
        "Septian Caesar Floresko",
        "Ade Romadhony",
        "Isman Kurniawan",
        "Warih Maharani",
        "Hilal Hudan Nuha"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CE",
        "cs.DB",
        "q-bio.BM"
      ],
      "published": "2025-12-31 05:32:13+00:00",
      "link": "https://arxiv.org/pdf/2512.24643v1",
      "tags": [
        "sr-bench",
        "大厂llm",
        "符号回归（示例）"
      ]
    },
    {
      "id": "2512.24639v1",
      "title": "From Sequential to Spatial: Reordering Autoregression for Efficient Visual Generation",
      "abstract": "Inspired by the remarkable success of autoregressive models in language modeling, this paradigm has been widely adopted in visual generation. However, the sequential token-by-token decoding mechanism inherent in traditional autoregressive models leads to low inference efficiency.In this paper, we propose RadAR, an efficient and parallelizable framework designed to accelerate autoregressive visual generation while preserving its representational capacity. Our approach is motivated by the observation that visual tokens exhibit strong local dependencies and spatial correlations with their neighbors--a property not fully exploited in standard raster-scan decoding orders. Specifically, we organize the generation process around a radial topology: an initial token is selected as the starting point, and all other tokens are systematically grouped into multiple concentric rings according to their spatial distances from this center. Generation then proceeds in a ring-wise manner, from inner to outer regions, enabling the parallel prediction of all tokens within the same ring. This design not only preserves the structural locality and spatial coherence of visual scenes but also substantially increases parallelization. Furthermore, to address the risk of inconsistent predictions arising from simultaneous token generation with limited context, we introduce a nested attention mechanism. This mechanism dynamically refines implausible outputs during the forward pass, thereby mitigating error accumulation and preventing model collapse. By integrating radial parallel prediction with dynamic output correction, RadAR significantly improves generation efficiency.",
      "authors": [
        "Siyang Wang",
        "Hanting Li",
        "Wei Li",
        "Jie Hu",
        "Xinghao Chen",
        "Feng Zhao"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2025-12-31 05:24:07+00:00",
      "link": "https://arxiv.org/pdf/2512.24639v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2512.24637v2",
      "title": "Towards Fully-fledged GPU Multitasking via Proactive Memory Scheduling",
      "abstract": "The limited HBM capacity has become the primary bottleneck for hosting an increasing number of larger-scale GPU tasks. While demand paging extends capacity via host DRAM, it incurs up to 78x slowdown due to the massive working sets and poor locality of GPU workloads. We observe, however, that GPU memory access patterns are inherently predictable via kernel launch arguments and their asynchronous execution nature. Leveraging this, we propose MSched, an OS-level scheduler that extends GPU context switching to include proactive working set preparation, thereby coalescing fragmented, eventual, and expensive page faults into a single efficient migration. MSched employs a template-based approach to predict working sets with near-perfect accuracy and proposes a co-design between task scheduler and memory manager to enforce a globally optimal page placement policy. Evaluation demonstrates that MSched outperforms demand paging by up to 11.05x for scientific and deep learning workloads, and 57.88x for LLM under memory oversubscription.",
      "authors": [
        "Weihang Shen",
        "Yinqiu Chen",
        "Rong Chen",
        "Haibo Chen"
      ],
      "primary_category": "cs.OS",
      "categories": [
        "cs.OS"
      ],
      "published": "2025-12-31 05:18:52+00:00",
      "link": "https://arxiv.org/pdf/2512.24637v2",
      "tags": [
        "sr-bench"
      ]
    },
    {
      "id": "2512.24618v1",
      "title": "Youtu-LLM: Unlocking the Native Agentic Potential for Lightweight Large Language Models",
      "abstract": "We introduce Youtu-LLM, a lightweight yet powerful language model that harmonizes high computational efficiency with native agentic intelligence. Unlike typical small models that rely on distillation, Youtu-LLM (1.96B) is pre-trained from scratch to systematically cultivate reasoning and planning capabilities. The key technical advancements are as follows: (1) Compact Architecture with Long-Context Support: Built on a dense Multi-Latent Attention (MLA) architecture with a novel STEM-oriented vocabulary, Youtu-LLM supports a 128k context window. This design enables robust long-context reasoning and state tracking within a minimal memory footprint, making it ideal for long-horizon agent and reasoning tasks. (2) Principled \"Commonsense-STEM-Agent\" Curriculum: We curated a massive corpus of approximately 11T tokens and implemented a multi-stage training strategy. By progressively shifting the pre-training data distribution from general commonsense to complex STEM and agentic tasks, we ensure the model acquires deep cognitive abilities rather than superficial alignment. (3) Scalable Agentic Mid-training: Specifically for the agentic mid-training, we employ diverse data construction schemes to synthesize rich and varied trajectories across math, coding, and tool-use domains. This high-quality data enables the model to internalize planning and reflection behaviors effectively. Extensive evaluations show that Youtu-LLM sets a new state-of-the-art for sub-2B LLMs. On general benchmarks, it achieves competitive performance against larger models, while on agent-specific tasks, it significantly surpasses existing SOTA baselines, demonstrating that lightweight models can possess strong intrinsic agentic capabilities.",
      "authors": [
        "Junru Lu",
        "Jiarui Qin",
        "Lingfeng Qiao",
        "Yinghui Li",
        "Xinyi Dai",
        "Bo Ke",
        "Jianfeng He",
        "Ruizhi Qiao",
        "Di Yin",
        "Xing Sun",
        "Yunsheng Wu",
        "Yinsong Liu",
        "Shuangyin Liu",
        "Mingkong Tang",
        "Haodong Lin",
        "Jiayi Kuang",
        "Fanxu Meng",
        "Xiaojuan Tang",
        "Yunjia Xi",
        "Junjie Huang",
        "Haotong Yang",
        "Zhenyi Shen",
        "Yangning Li",
        "Qianwen Zhang",
        "Yifei Yu",
        "Siyu An",
        "Junnan Dong",
        "Qiufeng Wang",
        "Jie Wang",
        "Keyu Chen",
        "Wei Wen",
        "Taian Guo",
        "Zhifeng Shen",
        "Daohai Yu",
        "Jiahao Li",
        "Ke Li",
        "Zongyi Li",
        "Xiaoyu Tan"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2025-12-31 04:25:11+00:00",
      "link": "https://arxiv.org/pdf/2512.24618v1",
      "tags": [
        "大厂llm"
      ]
    },
    {
      "id": "2512.24617v1",
      "title": "Dynamic Large Concept Models: Latent Reasoning in an Adaptive Semantic Space",
      "abstract": "Large Language Models (LLMs) apply uniform computation to all tokens, despite language exhibiting highly non-uniform information density. This token-uniform regime wastes capacity on locally predictable spans while under-allocating computation to semantically critical transitions. We propose $\\textbf{Dynamic Large Concept Models (DLCM)}$, a hierarchical language modeling framework that learns semantic boundaries from latent representations and shifts computation from tokens to a compressed concept space where reasoning is more efficient. DLCM discovers variable-length concepts end-to-end without relying on predefined linguistic units. Hierarchical compression fundamentally changes scaling behavior. We introduce the first $\\textbf{compression-aware scaling law}$, which disentangles token-level capacity, concept-level reasoning capacity, and compression ratio, enabling principled compute allocation under fixed FLOPs. To stably train this heterogeneous architecture, we further develop a $\\textbf{decoupled $μ$P parametrization}$ that supports zero-shot hyperparameter transfer across widths and compression regimes. At a practical setting ($R=4$, corresponding to an average of four tokens per concept), DLCM reallocates roughly one-third of inference compute into a higher-capacity reasoning backbone, achieving a $\\textbf{+2.69$\\%$ average improvement}$ across 12 zero-shot benchmarks under matched inference FLOPs.",
      "authors": [
        "Xingwei Qu",
        "Shaowen Wang",
        "Zihao Huang",
        "Kai Hua",
        "Fan Yin",
        "Rui-Jie Zhu",
        "Jundong Zhou",
        "Qiyang Min",
        "Zihao Wang",
        "Yizhi Li",
        "Tianyu Zhang",
        "He Xing",
        "Zheng Zhang",
        "Yuxuan Song",
        "Tianyu Zheng",
        "Zhiyuan Zeng",
        "Chenghua Lin",
        "Ge Zhang",
        "Wenhao Huang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2025-12-31 04:19:33+00:00",
      "link": "https://arxiv.org/pdf/2512.24617v1",
      "tags": [
        "sr-bench",
        "大厂llm"
      ]
    },
    {
      "id": "2512.24615v1",
      "title": "Youtu-Agent: Scaling Agent Productivity with Automated Generation and Hybrid Policy Optimization",
      "abstract": "Existing Large Language Model (LLM) agent frameworks face two significant challenges: high configuration costs and static capabilities. Building a high-quality agent often requires extensive manual effort in tool integration and prompt engineering, while deployed agents struggle to adapt to dynamic environments without expensive fine-tuning. To address these issues, we propose \\textbf{Youtu-Agent}, a modular framework designed for the automated generation and continuous evolution of LLM agents. Youtu-Agent features a structured configuration system that decouples execution environments, toolkits, and context management, enabling flexible reuse and automated synthesis. We introduce two generation paradigms: a \\textbf{Workflow} mode for standard tasks and a \\textbf{Meta-Agent} mode for complex, non-standard requirements, capable of automatically generating tool code, prompts, and configurations. Furthermore, Youtu-Agent establishes a hybrid policy optimization system: (1) an \\textbf{Agent Practice} module that enables agents to accumulate experience and improve performance through in-context optimization without parameter updates; and (2) an \\textbf{Agent RL} module that integrates with distributed training frameworks to enable scalable and stable reinforcement learning of any Youtu-Agents in an end-to-end, large-scale manner. Experiments demonstrate that Youtu-Agent achieves state-of-the-art performance on WebWalkerQA (71.47\\%) and GAIA (72.8\\%) using open-weight models. Our automated generation pipeline achieves over 81\\% tool synthesis success rate, while the Practice module improves performance on AIME 2024/2025 by +2.7\\% and +5.4\\% respectively. Moreover, our Agent RL training achieves 40\\% speedup with steady performance improvement on 7B LLMs, enhancing coding/reasoning and searching capabilities respectively up to 35\\% and 21\\% on Maths and general/multi-hop QA benchmarks.",
      "authors": [
        "Yuchen Shi",
        "Yuzheng Cai",
        "Siqi Cai",
        "Zihan Xu",
        "Lichao Chen",
        "Yulei Qin",
        "Zhijian Zhou",
        "Xiang Fei",
        "Chaofan Qiu",
        "Xiaoyu Tan",
        "Gang Li",
        "Zongyi Li",
        "Haojia Lin",
        "Guocan Cai",
        "Yong Mao",
        "Yunsheng Wu",
        "Ke Li",
        "Xing Sun"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2025-12-31 04:17:36+00:00",
      "link": "https://arxiv.org/pdf/2512.24615v1",
      "tags": [
        "sr-bench",
        "大厂llm"
      ]
    },
    {
      "id": "2512.24594v1",
      "title": "A Tale of 1001 LoC: Potential Runtime Error-Guided Specification Synthesis for Verifying Large-Scale Programs",
      "abstract": "Fully automated verification of large-scale software and hardware systems is arguably the holy grail of formal methods. Large language models (LLMs) have recently demonstrated their potential for enhancing the degree of automation in formal verification by, e.g., generating formal specifications as essential to deductive verification, yet exhibit poor scalability due to long-context reasoning limitations and, more importantly, the difficulty of inferring complex, interprocedural specifications. This paper presents Preguss -- a modular, fine-grained framework for automating the generation and refinement of formal specifications. Preguss synergizes between static analysis and deductive verification by steering two components in a divide-and-conquer fashion: (i) potential runtime error-guided construction and prioritization of verification units, and (ii) LLM-aided synthesis of interprocedural specifications at the unit level. We show that Preguss substantially outperforms state-of-the-art LLM-based approaches and, in particular, it enables highly automated RTE-freeness verification for real-world programs with over a thousand LoC, with a reduction of 80.6%~88.9% human verification effort.",
      "authors": [
        "Zhongyi Wang",
        "Tengjie Lin",
        "Mingshuai Chen",
        "Haokun Li",
        "Mingqi Yang",
        "Xiao Yi",
        "Shengchao Qin",
        "Yixing Luo",
        "Xiaofeng Li",
        "Bin Gu",
        "Liqiang Lu",
        "Jianwei Yin"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE",
        "cs.LO"
      ],
      "published": "2025-12-31 03:31:51+00:00",
      "link": "https://arxiv.org/pdf/2512.24594v1",
      "tags": [
        "大厂llm"
      ]
    },
    {
      "id": "2512.24591v1",
      "title": "Improving Few-Shot Change Detection Visual Question Answering via Decision-Ambiguity-guided Reinforcement Fine-Tuning",
      "abstract": "Change detection visual question answering (CDVQA) requires answering text queries by reasoning about semantic changes in bi-temporal remote sensing images. A straightforward approach is to boost CDVQA performance with generic vision-language models via supervised fine-tuning (SFT). Despite recent progress, we observe that a significant portion of failures do not stem from clearly incorrect predictions, but from decision ambiguity, where the model assigns similar confidence to the correct answer and strong distractors. To formalize this challenge, we define Decision-Ambiguous Samples (DAS) as instances with a small probability margin between the ground-truth answer and the most competitive alternative. We argue that explicitly optimizing DAS is crucial for improving the discriminability and robustness of CDVQA models. To this end, we propose DARFT, a Decision-Ambiguity-guided Reinforcement Fine-Tuning framework that first mines DAS using an SFT-trained reference policy and then applies group-relative policy optimization on the mined subset. By leveraging multi-sample decoding and intra-group relative advantages, DARFT suppresses strong distractors and sharpens decision boundaries without additional supervision. Extensive experiments demonstrate consistent gains over SFT baselines, particularly under few-shot settings.",
      "authors": [
        "Fuyu Dong",
        "Ke Li",
        "Di Wang",
        "Nan Luo",
        "Yiming Zhang",
        "Kaiyu Li",
        "Jianfei Yang",
        "Quan Wang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2025-12-31 03:28:17+00:00",
      "link": "https://arxiv.org/pdf/2512.24591v1",
      "tags": [
        "sr-bench"
      ]
    },
    {
      "id": "2512.24587v1",
      "title": "MultiRisk: Multiple Risk Control via Iterative Score Thresholding",
      "abstract": "As generative AI systems are increasingly deployed in real-world applications, regulating multiple dimensions of model behavior has become essential. We focus on test-time filtering: a lightweight mechanism for behavior control that compares performance scores to estimated thresholds, and modifies outputs when these bounds are violated. We formalize the problem of enforcing multiple risk constraints with user-defined priorities, and introduce two efficient dynamic programming algorithms that leverage this sequential structure. The first, MULTIRISK-BASE, provides a direct finite-sample procedure for selecting thresholds, while the second, MULTIRISK, leverages data exchangeability to guarantee simultaneous control of the risks. Under mild assumptions, we show that MULTIRISK achieves nearly tight control of all constraint risks. The analysis requires an intricate iterative argument, upper bounding the risks by introducing several forms of intermediate symmetrized risk functions, and carefully lower bounding the risks by recursively counting jumps in symmetrized risk functions between appropriate risk levels. We evaluate our framework on a three-constraint Large Language Model alignment task using the PKU-SafeRLHF dataset, where the goal is to maximize helpfulness subject to multiple safety constraints, and where scores are generated by a Large Language Model judge and a perplexity filter. Our experimental results show that our algorithm can control each individual risk at close to the target level.",
      "authors": [
        "Sunay Joshi",
        "Yan Sun",
        "Hamed Hassani",
        "Edgar Dobriban"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "published": "2025-12-31 03:25:30+00:00",
      "link": "https://arxiv.org/pdf/2512.24587v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2512.24581v1",
      "title": "On Circular Threshold Words and Other Stronger Versions of Dejean's conjecture",
      "abstract": "Let the root of the word $w$ be the smallest prefix $v$ of $w$ such that $w$ is a prefix of $vvv...$. $per(w)$ is the length of the root of $w$. For any $n\\ge5$, an $n$-ary threshold word is a word $w$ such that for any factor (subword) $v$ of $w$ the condition $\\frac{|v|}{per(v)}\\le\\frac{n}{n-1}$ holds. Dejean conjecture (completely proven in 2009) states for $n\\ge5$ that exists infinitely many of $n$-ary TWs.   This manuscript is based on the author's student works (diplomas of 2011 (bachelor's thesis) and 2013 (master's thesis) years) and presents an edited version (in Russian) of these works with some improvements.   In a 2011 work proposed new methods of proving of the Dejean conjecture for some odd cases $n\\ge5$, using computer verification in polynomial time (depending on $n$). Moreover, the constructed threshold words (TWs) are ciclic/ring TWs (any cyclic shift is a TW).   In the 2013 work, the proof method (of 2011) was improved by reducing the verification conditions. A solution for some even cases $n\\ge6$ is also proposed. A 2013 work also proposed a method to construct stronger TWs, using a TW tree with regular exponential growth. Namely, the TWs, where all long factors have an exponent close to 1.",
      "authors": [
        "Igor N. Tunev"
      ],
      "primary_category": "math.CO",
      "categories": [
        "math.CO",
        "cs.DS"
      ],
      "published": "2025-12-31 03:16:17+00:00",
      "link": "https://arxiv.org/pdf/2512.24581v1",
      "tags": [
        "sr-bench"
      ]
    },
    {
      "id": "2512.24580v1",
      "title": "Robust Bayesian Dynamic Programming for On-policy Risk-sensitive Reinforcement Learning",
      "abstract": "We propose a novel framework for risk-sensitive reinforcement learning (RSRL) that incorporates robustness against transition uncertainty. We define two distinct yet coupled risk measures: an inner risk measure addressing state and cost randomness and an outer risk measure capturing transition dynamics uncertainty. Our framework unifies and generalizes most existing RL frameworks by permitting general coherent risk measures for both inner and outer risk measures. Within this framework, we construct a risk-sensitive robust Markov decision process (RSRMDP), derive its Bellman equation, and provide error analysis under a given posterior distribution. We further develop a Bayesian Dynamic Programming (Bayesian DP) algorithm that alternates between posterior updates and value iteration. The approach employs an estimator for the risk-based Bellman operator that combines Monte Carlo sampling with convex optimization, for which we prove strong consistency guarantees. Furthermore, we demonstrate that the algorithm converges to a near-optimal policy in the training environment and analyze both the sample complexity and the computational complexity under the Dirichlet posterior and CVaR. Finally, we validate our approach through two numerical experiments. The results exhibit excellent convergence properties while providing intuitive demonstrations of its advantages in both risk-sensitivity and robustness. Empirically, we further demonstrate the advantages of the proposed algorithm through an application on option hedging.",
      "authors": [
        "Shanyu Han",
        "Yangbo He",
        "Yang Liu"
      ],
      "primary_category": "q-fin.RM",
      "categories": [
        "q-fin.RM",
        "cs.LG"
      ],
      "published": "2025-12-31 03:13:22+00:00",
      "link": "https://arxiv.org/pdf/2512.24580v1",
      "tags": [
        "sr-bench"
      ]
    },
    {
      "id": "2512.24570v1",
      "title": "On the Effectiveness of Training Data Optimization for LLM-based Code Generation: An Empirical Study",
      "abstract": "Large language models (LLMs) have achieved remarkable progress in code generation, largely driven by the availability of high-quality code datasets for effective training. To further improve data quality, numerous training data optimization techniques have been proposed; however, their overall effectiveness has not been systematically evaluated. To bridge this gap, we conduct the first large-scale empirical study, examining five widely-used training data optimization techniques and their pairwise combinations for LLM-based code generation across three benchmarks and four LLMs. Our results show that data synthesis is the most effective technique for improving functional correctness and reducing code smells, although it performs relatively worse on code maintainability compared to data refactoring, cleaning, and selection. Regarding combinations, we find that most combinations do not further improve functional correctness but can effectively enhance code quality (code smells and maintainability). Among all combinations, data synthesis combined with data refactoring achieves the strongest overall performance. Furthermore, our fine-grained analysis reinforces these findings and provides deeper insights into how individual techniques and their combinations influence code generation effectiveness. Overall, this work represents a first step toward a systematic understanding of training data optimization and combination strategies, offering practical guidance for future research and deployment in LLM-based code generation.",
      "authors": [
        "Shiqi Kuang",
        "Zhao Tian",
        "Tao Xiao",
        "Dong Wang",
        "Junjie Chen"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE"
      ],
      "published": "2025-12-31 02:30:05+00:00",
      "link": "https://arxiv.org/pdf/2512.24570v1",
      "tags": [
        "sr-bench"
      ]
    },
    {
      "id": "2512.24565v1",
      "title": "MCPAgentBench: A Real-world Task Benchmark for Evaluating LLM Agent MCP Tool Use",
      "abstract": "Large Language Models (LLMs) are increasingly serving as autonomous agents, and their utilization of external tools via the Model Context Protocol (MCP) is considered a future trend. Current MCP evaluation sets suffer from issues such as reliance on external MCP services and a lack of difficulty awareness. To address these limitations, we propose MCPAgentBench, a benchmark based on real-world MCP definitions designed to evaluate the tool-use capabilities of agents. We construct a dataset containing authentic tasks and simulated MCP tools. The evaluation employs a dynamic sandbox environment that presents agents with candidate tool lists containing distractors, thereby testing their tool selection and discrimination abilities. Furthermore, we introduce comprehensive metrics to measure both task completion rates and execution efficiency. Experiments conducted on various latest mainstream Large Language Models reveal significant performance differences in handling complex, multi-step tool invocations. All code is open-source at Github.",
      "authors": [
        "Wenrui Liu",
        "Zixiang Liu",
        "Elsie Dai",
        "Wenhan Yu",
        "Lei Yu",
        "Tong Yang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2025-12-31 02:09:48+00:00",
      "link": "https://arxiv.org/pdf/2512.24565v1",
      "tags": [
        "sr-bench"
      ]
    },
    {
      "id": "2512.24564v1",
      "title": "CPR: Causal Physiological Representation Learning for Robust ECG Analysis under Distribution Shifts",
      "abstract": "Deep learning models for Electrocardiogram (ECG) diagnosis have achieved remarkable accuracy but exhibit fragility against adversarial perturbations, particularly Smooth Adversarial Perturbations (SAP) that mimic biological morphology. Existing defenses face a critical dilemma: Adversarial Training (AT) provides robustness but incurs a prohibitive computational burden, while certified methods like Randomized Smoothing (RS) introduce significant inference latency, rendering them impractical for real-time clinical monitoring. We posit that this vulnerability stems from the models' reliance on non-robust spurious correlations rather than invariant pathological features. To address this, we propose Causal Physiological Representation Learning (CPR). Unlike standard denoising approaches that operate without semantic constraints, CPR incorporates a Physiological Structural Prior within a causal disentanglement framework. By modeling ECG generation via a Structural Causal Model (SCM), CPR enforces a structural intervention that strictly separates invariant pathological morphology (P-QRS-T complex) from non-causal artifacts. Empirical results on PTB-XL demonstrate that CPR significantly outperforms standard clinical preprocessing methods. Specifically, under SAP attacks, CPR achieves an F1 score of 0.632, surpassing Median Smoothing (0.541 F1) by 9.1%. Crucially, CPR matches the certified robustness of Randomized Smoothing while maintaining single-pass inference efficiency, offering a superior trade-off between robustness, efficiency, and clinical interpretability.",
      "authors": [
        "Shunbo Jia",
        "Caizhi Liao"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "eess.SP"
      ],
      "published": "2025-12-31 02:08:34+00:00",
      "link": "https://arxiv.org/pdf/2512.24564v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2512.24562v1",
      "title": "HaluNet: Multi-Granular Uncertainty Modeling for Efficient Hallucination Detection in LLM Question Answering",
      "abstract": "Large Language Models (LLMs) excel at question answering (QA) but often generate hallucinations, including factual errors or fabricated content. Detecting hallucinations from internal uncertainty signals is attractive due to its scalability and independence from external resources. Existing methods often aim to accurately capture a single type of uncertainty while overlooking the complementarity among different sources, particularly between token-level probability uncertainty and the uncertainty conveyed by internal semantic representations, which provide complementary views on model reliability. We present \\textbf{HaluNet}, a lightweight and trainable neural framework that integrates multi granular token level uncertainties by combining semantic embeddings with probabilistic confidence and distributional uncertainty. Its multi branch architecture adaptively fuses what the model knows with the uncertainty expressed in its outputs, enabling efficient one pass hallucination detection. Experiments on SQuAD, TriviaQA, and Natural Questions show that HaluNet delivers strong detection performance and favorable computational efficiency, with or without access to context, highlighting its potential for real time hallucination detection in LLM based QA systems.",
      "authors": [
        "Chaodong Tong",
        "Qi Zhang",
        "Jiayang Gao",
        "Lei Jiang",
        "Yanbing Liu",
        "Nannan Sun"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2025-12-31 02:03:10+00:00",
      "link": "https://arxiv.org/pdf/2512.24562v1",
      "tags": [
        "sr-bench",
        "大厂llm"
      ]
    },
    {
      "id": "2512.24560v1",
      "title": "Localized Calibrated Uncertainty in Code Language Models",
      "abstract": "Large Language models (LLMs) can generate complicated source code from natural language prompts. However, LLMs can generate output that deviates from what the user wants, requiring supervision and editing. To support this process, we offer techniques to localize where generations might be misaligned from user intent. We first create a dataset of \"Minimal Intent Aligning Patches\" of repaired LLM generated programs. Each program uses test cases to verify correctness. After creating a dataset of programs, we measure how well various techniques can assign a well-calibrated probability to indicate which parts of code will be edited in a minimal patch (i.e., give a probability that corresponds with empirical odds it is edited). We compare white-box probing (where we propose a technique for efficient arbitrary-span querying), against black-box reflective and self-consistency based approaches. We find probes with a small supervisor model can achieve low calibration error and Brier Skill Score of approx 0.2 estimating edited lines on code generated by models many orders of magnitude larger. We discuss the generalizability of the techniques, and the connections to AI oversight and control, finding a probe trained only on code shows some signs of generalizing to natural language errors if new probability scaling is allowed.",
      "authors": [
        "David Gros",
        "Prem Devanbu"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "published": "2025-12-31 02:00:17+00:00",
      "link": "https://arxiv.org/pdf/2512.24560v1",
      "tags": [
        "大厂llm"
      ]
    },
    {
      "id": "2512.24559v1",
      "title": "Evolutionary Discovery of Sequence Acceleration Methods for Slab Geometry Neutron Transport",
      "abstract": "We present a genetic programming approach to automatically discover convergence acceleration methods for discrete ordinates solutions of neutron transport problems in slab geometry. Classical acceleration methods such as Aitken's delta-squared and Wynn epsilon assume specific convergence patterns and do not generalize well to the broad set of transport problems encountered in practice. We evolved mathematical formulas specifically tailored to SN convergence characteristics in this work. The discovered accelerator, featuring second differences and cross-product terms, achieved over 75 percent success rate in improving convergence compared to raw sequences - almost double that observed for classical techniques for the problem set considered. This work demonstrates the potential for discovering novel numerical methods in computational physics via genetic programming and attempts to honor Prof. Ganapol's legacy of advancing experimental mathematics applied to neutron transport.",
      "authors": [
        "Japan K. Patel",
        "Barry D. Ganapol",
        "Anthony Magliari",
        "Matthew C. Schmidt",
        "Todd A. Wareing"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE"
      ],
      "published": "2025-12-31 01:53:34+00:00",
      "link": "https://arxiv.org/pdf/2512.24559v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2512.24551v1",
      "title": "PhyGDPO: Physics-Aware Groupwise Direct Preference Optimization for Physically Consistent Text-to-Video Generation",
      "abstract": "Recent advances in text-to-video (T2V) generation have achieved good visual quality, yet synthesizing videos that faithfully follow physical laws remains an open challenge. Existing methods mainly based on graphics or prompt extension struggle to generalize beyond simple simulated environments or learn implicit physical reasoning. The scarcity of training data with rich physics interactions and phenomena is also a problem. In this paper, we first introduce a Physics-Augmented video data construction Pipeline, PhyAugPipe, that leverages a vision-language model (VLM) with chain-of-thought reasoning to collect a large-scale training dataset, PhyVidGen-135K. Then we formulate a principled Physics-aware Groupwise Direct Preference Optimization, PhyGDPO, framework that builds upon the groupwise Plackett-Luce probabilistic model to capture holistic preferences beyond pairwise comparisons. In PhyGDPO, we design a Physics-Guided Rewarding (PGR) scheme that embeds VLM-based physics rewards to steer optimization toward physical consistency. We also propose a LoRA-Switch Reference (LoRA-SR) scheme that eliminates memory-heavy reference duplication for efficient training. Experiments show that our method significantly outperforms state-of-the-art open-source methods on PhyGenBench and VideoPhy2. Please check our project page at https://caiyuanhao1998.github.io/project/PhyGDPO for more video results. Our code, models, and data will be released at https://github.com/caiyuanhao1998/Open-PhyGDPO",
      "authors": [
        "Yuanhao Cai",
        "Kunpeng Li",
        "Menglin Jia",
        "Jialiang Wang",
        "Junzhe Sun",
        "Feng Liang",
        "Weifeng Chen",
        "Felix Juefei-Xu",
        "Chu Wang",
        "Ali Thabet",
        "Xiaoliang Dai",
        "Xuan Ju",
        "Alan Yuille",
        "Ji Hou"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2025-12-31 01:19:14+00:00",
      "link": "https://arxiv.org/pdf/2512.24551v1",
      "tags": [
        "sr-bench",
        "大厂llm"
      ]
    },
    {
      "id": "2512.24545v1",
      "title": "More Than Bits: Multi-Envelope Double Binary Factorization for Extreme Quantization",
      "abstract": "For extreme low-bit quantization of large language models (LLMs), Double Binary Factorization (DBF) is attractive as it enables efficient inference without sacrificing accuracy. However, the scaling parameters of DBF are too restrictive; after factoring out signs, all rank components share the same magnitude profile, resulting in performance saturation. We propose Multi-envelope DBF (MDBF), which retains a shared pair of 1-bit sign bases but replaces the single envelope with a rank-$l$ envelope. By sharing sign matrices among envelope components, MDBF effectively maintains a binary carrier and utilizes the limited memory budget for magnitude expressiveness. We also introduce a closed-form initialization and an alternating refinement method to optimize MDBF. Across the LLaMA and Qwen families, MDBF enhances perplexity and zero-shot accuracy over previous binary formats at matched bits per weight while preserving the same deployment-friendly inference primitive.",
      "authors": [
        "Yuma Ichikawa",
        "Yoshihiko Fujisawa",
        "Yudai Fujimoto",
        "Akira Sakai",
        "Katsuki Fujisawa"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "published": "2025-12-31 01:04:34+00:00",
      "link": "https://arxiv.org/pdf/2512.24545v1",
      "tags": [
        "sr-bench"
      ]
    },
    {
      "id": "2512.24532v1",
      "title": "From Building Blocks to Planning: Multi-Step Spatial Reasoning in LLMs with Reinforcement Learning",
      "abstract": "Spatial reasoning in large language models (LLMs) has gained increasing attention due to applications in navigation and planning. Despite strong general language capabilities, LLMs still struggle with spatial transformations and multi-step planning in structured environments. We propose a two-stage approach that decomposes spatial reasoning into atomic building blocks and their composition. First, we apply supervised fine-tuning on elementary spatial transformations, such as rotation, translation, and scaling, to equip the model with basic spatial physics. We then freeze this physics-aware model and train lightweight LoRA adapters within the GRPO framework to learn policies that compose these building blocks for multi-step planning in puzzle-based environments, in a closed-loop manner. To support this pipeline, we synthesize an ASCII-art dataset and construct a corresponding ASCII-based reinforcement learning environment. Our method consistently outperforms baselines, including the generic backbone, physics-aware model, and end-to-end RL models, under both Dynamic environments with explicit state updates and Static environments where the model must rely on its internal state across steps. In addition, the proposed approach converges faster and exhibits more stable training compared to end-to-end reinforcement learning from scratch. Finally, we analyze attention patterns to assess whether fine-tuning induces meaningful improvements in spatial understanding.",
      "authors": [
        "Amir Tahmasbi",
        "Sadegh Majidi",
        "Kazem Taram",
        "Aniket Bera"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "published": "2025-12-31 00:36:03+00:00",
      "link": "https://arxiv.org/pdf/2512.24532v1",
      "tags": [
        "sr-bench",
        "大厂llm",
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00041v1",
      "title": "Deep Learning Approach for the Diagnosis of Pediatric Pneumonia Using Chest X-ray Imaging",
      "abstract": "Pediatric pneumonia remains a leading cause of morbidity and mortality in children worldwide. Timely and accurate diagnosis is critical but often challenged by limited radiological expertise and the physiological and procedural complexity of pediatric imaging. This study investigates the performance of state-of-the-art convolutional neural network (CNN) architectures ResNetRS, RegNet, and EfficientNetV2 using transfer learning for the automated classification of pediatric chest Xray images as either pneumonia or normal.A curated subset of 1,000 chest X-ray images was extracted from a publicly available dataset originally comprising 5,856 pediatric images. All images were preprocessed and labeled for binary classification. Each model was fine-tuned using pretrained ImageNet weights and evaluated based on accuracy and sensitivity. RegNet achieved the highest classification performance with an accuracy of 92.4 and a sensitivity of 90.1, followed by ResNetRS (accuracy: 91.9, sensitivity: 89.3) and EfficientNetV2 (accuracy: 88.5, sensitivity: 88.1).",
      "authors": [
        "Fatemeh Hosseinabadi",
        "Mohammad Mojtaba Rohani"
      ],
      "primary_category": "eess.IV",
      "categories": [
        "eess.IV",
        "cs.CV",
        "cs.LG"
      ],
      "published": "2025-12-31 00:07:06+00:00",
      "link": "https://arxiv.org/pdf/2601.00041v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00780v1",
      "title": "Energy Efficiency Maximization of MIMO Systems through Reconfigurable Holographic Beamforming",
      "abstract": "This study considers a point-to-point wireless link, in which both the transmitter and receiver are equipped with multiple antennas. In addition, two reconfigurable metasurfaces are deployed, one in the immediate vicinity of the transmit antenna array, and one in the immediate vicinity of the receive antenna array. The resulting architecture implements a holographic beamforming structure at both the transmitter and receiver. In this scenario, the system energy efficiency is optimized with respect to the transmit covariance matrix, and the reflection matrices of the two metasurfaces. A low-complexity algorithm is developed, which is guaranteed to converge to a first-order optimal point of the energy efficiency maximization problem. Moreover, closed-form expressions are derived for the metasurface matrices in the special case of single-antenna or single-stream transmission. The two metasurfaces are considered to be nearly-passive and subject to global reflection constraints. A numerical performance analysis is conducted to assess the performance of the proposed optimization methods, showing, in particular, that the use of holographic beamforming by metasurfaces can provide significant energy efficiency gains compared to fully digital beamforming architectures, even when the latter achieve substantial multiplexing gains.",
      "authors": [
        "Robert Kuku Fotock",
        "Alessio Zappone",
        "Agbotiname Lucky Imoize",
        "Marco Di Renzo"
      ],
      "primary_category": "eess.SP",
      "categories": [
        "eess.SP",
        "math.OC"
      ],
      "published": "2026-01-02 18:26:42+00:00",
      "link": "https://arxiv.org/pdf/2601.00780v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2601.00758v1",
      "title": "Rational codegree Turán density of hypergraphs",
      "abstract": "Let $H$ be a $k$-graph (i.e. a $k$-uniform hypergraph). Its minimum codegree $δ_{k-1}(H)$ is the largest integer $t$ such that every $(k-1)$-subset of $V(H)$ is contained in at least $t$ edges of~$H$. The \\emph{codegree Turán density} $γ(\\mathcal{F})$ of a family $\\mathcal{F}$ of $k$-graphs is the infimum of $γ> 0$ such that every $k$-graph $H$ on $n\\to\\infty$ vertices with $δ_{k-1}(H) \\ge (γ+o(1))\\, n$ contains some member of $\\mathcal{F}$ as a subgraph.   We prove that, for every integer $k\\ge3$ and every rational number $α\\in [0,1)$, there exists a finite family of $k$-graphs $\\mathcal{F}$ such that $γ(\\mathcal{F})=α$.   Also, for every $k \\ge 3$, we establish a strong version of non-principality, namely that there are two $k$-graphs $F_1$ and $F_2$ such that the codegree Turán density of $\\{F_1,F_2\\}$ is strictly smaller than that of each $F_i$. This answers a question of Mubayi and Zhao [J Comb Theory (A) 114 (2007) 1118--1132].",
      "authors": [
        "Jun Gao",
        "Oleg Pikhurko",
        "Mingyuan Rong",
        "Shumin Sun"
      ],
      "primary_category": "math.CO",
      "categories": [
        "math.CO"
      ],
      "published": "2026-01-02 17:30:38+00:00",
      "link": "https://arxiv.org/pdf/2601.00758v1",
      "tags": [
        "sr-bench"
      ]
    },
    {
      "id": "2601.00717v1",
      "title": "Sherman-Takeda type theorems for locally C*-algebras",
      "abstract": "In this article, we will first establish some density results for a locally $C^*$-algebra $\\mathcal A$ and then identify a property, called Kaplansky density property (KDP). We then give a induced faithful continuous $*$-representation $\\varphi$ of $\\mathcal A^{**}$ (equipped with unique Arens product) on the space $B_{loc}(\\mathcal H)$ such that $\\varphi(\\mathcal A^{**})\\subset \\overline{π(\\mathcal A)}^{WOT}$, where $π:\\mathcal A\\to B_{loc}(\\mathcal H)$ is the associated universal $*$-representation and $\\mathcal H$ is the associated locally Hilbert space. Finally we show that for a Fréchet locally $C^*$-algebra $\\mathcal A$ possessing KDP, the second strong dual is algebraically and topologically $*$-isomorphic to $ \\overline{π(\\mathcal A)}^{WOT}$, which is a direct analogue of the classical Sherman-Takeda theorem for $C^*$-algebras. We shall also observe the joint continuity of some associated bilinear maps in the running.",
      "authors": [
        "Lav Kumar Singh",
        "Aljoša Peperko"
      ],
      "primary_category": "math.OA",
      "categories": [
        "math.OA"
      ],
      "published": "2026-01-02 15:12:46+00:00",
      "link": "https://arxiv.org/pdf/2601.00717v1",
      "tags": [
        "sr-bench"
      ]
    },
    {
      "id": "2601.00403v1",
      "title": "Nonlinear determination and phase retrieval under unimodular constraints",
      "abstract": "We study nonlinear determination problems in Hilbert spaces in which inner products are observed up to prescribed rotations in the complex plane. Given a Hilbert space $H$ and a subset $Θ$ of the unit circle $\\mathbb{T}$, we say that a system $\\mathbf{G}\\subseteq H$ does $Θ$-phase retrieval ($Θ$-PR) if for all $f,h\\in H$ the condition that for every $g\\in\\mathbf{G}$ there exists $θ_g\\inΘ$ with $\\langle f,g\\rangle=θ_g\\langle h,g\\rangle$ forces $f=θh$ for some $θ\\inΘ$. This framework unifies classical phase retrieval ($Θ=\\mathbb{T}$) and sign retrieval ($Θ=\\{1,-1\\}$). For every countable $Θ$ we give a complete characterization of $Θ$-PR in terms of covers of $\\mathbf{G}$ and geometric relations among vectors in the corresponding orthogonal complements, extending the complement-property characterization of Cahill, Casazza, and Daubechies. For cyclic phase sets we show that $Θ$-PR is equivalent to the existence of specific second-order recurrence relations. We apply this to obtain a sharp lattice density criterion for $Θ$-PR of exponential systems. For uncountable $Θ$ we obtain a topological dichotomy in the Fourier determination setting, showing that $Θ$-PR is characterized in terms of connectedness of $Θ$. We further develop a Möbius-invariant framework, proving that $Θ$-PR is preserved under circle automorphisms and is governed by projective invariants such as the cross ratio. Finally, in $\\mathbb{C}^d$ we determine sharp impossibility thresholds and prove that for countable $Θ$ the property is generic once one passes the failure regime, yielding the minimal number of vectors required for $Θ$-PR.",
      "authors": [
        "Lukas Liehr",
        "Tomasz Szczepanski"
      ],
      "primary_category": "math.FA",
      "categories": [
        "math.FA",
        "math.CA",
        "math.CV"
      ],
      "published": "2026-01-01 17:30:44+00:00",
      "link": "https://arxiv.org/pdf/2601.00403v1",
      "tags": [
        "sr-bench",
        "大厂llm"
      ]
    },
    {
      "id": "2601.00371v1",
      "title": "Associating modules for the $h$-Yangian and quantum elliptic algebra in type $A$ with $h$-adic quantum vertex algebras",
      "abstract": "We consider the Etingof-Kazhdan quantum vertex algebra $\\mathcal{V}^c(R)$ associated with the trigonometric and elliptic $R$-matrix of type $A.$ We establish a connection between (restricted) modules for the $h$-Yangian $\\textrm{Y}_h(\\mathfrak{gl}_N)$ and the elliptic quantum algebra $\\mathcal{A}_{h,p}(\\widehat{\\mathfrak{gl}}_2)$ of level zero, and deformed (twisted) $φ$-coordinated $\\mathcal{V}^c(R)$-modules. As its application, in the trigonometric case, we construct new families of central elements of $\\mathcal{V}^c(R)$ at the critical level $c=-N,$ which we then use to derive commutative families in the $h$-Yangian $\\textrm{Y}_h(\\mathfrak{gl}_N).$",
      "authors": [
        "Lucia Bagnoli",
        "Naihuan Jing",
        "Slaven Kožić"
      ],
      "primary_category": "math.QA",
      "categories": [
        "math.QA"
      ],
      "published": "2026-01-01 15:15:44+00:00",
      "link": "https://arxiv.org/pdf/2601.00371v1",
      "tags": [
        "sr-bench",
        "大厂llm"
      ]
    },
    {
      "id": "2601.00295v1",
      "title": "Coupled Modal-Nonmodal Interactions Due to Periodic, Infinite Train of Convecting Vortices (TCV)",
      "abstract": "Events during transition to turbulence either follow modal or non-modal routes, or combinations of the two. Here, we report a computational investigation of strong freestream excitation caused by a train of convecting vortices. For this TCV excitation, we show a strong interaction of modal and non-modal components causing a spectacular growth of disturbances. We propose this as the mechanism for the severe encounters due to convective vortical disturbances on the underlying shear layer.",
      "authors": [
        "Jyothi Kumar Puttam",
        "Prasannabalaji Sundaram",
        "Vajjala K. Suman",
        "Ankan Sarkar",
        "Tapan K. Sengupta",
        "Tirupathur N. Venkatesh",
        "Rakesh K. Mathpal"
      ],
      "primary_category": "physics.flu-dyn",
      "categories": [
        "physics.flu-dyn",
        "math-ph",
        "physics.comp-ph"
      ],
      "published": "2026-01-01 10:26:17+00:00",
      "link": "https://arxiv.org/pdf/2601.00295v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2601.00284v1",
      "title": "Deep learning estimation of the spectral density of functional time series on large domains",
      "abstract": "We derive an estimator of the spectral density of a functional time series that is the output of a multilayer perceptron neural network. The estimator is motivated by difficulties with the computation of existing spectral density estimators for time series of functions defined on very large grids that arise, for example, in climate compute models and medical scans. Existing estimators use autocovariance kernels represented as large $G \\times G$ matrices, where $G$ is the number of grid points on which the functions are evaluated. In many recent applications, functions are defined on 2D and 3D domains, and $G$ can be of the order $G \\sim 10^5$, making the evaluation of the autocovariance kernels computationally intensive or even impossible. We use the theory of spectral functional principal components to derive our deep learning estimator and prove that it is a universal approximator to the spectral density under general assumptions. Our estimator can be trained without computing the autocovariance kernels and it can be parallelized to provide the estimates much faster than existing approaches. We validate its performance by simulations and an application to fMRI images.",
      "authors": [
        "Neda Mohammadi",
        "Soham Sarkar",
        "Piotr Kokoszka"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME",
        "math.ST",
        "stat.ML"
      ],
      "published": "2026-01-01 09:52:21+00:00",
      "link": "https://arxiv.org/pdf/2601.00284v1",
      "tags": [
        "sr-bench",
        "大厂llm",
        "大语言模型",
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00209v1",
      "title": "Limit Computation Over Posets via Minimal Initial Functors",
      "abstract": "It is well known that limits can be computed by restricting along an initial functor, and that this can often simplify limit computation. We systematically study the algorithmic implications of this idea for diagrams indexed by a finite poset. We say an initial functor $F\\colon C\\to D$ with $C$ small is \\emph{minimal} if the sets of objects and morphisms of $C$ each have minimum cardinality, among the sources of all initial functors with target $D$. For $Q$ a finite poset or $Q\\subseteq \\mathbb N^d$ an interval (i.e., a convex, connected subposet), we describe all minimal initial functors $F\\colon P\\to Q$ and in particular, show that $F$ is always a poset inclusion. We give efficient algorithms to compute a choice of minimal initial functor. In the case that $Q\\subseteq \\mathbb N^d$ is an interval, we give asymptotically optimal bounds on $|P|$, the number of relations in $P$ (including identities), in terms of the number $n$ of minima of $Q$: We show that $|P|=Θ(n)$ for $d\\leq 3$, and $|P|=Θ(n^2)$ for $d>3$. We apply these results to give new bounds on the cost of computing $\\lim G$ for a functor $G \\colon Q\\to \\mathbf{Vec}$ valued in vector spaces. For $Q$ connected, we also give new bounds on the cost of computing the \\emph{generalized rank} of $G$ (i.e., the rank of the induced map $\\lim G\\to \\mathop{\\mathrm{colim}} G$), which is of interest in topological data analysis.",
      "authors": [
        "Tamal K. Dey",
        "Michael Lesnick"
      ],
      "primary_category": "math.AT",
      "categories": [
        "math.AT",
        "math.CT"
      ],
      "published": "2026-01-01 04:55:10+00:00",
      "link": "https://arxiv.org/pdf/2601.00209v1",
      "tags": [
        "sr-bench"
      ]
    },
    {
      "id": "2601.00199v1",
      "title": "A POD-DeepONet Framework for Forward and Inverse Design of 2D Photonic Crystals",
      "abstract": "We develop a reduced-order operator-learning framework for forward and inverse band-structure design of two-dimensional photonic crystals with binary, pixel-based $p4m$-symmetric unit cells. We construct a POD--DeepONet surrogate for the discrete band map along the standard high-symmetry path by coupling a POD trunk extracted from high-fidelity finite-element band snapshots with a neural branch network that predicts reduced coefficients. This architecture yields a compact and differentiable forward model that is tailored to the underlying Bloch eigenvalue discretization. We establish continuity of the discrete band map on the relaxed design space and prove a uniform approximation property of the POD--DeepONet surrogate, leading to a natural decomposition of the total surrogate error into POD truncation and network approximation contributions. Building on this forward surrogate, we formulate two end-to-end neural inverse design procedures, namely dispersion-to-structure and band-gap inverse design, with training objectives that combine data misfit, binarity promotion, and supervised regularization to address the intrinsic non-uniqueness of the inverse mapping and to enable stable gradient-based optimization in the relaxed space. Our numerical results show that the proposed framework achieves accurate forward predictions and produces effective inverse designs on practical high-contrast, pixel-based photonic layouts.",
      "authors": [
        "Yueqi Wang",
        "Guanglian Li",
        "Guang Lin"
      ],
      "primary_category": "physics.optics",
      "categories": [
        "physics.optics",
        "math.NA"
      ],
      "published": "2026-01-01 04:21:28+00:00",
      "link": "https://arxiv.org/pdf/2601.00199v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00188v1",
      "title": "An exact unbiased semi-parametric L2 quasi-likelihood framework, complete in the presence of ties",
      "abstract": "Maximum likelihood style estimators possesses a number of ideal characteristics, but require prior identification of the distribution of errors to ensure exact unbiasedness. Independent of the focus of the primary statistical analysis, the estimation of a covariance matrix \\(S^{P \\times P}\\approx Σ^{P \\times P}\\) must possess a specific structure and regularity constraints. The need to estimate a linear Gaussian covariance models appear in various applications as a formal precondition for scientific investigation and predictive analytics. In this work, we construct an \\(\\ell_{2}\\)-norm based quasi-likelihood framework, identified by binomial comparisons between all pairs \\(X_{n},Y_{n}, \\forall {n}\\). Our work here focuses upon the quasi-likelihood basis for estimation of an exactly unbiased linear regression Hájek projection, within which the Kemeny metric space is operationalised via Whitney embedding to obtain exact unbiased minimum variance multivariate covariance estimators upon both discrete and continuous random variables (i.e., exact unbiased identification in the presence of ties upon finite samples). While the covariance estimator is inherently useful, expansion of the Wilcoxon rank-sum testing framework to handle multiple covariates with exact unbiasedness upon finite samples is a currently unresolved research problem, as it maintains identification in the presence of linear surjective mappings onto common points: this model space, by definition, expands our likelihood framework into a consistent non-parametric form of the standard general linear model, which we extend to address both unknown heterogeneity and the problem of weak inferential instruments.",
      "authors": [
        "Landon Hurley"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME",
        "math.ST"
      ],
      "published": "2026-01-01 03:20:20+00:00",
      "link": "https://arxiv.org/pdf/2601.00188v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00176v1",
      "title": "Exponential ergodicity of first order endotactic stochastic reaction systems",
      "abstract": "Chemical reaction networks are a widely accepted modeling framework for diverse science phenomena stemming from all disciplines of science, such as biochemistry, ecology, epidemiology, social and political science. In this paper we prove that every first order endotactic stochastic mass-action reaction system (SMART) is essential (i.e., every state in the state space is within a closed communicating class of the underlying continuous time Markov chain model) and is exponentially ergodic. The proof is based on a recent result on first order endotactic reaction networks in a companion paper [C.X., First order endotactic reaction networks. arXiv:2409.01598v2]. Besides, we show that a stochastic reaction system (of possibly nonlinear propensities) dominated by a first order endotactic SMART is exponentially erogdic. To demonstrate the applicability of results, we provide various examples of higher order SMART, including e.g., (1) SMART with a first order endotactic asymptotic limit as well as, (2) joint of translations of first order endotactic SMART.",
      "authors": [
        "Chuang Xu"
      ],
      "primary_category": "math.PR",
      "categories": [
        "math.PR"
      ],
      "published": "2026-01-01 02:34:34+00:00",
      "link": "https://arxiv.org/pdf/2601.00176v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00161v1",
      "title": "Fast Ewald Summation with Prolates for Charged Systems in the NPT Ensemble",
      "abstract": "We present an NPT extension of Ewald summation with prolates (ESP), a spectrally accurate and scalable particle-mesh method for molecular dynamics simulations of periodic, charged systems. Building on the recently introduced ESP framework, this work focuses on rigorous and thermodynamically consistent pressure/stress evaluation in the isothermal--isobaric ensemble. ESP employs prolate spheroidal wave functions as both splitting and spreading kernels, reducing the Fourier grid size needed to reach a prescribed pressure accuracy compared with current widely used mesh-Ewald methods based on Gaussian splitting and B-spline spreading. We derive a unified pressure-tensor formulation applicable to isotropic, semi-isotropic, anisotropic, and fully flexible cells, and show that the long-range pressure can be evaluated with a single forward FFT followed by diagonal scaling, whereas force evaluation requires both forward and inverse transforms. We provide production implementations in LAMMPS and GROMACS and validate pressure and force accuracy on bulk water, LiTFSI ionic liquids, and a transmembrane system. Benchmarks on up to $3\\times 10^3$ CPU cores demonstrate strong scaling and reduced communication cost at matched accuracy, particularly for NPT pressure evaluation.",
      "authors": [
        "Jiuyang Liang",
        "Libin Lu",
        "Shidong Jiang"
      ],
      "primary_category": "math.NA",
      "categories": [
        "math.NA",
        "physics.chem-ph"
      ],
      "published": "2026-01-01 01:58:34+00:00",
      "link": "https://arxiv.org/pdf/2601.00161v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2601.00064v1",
      "title": "Pauli stabilizer formalism for topological quantum field theories and generalized statistics",
      "abstract": "Topological quantum field theory (TQFT) provides a unifying framework for describing topological phases of matter and for constructing quantum error-correcting codes, playing a central role across high-energy physics, condensed matter, and quantum information. A central challenge is to formulate topological order on the lattice and to extract the properties of topological excitations from microscopic Hamiltonians. In this work, we construct new classes of lattice gauge theories as Pauli stabilizer models, realizing a wide range of TQFTs in general spacetime dimensions. We develop a lattice description of the resulting extended excitations and systematically determine their generalized statistics.   Our main example is the $(4+1)$D \\emph{fermionic-loop toric code}, obtained by condensing the $e^2 m^2$-loop in the $(4+1)$D $\\mathbb{Z}_4$ toric code. We show that the loop excitation exhibits fermionic loop statistics: the 24-step loop-flipping process yields a phase of $-1$. Our Pauli stabilizer models realize all twisted 2-form gauge theories in $(4+1)$D, the higher-form Dijkgraaf-Witten TQFT classified by $H^{5}(B^{2}G, U(1))$. % Beyond $(4+1)$D, the fermionic-loop toric codes form a family of $\\mathbb{Z}_2$ topological orders in arbitrary dimensions featuring fermionic loop excitations, realized as explicit Pauli stabilizer codes using $\\mathbb{Z}_4$ qudits. % Finally, we develop a Pauli-based framework that defines generalized statistics for extended excitations in any dimension, yielding computable lattice unitary processes to detect nontrivial generalized statistics. For example, we propose anyonic membrane statistics in $(6+1)$D, as well as fermionic membrane and volume statistics in arbitrary dimensions. We construct new families of $\\mathbb{Z}_2$ topological orders: the \\emph{fermionic-membrane toric code} and the \\emph{fermionic-volume toric code}.",
      "authors": [
        "Yitao Feng",
        "Hanyu Xue",
        "Ryohei Kobayashi",
        "Po-Shen Hsin",
        "Yu-An Chen"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "cond-mat.str-el",
        "hep-th",
        "math.QA"
      ],
      "published": "2025-12-31 19:00:01+00:00",
      "link": "https://arxiv.org/pdf/2601.00064v1",
      "tags": [
        "大厂llm",
        "大语言模型"
      ]
    },
    {
      "id": "2512.25042v1",
      "title": "Compound Estimation for Binomials",
      "abstract": "Many applications involve estimating the mean of multiple binomial outcomes as a common problem -- assessing intergenerational mobility of census tracts, estimating prevalence of infectious diseases across countries, and measuring click-through rates for different demographic groups. The most standard approach is to report the plain average of each outcome. Despite simplicity, the estimates are noisy when the sample sizes or mean parameters are small. In contrast, the Empirical Bayes (EB) methods are able to boost the average accuracy by borrowing information across tasks. Nevertheless, the EB methods require a Bayesian model where the parameters are sampled from a prior distribution which, unlike the commonly-studied Gaussian case, is unidentified due to discreteness of binomial measurements. Even if the prior distribution is known, the computation is difficult when the sample sizes are heterogeneous as there is no simple joint conjugate prior for the sample size and mean parameter.   In this paper, we consider the compound decision framework which treats the sample size and mean parameters as fixed quantities. We develop an approximate Stein's Unbiased Risk Estimator (SURE) for the average mean squared error given any class of estimators. For a class of machine learning-assisted linear shrinkage estimators, we establish asymptotic optimality, regret bounds, and valid inference. Unlike existing work, we work with the binomials directly without resorting to Gaussian approximations. This allows us to work with small sample sizes and/or mean parameters in both one-sample and two-sample settings. We demonstrate our approach using three datasets on firm discrimination, education outcomes, and innovation rates.",
      "authors": [
        "Yan Chen",
        "Lihua Lei"
      ],
      "primary_category": "econ.EM",
      "categories": [
        "econ.EM",
        "math.ST",
        "stat.ME"
      ],
      "published": "2025-12-31 18:38:01+00:00",
      "link": "https://arxiv.org/pdf/2512.25042v1",
      "tags": [
        "sr-bench",
        "符号回归（示例）"
      ]
    },
    {
      "id": "2512.25032v1",
      "title": "Testing Monotonicity in a Finite Population",
      "abstract": "We consider the extent to which we can learn from a completely randomized experiment whether everyone has treatment effects that are weakly of the same sign, a condition we call monotonicity. From a classical sampling perspective, it is well-known that monotonicity is untestable. By contrast, we show from the design-based perspective -- in which the units in the population are fixed and only treatment assignment is stochastic -- that the distribution of treatment effects in the finite population (and hence whether monotonicity holds) is formally identified. We argue, however, that the usual definition of identification is unnatural in the design-based setting because it imagines knowing the distribution of outcomes over different treatment assignments for the same units. We thus evaluate the informativeness of the data by the extent to which it enables frequentist testing and Bayesian updating. We show that frequentist tests can have nontrivial power against some alternatives, but power is generically limited. Likewise, we show that there exist (non-degenerate) Bayesian priors that never update about whether monotonicity holds. We conclude that, despite the formal identification result, the ability to learn about monotonicity from data in practice is severely limited.",
      "authors": [
        "Jiafeng Chen",
        "Jonathan Roth",
        "Jann Spiess"
      ],
      "primary_category": "econ.EM",
      "categories": [
        "econ.EM",
        "math.ST",
        "stat.ME"
      ],
      "published": "2025-12-31 18:29:54+00:00",
      "link": "https://arxiv.org/pdf/2512.25032v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2512.25022v1",
      "title": "Real Riemann Surfaces: Smooth and Discrete",
      "abstract": "This paper develops a discrete theory of real Riemann surfaces based on quadrilateral cellular decompositions (quad-graphs) and a linear discretization of the Cauchy-Riemann equations. We construct a discrete analogue of an antiholomorphic involution and classify the topological types of discrete real Riemann surfaces, recovering the classical results on the number of real ovals and the separation of the surface.   Central to our approach is the construction of a symplectic homology basis adapted to the discrete involution. Using this basis, we prove that the discrete period matrix admits the same canonical decomposition $Π= \\frac{1}{2} H + i T$ as in the smooth setting, where $H$ encodes the topological type and $T$ is purely imaginary. This structural result bridges the gap between combinatorial models and the classical theory of real algebraic curves.",
      "authors": [
        "Johanna Düntsch",
        "Felix Günther"
      ],
      "primary_category": "math.CV",
      "categories": [
        "math.CV",
        "math.CO",
        "math.DG"
      ],
      "published": "2025-12-31 18:21:17+00:00",
      "link": "https://arxiv.org/pdf/2512.25022v1",
      "tags": [
        "大厂llm"
      ]
    },
    {
      "id": "2512.25021v1",
      "title": "Detector Response Matrices, Effective Areas, and Flash-Effective Areas for Radiation Detectors",
      "abstract": "A Detector Response Matrix (DRM) is a discrete representation of an instrument's Detector Response Function (DRF), which quantifies how many discrete energy depositions occur in a detector volume for a given distribution of particles incident on the detector. For simple radiation detectors that can count such energy depositions (such as scintillators, Proportional Counter Tubes (PCTs), etc), we consider the ideal counting DRF, $\\mathbf{G}_\\varphi (E_\\mathrm{in}, E_\\mathrm{dep})$, which relates the detector's counting histogram (number of energy depositions within a given channel) to an incident particles characterization, $\\varphi$ (e.g. incident flux, fluence, intensity). From the counting DRF we can derive the counting DRM, the effective area, and the flash effective area (which measures the total energy deposited in the detector from a large, instantaneous fluence).",
      "authors": [
        "Gregory Bowers",
        "Eve Chase",
        "William Ford",
        "Daniel Coupland",
        "Brian Larsen",
        "Caleb Roecker",
        "Karl Smith",
        "Kurtis Bartlett",
        "Katherine Gattiker Katherine Mesick"
      ],
      "primary_category": "physics.ins-det",
      "categories": [
        "physics.ins-det",
        "hep-ex",
        "math-ph"
      ],
      "published": "2025-12-31 18:20:10+00:00",
      "link": "https://arxiv.org/pdf/2512.25021v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2512.25010v1",
      "title": "Bounding regularity of $\\mathrm{VI}^m$-modules",
      "abstract": "Fix a finite field $\\mathbb{F}$. Let $\\mathrm{VI}$ be a skeleton of the category of finite dimensional $\\mathbb{F}$-vector spaces and injective $\\mathbb{F}$-linear maps. We study $\\mathrm{VI}^m$-modules over a noetherian commutative ring in the nondescribing characteristic case. We prove that if a finitely generated $\\mathrm{VI}^m$-module is generated in degree $\\leqslant d$ and related in degree $\\leqslant r$, then its regularity is bounded above by a function of $m$, $d$, and $r$. A key ingredient of the proof is a shift theorem for finitely generated $\\mathrm{VI}^m$-modules.",
      "authors": [
        "Wee Liang Gan",
        "Khoa Ta"
      ],
      "primary_category": "math.RT",
      "categories": [
        "math.RT"
      ],
      "published": "2025-12-31 17:58:25+00:00",
      "link": "https://arxiv.org/pdf/2512.25010v1",
      "tags": [
        "sr-bench"
      ]
    },
    {
      "id": "2512.24972v1",
      "title": "From Complex-Analytic Models to Sparse Domination: A Dyadic Approach of Hypersingular Operators via Bourgain's Interpolation Method",
      "abstract": "Motivated by the work of Cheng--Fang--Wang--Yu on the hypersingular Bergman projection, we develop a real-variable and dyadic framework for hypersingular operators in regimes where strong-type estimates fail at the critical line. The main new input is a hypersingular sparse domination principle combined with Bourgain's interpolation method, which provides a flexible mechanism to establish critical-line (and endpoint) estimates.   In the unit disc setting with $1<t<3/2$, we obtain a full characterization of the $(p,q)$ mapping theory for the dyadic hypersingular maximal operator $\\mathcal M_t^{\\mathcal D}$, in particular including estimates on the critical line $1/q-1/p=2t-2$ and a weighted endpoint criterion in the radial setting. We also prove endpoint estimates for the hypersingular Bergman projection \\[ K_{2t}f(z)=\\int_{\\mathbb D}\\frac{f(w)}{(1-z\\overline w)^{2t}}\\,dA(w), \\] including a restricted weak-type bound at $(p,q)=\\bigl(\\tfrac{1}{3-2t},1\\bigr)$. Finally, we introduce a class of hypersingular cousin of sparse operators in $\\mathbb R^n$ associated with \\emph{graded} sparse families, quantified by the sparseness $η$ and a new structural parameter (the \\emph{degree}) $K_{\\mathcal S}$, and we characterize the corresponding strong/weak/restricted weak-type regimes in terms of $(n,t,η,K_{\\mathcal S})$.   Our real-variable perspective addresses to an inquiry raised by Cheng--Fang--Wang--Yu on developing effective real-analytic tools in the hypersingular regime for $K_{2t}$, and it also provides a new route toward the critical-line analysis of Forelli--Rudin type operators and related hypersingular operators in both real and complex settings.",
      "authors": [
        "Bingyang Hu",
        "Xiaojing Zhou"
      ],
      "primary_category": "math.CA",
      "categories": [
        "math.CA",
        "math.CV"
      ],
      "published": "2025-12-31 17:03:19+00:00",
      "link": "https://arxiv.org/pdf/2512.24972v1",
      "tags": [
        "sr-bench",
        "大厂llm"
      ]
    },
    {
      "id": "2512.24963v1",
      "title": "The least prime with a given cycle type",
      "abstract": "Let $G$ be a finite group. Let $K/k$ be a Galois extension of number fields with Galois group isomorphic to $G$, and let $C \\subseteq \\mathrm{Gal}(K/k) \\simeq G$ be a conjugacy invariant subset. It is well known that there exists an unramified prime ideal $\\mathfrak{p}$ of $k$ with Frobenius element lying in $C$ and norm satisfying $\\mathrm{N}\\mathfrak{p} \\ll |\\mathrm{Disc}(K)|^α$ for some constant $α= α(G,C)$. There is a rich literature establishing unconditional admissible values for $α$, with most approaches proceeding by studying the zeros of $L$-functions. We give an alternative approach, not relying on zeros, that often substantially improves this exponent $α$ for any fixed finite group $G$, provided $C$ is a union of rational equivalence classes. As a particularly striking example, we prove that there exist absolute constants $c_1,c_2 > 0$ such that for any $n\\geq 2$ and any conjugacy class $C \\subset S_n$, one may take $α(S_n,C) = c_1 \\exp(-c_2n)$. Our approach reduces the core problem to a question in character theory.",
      "authors": [
        "Peter J. Cho",
        "Robert J. Lemke Oliver",
        "Asif Zaman"
      ],
      "primary_category": "math.NT",
      "categories": [
        "math.NT"
      ],
      "published": "2025-12-31 16:48:57+00:00",
      "link": "https://arxiv.org/pdf/2512.24963v1",
      "tags": [
        "大厂llm"
      ]
    },
    {
      "id": "2512.24937v1",
      "title": "Modelling the movements of organisms by stochastic theory in a comoving frame",
      "abstract": "Imagine you walk in a plane. You move by making a step of a certain length per time interval in a chosen direction. Repeating this process by randomly sampling step length and turning angle defines a two-dimensional random walk in what we call comoving frame coordinates. This is precisely how Ross and Pearson proposed to model the movements of organisms more than a century ago. Decades later their concept was generalised by including persistence leading to a correlated random walk, which became a popular model in Movement Ecology. In contrast, Langevin equations describing cell migration and used in active matter theory are typically formulated by position and velocity in a fixed Cartesian frame. In this article, we explore the transformation of stochastic Langevin dynamics from the Cartesian into the comoving frame. We show that the Ornstein-Uhlenbeck process for the Cartesian velocity of a walker can be transformed exactly into a stochastic process that is defined self-consistently in the comoving frame, thereby profoundly generalising correlated random walk models. This approach yields a general conceptual framework how to transform stochastic processes from the Cartesian into the comoving frame. Our theory paves the way to derive, invent and explore novel stochastic processes in the comoving frame for modelling the movements of organisms. It can also be applied to design novel stochastic dynamics for autonomously moving robots and drones.",
      "authors": [
        "Norberto Lucero Azuara",
        "Rainer Klages"
      ],
      "primary_category": "physics.bio-ph",
      "categories": [
        "physics.bio-ph",
        "cond-mat.soft",
        "cond-mat.stat-mech",
        "math-ph",
        "math.DS"
      ],
      "published": "2025-12-31 15:57:13+00:00",
      "link": "https://arxiv.org/pdf/2512.24937v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2512.24920v1",
      "title": "Transgression in the primitive cohomology",
      "abstract": "We study the Chern-Weil theory for the primitive cohomology of a symplectic manifold. First, given a symplectic manifold, we review the superbundle-valued forms on this manifold and prove a primitive version of the Bianchi identity. Second, as the main result, we prove a transgression formula associated with the boundary map of the primitive cohomology. Third, as an application of the main result, we introduce the concept of primitive characteristic classes and point out a further direction.",
      "authors": [
        "Hao Zhuang"
      ],
      "primary_category": "math.DG",
      "categories": [
        "math.DG",
        "math-ph",
        "math.SG"
      ],
      "published": "2025-12-31 15:24:57+00:00",
      "link": "https://arxiv.org/pdf/2512.24920v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00048v1",
      "title": "The fifth algebraic transfer in generic degrees and validation of a localized Kameko's conjecture",
      "abstract": "This paper develops our previous works concerning the classical Peterson hit problem of five variables for the 2-primary Steenrod algebra $\\mathscr A$ in generic degrees and related applications. To illustrate the utility of the Steenrod algebra, we give a proof that $\\mathbb{C}P^4/\\mathbb{C}P^2$ and $\\mathbb{S}^6\\vee \\mathbb{S}^8$ are not homotopy equivalent by demonstrating that they are not isomorphic as $\\mathscr A$-modules. The results are used to describe the representations of the general linear group of rank $5$ over the binary field $\\mathbb F_2.$ As a consequence, the fifth algebraic transfer is an isomorphism at the internal degrees under consideration. These results have also been completely verified based on our novel algorithmic programs implemented in the computer algebra systems SageMath and OSCAR, announced in [arXiv:2507.10108] and [arXiv:2509.09455]. We also study a localized variation of Kameko's conjecture concerning the dimension of the indecomposables $\\mathbb F_2\\otimes_{\\mathscr A}\\mathbb F_2[x_1, x_2, \\ldots, x_m]$ relative to parameter vectors and prove that this conjecture is valid for all $m\\geq 1$ in certain degrees.",
      "authors": [
        "Dang Vo Phuc"
      ],
      "primary_category": "math.AT",
      "categories": [
        "math.AT"
      ],
      "published": "2025-12-31 13:58:02+00:00",
      "link": "https://arxiv.org/pdf/2601.00048v1",
      "tags": [
        "sr-bench"
      ]
    },
    {
      "id": "2512.24812v1",
      "title": "Four collapsing one-dimensional particles: a dynamical system approach of the spherical billiard reduction",
      "abstract": "We consider a system of four one-dimensional inelastic hard spheres evolving on the real line $\\mathbb{R}$, and colliding according to a scattering law characterized by a fixed restitution coefficient $r$. We study the possible orders of collisions when the inelastic collapse occurs, relying on the so-called $\\mathfrak{b}$-to-$\\mathfrak{b}$ mapping, a two-dimensional dynamical system associated to the original particle system which encodes all the possible collision orders. We prove that the $\\mathfrak{b}$-to-$\\mathfrak{b}$ mapping is a piecewise projective transformation, which allows one to perform efficient numerical simulations of its orbits. We recover previously known results concerning the one-dimensional four-particle inelastic hard sphere system and we support the conjectures stated in the literature concerning particular periodic orbits. We discover three new families of periodic orbits that coexist depending on the restitution coefficient, we prove rigorously that there exist stable periodic orbits for the $\\mathfrak{b}$-to-$\\mathfrak{b}$ mapping for restitution coefficients larger than the upper bounds previously known, and we prove the existence of quasi-periodic orbits for this mapping.",
      "authors": [
        "Roberto Castorrini",
        "Théophile Dolmaire"
      ],
      "primary_category": "math.DS",
      "categories": [
        "math.DS",
        "math-ph"
      ],
      "published": "2025-12-31 11:58:21+00:00",
      "link": "https://arxiv.org/pdf/2512.24812v1",
      "tags": [
        "大厂llm",
        "大语言模型"
      ]
    },
    {
      "id": "2512.24807v1",
      "title": "Heat kernel estimates for Markov processes with jump kernels blowing-up at the boundary",
      "abstract": "In this paper, we study purely discontinuous symmetric Markov processes on closed subsets of ${\\mathbb R}^d$, $d\\ge 1$, with jump kernels of the form $J(x,y)=|x-y|^{-d-α}{\\mathcal B}(x,y)$, $α\\in (0,2)$, where the function ${\\mathcal B}(x,y)$ may blow up at the boundary of the state space. This extends the framework developed recently for conservative self-similar Markov processes on the upper half-space to a broader geometric setting. Examples of Markov processes that fall into our general framework include traces of isotropic $α$-stable processes in $C^{1,\\rm Dini}$ sets, processes in Lipschitz sets arising in connection with the nonlocal Neumann problem, and a large class of resurrected self-similar processes in the closed upper half-space.   We establish sharp two-sided heat kernel estimates for these Markov processes. A fundamental difficulty in accomplishing this task is that, in contrast to the existing literature on heat kernels for jump processes, the tails of the associated jump measures in our setting are not uniformly bounded. Thus, standard techniques in the existing literature used to study heat kernels are not applicable. To overcome this obstacle, we employ recently developed weighted functional inequalities specifically designed for jump kernels blowing up at the boundary.",
      "authors": [
        "Soobin Cho",
        "Panki Kim",
        "Renming Song",
        "Zoran Vondraček"
      ],
      "primary_category": "math.PR",
      "categories": [
        "math.PR",
        "math.AP"
      ],
      "published": "2025-12-31 11:49:51+00:00",
      "link": "https://arxiv.org/pdf/2512.24807v1",
      "tags": [
        "sr-bench"
      ]
    },
    {
      "id": "2512.24800v1",
      "title": "A Study of S-primary Ideals in Commutative Semirings",
      "abstract": "In this article, we define the concept of an $S$-$k$-irreducible ideal and $S$-$k$-maximal ideal in a commutative semiring. We also establish several results concerning $S$-$k$-primary ideals and prove the existence theorem and the $S$-version of the uniqueness theorem using localization, for $S$-$k$-primary decompositions.   Also we show that the $S$-radical of every $S$-primary ideal is a prime ideal of $R$. Moreover, we investigate the structure of $S$-primary ideals in principal ideal semidomain and prove that each such ideal can be expressed of the form, $I = (vp^n)$, $n\\in \\mathbf{N}$ and for some $p \\in \\mathbf P -\\mathbf P_S$ and $v\\in R$ such that $(v)\\cap S\\neq \\varnothing $, where $\\mathbf P$ is the set of all irreducible (prime) elements of R and for a multiplicative subset $S\\subsetneq R$, the set $\\mathbf P_S$ defined by $\\mathbf P_S=\\{p\\in \\mathbf P : (p) \\cap S \\neq \\varnothing \\}$.",
      "authors": [
        "Amaresh Mahato",
        "Sampad Das",
        "Manasi Mandal"
      ],
      "primary_category": "math.AC",
      "categories": [
        "math.AC"
      ],
      "published": "2025-12-31 11:39:45+00:00",
      "link": "https://arxiv.org/pdf/2512.24800v1",
      "tags": [
        "sr-bench"
      ]
    },
    {
      "id": "2512.24775v1",
      "title": "Phase Reduction of Limit Cycle Oscillators: A Tutorial Review with New Perspectives on Isochrons and an Outlook to Higher-Order Reductions",
      "abstract": "The phase reduction technique is essential for studying rhythmic phenomena across various scientific fields. It allows the complex dynamics of high-dimensional oscillatory systems to be expressed by a single phase variable. This paper provides a detailed review and synthesis of phase reduction with two main goals. First, we develop a solid geometric framework for the theory by creating isochrons, which are the level sets of the asymptotic phase, using the Graph Transform theorem. We show that isochrons form an invariant, continuous structure of the basin of attraction of a stable limit cycle, helping to clarify the concept of the asymptotic phase. Second, we systematically explain how to derive the first-order phase reduction for weakly perturbed and coupled systems. In the end, we discuss the limitations of the first-order approach, particularly its restriction to very small perturbations and the issue of vanishing coupling terms in certain networks. We finish by outlining the framework and importance of higher-order phase reductions. This establishes a clear link from classical theory to modern developments and sets the stage for a more in-depth discussion in a future publication.",
      "authors": [
        "Zeray Hagos Gebrezabher"
      ],
      "primary_category": "math.DS",
      "categories": [
        "math.DS",
        "math-ph"
      ],
      "published": "2025-12-31 10:45:55+00:00",
      "link": "https://arxiv.org/pdf/2512.24775v1",
      "tags": [
        "大厂llm",
        "大语言模型"
      ]
    },
    {
      "id": "2512.24669v1",
      "title": "Nonparametric Bandits with Single-Index Rewards: Optimality and Adaptivity",
      "abstract": "Contextual bandits are a central framework for sequential decision-making, with applications ranging from recommendation systems to clinical trials. While nonparametric methods can flexibly model complex reward structures, they suffer from the curse of dimensionality. We address this challenge using a single-index model, which projects high-dimensional covariates onto a one-dimensional subspace while preserving nonparametric flexibility.   We first develop a nonasymptotic theory for offline single-index regression for each arm, combining maximum rank correlation for index estimation with local polynomial regression. Building on this foundation, we propose a single-index bandit algorithm and establish its convergence rate. We further derive a matching lower bound, showing that the algorithm achieves minimax-optimal regret independent of the ambient dimension $d$, thereby overcoming the curse of dimensionality.   We also establish an impossibility result for adaptation: without additional assumptions, no policy can adapt to unknown smoothness levels. Under a standard self-similarity condition, however, we construct a policy that remains minimax-optimal while automatically adapting to the unknown smoothness. Finally, as the dimension $d$ increases, our algorithm continues to achieve minimax-optimal regret, revealing a phase transition that characterizes the fundamental limits of single-index bandit learning.",
      "authors": [
        "Wanteng Ma",
        "T. Tony Cai"
      ],
      "primary_category": "math.ST",
      "categories": [
        "math.ST"
      ],
      "published": "2025-12-31 06:48:58+00:00",
      "link": "https://arxiv.org/pdf/2512.24669v1",
      "tags": [
        "sr-bench",
        "符号回归（示例）"
      ]
    },
    {
      "id": "2512.24660v1",
      "title": "Rational Angle Bisection Problem in Higher Dimensional Spaces and Incenters of Simplices over Fields",
      "abstract": "In this article, we generalize the following problem, which is called the rational angle bisection problem, to the $n$-dimensional space $k^n$ over a subfield $k$ of $\\mathbb R$: on the coordinate plane, for which rational numbers $a$ and $b$ are the slopes of the angle bisectors between two lines with slopes $a$ and $b$ rational? First, we give a few characterizations of when the angle bisectors between two lines with direction vectors in $k^n$ have direction vectors in $k^n.$ To find solutions to the problem in the case when $k = \\mathbb Q,$ we also give a formula for the integral solutions of $x_1{}^2+\\dots +x_n{}^2 = dx_{n+1}{}^2,$ which is a generalization of the negative Pell's equation $x^2-dy^2 = -1,$ where $d$ is a square-free positive integer. Second, by applying the above characterizations, we give a necessary and sufficient condition for the incenter of a given $n$-simplex with $k$-rational vertices to be $k$-rational. On the coordinate plane, we prove that every triangle with $k$-rational vertices and incenter can be obtained by scaling a triangle with $k$-rational side lengths and area, which is a generalization of a Heronian triangle. We also state certain fundamental properties of a few centers of a given triangle with $k$-rational vertices.",
      "authors": [
        "Takashi Hirotsu"
      ],
      "primary_category": "math.NT",
      "categories": [
        "math.NT",
        "math.MG"
      ],
      "published": "2025-12-31 06:14:39+00:00",
      "link": "https://arxiv.org/pdf/2512.24660v1",
      "tags": [
        "sr-bench"
      ]
    },
    {
      "id": "2512.24649v1",
      "title": "Periodic Beurling-Ahlfors Extensions and Quasisymmetric Rigidity of Carpets",
      "abstract": "We establish periodic quasiconformal extension theorems for periodic orientation-preserving quasisymmetric self homeomorphisms of quasicircles or quasi-round carpets. As applications, we prove that, if $f$ is a periodic orientation-preserving quasisymmetric self homeomorphism of a quasi-round carpet $S$ of measure zero in $\\mathbb{C}$, which has a fixed point in the outer peripheral circle of $S$, then $f$ is the identity on $S$. Moreover, we prove that, if $f$ is a quasisymmetric self homeomorphism of a square carpet $S$ of measure zero in a rectangle ring, which fixes each of the four vertices of the outer peripheral circle of $S$, then $f$ is the identity on $S$. An analogous rigidity problem for the $\\mathbb{C}^*$-square carpets is discussed.",
      "authors": [
        "Fan Wen"
      ],
      "primary_category": "math.MG",
      "categories": [
        "math.MG",
        "math.DS"
      ],
      "published": "2025-12-31 05:47:43+00:00",
      "link": "https://arxiv.org/pdf/2512.24649v1",
      "tags": [
        "sr-bench"
      ]
    },
    {
      "id": "2512.24575v1",
      "title": "Functional Calculi, Positivity, and Convolution of Matrices",
      "abstract": "Convolution admits a natural formulation as a functional operation on matrices. Motivated by the functional and entrywise calculi, this leads to a framework in which convolution defines a matrix transform that preserves positivity. Within this setting, we establish results parallel to the classical theories of Pólya--Szegő, Schoenberg, Rudin, Loewner, and Horn in the context of entrywise calculus. The structure of our transform is governed by a Cayley--Hamilton-type theory valid in commutative rings of characteristic zero, together with a novel polynomial-matrix identity specific to convolution. Beyond these analytic aspects, we uncover an intrinsic connection between convolution and the Bruhat order on the symmetric group, illuminating the combinatorial aspect of this functional operation. This work extends the classical theory of entrywise positivity preservers and operator monotone functions into the convolutional setting.",
      "authors": [
        "Javad Mashreghi",
        "Mostafa Nasri",
        "Prateek Kumar Vishwakarma"
      ],
      "primary_category": "math.FA",
      "categories": [
        "math.FA",
        "math.CO"
      ],
      "published": "2025-12-31 02:47:14+00:00",
      "link": "https://arxiv.org/pdf/2512.24575v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2512.24567v1",
      "title": "Newton-Krylov Methods for Computing Steady States of Particle Timesteppers via Optimal Transport",
      "abstract": "Timesteppers constitute a powerful tool in modern computational science and engineering. Although they are typically used to advance the system forward in time, they can also be viewed as nonlinear mappings that implicitly encode steady states and stability information. In this work, we present an extension of the matrix-free framework for calculating, via timesteppers, steady states of deterministic systems to stochastic particle simulations, where intrinsic randomness prevents direct steady state extraction. By formulating stochastic timesteppers in the language of optimal transport, we reinterpret them as operators acting on probability measures rather than on individual particle trajectories. This perspective enables the construction of smooth cumulative- and inverse-cumulative-distribution-function ((I)CDF) timesteppers that evolve distributions rather than particles. Combined with matrix-free Newton-Krylov solvers, these smooth timesteppers allow efficient computation of steady-state distributions even under high stochastic noise. We perform an error analysis quantifying how noise affects finite-difference Jacobian action approximations, and demonstrate that convergence can be obtained even in high noise regimes. Finally, we introduce higher-dimensional generalizations based on smooth CDF-related representations of particles and validate their performance on a non-trivial two-dimensional distribution. Together, these developments establish a unified variational framework for computing meaningful steady states of both deterministic and stochastic timesteppers.",
      "authors": [
        "Hannes Vandecasteele",
        "Nicholas Karris",
        "Alexander Cloninger",
        "Ioannis G. Kevrekidis"
      ],
      "primary_category": "math.NA",
      "categories": [
        "math.NA",
        "math.PR"
      ],
      "published": "2025-12-31 02:22:47+00:00",
      "link": "https://arxiv.org/pdf/2512.24567v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2512.24527v1",
      "title": "Dimension-free estimators of gradients of functions with(out) non-independent variables",
      "abstract": "This study proposes a unified stochastic framework for approximating and computing the gradient of every smooth function evaluated at non-independent variables, using $\\ell_p$-spherical distributions on $\\R^d$ with $d, p\\geq 1$. The upper-bounds of the bias of the gradient surrogates do not suffer from the curse of dimensionality for any $p\\geq 1$. Also, the mean squared errors (MSEs) of the gradient estimators are bounded by $K_0 N^{-1} d$ for any $p \\in [1, 2]$, and by $K_1 N^{-1} d^{2/p}$ when $2 \\leq p \\ll d$ with $N$ the sample size and $K_0, K_1$ some constants. Taking $\\max\\left\\{2, \\log(d) \\right\\} < p \\ll d$ allows for achieving dimension-free upper-bounds of MSEs. In the case where $d\\ll p< +\\infty$, the upper-bound $K_2 N^{-1} d^{2-2/p}/ (d+2)^2$ is reached with $K_2$ a constant. Such results lead to dimension-free MSEs of the proposed estimators, which boil down to estimators of the traditional gradient when the variables are independent. Numerical comparisons show the efficiency of the proposed approach.",
      "authors": [
        "Matieyendou Lamboni"
      ],
      "primary_category": "math.ST",
      "categories": [
        "math.ST",
        "math.OC",
        "math.PR"
      ],
      "published": "2025-12-31 00:22:47+00:00",
      "link": "https://arxiv.org/pdf/2512.24527v1",
      "tags": [
        "sr-bench",
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00773v1",
      "title": "Variable Importance in Generalized Linear Models -- A Unifying View Using Shapley Values",
      "abstract": "Variable importance in regression analyses is of considerable interest in a variety of fields. There is no unique method for assessing variable importance. However, a substantial share of the available literature employs Shapley values, either explicitly or implicitly, to decompose a suitable goodness-of-fit measure, in the linear regression model typically the classical $R^2$. Beyond linear regression, there is no generally accepted goodness-of-fit measure, only a variety of pseudo-$R^2$s. We formulate and discuss the desirable properties of goodness-of-fit measures that enable Shapley values to be interpreted in terms of relative, and even absolute, importance. We suggest to use a pseudo-$R^2$ based on the Kullback-Leibler divergence, the Kullback-Leibler $R^2$, which has a convenient form for generalized linear models and permits to unify and extend previous work on variable importance for linear and nonlinear models. Several examples are presented, using data from public health and insurance.",
      "authors": [
        "Sinan Acemoglu",
        "Christian Kleiber",
        "Jörg Urban"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME"
      ],
      "published": "2026-01-02 18:09:33+00:00",
      "link": "https://arxiv.org/pdf/2601.00773v1",
      "tags": [
        "sr-bench",
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00531v1",
      "title": "Fair Policy Learning under Bipartite Network Interference: Learning Fair and Cost-Effective Environmental Policies",
      "abstract": "Numerous studies have shown the harmful effects of airborne pollutants on human health. Vulnerable groups and communities often bear a disproportionately larger health burden due to exposure to airborne pollutants. Thus, there is a need to design policies that effectively reduce the public health burdens while ensuring cost-effective policy interventions. Designing policies that optimally benefit the population while ensuring equity between groups under cost constraints is a challenging statistical and causal inference problem. In the context of environmental policy this is further complicated by the fact that interventions target emission sources but health impacts occur in potentially distant communities due to atmospheric pollutant transport -- a setting known as bipartite network interference (BNI). To address these issues, we propose a fair policy learning approach under BNI. Our approach allows to learn cost-effective policies under fairness constraints even accounting for complex BNI data structures. We derive asymptotic properties and demonstrate finite sample performance via Monte Carlo simulations. Finally, we apply the proposed method to a real-world dataset linking power plant scrubber installations to Medicare health records for more than 2 million individuals in the U.S. Our method determine fair scrubber allocations to reduce mortality under fairness and cost constraints.",
      "authors": [
        "Raphael C. Kim",
        "Rachel C. Nethery",
        "Kevin L. Chen",
        "Falco J. Bargagli-Stoffi"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME"
      ],
      "published": "2026-01-02 01:55:22+00:00",
      "link": "https://arxiv.org/pdf/2601.00531v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00310v1",
      "title": "Asymptotic distribution of a robust wavelet-based NKK periodogram",
      "abstract": "This paper investigates the asymptotic distribution of a wavelet-based NKK periodogram constructed from least absolute deviations (LAD) harmonic regression at a fixed resolution level. Using a wavelet representation of the underlying time series, we analyze the probabilistic structure of the resulting periodogram under long-range dependence. It is shown that, under suitable regularity conditions, the NKK periodogram converges in distribution to a nonstandard limit characterized as a quadratic form in a Gaussian random vector, whose covariance structure depends on the memory properties of the process and on the chosen wavelet filters. This result establishes a rigorous theoretical foundation for the use of robust wavelet-based periodograms in the spectral analysis of long-memory time series with heavy-tailed inovations.",
      "authors": [
        "Manganaw N'Daam",
        "Tchilabalo Abozou Kpanzou",
        "Edoh Katchekpele"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME"
      ],
      "published": "2026-01-01 11:14:27+00:00",
      "link": "https://arxiv.org/pdf/2601.00310v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00147v1",
      "title": "Multi-Resolution Analysis of Variable Selection for Road Safety in St. Louis and Its Neighboring Area",
      "abstract": "Generally, Lasso, Adaptive Lasso, and SCAD are standard approaches in variable selection in the presence of a large number of predictors. In recent years, during intensity function estimation for spatial point processes with a diverging number of predictors, many researchers have considered these penalized methods. But we have discussed a multi-resolution perspective for the variable selection method for spatial point process data. Its advantage is twofold: it not only efficiently selects the predictors but also provides the idea of which points are liable for selecting a predictor at a specific resolution. Actually, our research is motivated by the crime and accident occurrences in St. Louis and its neighborhoods. It is more relevant to select predictors at the local level, and thus we get the idea of which set of predictors is relevant for the occurrences of crime or accident in which parts of St. Louis. We describe the simulation results to justify the accuracy of local-level variable selection during intensity function estimation.",
      "authors": [
        "Debjoy Thakur",
        "Soumendra N. Lahiri"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME"
      ],
      "published": "2026-01-01 00:26:52+00:00",
      "link": "https://arxiv.org/pdf/2601.00147v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00136v1",
      "title": "Subgroup Identification and Individualized Treatment Policies: A Tutorial on the Hybrid Two-Stage Workflow",
      "abstract": "Patients in clinical studies often exhibit heterogeneous treatment effect (HTE). Classical subgroup analyses provide inferential tools to test for effect modification, while modern machine learning methods estimate the Conditional Average Treatment Effect (CATE) to enable individual level prediction. Each paradigm has limitations: inference focused approaches may sacrifice predictive utility, and prediction focused approaches often lack statistical guarantees. We present a hybrid two-stage workflow that integrates these perspectives. Stage 1 applies statistical inference to test whether credible treatment effect heterogeneity exists with the protection against spurious findings. Stage 2 translates heterogeneity evidence into individualized treatment policies, evaluated by cross fitted doubly robust (DR) metrics with Neyman-Pearson (NP) constraints on harm. We illustrate the workflow with working examples based on simulated data and a real ACTG 175 HIV trial. This tutorial provides practical implementation checklists and discusses links to sponsor oriented HTE workflows, offering a transparent and auditable pathway from heterogeneity assessment to individualized treatment policies.",
      "authors": [
        "Nan Miles Xi",
        "Xin Huang",
        "Lin Wang"
      ],
      "primary_category": "stat.AP",
      "categories": [
        "stat.AP"
      ],
      "published": "2025-12-31 23:11:37+00:00",
      "link": "https://arxiv.org/pdf/2601.00136v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2512.25045v1",
      "title": "Bayesian Elastic Net Regression with Structured Prior Dependence",
      "abstract": "Many regularization priors for Bayesian regression assume the regression coefficients are a priori independent. In particular this is the case for standard Bayesian treatments of the lasso and the elastic net. While independence may be reasonable in some data-analytic settings, incorporating dependence in these prior distributions provides greater modeling flexibility. This paper introduces the orthant normal distribution in its general form and shows how it can be used to structure prior dependence in the Bayesian elastic net regression model. An L1-regularized version of Zellner's g prior is introduced as a special case, creating a new link between the literature on penalized optimization and an important class of regression priors. Computation is challenging due to an intractable normalizing constant in the prior. We avoid this issue by modifying slightly a standard prior of convenience for the hyperparameters in such a way to enable simple and fast Gibbs sampling of the posterior distribution. The benefit of including structured prior dependence in the Bayesian elastic net regression model is demonstrated through simulation and a near-infrared spectroscopy data example.",
      "authors": [
        "Christopher M. Hans",
        "Ningyi Liu"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME"
      ],
      "published": "2025-12-31 18:41:52+00:00",
      "link": "https://arxiv.org/pdf/2512.25045v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2512.24748v1",
      "title": "Quasi-Maximum Likelihood Estimation for a Genuinely Unbalanced Dynamic Network Panel Data Model",
      "abstract": "This paper develops a quasi-maximum likelihood estimator for genuinely unbalanced dynamic network panel data models with individual fixed effects. We propose a model that accommodates contemporaneous and lagged network spillovers, temporal dependence, and a listing effect that activates upon a unit's first appearance in the panel. We establish the consistency of the QMLE as both $N$ and $T$ go to infinity, derive its asymptotic distribution, and identify an asymptotic bias arising from incidental parameters when $N$ is asymptotically large relative to $T$. Based on the asymptotic bias expression, we propose a bias-corrected estimator that is asymptotically unbiased and normally distributed under appropriate regularity conditions. Monte Carlo experiments examine the finite sample performance of the bias-corrected estimator across different criteria, including bias, RMSE, coverage probability, and the normality of the estimator. The empirical application to Airbnb listings from New Zealand and New York City reveals region-specific patterns in spatial and temporal price transmission, illustrating the importance of modeling genuine unbalancedness in dynamic network settings.",
      "authors": [
        "Zhijian Wang",
        "Xingbai Xu",
        "Tuo Liu"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME",
        "stat.AP"
      ],
      "published": "2025-12-31 09:47:30+00:00",
      "link": "https://arxiv.org/pdf/2512.24748v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2512.24642v1",
      "title": "$\\ell_0$-Regularized Item Response Theory Model for Robust Ideal Point Estimation",
      "abstract": "Ideal point estimation methods face a significant challenge when legislators engage in protest voting -- strategically voting against their party to express dissatisfaction. Such votes introduce attenuation bias, making ideologically extreme legislators appear artificially moderate. We propose a novel statistical framework that extends the fast EM-based estimation approach of \\cite{Imai2016} using $\\ell_0$ regularization method to handle protest votes. Through simulation studies, we demonstrate that our proposed method maintains estimation accuracy even with high proportions of protest votes, while being substantially faster than MCMC-based methods. Applying our method to the 116th and 117th U.S. House of Representatives, we successfully recover the extreme liberal positions of ``the Squad'', whose protest votes had caused conventional methods to misclassify them as moderates. While conventional methods rank Ocasio-Cortez as more conservative than 69\\% of Democrats, our method places her firmly in the progressive wing, aligning with her documented policy positions. This approach provides both robust ideal point estimates and systematic identification of protest votes, facilitating deeper analysis of strategic voting behavior in legislatures.",
      "authors": [
        "Kwangok Seo",
        "Johan Lim",
        "Seokho Lee",
        "Jong Hee Park"
      ],
      "primary_category": "stat.AP",
      "categories": [
        "stat.AP"
      ],
      "published": "2025-12-31 05:29:24+00:00",
      "link": "https://arxiv.org/pdf/2512.24642v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2512.24611v1",
      "title": "Empirical Bayes Method for Large Scale Multiple Testing with Heteroscedastic Errors",
      "abstract": "In this paper, we address the normal mean inference problem, which involves testing multiple means of normal random variables with heteroscedastic variances. Most existing empirical Bayes methods for this setting are developed under restrictive assumptions, such as the scaled inverse-chi-squared prior for variances and unimodality for the non-null mean distribution. However, when either of these assumptions is violated, these methods often fail to control the false discovery rate (FDR) at the target level or suffer from a substantial loss of power. To overcome these limitations, we propose a new empirical Bayes method, gg-Mix, which assumes only independence between the normal means and variances, without imposing any structural restrictions on their distributions. We thoroughly evaluate the FDR control and power of gg-Mix through extensive numerical studies and demonstrate its superior performance compared to existing methods. Finally, we apply gg-Mix to three real data examples to further illustrate the practical advantages of our approach.",
      "authors": [
        "Kwangok Seo",
        "Johan Lim",
        "Kaiwen Wang",
        "Dohwan Park",
        "Shota Katayama",
        "Xinlei Wang"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME"
      ],
      "published": "2025-12-31 04:02:43+00:00",
      "link": "https://arxiv.org/pdf/2512.24611v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2512.24588v1",
      "title": "Multiple Testing of One-Sided Hypotheses with Conservative $p$-values",
      "abstract": "We study a large-scale one-sided multiple testing problem in which test statistics follow normal distributions with unit variance, and the goal is to identify signals with positive mean effects. A common approach is to compute $p$-values under the assumption that all null means are exactly zero and then apply standard multiple testing procedures such as the Benjamini--Hochberg (BH) or Storey--BH method. However, because the null hypothesis is composite, some null means may be strictly negative. In this case, the resulting $p$-values are conservative, leading to a substantial loss of power. Existing methods address this issue by modifying the multiple testing procedure itself, for example through conditioning strategies or discarding rules. In contrast, we focus on correcting the $p$-values so that they are exact under the null. Specifically, we estimate the marginal null distribution of the test statistics within an empirical Bayes framework and construct refined $p$-values based on this estimated distribution. These refined $p$-values can then be directly used in standard multiple testing procedures without modification. Extensive simulation studies show that the proposed method substantially improves power when $p$-values are conservative, while achieving comparable performance to existing methods when $p$-values are exact. An application to phosphorylation data further demonstrates the practical effectiveness of our approach.",
      "authors": [
        "Kwangok Seo",
        "Johan Lim",
        "Hyungwon Choi",
        "Jaesik Jeong"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME"
      ],
      "published": "2025-12-31 03:26:43+00:00",
      "link": "https://arxiv.org/pdf/2512.24588v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00613v1",
      "title": "Personalized Forecasting of Glycemic Control in Type 1 and 2 Diabetes Using Foundational AI and Machine Learning Models",
      "abstract": "Background: Accurate week-ahead forecasts of continuous glucose monitoring (CGM) derived metrics could enable proactive diabetes management, but relative performance of modern tabular learning approaches is incompletely defined.   Methods: We trained and internally validated four regression models (CatBoost, XGBoost, AutoGluon, tabPFN) to predict six weekahead CGM metrics (TIR, TITR, TAR, TBR, CV, MAGE, and related quantiles) using 4,622 case-weeks from two cohorts (T1DM n=3,389; T2DM n=1,233). Performance was assessed with mean absolute error (MAE) and mean absolute relative difference (MARD); quantile classification was summarized via confusion-matrix heatmaps.   Results: Across T1DM and T2DM, all models produced broadly comparable performance for most targets. For T1DM, MARD for TIR, TITR, TAR and MAGE ranged 8.5 to 16.5% while TBR showed large MARD (mean ~48%) despite low MAE. AutoGluon and tabPFN showed lower MAE than XGBoost for several targets (e.g., TITR: p<0.01; TAR/TBR: p<0.05 to 0.01). For T2DM MARD ranged 7.8 to 23.9% and TBR relative error was ~78%; tabPFN outperformed other models for TIR (p<0.01), and AutoGluon/ tabPFN outperformed CatBoost/XGBoost on TAR (p<0.05). Inference time per 1,000 cases varied markedly (PFN 699 s; AG 2.7 s; CatBoost 0.04 s, XGBoost 0.04 s).   Conclusions: Week-ahead CGM metrics are predictable with reasonable accuracy using modern tabular models, but low-prevalence hypoglycemia remains difficult to predict in relative terms. Advanced AutoML and foundation models yield modest accuracy gains at substantially higher computational cost.",
      "authors": [
        "Simon Lebech Cichosz",
        "Stine Hangaard",
        "Thomas Kronborg",
        "Peter Vestergaard",
        "Morten Hasselstrøm Jensen"
      ],
      "primary_category": "q-bio.OT",
      "categories": [
        "q-bio.OT"
      ],
      "published": "2026-01-02 08:58:11+00:00",
      "link": "https://arxiv.org/pdf/2601.00613v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00608v1",
      "title": "Peak-Nadir Encoding for Efficient CGM Data Compression and High-Fidelity Reconstruction",
      "abstract": "Aim/background: Continuous glucose monitoring (CGM) generates dense time-series data, posing challenges for efficient storage, transmission, and analysis. This study evaluates novel encoding strategies that reduce CGM profiles to a compact set of landmark points while maintaining fidelity in reconstructed signals and derived glycemic metrics.   Methods: We utilized two complementary CGM datasets, synthetic data generated via a Conditional Generative Adversarial Network (CGAN) and real-world measurements from a randomized crossover trial, to develop and validate three encoding approaches: (1) Peaks & Nadirs (PN), (2) Peaks, Nadirs, and Support Points (PN+), and (3) Uniform Downsampling. Each method compresses CGM profiles by selecting key timestamps and glucose values, followed by signal reconstruction via interpolation. Performance was assessed using compression ratio, mean absolute error (MAE), and R^2 between original and reconstructed clinically relevant CGM-derived metrics. Statistical analyses evaluated the preservation of clinically relevant glucose features.   Results: Across varying compression settings, PN+ consistently outperformed PN and downsampling, achieving the highest R^2 and lowest MAE. At a compression ratio of 13 (22 landmark points per 24-hour profile), PN+ reduced MAE by a factor of 3.6 compared to downsampling (0.77 vs. 2.75), with notable improvements in metrics sensitive to glucose excursions. Encoding and decoding required an average of 0.13 seconds per profile. Validation on real-world data confirmed these trends.   Conclusions: The proposed PN+ method produces a compact CGM representation that retains critical glycemic dynamics while discarding redundant portions of the profiles. The CGM signal can be reconstructed with high precision from the encoding representation.",
      "authors": [
        "Clara Bender",
        "Line Davidsen",
        "Søren Schou Olesen",
        "Simon Lebech Cichosz"
      ],
      "primary_category": "q-bio.QM",
      "categories": [
        "q-bio.QM"
      ],
      "published": "2026-01-02 08:32:54+00:00",
      "link": "https://arxiv.org/pdf/2601.00608v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2512.24843v1",
      "title": "friends.test: rank-based method for feature selection in interaction matrices",
      "abstract": "The analysis of the interaction matrix between two distinct sets is essential across diverse fields, from pharmacovigilance to transcriptomics. Not all interactions are equally informative: a marker gene associated with a few specific biological processes is more informative than a highly expressed non-specific gene associated with most observed processes. Identifying these interactions is challenging due to background connections. Furthermore, data heterogeneity across sources precludes universal identification criteria.   To address this challenge, we introduce \\textsf{friends.test}, a method for identifying specificity by detecting structural breaks in entity interactions. Rank-based representation of the interaction matrix ensures invariance to heterogeneous data and allows for integrating data from diverse sources. To automatically locate the boundary between specific interactions and background activity, we employ model fitting. We demonstrate the applicability of \\textsf{friends.test} on the GSE112026 -- transnational data from head and neck cancer. A computationally efficient \\textsf{R} implementation is available at https://github.com/favorov/friends.test.",
      "authors": [
        "Alexandra Suvorikova",
        "Alexey Kroshnin",
        "Dmirijs Lvovs",
        "Vera Mukhina",
        "Andrey Mironov",
        "Elana J. Fertig",
        "Ludmila Danilova",
        "Alexander Favorov"
      ],
      "primary_category": "q-bio.QM",
      "categories": [
        "q-bio.QM"
      ],
      "published": "2025-12-31 13:03:52+00:00",
      "link": "https://arxiv.org/pdf/2512.24843v1",
      "tags": [
        "sr-bench"
      ]
    },
    {
      "id": "2601.00478v1",
      "title": "Multimodal Insights into Credit Risk Modelling: Integrating Climate and Text Data for Default Prediction",
      "abstract": "Credit risk assessment increasingly relies on diverse sources of information beyond traditional structured financial data, particularly for micro and small enterprises (mSEs) with limited financial histories. This study proposes a multimodal framework that integrates structured credit variables, climate panel data, and unstructured textual narratives within a unified learning architecture. Specifically, we use long short-term memory (LSTM), the gated recurrent unit (GRU), and transformer models to analyse the interplay between these data modalities. The empirical results demonstrate that unimodal models based on climate or text data outperform those relying solely on structured data, while the integration of multiple data modalities yields significant improvements in credit default prediction. Using SHAP-based explainability methods, we find that physical climate risks play an important role in default prediction, with water-logging by rain emerging as the most influential factor. Overall, this study demonstrates the potential of multimodal approaches in AI-enabled decision-making, which provides robust tools for credit risk assessment while contributing to the broader integration of environmental and textual insights into predictive analytics.",
      "authors": [
        "Zongxiao Wu",
        "Ran Liu",
        "Jiang Dai",
        "Dan Luo"
      ],
      "primary_category": "q-fin.RM",
      "categories": [
        "q-fin.RM",
        "q-fin.CP"
      ],
      "published": "2026-01-01 21:16:28+00:00",
      "link": "https://arxiv.org/pdf/2601.00478v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00395v1",
      "title": "Core-Periphery Dynamics in Market-Conditioned Financial Networks: A Conditional P-Threshold Mutual Information Approach",
      "abstract": "This study investigates how financial market structure reorganizes during the COVID-19 crash using a conditional p-threshold mutual information (MI) based Minimum Spanning Tree (MST) framework. We analyze nonlinear dependencies among the largest stocks from four diverse QUAD countries: the US, Japan, Australia, and India. Crashes are identified using the Hellinger distance and Hilbert spectrum; a crash occurs when HD = mu\\_H + 2*sigma\\_H, segmenting data into pre-crash, crash, and post-crash periods. Conditional p-threshold MI filters out common market effects and applies permutation-based significance testing. Resulting validated dependencies are used to construct MST networks for comparison across periods. Networks become more integrated during the crash, with shorter path lengths, higher centrality, and lower algebraic connectivity, indicating fragility. Core-periphery structure declines, with increased periphery vulnerability, and disassortative mixing facilitates shock transmission. Post-crash networks show only partial recovery. Aftershock analysis using the Gutenberg-Richter law indicates higher relative frequency of large volatility events following the crash. Results are consistent across all markets, highlighting the conditional p-threshold MI framework for capturing nonlinear interdependencies and systemic vulnerability.",
      "authors": [
        "Kundan Mukhia",
        "Imran Ansari",
        "S R Luwang",
        "Md Nurujjaman"
      ],
      "primary_category": "q-fin.ST",
      "categories": [
        "q-fin.ST"
      ],
      "published": "2026-01-01 17:16:29+00:00",
      "link": "https://arxiv.org/pdf/2601.00395v1",
      "tags": [
        "sr-bench",
        "大厂llm"
      ]
    },
    {
      "id": "2601.00281v1",
      "title": "A Global Optimal Theory of Portfolio beyond R-$σ$ Model",
      "abstract": "The deviation of the efficient market hypothesis (EMH) for the practical economic system allows us gain the arbitrary or risk premium in finance markets. We propose the triplet $(R,H,σ)$ theory to give the local and global optimal portfolio, which eneralize from the $(R,σ)$ model. We present the formulation of the triplet $(R,H,σ)$ model and give the Pareto optimal solution as well as comparing it with the numerical investigations for the Chinese stock market. We define the local optimal weights of the triplet $(\\mathbf{w}_{R},\\mathbf{w}_{H},\\mathbf{w}_σ)$, which constructs the triangle of the quasi-optimal investing subspace such that we further define the centroid of the triangle or the incenter of the triangle as the optimal investing weights, which optimizes the mean return, the arbitrary or risk premium and the volatility risk. By investigating numerically the Chinese stock market as an example we demonstrate the validity of the formulation and obtain the global optimal strategy and quasi-optimal investing subspace. The theory provides an efficient way to design the portfolio for different style investors, conservative or aggressive investors, in finance market to maximize the mean return and arbitrary or risk premium with a small volatility risk.",
      "authors": [
        "Yifan Liu",
        "Shi-Dong Liang"
      ],
      "primary_category": "q-fin.PM",
      "categories": [
        "q-fin.PM"
      ],
      "published": "2026-01-01 09:49:52+00:00",
      "link": "https://arxiv.org/pdf/2601.00281v1",
      "tags": [
        "sr-bench",
        "大厂llm",
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00434v1",
      "title": "Time--to--Digital Converter (TDC)--Based Resonant Compute--in--Memory for INT8 CNNs with Layer--Optimized SRAM Mapping",
      "abstract": "In recent years, Compute-in-memory (CiM) architectures have emerged as a promising solution for deep neural network (NN) accelerators. Multiply-accumulate~(MAC) is considered a {\\textit de facto} unit operation in NNs. By leveraging the inherent parallel processing capabilities of CiM, NNs that require numerous MAC operations can be executed more efficiently. This is further facilitated by storing the weights in SRAM, reducing the need for extensive data movement and enhancing overall computational speed and efficiency. Traditional CiM architectures execute MAC operations in the analog domain, employing an Analog-to-Digital converter (ADC) to convert the analog MAC values into digital outputs. However, these ADCs introduce significant increase in area and power consumption, as well as introduce non-linearities. This work proposes a resonant time-domain compute-in-memory (TDC-CiM) architecture that eliminates the need for an ADC by using a time-to-digital converter (TDC) to digitize analog MAC results with lower power and area cost. A dedicated 8T SRAM cell enables reliable bitwise MAC operations, while the readout uses a 4-bit TDC with pulse-shrinking delay elements, achieving 1 GS/s sampling with a power consumption of only 1.25 mW. In addition, a weight stationary data mapping strategy combined with an automated SRAM macro selection algorithm enables scalable and energy-efficient deployment across CNN workloads. Evaluation across six CNN models shows that the algorithm reduces inference energy consumption by up to 8x when scaling SRAM size from 32~KB to 256~KB, while maintaining minimal accuracy loss after quantization. The feasibility of the proposed architecture is validated on an 8~KB SRAM memory array using TSMC 28~nm technology. The proposed TDC-CiM architecture demonstrates a throughput of 320~GOPS with an energy efficiency of 38.46~TOPS/W.",
      "authors": [
        "Dhandeep Challagundla",
        "Ignatius Bezzam",
        "Riadul Islam"
      ],
      "primary_category": "eess.SP",
      "categories": [
        "eess.SP"
      ],
      "published": "2026-01-01 18:57:41+00:00",
      "link": "https://arxiv.org/pdf/2601.00434v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2601.00171v1",
      "title": "Edge AI Inference in ISCC Networks: Sensing Accuracy Analysis and Precoding Design",
      "abstract": "This work explores the relationship between sensing accuracy and precoding coefficients for edge artificial intelligence (AI) inference in integrated sensing, communication and computation (ISCC) networks. We start by constructing a system model of an over-the-air-empowered ISCC network for edge AI inference, involving distributed edge sensors for feature extraction and an edge server for classification. Based on this model, we introduce a discriminant gain (DG) to characterize sensing accuracy and novelly derive an explicit function of the DG about precoding coefficients, giving valuable insights into precoding design. Guided by this, we propose an effective precoding algorithm to solve a non-convex DG-maximization problem. Simulation results verify the effectiveness and feasibility of the proposed design for edge inference in ISCC networks.",
      "authors": [
        "Lingyun Xu",
        "Bowen Wang",
        "Huiyong Li",
        "Ziyang Cheng"
      ],
      "primary_category": "eess.SP",
      "categories": [
        "eess.SP"
      ],
      "published": "2026-01-01 02:20:00+00:00",
      "link": "https://arxiv.org/pdf/2601.00171v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00776v1",
      "title": "TWICE: Tree-based Wage Inference with Clustering and Estimation",
      "abstract": "How much do worker skills, firm pay policies, and their interaction contribute to wage inequality? Standard approaches rely on latent fixed effects identified through worker mobility, but sparse networks inflate variance estimates, additivity assumptions rule out complementarities, and the resulting decompositions lack interpretability. We propose TWICE (Tree-based Wage Inference with Clustering and Estimation), a framework that models the conditional wage function directly from observables using gradient-boosted trees, replacing latent effects with interpretable, observable-anchored partitions. This trades off the ability to capture idiosyncratic unobservables for robustness to sampling noise and out-of-sample portability. Applied to Portuguese administrative data, TWICE outperforms linear benchmarks out of sample and reveals that sorting and non-additive interactions explain substantially more wage dispersion than implied by standard AKM estimates.",
      "authors": [
        "Aslan Bakirov",
        "Francesco Del Prato",
        "Paolo Zacchia"
      ],
      "primary_category": "econ.GN",
      "categories": [
        "econ.GN"
      ],
      "published": "2026-01-02 18:15:27+00:00",
      "link": "https://arxiv.org/pdf/2601.00776v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00603v1",
      "title": "Difference-in-Differences using Double Negative Controls and Graph Neural Networks for Unmeasured Network Confounding",
      "abstract": "Estimating causal effects from observational network data faces dual challenges of network interference and unmeasured confounding. To address this, we propose a general Difference-in-Differences framework that integrates double negative controls (DNC) and graph neural networks (GNNs). Based on the modified parallel trends assumption and DNC, semiparametric identification of direct and indirect causal effects is established. We then propose doubly robust estimators. Specifically, an approach combining GNNs with the generalized method of moments is developed to estimate the functions of high-dimensional covariates and network structure. Furthermore, we derive the estimator's asymptotic normality under the $ψ$-network dependence and approximate neighborhood interference. Simulations show the finite-sample performance of our estimators. Finally, we apply our method to analyze the impact of China's green credit policy on corporate green innovation.",
      "authors": [
        "Zihan Zhang",
        "Lianyan Fu",
        "Dehui Wang"
      ],
      "primary_category": "econ.EM",
      "categories": [
        "econ.EM"
      ],
      "published": "2026-01-02 08:18:50+00:00",
      "link": "https://arxiv.org/pdf/2601.00603v1",
      "tags": [
        "sr-bench",
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00279v1",
      "title": "What Is a Causal Effect When Firms Interact? Counterfactuals and Interdependence",
      "abstract": "Many empirical studies estimate causal effects in environments where economic units interact through spatial or network connections. In such settings, outcomes are jointly determined, and treatment induced shocks propagate across economically connected units. A growing literature highlights identification challenges in these models and questions the causal interpretation of estimated spillovers. This paper argues that the problem is more fundamental. Under interdependence, causal effects are not uniquely defined objects even when the interaction structure is correctly specified or consistently learned, and even under ideal identifying conditions. We develop a causal framework for firm-level economies in which interaction structures are unobserved but can be learned from predetermined characteristics. We show that learning the network, while necessary to model interdependence, is not sufficient for causal interpretation. Instead, causal conclusions hinge on explicit counterfactual assumptions governing how outcomes adjust following a treatment change. We formalize three economically meaningful counterfactual regimes partial equilibrium, local interaction, and network, consistent equilibrium, and show that standard spatial autoregressive estimates map into distinct causal effects depending on the counterfactual adopted. We derive identification conditions for each regime and demonstrate that equilibrium causal effects require substantially stronger assumptions than direct or local effects. A Monte Carlo simulation illustrates that equilibrium and partial-equilibrium effects differ mechanically even before estimation, and that network feedback can amplify bias when identifying assumptions fail. Taken together, our results clarify what existing spatial and network estimators can and cannot identify and provide practical guidance for empirical research in interdependent economic environments",
      "authors": [
        "Mariluz Mate"
      ],
      "primary_category": "econ.GN",
      "categories": [
        "econ.GN"
      ],
      "published": "2026-01-01 09:29:30+00:00",
      "link": "https://arxiv.org/pdf/2601.00279v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2512.24862v1",
      "title": "Antecedents of Consumer Regret Frequency: The Roles of Decision Agency, Status Signaling, and Online Shopping Preference",
      "abstract": "Consumer regret is a widespread post-purchase emotion that significantly impacts satisfaction, product returns, complaint behavior, and customer loyalty. Despite its prevalence, there is a limited understanding of why certain consumers experience regret more frequently as a chronic aspect of their engagement in the marketplace. This study explores the antecedents of consumer regret frequency by integrating decision agency, status signaling motivations, and online shopping preferences into a cohesive framework. By analyzing survey data (n=338), we assess whether consumers' perceived agency and decision-making orientation correlate with the frequency of regret, and whether tendencies towards status-related consumption and preferences for online shopping environments exacerbate regret through mechanisms such as increased social comparison, expanded choice sets, and continuous exposure to alternative offers. The findings reveal that regret frequency is significantly linked to individual differences in decision-related orientations and status signaling, with a preference for online shopping further contributing to regret-prone consumption behaviors. These results extend the scope of regret and cognitive dissonance research beyond isolated decision episodes by emphasizing regret frequency as a persistent consumer outcome. From a managerial standpoint, the findings suggest that retailers can alleviate regret-driven dissatisfaction by enhancing decision support, minimizing choice overload, and developing post-purchase reassurance strategies tailored to segments prone to regret..",
      "authors": [
        "Shawn Berry"
      ],
      "primary_category": "econ.GN",
      "categories": [
        "econ.GN"
      ],
      "published": "2025-12-31 13:45:47+00:00",
      "link": "https://arxiv.org/pdf/2512.24862v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2512.24852v1",
      "title": "Scaling Charitable Incentives: Policy Selection, Beliefs, and Evidence from a Field Experiment",
      "abstract": "Why are interventions with weak evidence still adopted? We study charitable incentives for physical activity in Japan using three linked methods, including a randomized field experiment (N=808), a stakeholder belief survey (local government officials and private-sector employees, N=2,400), and a conjoint experiment on policy choice. Financial incentives increase daily steps by about 1,000, whereas charitable incentives deliver a precisely estimated null. Nonetheless, stakeholders greatly overpredict charitable incentives' effects on walking, participation, and prosociality. Conjoint choices show policymakers value step gains as well as other outcomes, shaping policy choice. Adoption thus reflects multidimensional beliefs and objectives, highlighting policy selection as a scaling challenge.",
      "authors": [
        "Shusaku Sasaki",
        "Takunori Ishihara",
        "Hirofumi Kurokawa"
      ],
      "primary_category": "econ.GN",
      "categories": [
        "econ.GN"
      ],
      "published": "2025-12-31 13:22:30+00:00",
      "link": "https://arxiv.org/pdf/2512.24852v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00742v1",
      "title": "Materials Informatics: Emergence To Autonomous Discovery In The Age Of AI",
      "abstract": "This perspective explores the evolution of materials informatics, from its foundational roots in physics and information theory to its maturation through artificial intelligence (AI). We trace the field's trajectory from early milestones to the transformative impact of the Materials Genome Initiative and the recent advent of large language models (LLMs). Rather than a mere toolkit, we present materials informatics as an evolving ecosystem, reviewing key methodologies such as Bayesian Optimization, Reinforcement Learning, and Transformers that drive inverse design and autonomous self-driving laboratories. We specifically address the practical challenges of LLM integration, comparing specialist versus generalist models and discussing solutions for uncertainty quantification. Looking forward, we assess the transition of AI from a predictive tool to a collaborative research partner. By leveraging active learning and retrieval-augmented generation (RAG), the field is moving toward a new era of autonomous materials science, increasingly characterized by \"human-out-of-the-loop\" discovery processes.",
      "authors": [
        "Turab Lookman",
        "YuJie Liu",
        "Zhibin Gao"
      ],
      "primary_category": "physics.comp-ph",
      "categories": [
        "physics.comp-ph"
      ],
      "published": "2026-01-02 16:53:19+00:00",
      "link": "https://arxiv.org/pdf/2601.00742v1",
      "tags": [
        "大厂llm",
        "大语言模型"
      ]
    },
    {
      "id": "2601.00726v1",
      "title": "Implicit Large Eddy Simulation of Nearly Incompressible Flows with a Discontinuous Galerkin-Boltzmann Formulation",
      "abstract": "We present a high-order implicit large eddy simulation (ILES) approach for simulating flows at the nearly incompressible regime. Our methodology based on utilization of a nodal discontinuous Galerkin (DG) discretization of the Boltzmann equations. The compactness and low-dissipative nature of the discontinuous Galerkin method are leveraged to mimic traditional large eddy simulations with subgrid-scale models. One of the key requirements of ILES is to provide dissipation only within a narrow band of high wavenumbers. This is validated through numerical experiments on the Taylor-Green Vortex problem in detail at a Reynolds number where varying scales of coherent turbulent structures are present. Furthermore, the approach is validated for external aerodynamic configurations by simulating the flow over a sphere at a Reynolds number of $Re=3700$, capturing the laminar-turbulent transition and the complex multiscale vortex dynamics characteristic of this regime. The results demonstrate the capability of the high-order DG-Boltzmann formulation to accurately capture transitional and turbulent flow features without the use of explicit sub-grid scale modeling, highlighting its potential as a robust and physically consistent framework for ILES of nearly incompressible turbulent flows.",
      "authors": [
        "Onur Ata",
        "Atakan Aygun",
        "Tim Warburton",
        "Ali Karakus"
      ],
      "primary_category": "physics.flu-dyn",
      "categories": [
        "physics.flu-dyn"
      ],
      "published": "2026-01-02 15:51:39+00:00",
      "link": "https://arxiv.org/pdf/2601.00726v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2601.00719v1",
      "title": "Gravitational instability in partially ionized plasmas: A two-fluid approach",
      "abstract": "We propose a new two-fluid model for a partially ionized magnetoplasma under gravity, where electrons and neutrals are treated as a single fluid, and singly charged positive ions are a separate fluid. We observe that the classical result of gravitational instability (also known as Rayleigh-Taylor instability) in fully ionized plasmas is significantly modified by the influence of ion-neutral collisions (with frequency $ν_{\\rm{in}}$) and transverse wave numbers ($k_x$ and $k_y$). The instability growth rate can be enhanced or decreased depending on the values of the ratios $κ\\equiv k_x/k_y$ and $f\\equivν_{\\rm{in}}/Ω_{\\rm{ci}}$, where $Ω_{\\rm{ci}}$ is the ion-cyclotron frequency. We also estimate the growth rates relevant to the ionospheric E-region and solar atmosphere, noting that such growth rates can be maximized for $κ,~f\\ll1$, or for $κ>1$ and $f\\sim0.64$, and minimized for $f\\gg1$ irrespective of the value of $κ$. Furthermore, the timescale of instability ranges from $1$ minute to $2$ minutes in the solar atmosphere, while in the E region, it ranges from $1$ minute to $80$ minutes. The latter can be a satisfactory result for the reported lifetime of solar prominence threads.",
      "authors": [
        "A. P. Misra",
        "V. Krishan"
      ],
      "primary_category": "physics.plasm-ph",
      "categories": [
        "physics.plasm-ph",
        "astro-ph.SR"
      ],
      "published": "2026-01-02 15:19:07+00:00",
      "link": "https://arxiv.org/pdf/2601.00719v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2601.00681v1",
      "title": "Nonlocal Microwave Engineering: Constructing Dispersion Relations and Enabling On-Demand Frequency-Momentum Transformations via Time-Switched Long-Distance Interactions",
      "abstract": "Nonlocal metamaterials (MTMs) have recently attracted significant research attention across different areas of wave physics, owing to their ability to translate long-range interactions among meta-atoms into a wide array of wavevector-dependent responses and functionalities. In this work, we introduce nonlocal transmission line metamaterials (TL MTMs) as a versatile platform to investigate and engineer nonlocality in the microwave frequency regime. We first establish a concise theoretical framework for nonlocal TL MTMs based on circuit and network theory, from which we derive the general dispersion relation for TL MTMs having arbitrarily complex nonlocal coupling configurations. Building upon this foundation, we demonstrate how such structures can be used to synthesize nearly arbitrary, even, dispersion functions within their first Brillouin zone, effectively linking nonlocal circuit parameters to prescribed dispersion profiles. Finally, we introduce time-switched nonlocal TL MTMs, a new class of metamaterials with time-varying nonlocality in which the nonlocal branches are dynamically activated as an electromagnetic pulse propagates through the structure. This platform enables complex, nearly arbitrary frequency-momentum transformations on a propagating pulse, as well as the simultaneous excitation of modes with positive, negative, and zero group velocity within the first Brillouin zone. Our results offer new physical insights into the behavior of nonlocal MTMs, a versatile platform to investigate the interplay of frequency dispersion, spatial dispersion and time modulation, and a general theoretical foundation for the design of more advanced nonlocal and time-varying electromagnetic and photonic systems.",
      "authors": [
        "Matteo Ciabattoni",
        "Francesco Monticone"
      ],
      "primary_category": "physics.optics",
      "categories": [
        "physics.optics"
      ],
      "published": "2026-01-02 13:13:14+00:00",
      "link": "https://arxiv.org/pdf/2601.00681v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2601.00619v1",
      "title": "High-Temperature Deformation Behavior of Co-Free Non-Equiatomic CrMnFeNi Alloy",
      "abstract": "Cobalt-free high-entropy alloys (HEAs) have garnered interest for nuclear structural applications due to their good mechanical performance, thermal stability, and resistance to radiation-induced degradation, while avoiding long-lived Co radioisotopes. This study presents an experimental and computational investigation of the plastic deformation behavior of a non-equatomic CrMnFeNi alloy, designed to maintain a stability of fcc phase in a large domain of temperatures and to balance stacking fault (SF) energies for enhanced strain hardening and ductility. Tensile tests reveal a temperature-dependent reduction in mechanical strength, attributed to thermally activated deformation mechanisms and microstructural evolution. Molecular dynamics simulations of single- and polycrystals capture dislocation activity, SF formation, and twin nucleation as a function of strain and temperature. Electron backscatter diffraction (EBSD) confirms twin formation and grain boundary activity. The Schmid factor mapping is drawn to interpret local slip activity and anisotropic deformation behavior. The absence of Co leads to enhanced high-temperature strength compared to the Cantor alloy.",
      "authors": [
        "F. J. Dominguez-Gutierrez",
        "M. Frelek-Kozak",
        "G. Markovic",
        "M. A. Strozyk",
        "A. Daramola",
        "M. Traversier",
        "A. Fraczkiewicz",
        "A. Zaborowska",
        "T. Khvan",
        "I. Jozwik",
        "L. Kurpaska"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "categories": [
        "cond-mat.mtrl-sci",
        "physics.comp-ph"
      ],
      "published": "2026-01-02 09:23:26+00:00",
      "link": "https://arxiv.org/pdf/2601.00619v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2601.00518v1",
      "title": "High-energy Emission from Turbulent Electron-ion Coronae of Accreting Black Holes",
      "abstract": "We develop a model of particle energization and emission from strongly turbulent black-hole coronae. Our local model is based on a set of 2D radiative particle-in-cell simulations with an electron-ion plasma composition, injection and diffusive escape of photons and charged particles, and self-consistent Compton scattering. We show that a radiatively compact turbulent corona generates extended nonthermal ion distributions, while producing X-ray spectra consistent with observations. As an example, we demonstrate excellent agreement with observed X-ray spectra of NGC 4151. The predicted emission spectra feature an MeV tail, which can be studied with future MeV-band instruments. The MeV tail is shaped by nonthermal electrons accelerated at turbulent current sheets. We also find that the corona regulates itself into a two-temperature state, with ions much hotter than electrons. The ions carry away roughly 60% to 70% of the dissipated power, and their energization is driven by a combination of shocks and reconnecting current sheets, embedded into the turbulent flow.",
      "authors": [
        "Daniel Groselj",
        "Alexander Philippov",
        "Andrei M. Beloborodov",
        "Richard Mushotzky"
      ],
      "primary_category": "astro-ph.HE",
      "categories": [
        "astro-ph.HE",
        "physics.plasm-ph"
      ],
      "published": "2026-01-02 00:45:22+00:00",
      "link": "https://arxiv.org/pdf/2601.00518v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2601.00483v1",
      "title": "Prediction of a measurable sign change in the Casimir force using a magnetic fluid",
      "abstract": "We demonstrate quantum levitation controlled by Casimir forces acting between a polystyrene surface and a Teflon-coated metallic substrate immersed in a mixture of Toluene and magnetite particles. This system experiences repulsion-attraction transitions in the Casimir interaction for distances where the effect is measurable. This Casimir trapping can be controlled by clever choices of metallic and ferrofluid materials, which are directly linked to the emergence of the trapping effect. Thermal and quantum contributions are investigated in detail, showing how the optical and magnetic properties of the ferrofluid and other materials affect the magnitude of the trapping and its distance range of observability.",
      "authors": [
        "Long Ma",
        "Larissa Inácio",
        "Dai-Nam Le",
        "Lilia M. Woods",
        "Mathias Boström"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "cond-mat.mes-hall",
        "physics.app-ph",
        "physics.optics"
      ],
      "published": "2026-01-01 21:31:19+00:00",
      "link": "https://arxiv.org/pdf/2601.00483v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2601.00354v1",
      "title": "A Topological Framework for Atmospheric River Interaction Using Framed Braids",
      "abstract": "Atmospheric Rivers (ARs) are filamentary moisture pathways responsible for a large fraction of extreme precipitation and often occur as interacting filament bundles within the same synoptic regime. Existing diagnostics typically analyze ARs in isolation, despite the frequent coexistence and interaction of multiple filaments. We introduce a topological framework for AR analysis based on framed braids and framed braidoids, which encodes both the geometric interaction of AR centroids and the internal evolution of moisture transport.   In this approach, AR filaments are represented as strands whose time-ordered crossings form braid words, while moisture-based framing captures internal intensification or weakening along each filament. Applying this framework to reanalysis-derived Atmospheric River track data, we construct braid and framed braid representations over sliding time windows and analyze a strongly interacting multi-filament AR episode in the North Pacific. The results show that braid-based indicators capture structural reorganizations and moisture intensification episodes that are not apparent from centroid geometry or IVT magnitude alone, offering a complementary structural perspective on atmospheric moisture transport.",
      "authors": [
        "Ioannis Diamantis"
      ],
      "primary_category": "nlin.CD",
      "categories": [
        "nlin.CD",
        "physics.ao-ph"
      ],
      "published": "2026-01-01 14:15:04+00:00",
      "link": "https://arxiv.org/pdf/2601.00354v1",
      "tags": [
        "大语言模型",
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00236v1",
      "title": "Transient spark dielectric barrier post-discharge plasma reactor with a liquid electrode for dye degradation: A primary study",
      "abstract": "The potential application of non-thermal plasma in treating textile industrial wastewater motivates researchers to develop innovative techniques at a laboratory scale to achieve the goal of wastewater mineralization. In line with this objective, a dielectric barrier post-discharge plasma reactor with a liquid electrode has been built for the study of synthetic dye degradation. The plasma reactor was optimized by altering various operating conditions to achieve a higher degradation efficiency at given discharge conditions. The reaction kinetics of crystal violet degradation were studied, and the same plasma reactor was tested for other synthetic dyes (wastewater model samples). The results suggest that the proposed dielectric barrier post-discharge plasma reactor may offer a promising solution for treating dye effluents from the textile industry.",
      "authors": [
        "Mangilal Choudhary",
        "Vanshika",
        "Surya"
      ],
      "primary_category": "physics.plasm-ph",
      "categories": [
        "physics.plasm-ph",
        "physics.app-ph",
        "physics.bio-ph",
        "physics.chem-ph"
      ],
      "published": "2026-01-01 06:58:22+00:00",
      "link": "https://arxiv.org/pdf/2601.00236v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2601.00180v1",
      "title": "Experimental study on an S-band near-field microwave magnetron power transmission system on hundred-watt level",
      "abstract": "A multi-magnetron microwave source, a metamaterial transmitting antenna, and a large power rectenna array are presented to build a near-field 2.45 GHz microwave power transmission system. The square 1 m2 rectenna array consists of sixteen rectennas with 2048 Schottky diodes for large power microwave rectifying. It receives microwave power and converts them into DC power. The design, structure, and measured performance of a unit rectenna as well as the entail rectenna array are presented in detail. The multi-magnetron microwave power source switches between half and full output power levels, i.e. the half-wave and full-wave modes. The transmission antenna is formed by a double-layer metallic hole array, which is applied to combine the output power of each magnetron. The rectenna array DC output power reaches 67.3 W on a 1.2 ohm DC load at a distance of 5.5 m from the transmission antenna. DC output power is affected by the distance, DC load, and the mode of microwave power source. It shows that conventional low power Schottky diodes can be applied to a microwave power transmission system with simple magnetrons to realise large power microwave rectifying.",
      "authors": [
        "Biao Zhang",
        "Wan Jiang",
        "Yang Yang",
        "Chengyang Yu",
        "Kama Huang",
        "Changjun Liu"
      ],
      "primary_category": "physics.app-ph",
      "categories": [
        "physics.app-ph"
      ],
      "published": "2026-01-01 02:44:43+00:00",
      "link": "https://arxiv.org/pdf/2601.00180v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2601.00174v1",
      "title": "Generalized model of anisotropic thermo-optic response on thin-film lithium niobate platform",
      "abstract": "Thermo-optic (TO) control is crucial for thin-film lithium niobate (TFLN) photonic integrated circuits (PICs), offering a simple and practical method for low-frequency and DC tuning while remaining compatible with high-frequency electro-optic (EO) modulation. In x-cut TFLN, the TO response is inherently anisotropic, depending on both waveguide propagation angle and polarization due to the mode-specific overlap of the electric field with the ordinary and extraordinary refractive index axes of the crystal. Despite its significance, a systematic and quantitative analysis of this anisotropy has remained elusive. Here, we present the first generalized analytical model that describes the anisotropic TO response as a function of polarization and arbitrary waveguide orientation, and rigorously validate it through numerical simulations and experiments. This study provides foundational insight into anisotropic thermal tuning and enables new opportunities for engineering energy-efficient and scalable photonic design in next-generation TFLN PICs.",
      "authors": [
        "Joonsup Shim",
        "Seonghun Kim",
        "Shengyuan Lu",
        "Jiayu Yang",
        "Seongjin Jeon",
        "Sanghyeon Kim",
        "Marko Lončar",
        "Young-Ik Sohn"
      ],
      "primary_category": "physics.optics",
      "categories": [
        "physics.optics"
      ],
      "published": "2026-01-01 02:27:07+00:00",
      "link": "https://arxiv.org/pdf/2601.00174v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2601.00127v1",
      "title": "Light-tight skipper-CCDs for X-ray detection in space",
      "abstract": "Skipper Charge-Coupled Devices (skipper-CCDs) are pixelated silicon detectors with deep sub-electron resolution. Their radiation hardness and capability to reconstruct energy deposits with unprecedented precision make them a promising technology for space-based X-ray astronomy. In this scenario, optical and near-infrared photons may saturate the sensor, distorting the reconstructed signal. We present a light-tight shield for skipper-CCDs to suppress optical backgrounds while preserving X-ray detection efficiency. We deposited thin aluminum layers on the CCD surface using an e-beam evaporator and evaluated their blinding performance across wavelengths from 650 to 1000 nm using a monochromator, as well as the X-ray transmission using an $^{55}$Fe source. We find that 50 and 100\\,nm layers provide >99.6\\% light suppression, with no efficiency loss for 5.9 and 6.4\\,keV X-rays. In addition, we used Geant4 simulations to extend these results to a broader energy range and quantify the efficiency loss for different aluminum thicknesses. Results show that thin aluminum coatings are an effective, low-cost solution for optical suppression in skipper-CCDs intended for X-ray detection and space instrumentation.",
      "authors": [
        "Ana M. Botti",
        "Yikai Wu",
        "Brenda Cervantes",
        "Claudio Chavez",
        "Juan Estrada",
        "Stephen E. Holland",
        "Nathan Saffold",
        "Javier Tiffenberg",
        "Sho Uemura"
      ],
      "primary_category": "astro-ph.IM",
      "categories": [
        "astro-ph.IM",
        "hep-ex",
        "physics.space-ph"
      ],
      "published": "2025-12-31 22:12:45+00:00",
      "link": "https://arxiv.org/pdf/2601.00127v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2601.00117v1",
      "title": "Spectral Sampling of Boron Diffusion in Ni Alloys: Cr and Mo Effects on Bulk and Grain Boundary Transport",
      "abstract": "Understanding how light interstitials migrate in chemically complex alloys is essential for predicting defect dynamics and long-term stability. Here, we introduce a spectral sampling framework to quantify boron diffusion activation energies in Ni and demonstrate how substitutional solutes (Cr, Mo) reshape interstitial point defect transport in both the bulk and along crystallographic defects. In the bulk, boron migration energy distributions exhibit distinct modality tied to solute identity and spatial arrangement: both Cr and Mo raise barriers in symmetric cages but induce directional asymmetry in partially decorated environments. Extending this framework to a $\\Sigma5\\langle100\\rangle{210}$ symmetric tilt grain boundary reveals solute-specific confinement effects. Cr preserves low-barrier in-plane mobility while suppressing out-of-plane transport, guiding boron into favorable midplane voids. Mo, by contrast, imposes an across-the-board reduction in boron mobility, suppressing average diffusivity by two additional orders of magnitude at 800 $^\\circ$C and reducing out-of-plane transport by five orders of magnitude relative to Cr. Both elements promote segregation by producing negative segregation energies, but their roles diverge: Cr facilitates rapid redistribution and stabilization at interfacial sites, consistent with Cr-rich boride formation, while Mo creates deeper and more uniform segregation wells that strongly anchor boron. Together, these complementary behaviors explain the experimental prevalence of Cr- and Mo-rich borides at grain boundaries and carbide interfaces in Ni-based superalloys. More broadly, we establish spectral sampling as a transferable framework for interpreting diffusion in disordered alloys and for designing dopant strategies that control transport across complex interfaces.",
      "authors": [
        "Tyler D. Doležal",
        "Rodrigo Freitas",
        "Ju Li"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "categories": [
        "cond-mat.mtrl-sci",
        "physics.app-ph"
      ],
      "published": "2025-12-31 21:30:23+00:00",
      "link": "https://arxiv.org/pdf/2601.00117v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2512.25061v1",
      "title": "Melting curve of correlated iron at Earth's core conditions from machine-learned DFT+DMFT",
      "abstract": "Reliable constraints on iron's melting curve at Earth's inner-core boundary require accurate finite-temperature electronic correlations, yet DFT+DMFT calculations remain too costly for large-scale thermodynamic sampling. Here, we develop a machine-learning accelerator for charge self-consistent DFT+DMFT by training E(3)-equivariant graph neural networks to predict the local self-energy and Fermi level from atomic environments, providing an efficient warm start to the DMFT self-consistency loop. Using high-throughput data for Fe, FeO, and NiO, we obtain a 2-4 times reuduction in DMFT iterations. Leveraging this improvement, we generate correlated energies and forces for Fe at core pressures, train a neural-network interatomic potential, and determine the melting curve via two-phase coexistence simulations. We obtain a predicted melting temperature of 6225 K at 330 GPa.",
      "authors": [
        "Rishi Rao",
        "Li Zhu"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "categories": [
        "cond-mat.mtrl-sci",
        "physics.geo-ph"
      ],
      "published": "2025-12-31 18:55:30+00:00",
      "link": "https://arxiv.org/pdf/2512.25061v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2512.25048v1",
      "title": "All optical Lithography for Spatiotemporal Patterning of Azopolymer Microreliefs",
      "abstract": "Microstructured surfaces are central to photonics, biointerfaces, and functional coatings, yet they are typically fabricated through multi-step lithographic workflows requiring masks or molds and post-processing. Azopolymers provide an alternative route by converting structured optical fields into surface reliefs via light-induced mass migration, but existing approaches have been limited to smooth, shallow, and engraving-like topographies produced from a flat film. Here we introduce an all-optical, maskless, fully digital lithography platform that exploits engineered darkness within computer-generated holograms to spatially localize inward mass transport and directly produce positive, protruding microreliefs. We show that isolated and array of micro-bumps can be generated from pristine flat azopolymer films in a single writing step, and we introduce spatiotemporal control through sequential tailored illumination to reshape microrelief profiles, enabling flattened-top micropillars, programmable array shapes and arrangements, and free-form continuous microrelief designs. Hierarchical microarchitectures are also demonstrated by extending the concept of multi-step illumination sequences. As functional demonstrations, we realize multi-focus microlenses and quasi-square diffraction gratings with enhanced 1st-order efficiencies. Finally, we leverage azopolymer reconfigurability to implement write-erase-rewrite cycles that reset and repurpose the same surface region for distinct micropatterns, enabling rewritable surfaces and reprogrammable master templates for replication. Overall, this work establishes a scalable spatiotemporal strategy for on-demand, all-optical microfabrication and reprogramming of structured surfaces, where spatial and temporal degrees of freedom of holographic patterns intermix to produce advanced patterning capabilities.",
      "authors": [
        "I Komang Januariyasa",
        "Francesco Reda",
        "Nikolai Liubimtsev",
        "Marina Saphiannikova",
        "Fabio Borbone",
        "Marcella Salvatore",
        "Stefano Luigi Oscurato"
      ],
      "primary_category": "physics.optics",
      "categories": [
        "physics.optics"
      ],
      "published": "2025-12-31 18:44:29+00:00",
      "link": "https://arxiv.org/pdf/2512.25048v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2512.25027v1",
      "title": "Computational Analysis of Disease Progression in Pediatric Pulmonary Arterial Hypertension",
      "abstract": "Pulmonary arterial hypertension (PAH) is a progressive cardiopulmonary disease that leads to increased pulmonary pressures, vascular remodeling, and eventual right ventricular (RV) failure. Pediatric PAH remains understudied due to limited data and the lack of targeted diagnostic and therapeutic strategies. In this study, we developed and calibrated multi-scale, patient-specific cardiovascular models for four pediatric PAH patients using longitudinal MRI and catheterization data collected approximately two years apart. Using the CRIMSON simulation framework, we coupled three-dimensional fluid-structure interaction (FSI) models of the pulmonary arteries with zero-dimensional (0D) lumped-parameter heart and Windkessel models to simulate patient hemodynamics. An automated Python-based optimizer was developed to calibrate boundary conditions by minimizing discrepancies between simulated and clinical metrics, reducing calibration time from weeks to days. Model-derived metrics such as arterial stiffness, pulse wave velocity, resistance, and compliance were found to align with clinical indicators of disease severity and progression. Our findings demonstrate that computational modeling can non-invasively capture patient-specific hemodynamic adaptation over time, offering a promising tool for monitoring pediatric PAH and informing future treatment strategies.",
      "authors": [
        "Omar Said",
        "Christopher Tossas-Betancourt",
        "Mary K. Olive",
        "Jimmy C. Lu",
        "Adam Dorfman",
        "C. Alberto Figueroa"
      ],
      "primary_category": "physics.med-ph",
      "categories": [
        "physics.med-ph",
        "physics.comp-ph",
        "physics.flu-dyn"
      ],
      "published": "2025-12-31 18:27:16+00:00",
      "link": "https://arxiv.org/pdf/2512.25027v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2512.25024v1",
      "title": "On Nonlinear Inertial Transformations",
      "abstract": "It is often assumed that the most general transformation between two inertial reference frames is affine linear in their Cartesian coordinates, an assumption which is however not true. We provide a complete derivation of the most general inertial frame transformation, which is indeed nonlinear; along the way, we shall find that the conditions of preserving the Law of Inertia take the form of Schwarzian differential equations, providing perhaps the simplest possible physics setting in which the Schwarzian derivative appears. We then demonstrate that the most general such inertial transformation which further preserves the speed of light in all directions is, however, still affine linear. Physically, this paper may be viewed as a reduction of the number of postulates needed to uniquely specify special relativity by one, as well as a proof that inertial transformations automatically imbue spacetime with a vector space structure, albeit in one higher dimension than might be expected. Mathematically, this paper may be viewed as a derivation of the higher-dimensional analog of the Schwarzian differential equation and its most general solution.",
      "authors": [
        "Nicholas Agia"
      ],
      "primary_category": "physics.class-ph",
      "categories": [
        "physics.class-ph",
        "gr-qc"
      ],
      "published": "2025-12-31 18:22:10+00:00",
      "link": "https://arxiv.org/pdf/2512.25024v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2512.24983v1",
      "title": "Optical Spiking Neural Networks via Rogue-Wave Statistics",
      "abstract": "Optical computing could reduce the energy cost of artificial intelligence by leveraging the parallelism and propagation speed of light. However, implementing nonlinear activation, essential for machine learning, remains challenging in low-power optical systems dominated by linear wave physics. Here, we introduce an optical spiking neural network that uses optical rogue-wave statistics as a programmable firing mechanism. By establishing a homomorphism between free-space diffraction and neuronal integration, we demonstrate that phase-engineered caustics enable robust, passive thresholding: sparse spatial spikes emerge when the local intensity exceeds a significant-intensity rogue-wave criterion. Using a physics-informed digital twin, we optimize granular phase masks to deterministically concentrate energy into targeted detector regions, enabling end-to-end co-design of the optical transformation and a lightweight electronic readout. We experimentally validate the approach on BreastMNIST and Olivetti Faces, achieving accuracies of 82.45\\% and 95.00\\%, respectively, competitive with standard digital baselines. These results demonstrate that extreme-wave phenomena, often treated as deleterious fluctuations, can be harnessed as structural nonlinearity for scalable, energy-efficient neuromorphic photonic inference.",
      "authors": [
        "Bahadır Utku Kesgin",
        "Gülsüm Yaren Durdu",
        "Uğur Teğin"
      ],
      "primary_category": "physics.optics",
      "categories": [
        "physics.optics"
      ],
      "published": "2025-12-31 17:28:12+00:00",
      "link": "https://arxiv.org/pdf/2512.24983v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2512.24865v1",
      "title": "Latent Twins: A Framework for Scene Recognition and Fast Radiative Transfer Inversion in FORUM All-Sky Observations",
      "abstract": "The FORUM (Far-infrared Outgoing Radiation Understanding and Monitoring) mission will provide, for the first time, systematic far-infrared spectral measurements of Earth's outgoing radiation, enabling improved understanding of atmospheric processes and the radiation budget. Retrieving atmospheric states from these observations constitutes a high-dimensional, ill-posed inverse problem, particularly under cloudy-sky conditions where multiple-scattering effects are present. In this work, we develop a data-driven, physics-aware inversion framework for FORUM all-sky retrievals based on latent twins: coupled autoencoders for atmospheric states and spectra, combined with bidirectional latent-space mappings. A lightweight model-consistency correction ensures physically plausible cloud variable reconstructions. The resulting framework demonstrates potential for retrievals of atmospheric, cloud and surface variables, providing information that can serve as a prior, initial guess, or surrogate for computationally expensive full-physics inversion methods. It also enables robust scene classification and near-instantaneous inference, making it suitable for operational near-real-time applications. We demonstrate its performance on synthetic FORUM-like data and discuss implications for future data assimilation and climate studies.",
      "authors": [
        "Cristina Sgattoni",
        "Luca Sgheri",
        "Matthias Chung",
        "Michele Martinazzo"
      ],
      "primary_category": "physics.ao-ph",
      "categories": [
        "physics.ao-ph"
      ],
      "published": "2025-12-31 13:53:52+00:00",
      "link": "https://arxiv.org/pdf/2512.24865v1",
      "tags": [
        "大厂llm"
      ]
    },
    {
      "id": "2512.24846v2",
      "title": "Generation of NIR and Visible Structured Light Beams with a Mechanical Long-Period Fiber Grating",
      "abstract": "This work presents the tunable generation of vortex, vector, and flat-top 1060-nm NIR beams in a few-mode fiber with a mechanical long-period fiber grating. By the variation of applied force on the fiber grating, the core mode to higher-order mode excitation can be adjusted. The manipulation of the beam transformation is achieved through the polarization control of the fiber eigenmodes and mode coupling efficiency. By precisely tuning the intensity ratio between fundamental and doughnut modes, we arrive at the generation of propagation-invariant vector flat-top beams for more than 5 m. Transverse optical field of 532-nm green light from frequency-doubled Nd-doped yttrium vanadate laser is manipulated and coupled into various intensity distributions in a few-mode fiber by using a mechanically induced long-period fiber grating. We show that the doughnut beam, the Mexican-hat beam, and the crater-lake beam can be generated from the input Gaussian beam via the coupling of the fundamental core mode to a series of co-propagating higher-order modes with properly applied forces and polarizations.",
      "authors": [
        "Wen-Hsuan Kuan",
        "Xin-Yu Hou",
        "Kuei-Huei Lin"
      ],
      "primary_category": "physics.optics",
      "categories": [
        "physics.optics"
      ],
      "published": "2025-12-31 13:12:34+00:00",
      "link": "https://arxiv.org/pdf/2512.24846v2",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2512.24823v1",
      "title": "In-vivo femtonewton-sensing nanotribology of Tradescantia zebrina leaf cell inner surface using roll rotation detection",
      "abstract": "Accessing the properties of a plant cell interior non-invasively is difficult due to the presence of a cell wall. Nanoparticles larger than 5 nm cannot be readily phagocytosed inside the cell like animal cells. It is here that we realise that Tradescantia zebrina plant cells have prismatic forms of calcium oxalate crystals present inside them naturally. These crystals make a ready choice to study properties of the inner cell surface with the application of optical tweezers. Moreover, out-of-plane rotations in optical tweezers have begun to be explored only recently. The pitch rotation has been detected with high resolution and several applications are explored. In this work, we first study the stable configuration while trapped in linearly polarized optical tweezers and then explore the other out-of-plane configurations to detect the roll rotation at high resolution. Then a micro-rheological analysis is performed to obtain the frictional properties of the inner surface of the plasma membrane of the leaf cell. The size of the particle is about 5 $μ$m along the diagonal, so that the contact length with the surface is about 200 nm. We measure a frictional force of 18.5 pN at a sensitivity of about 200 fN without averaging.",
      "authors": [
        "Snigdhadev Chakraborty",
        "Mukul Sagar",
        "Atanu Ghosh",
        "Krishna Kumari Swain",
        "Mrutyunjaya Rath",
        "Agniva Das",
        "Susy Varughese",
        "Basudev Roy"
      ],
      "primary_category": "physics.bio-ph",
      "categories": [
        "physics.bio-ph"
      ],
      "published": "2025-12-31 12:24:24+00:00",
      "link": "https://arxiv.org/pdf/2512.24823v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2512.24816v1",
      "title": "Upscaling from ab initio atomistic simulations to electrode scale: The case of manganese hexacyanoferrate, a cathode material for Na-ion batteries",
      "abstract": "We present a generalizable scale-bridging computational framework that enables predictive modeling of insertion-type electrode materials from atomistic to device scales. Applied to sodium manganese hexacyanoferrate, a promising cathode material for grid-scale sodium-ion batteries, our methodology employs an active-learning strategy to train a Moment Tensor Potential through iterative hybrid grand-canonical Monte Carlo--molecular dynamics sampling, robustly capturing configuration spaces at all sodiation levels. The resulting machine learning interatomic potential accurately reproduces experimental properties including volume expansion, operating voltage, and sodium concentration-dependent structural transformations, while revealing a four-order-of-magnitude difference in sodium diffusivity between the rhombohedral (sodium-rich) and tetragonal (sodium-poor) phases at 300 K. We directly compute all critical parameters -- temperature- and concentration-dependent diffusivities, interfacial and strain energies, and complete free-energy landscapes -- to feed them into pseudo-2D phase-field simulations that predict phase-boundary propagation and rate-dependent performances across electrode length scales. This multiscale workflow establishes a blueprint for rational computational design of next-generation insertion-type materials, such as battery electrode materials, demonstrating how atomistic insights can be systematically translated into continuum-scale predictions.",
      "authors": [
        "Yuan-Chi Yang",
        "Eric Woillez",
        "Quentin Jacquet",
        "Ambroise van Roekeghem"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "categories": [
        "cond-mat.mtrl-sci",
        "physics.app-ph",
        "physics.chem-ph",
        "physics.comp-ph"
      ],
      "published": "2025-12-31 12:04:38+00:00",
      "link": "https://arxiv.org/pdf/2512.24816v1",
      "tags": [
        "大厂llm",
        "大语言模型",
        "符号回归（示例）"
      ]
    },
    {
      "id": "2512.24786v1",
      "title": "A Dual-Tuned Concentric Multimodal RF Coil for 7T 1H/31P MRSI: Concurrently Enhancing B1 Efficiency Over Single-Tuned References",
      "abstract": "This study presents the design, simulation, and experimental validation of a dual-tuned concentric multimodal surface coil for 7T 1H/31P magnetic resonance spectroscopic imaging (MRSI), developed to significantly enhance 31P B1 efficiency while improving 1H performance. The coil architecture utilizes two interleaved sets of three concentric loop resonators. Intra-nucleus electromagnetic coupling within each three-loop set generates a spectrum of eigenmodes; the operational modes for 1H and 31P were specifically selected because their co-directed current distributions reinforce the magnetic field at the center, yielding B1 patterns that resemble those of conventional single-loop surface coils but with superior efficiency. Full-wave electromagnetic simulations and bench measurements on a fabricated prototype were conducted to characterize the multimodal resonance behavior, scattering parameters, B1 distribution, and 10-g local SAR, using size-matched conventional single-tuned loops as references. The results confirmed that the design reproducibly generated the predicted eigenmode ordering with sufficient spectral separation to prevent interference from parasitic or undesired modes. Notably, the multimodal design achieved an 83% boost in 31P B1 efficiency and a 21% boost in 1H B1 efficiency at the coil center compared to same-sized single-tuned references. Sufficient inter-nuclear decoupling was achieved to prevent signal leakage between channels, and simulations with a human head model confirmed that the peak 10-g local SAR remained comparable to conventional designs. These findings demonstrate that this multimodal concentric design offers a robust and highly efficient solution for multinuclear MRSI at ultrahigh fields, effectively mitigating the sensitivity limitations of X-nuclei without compromising proton-based imaging capabilities.",
      "authors": [
        "Yunkun Zhao",
        "Xiaoliang Zhang"
      ],
      "primary_category": "physics.med-ph",
      "categories": [
        "physics.med-ph"
      ],
      "published": "2025-12-31 11:15:45+00:00",
      "link": "https://arxiv.org/pdf/2512.24786v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2512.24760v1",
      "title": "Runaway electron avalanche and macroscopic beam formation: simulations of the DTT full power scenario",
      "abstract": "The transition of the Divertor Tokamak Test (DTT) facility from its initial commissioning phase (Day-0, plasma current $I_{p}=2$ MA) to the full power scenario ($I_{p}=5.5$ MA) introduces a critical shift in the dynamics of runaway electrons (REs) generation. While previous predictive studies of the low-current scenario indicated a robust safety margin against RE beam formation, this work reveals that the exponential scaling of the RE avalanche gain with plasma current severely narrows the safe operational window in the full power scenario. Using the non-linear magnetohydrodynamic code JOREK, we perform comprehensive 2D simulations of the current quench (CQ) phase of several disruption scenarios, systematically scanning initial RE seed currents and injected impurity levels. The results demonstrate that in the full power scenario, the avalanche multiplication factor is sufficiently high ($G_\\text{av} \\approx 1.3 \\cdot 10^5$) to convert a mere 5.5 A seed current into macroscopic RE beams of $\\approx 0.7$ MA when large amounts of impurities are present. For even higher RE seeds, the RE current can peak at $ \\approx 3.2$ MA, constituting up to $\\approx$ 80% of the total plasma current during the CQ. These findings suggest that, unlike the Day-0 phase, the disruption mitigation strategy for the full power scenario involves a careful balance between thermal load mitigation and RE avoidance, necessitating a well-chosen quantity of injected impurities. This work provides the baseline needed for future estimations of RE loads on the plasma-facing components of DTT, which will be essential for designing and positioning mitigation components like sacrificial limiters.",
      "authors": [
        "E. Emanuelli",
        "F. Vannini",
        "M. Hoelzl",
        "E. Nardon",
        "V. Bandaru",
        "N. Schwarz",
        "D. Bonfiglio",
        "G. Ramogida",
        "F. Subba",
        "JOREK Team"
      ],
      "primary_category": "physics.plasm-ph",
      "categories": [
        "physics.plasm-ph"
      ],
      "published": "2025-12-31 10:09:27+00:00",
      "link": "https://arxiv.org/pdf/2512.24760v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2512.24757v1",
      "title": "Generalization Capability of Deep Learning for Predicting Drag Reduction in Pulsating Turbulent Pipe Flow with Arbitrary Acceleration and Deceleration",
      "abstract": "The spatiotemporal evolution of pulsating turbulent pipe flow was predicted by deep learning. A convolutional neural network (CNN) and long short-term memory (LSTM) were employed for long-term prediction by recursively predicting the local temporal evolution. To enhance prediction, physical components such as wall shear stress were informed into the training process. The datasets were obtained from direct numerical simulation (DNS). The model was trained exclusively on a limited set of sinusoidal pulsating flows driven by pressure gradients defined by their period and amplitude. Subsequently, 36 pulsating flows with arbitrary non-sinusoidal acceleration and deceleration were predicted to evaluate the generalization capability, defined as the predictive performance on unseen data during training. The model successfully predicted drag reduction rates ranging from $-1\\%$ to $86\\%$, with a mean absolute error of 9.2. This predictive performance for unseen pulsations indicates that local temporal prediction plays a central role, rather than learning the global profile of the pulsating waveforms. This implication was quantitatively verified by analyzing the differences in periodic $C_f$--$Re_b$ trajectories between the training and test datasets, demonstrating that flows exhibiting local similarity to the training data are more predictable. Furthermore, it was demonstrated that flows exhibiting intermittent laminar--turbulent transition and relaminarization become predictable when such regimes are incorporated into the training data. The results indicate that accurate prediction is achievable provided that the training data sufficiently cover the local flow-state space, highlighting the importance of appropriate training data selection for generalized flow prediction.",
      "authors": [
        "Sota Kumazawa",
        "Yasuhiro Yoshida",
        "Tomohiro Nimura",
        "Akira Murata",
        "Kaoru Iwamoto"
      ],
      "primary_category": "physics.flu-dyn",
      "categories": [
        "physics.flu-dyn"
      ],
      "published": "2025-12-31 10:02:40+00:00",
      "link": "https://arxiv.org/pdf/2512.24757v1",
      "tags": [
        "大厂llm",
        "大语言模型"
      ]
    },
    {
      "id": "2512.24655v1",
      "title": "Thermodynamics Reconstructed from Information Theory:An Axiomatic Framework via Information-Volume Constraints and Path-Space KL Divergence",
      "abstract": "We develop an axiomatic reconstruction of thermodynamics based entirely on two primitive components: a description of what aspects of a system are observed and a reference measure that encodes the underlying descriptive convention. These ingredients define an \"information volume\" for each observational cell.   By incorporating the logarithm of this volume as an additional constraint in a minimum-relative-entropy inference scheme, temperature, chemical potential, and pressure arise as conjugate variables of a single information-theoretic functional. This leads to a Legendre-type structure and a first-law-like relation in which pressure corresponds to information volume rather than geometric volume.   For nonequilibrium dynamics, entropy production is characterized through the relative-entropy asymmetry between forward and time-reversed stochastic evolutions. A decomposition using observational entropy then separates total dissipation into system and environment contributions. Heat is defined as the part of dissipation not accounted for by the system-entropy change, yielding a representation that does not rely on local detailed balance or a specific bath model. We further show that the difference between joint and partially observed dissipation equals the average of conditional relative entropies, providing a unified interpretation of hidden dissipation and information-flow terms as projection-induced gaps.",
      "authors": [
        "Tatsuaki Tsuruyama"
      ],
      "primary_category": "physics.chem-ph",
      "categories": [
        "physics.chem-ph"
      ],
      "published": "2025-12-31 06:02:19+00:00",
      "link": "https://arxiv.org/pdf/2512.24655v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2512.24641v1",
      "title": "Pathway to Optical-Cycle Dynamic Photonics: Extreme Electron Temperatures in Transparent Conducting Oxides",
      "abstract": "We find that transparent conducting oxides (TCOs) exhibit oscillatory (sign-reversing) dynamics on a few optical cycle timescale under extreme electron temperatures. We demonstrate a mechanism for such transient dynamics and present an inverse-designed multilayer cavity incorporating an ultrathin TCO layer that supports the oscillatory behavior. This approach yields transmittance oscillations with a period of ~20 fs, which corresponds to three optical cycles of the probe beam. To achieve a similar oscillatory modulation in the refractive index, we incorporate a TCO electron-acceptor layer on top of the inverse-designed cavity, enabling thermionic carrier injection at the TCO heterojunction. The resulting acceptor layer achieves a striking Δn response time as short as 9 fs, approaching a single optical cycle, and is further tunable to sub-cycle timescales. The findings not only clarify the elusive transient physics in TCOs but also demonstrate, for the first time, the critical role of electron temperatures in driving oscillatory dynamic responses. More broadly, we establish TCO-based thermionic carrier injection as a practical route to novel time-varying photonic media operating on the timescale of an optical cycle, enabling time-reflection, time-refraction, and related dynamic phenomena from the visible to the infrared.",
      "authors": [
        "Jae Ik Choi",
        "Vahagn Mkhitaryan",
        "Colton Fruhling",
        "Jacob B. Khurgin",
        "Alexander V. Kildishev",
        "Vladimir M. Shalaev",
        "Alexandra Boltasseva"
      ],
      "primary_category": "physics.optics",
      "categories": [
        "physics.optics"
      ],
      "published": "2025-12-31 05:27:19+00:00",
      "link": "https://arxiv.org/pdf/2512.24641v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2512.24529v1",
      "title": "Towards Interpretable AI in Personalized Medicine: A Radiological-Biological Radiomics Dictionary Connecting Semantic Lung-RADS and imaging Radiomics Features; Dictionary LC 1.0",
      "abstract": "Lung cancer remains the leading cause of cancer-related mortality worldwide, with survival strongly dependent on early detection. Standard-dose computed tomography (CT) screening using the Lung Imaging Reporting and Data System (Lung-RADS) standardizes pulmonary nodule assessment but is limited by inter-reader variability and reliance on qualitative descriptors, while radiomics offers quantitative biomarkers that often lack clinical interpretability. To bridge this gap, we propose a radiological-biological dictionary that aligns radiomic features (RFs) with Lung-RADS semantic categories. A clinically informed dictionary translating ten Lung-RADS descriptors into radiomic proxies was developed through literature curation and validated by eight expert reviewers. As a proof of concept, imaging and clinical data from 977 patients across 12 collections in The Cancer Imaging Archive (TCIA) were analyzed; following preprocessing and manual segmentation, 110 RFs per nodule were extracted using PyRadiomics in compliance with the Image Biomarker Standardization Initiative (IBSI). A semi-supervised learning framework incorporating 499 labeled and 478 unlabeled cases was applied to improve generalizability, evaluating seven feature selection methods and ten interpretable classifiers. The optimal pipeline (ANOVA feature selection with a support vector machine) achieved a mean validation accuracy of 0.79. SHapley Additive exPlanations (SHAP) analysis identified key RFs corresponding to Lung-RADS semantics such as attenuation, margin irregularity, and spiculation, supporting the validity of the proposed mapping. Overall, this dictionary provides an interpretable framework linking radiomics and Lung-RADS semantics, advancing explainable artificial intelligence for CT-based lung cancer screening.",
      "authors": [
        "Ali Fathi Jouzdani",
        "Shahram Taeb",
        "Mehdi Maghsudi",
        "Arman Gorji",
        "Arman Rahmim",
        "Mohammad R. Salmanpour"
      ],
      "primary_category": "physics.med-ph",
      "categories": [
        "physics.med-ph"
      ],
      "published": "2025-12-31 00:23:39+00:00",
      "link": "https://arxiv.org/pdf/2512.24529v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00761v1",
      "title": "Exponentially Accelerated Sampling of Pauli Strings for Nonstabilizerness",
      "abstract": "Quantum magic, quantified by nonstabilizerness, measures departures from stabilizer structure and underlies potential quantum speedups. We introduce an efficient classical algorithm that exactly computes stabilizer Rényi entropies and stabilizer nullity for generic many-body wavefunctions of $N$ qubits. The method combines the fast Walsh-Hadamard transform with an exact partition of Pauli operators. It achieves an exponential speedup over direct approaches, reducing the average cost per sampled Pauli string from $O(2^N)$ to $O(N)$. Building on this framework, we further develop a Monte-Carlo estimator for stabilizer Rényi entropies together with a Clifford-based variance-reduction scheme that suppresses sampling fluctuations. We benchmark the accuracy and efficiency on ensembles of random magic states, and apply the method to random Clifford circuits with doped $T$ gates, comparing different doping architectures. Our approach applies to arbitrary quantum states and provides quantitative access to magic resources both encoded in highly entangled states and generated by long-time nonequilibrium dynamics.",
      "authors": [
        "Zhenyu Xiao",
        "Shinsei Ryu"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "cond-mat.mes-hall",
        "cond-mat.stat-mech"
      ],
      "published": "2026-01-02 17:37:04+00:00",
      "link": "https://arxiv.org/pdf/2601.00761v1",
      "tags": [
        "sr-bench",
        "大语言模型"
      ]
    },
    {
      "id": "2601.00492v1",
      "title": "Thermal History-Dependent Coalescence Mechanisms and Sintering Dynamics in Al-6.8%Cu Nanopowders",
      "abstract": "Aluminum-Copper (Al-Cu) alloys are essential materials for weight reduction critical structures in the aerospace and automotive industries, yet achieving their maximum ultrahigh-strength potential remains limited by nanoscale defect control during powder metallurgy processing. We employ large-scale molecular dynamics simulations on Al-6.8%Cu nanoparticles to explore atomic-scale mechanisms governing the full thermal sintering cycle. We demonstrate that while the sintering temperature primarily initiates neck formation, the subsequent cooling rate is the dominant kinetic parameter dictating the final microstructure. Fast cooling rates trap a significantly higher density of stacking faults and can unexpectedly lead to the formation of an amorphous phase at the interparticle interfaces, a feature critically dependent on the rate of thermal dissipation. We confirm a clear shift in the coalescence mechanism from plastic deformation (dislocation slip) at low temperatures (300 K and 450 K) to mass transport via atomic diffusion at high temperatures (600 K). These findings provide essential, atomic-scale guidelines for controlling thermal processing, particularly cooling rates, to design defect-stabilized, high-performance Al-Cu components.",
      "authors": [
        "Amirhossein Abedini",
        "Behzad Mehrafrooz",
        "Iyad Alabd Alhafez",
        "Arash Kardani"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "categories": [
        "cond-mat.mtrl-sci"
      ],
      "published": "2026-01-01 22:18:20+00:00",
      "link": "https://arxiv.org/pdf/2601.00492v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2601.00302v1",
      "title": "High-pressure structural and lattice-dynamics study of Yttria-Stabilized Zirconia",
      "abstract": "The structural evolution of two selected compositions of Yttria-Stabilized Zirconia (YSZ), with 3mol% (3YSZ) and 8mol% (8YSZ) of Y2O3, have been investigated under pressure using in-situ synchrotron X-ray diffraction (XRD) and Raman spectroscopy in a diamond anvil cell up to 40 GPa (at room temperature).The close crystallographic relation between the observed structures and the relatively large difference in the atomic numbers of Y/Zr and O, imposes the simultaneous study using both techniques, aiming to fully elucidate the structural evolution under pressure. The results, by combining both techniques, reveal that for both 3YSZ and 8YSZ, pressure promotes higher-symmetry structures. Under initial compression, the minority at ambient conditions monoclinic phase (m-phase) gradually transforms towards t-phase, a transition that is concluded for both 3YSZ/8YSZ at ~10 GPa. At higher pressures, the solely remaining t-phase of 3YSZ transforms to the t'', that in turns transforms to the c-phase above 28 GPa. Likewise, for 8YSZ the coexistence of t- and t''-phases continue up to 31 GPa, where both transforms towards c-phase, that remains stable up to the highest pressure of this study. Upon pressure release, all observed transitions are fully reversible with negligible hysteresis, with the exception of the practical disappearance of the monoclinic phase at ambient conditions. Our study underscores the significance of simultaneously performing and analyzing the results of both XRD and Raman spectroscopy studies in relevant crystallographic systems. Moreover, it provides a route towards a ``structural purification'' of YSZ through the elimination of the m-phase aiming to improve material properties.",
      "authors": [
        "Shennan Hu",
        "Baihong Sun",
        "Wenting Lu",
        "Shiyu Feng",
        "Bihan Wang",
        "Hirokazu Kadobayashi",
        "Yuzhu Wang",
        "Xingya Wang",
        "Lili Zhang",
        "Bora Kalkan",
        "Azkar Saeed Ahmad",
        "Elissaios Stavrou"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "categories": [
        "cond-mat.mtrl-sci"
      ],
      "published": "2026-01-01 10:39:02+00:00",
      "link": "https://arxiv.org/pdf/2601.00302v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2601.00230v1",
      "title": "Deterministic Helicity Locking of Bloch Skyrmions in Centrosymmetric Systems",
      "abstract": "Magnetic skyrmions in centrosymmetric materials exhibit Bloch-type spin textures with degenerate helicity states due to the absence of Dzyaloshinskii Moriya interaction (DMI), resulting in random nucleation and uncontrolled chirality. Here, we present a comprehensive micromagnetic study demonstrating a fully DMI free strategy for deterministic helicity control by interfacing ferromagnetic (FM) stripes or notch structures with centrosymmetric magnetic (CM) films. We first show that a geometrically constrained configuration comprising two FM stripes with opposite in-plane magnetizations stabilizes skyrmions with a selected helicity, either clockwise (CW) or counterclockwise (CCW). We further extend this concept to achieve deterministic nucleation of CW or CCW skyrmions using current pulses applied to an FM notch patterned on the CM film. The combined effects of the FM stripe/notch geometry and interfacial exchange coupling generate dipolar fields that lift the helicity degeneracy, enabling controlled formation of skyrmions with fixed chirality. These results establish FM/CM heterostructures as a robust, DMI-free platform for deterministic generation and guided motion of helicity-locked skyrmions, opening new pathways for advanced spintronic applications.",
      "authors": [
        "Jayaseelan Dhakshinamoorthy",
        "Hitesh Chhabra",
        "Ajaya K Nayak"
      ],
      "primary_category": "cond-mat.other",
      "categories": [
        "cond-mat.other"
      ],
      "published": "2026-01-01 06:26:25+00:00",
      "link": "https://arxiv.org/pdf/2601.00230v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2601.00145v1",
      "title": "Machine-learned potential for amorphous Indium-Tin-Oxide alloys",
      "abstract": "Machine-learned potential-driven molecular dynamics (MLMD) simulations are of great value in guiding the design and optimization of memory devices. Amorphous indium-tin-oxide (ITO) is widely used as transparent conducting oxide for flat-panel display and solar cell applications, and also as a capping layer in phase-change-materials-based reconfigurable color display devices. However, atomistic simulations of ITO using ab initio molecular dynamics (AIMD) are limited to systems of a few hundred atoms due to expensive computational costs, which prevents the device-scale modelling of real-world applications. In this work, we develop a machine-learned potential for ITO and its parent phase In2O3 based on the Gaussian approximation potential (GAP) framework. We generate a comprehensive training dataset using an iterative training protocol. Our MLMD simulations of crystalline, liquid and melt-quenched amorphous ITO models are in great agreement with the AIMD reference. In particular, the ML potential well captures the minority atomic interaction, such as Sn-Sn bonds, which have poor statistics in small-scale AIMD simulations. We demonstrate that the MLMD simulations are 3-4 orders of magnitude faster than AIMD. The training dataset and the fitted GAP potentials for ITO and In2O3 are openly accessible.",
      "authors": [
        "Shuaiyang Guo",
        "Yuan Wang",
        "Wei Zhang"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "categories": [
        "cond-mat.mtrl-sci"
      ],
      "published": "2026-01-01 00:25:36+00:00",
      "link": "https://arxiv.org/pdf/2601.00145v1",
      "tags": [
        "大厂llm"
      ]
    },
    {
      "id": "2601.00133v1",
      "title": "In context learning Foundation models for Materials Property Prediction with Small datasets",
      "abstract": "Foundation models (FMs) have recently shown remarkable in-context learning (ICL) capabilities across diverse scientific domains. In this work, we introduce a unified in-context learning foundation model (ICL-FM) framework for materials property prediction that integrates both composition-based and structure-aware representations. The proposed approach couples the pretrained TabPFN transformer with graph neural network (GNN)-derived embeddings and our novel MagpieEX descriptors. MagpieEX augments traditional features with cation-anion interaction data to explicitly measure bond ionicity and charge-transfer asymmetry, capturing interatomic bonding characteristics that influence vibrational and thermal transport properties. Comprehensive experiments on the MatBench benchmark suite and a standalone lattice thermal conductivity (LTC) dataset demonstrate that ICL-FM achieves competitive or superior performance to state-of-the-art (SOTA) models with significantly reduced training costs. Remarkably, the training-free ICL-FM outperformed sophisticated SOTA GNN models in five out of six representative composition-based tasks, including a significant 9.93\\% improvement in phonon frequency prediction. On the LTC dataset, the FM effectively models complex phenomena such as phonon-phonon scattering and atomic mass contrast. t-SNE analysis reveals that the FM acts as a physics-aware feature refiner, transforming raw, disjoint feature clusters into continuous manifolds with gradual property transitions. This restructured latent space enhances interpolative prediction accuracy while aligning learned representations with underlying physical laws. This study establishes ICL-FM as a generalizable, data-efficient paradigm for materials informatics.",
      "authors": [
        "Qinyang Li",
        "Rongzhi Dong",
        "Nicholas Miklaucic",
        "Jeffrey Hu",
        "Sadman Sadeed Omee",
        "Lai Wei",
        "Sourin Dey",
        "Ming Hu",
        "Jianjun Hu"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "categories": [
        "cond-mat.mtrl-sci"
      ],
      "published": "2025-12-31 22:29:52+00:00",
      "link": "https://arxiv.org/pdf/2601.00133v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2512.25074v1",
      "title": "Randomization Times under Quantum Chaotic Hamiltonian Evolution",
      "abstract": "Randomness generation through quantum-chaotic evolution underpins foundational questions in statistical mechanics and applications across quantum information science, including benchmarking, tomography, metrology, and demonstrations of quantum computational advantage. While statistical mechanics successfully captures the temporal averages of local observables, understanding randomness at the level of higher statistical moments remains a daunting challenge, with analytic progress largely confined to random quantum circuit models or fine-tuned systems exhibiting space-time duality. Here we study how much randomness can be dynamically generated by generic quantum-chaotic evolution under physical, non-random Hamiltonians. Combining theoretical insights with numerical simulations, we show that for broad classes of initially unentangled states, the dynamics become effectively Haar-random well before the system can ergodically explore the physically accessible Hilbert space. Both local and highly nonlocal observables, including entanglement measures, equilibrate to their Haar expectation values and fluctuations on polynomial timescales with remarkably high numerical precision, and with the fastest randomization occurring in regions of parameter space previously identified as maximally chaotic. Interestingly, this effective randomization can occur on timescales linear in system size, suggesting that the sub-ballistic growth of Renyi entropies typically observed in systems with conservation laws can be bypassed in non-random Hamiltonians with an appropriate choice of initial conditions.",
      "authors": [
        "Souradeep Ghosh",
        "Nicholas Hunter-Jones",
        "Joaquin F. Rodriguez-Nieva"
      ],
      "primary_category": "cond-mat.stat-mech",
      "categories": [
        "cond-mat.stat-mech",
        "quant-ph"
      ],
      "published": "2025-12-31 18:59:56+00:00",
      "link": "https://arxiv.org/pdf/2512.25074v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2512.25069v1",
      "title": "Classification of Interacting Topological Crystalline Superconductors in Three Dimensions and Beyond",
      "abstract": "Although classification for free-fermion topological superconductors (TSC) is established, systematically understanding the classification of 3D interacting TSCs remains difficult, especially those protected by crystalline symmetries like the 230 space groups. We build up a general framework for systematically classifying 3D interacting TSCs protected by crystalline symmetries together with discrete internal symmetries. We first establish a complete classification for fermionic symmetry protected topological phases (FSPT) with purely discrete internal symmetries, which determines the crystalline case via the crystalline equivalence principle. Using domain wall decoration, we obtain classification data and formulas for generic FSPTs, what are suitable for systematic computation. The four layers of decoration data $(n_1, n_2, n_3, ν_4)$ characterize a 3D FSPT with symmetry $G_b\\times_{ω_2}Z_2^f$, corresponding to $p+ip$, Kitaev chain, complex fermion, and bosonic SPT layers. Inspired by previous works, a crucial aspect is the $p+ip$ layer, where classification involves two possibilities: anti-unitary and infinite-order symmetries (e.g., translation). We show the former maps to some mirror FSPT classification with the mirror plane decorated by a $p+ip$ superconductor, while the latter is determined by the free part of $H^1(G_b, Z_T)$, corresponding to weak TSCs. Another key point is the Kitaev chain decoration for the anti-unitary symmetries, which differs essentially from unitary ones. We explicitly obtain formulas for all three layers of decoration $(n_2, n_3, ν_4)$, which are amenable to automatic computation. As an application, we classify the 230 space-group topological crystalline superconductors in interacting electronic systems.",
      "authors": [
        "Shang-Qiang Ning",
        "Xing-Yu Ren",
        "Qing-Rui Wang",
        "Yang Qi",
        "Zheng-Cheng Gu"
      ],
      "primary_category": "cond-mat.str-el",
      "categories": [
        "cond-mat.str-el",
        "cond-mat.mes-hall",
        "cond-mat.supr-con"
      ],
      "published": "2025-12-31 18:59:38+00:00",
      "link": "https://arxiv.org/pdf/2512.25069v1",
      "tags": [
        "sr-bench",
        "大厂llm",
        "大语言模型"
      ]
    },
    {
      "id": "2512.25054v1",
      "title": "Emergence of 3D Superconformal Ising Criticality on the Fuzzy Sphere",
      "abstract": "Supersymmetric conformal field theories (SCFTs) form a unique subset of quantum field theories which provide powerful insights into strongly coupled critical phenomena. Here, we present a microscopic and non-perturbative realization of the three-dimensional $\\mathcal{N}=1$ superconformal Ising critical point, based on a Yukawa-type coupling between a 3D Ising CFT and a gauged Majorana fermion. Using the recently developed fuzzy sphere regularization, we directly extract the scaling dimensions of low-lying operators via the state-operator correspondence. At the critical point, we demonstrate conformal multiplet structure together with the hallmark of emergent spacetime supersymmetry through characteristic relations between fermionic and bosonic operators. Moreover, by tuning the Yukawa coupling, we explicitly track the evolution of operator spectra from the decoupled Ising-Majorana fixed point to the interacting superconformal fixed point, revealing renormalization-group flow at the operator level. Our results establish a controlled, non-perturbative microscopic route to 3D SCFTs.",
      "authors": [
        "Yin Tang",
        "Cristian Voinea",
        "Liangdong Hu",
        "Zlatko Papić",
        "W. Zhu"
      ],
      "primary_category": "cond-mat.str-el",
      "categories": [
        "cond-mat.str-el",
        "cond-mat.stat-mech",
        "hep-th"
      ],
      "published": "2025-12-31 18:49:36+00:00",
      "link": "https://arxiv.org/pdf/2512.25054v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2512.24849v1",
      "title": "SSCHA-based evolutionary crystal structure prediction at finite temperatures with account for quantum nuclear motion",
      "abstract": "Accurate crystal structure prediction (CSP) at finite temperatures with quantum anharmonic effects remains challenging but very prominent in systems with lightweight atoms such as superconducting hydrides. In this work, we integrate machine-learned interatomic potentials (MLIPs) with the stochastic self-consistent harmonic approximation (SSCHA) to enable evolutionary CSP on the quantum anharmonic free-energy landscape. Using LaH$_{10}$ at 150 GPa and 300 K as a test case, we compare two approaches for SSCHA-based CSP: using light-weight active-learning MLIPs (AL-MLIPs) trained on-the-fly from scratch, and foundation models or universal MLIPs (uMLIPs) from the Matbench project. We demonstrate that AL-MLIPs allow to correctly predict the experimentally known cubic Fm$\\bar{3}$m phase as the most stable polymorph at 150 GPa but require corrections within the thermodynamic perturbation theory to get consistent results. The uMLIP Mattersim-5m allow to conduct SSCHA-based CSP without requiring per-structure training and even get correct structure ranking near the global minimum, though fine-tuning may be needed for higher accuracy. Our results show that including quantum anharmonicity simplifies the free-energy landscape and is essential for correct stability rankings, that is especially important for high-temperature phases that could be missed in classical 0 K CSP. The proposed approach extends the reach of CSP to systems where quantum nuclear motion and anharmonicity dominate.",
      "authors": [
        "Daniil Poletaev",
        "Artem Oganov"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "categories": [
        "cond-mat.mtrl-sci",
        "cond-mat.supr-con"
      ],
      "published": "2025-12-31 13:17:49+00:00",
      "link": "https://arxiv.org/pdf/2512.24849v1",
      "tags": [
        "sr-bench"
      ]
    },
    {
      "id": "2512.24831v1",
      "title": "Time-Reversal Symmetry Breaking Superconducting State and Collective Modes in Kagome Superconductors",
      "abstract": "We comprehensively study the unconventional pairing and collective modes in the multiband kagome superconductors AV$_3$Sb$_5$ (A=$\\mathrm{K},\\mathrm{Cs},\\mathrm{Rb}$). By solving gap equations at zero temperature, we identify a transition from normal $s++/s\\pm$-wave pairing to time-reversal symmetry (TRS) breaking pairing with a variation of inter-pocket interactions or density of states. This TRS breaking pairing originates from the superconducting phase frustration of different Fermi pockets and can account for experimental TRS breaking signal in kagome superconductors. Moreover, we investigate collective modes, including the Higgs, Leggett, and Bogoloubov-Anderson-Goldstone modes, arising from fluctuations of the amplitude, relative phase, and overall phase of the superconducting order parameters, respectively. Remarkably, due to the presence of multibands, one branch of the Leggett modes becomes nearly massless near the TRS breaking transition, providing a compelling smoking-gun signature of TRS-breaking superconductivity, in clear contrast to TRS-breaking charge orders. Our results elucidate the rich superconducting physics and its associated collective modes in kagome metals, and suggest feasible experimental detection of TRS breaking pairing.",
      "authors": [
        "Xinloong Han",
        "Jun Zhan",
        "Jiangping Hu",
        "Fu-chun Zhang",
        "Xianxin Wu"
      ],
      "primary_category": "cond-mat.supr-con",
      "categories": [
        "cond-mat.supr-con"
      ],
      "published": "2025-12-31 12:53:30+00:00",
      "link": "https://arxiv.org/pdf/2512.24831v1",
      "tags": [
        "sr-bench"
      ]
    },
    {
      "id": "2512.24758v1",
      "title": "Intriguing Magnetocaloric Effect in 6H-perovskite Ba3RRu2O9 (R=Ho, Gd, Tb, Nd) with Strong 4d-4f Correlations",
      "abstract": "Here we demonstrate the magnetocaloric effect (MCE) of a 4d-4f correlated system, namely Ba3RRu2O9 (R= Ho, Gd, Tb, Nd). The compound Ba3HoRu2O9 antiferromagnetically orders at 50 K where both the Ho and Ru-moments order, followed by another phase transition ~ 10 K. Whereas, the compound Ba3GdRu2O9 and Ba3TbRu2O9 orders at 14.5 and 10.5 K respectively, where the ordering of both R and Ru moments are speculated. Our results reveal robust MCE around low-T magnetic phase transition for all the heavy rare-earth members (Ho, Gd, Tb) in this family. The heavy rare-earth members exhibit an intriguing MCE behavior switching from conventional to non-conventional MCE. Interestingly, the light R-member, Ba3NdRu2O9, orders ferromagnetically below 24 K where Nd-moments order, followed by Ru-ordering below 18 K, exhibits a positive MCE below and above FM-ordering. The compelling MCE are attributed to temperature dependent complex spin-reorientations for different R-members and anisotropy.",
      "authors": [
        "Mohit Kumar",
        "Sayan Ghosh",
        "Gourab Roy",
        "Ekta Kushwaha",
        "Vincent Caignaert",
        "Wilfrid Prellier",
        "Subham Majumdar",
        "Vincent Hardy",
        "Tathamay Basu"
      ],
      "primary_category": "cond-mat.str-el",
      "categories": [
        "cond-mat.str-el"
      ],
      "published": "2025-12-31 10:04:34+00:00",
      "link": "https://arxiv.org/pdf/2512.24758v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2512.24752v1",
      "title": "A Quantum Framework for Negative Magnetoresistance in Multi-Weyl Semimetals",
      "abstract": "We develop a fully quantum-mechanical theory of negative magnetoresistance in multi-Weyl semimetals in the ${\\bf E}\\parallel{\\bf B}$ configuration, where the chiral anomaly is activated. The magnetotransport response is governed by Landau quantization and the emergence of multiple chiral Landau levels associated with higher-order Weyl nodes. These anomaly-active modes have unidirectional dispersion fixed by the node's monopole charge and dominate charge transport. As the magnetic field increases, individual chiral branches successively cross the Fermi energy, producing discrete slope changes in the longitudinal conductivity and a step-like negative magnetoresistance. This quantized evolution provides a direct experimental signature of multi-Weyl topology. Bulk Landau levels contribute only at very low fields due to strong disorder scattering and do not affect the anomaly-driven regime. Our results establish a unified, fully quantum-mechanical framework in which negative magnetoresistance arises from the discrete Landau-quantized spectrum and microscopic impurity scattering, beyond semiclassical anomaly descriptions.",
      "authors": [
        "Arka Ghosh",
        "Sushmita Saha",
        "Alestin Mawrie"
      ],
      "primary_category": "cond-mat.mes-hall",
      "categories": [
        "cond-mat.mes-hall"
      ],
      "published": "2025-12-31 09:52:50+00:00",
      "link": "https://arxiv.org/pdf/2512.24752v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2512.24589v1",
      "title": "Hidden rotation symmetry of the Jordan-Wigner transformation and its application to measurement in quantum computation",
      "abstract": "Using a global rotation by theta about the z-axis in the spin sector of the Jordan-Wigner transformation rotates Pauli matrices X and Y in the x-y-plane, while it adds a global complex phase to fermionic quantum states that have a fixed number of particles. With the right choice of angles, this relates expectation values of Pauli strings containing products of X and Y to different products, which can be employed to reduce the number of measurements needed when simulating fermionic systems on a quantum computer. Here, we derive this symmetry and show how it can be applied to systems in Physics and Chemistry that involve Hamiltonians with only single-particle (hopping) and two-particle (interaction) terms. We also discuss the consequences of this for finding efficient measurement circuits in variational ground state preparation.",
      "authors": [
        "Grant Davis",
        "James K. Freericks"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "cond-mat.str-el"
      ],
      "published": "2025-12-31 03:27:15+00:00",
      "link": "https://arxiv.org/pdf/2512.24589v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2512.24533v1",
      "title": "Detection of a Rényi Index Dependent Transition in Entanglement Entropy Scaling",
      "abstract": "The scaling of entanglement with subsystem size encodes key information about phases and criticality, but the von Neumann entropy is costly to access in experiments and simulations, often requiring full state tomography. The second Rényi entropy is readily measured using two-copy protocols and is often used as a proxy for the von Neumann entanglement entropy, where it is assumed to track its asymptotic scaling. However, Sugino and Korepiny (Int. J. Mod. Phys. B 32, 1850306 (2018)) revealed that in the ground state of some spin models, the scaling of the von Neumann and second Rényi entropies varies from power law to logarithmic scaling as a function of the Rényi index. By constructing a number-conserving many-body state with only two local degrees of freedom, we obtain a Rényi-index-dependent change in the leading entanglement scaling: the second Rényi entropy remains logarithmic while the von Neumann entropy is parametrically larger. We then introduce a symmetry-aware lower bound on the von Neumann entropy built from charge-resolved second Rényi entropies and the subsystem charge distribution. Comparing this bound to the total second Rényi entropy provides a practical diagnostic for anomalous entanglement scaling from experimentally accessible data.",
      "authors": [
        "Hatem Barghathi",
        "Adrian Del Maestro"
      ],
      "primary_category": "cond-mat.str-el",
      "categories": [
        "cond-mat.str-el"
      ],
      "published": "2025-12-31 00:41:41+00:00",
      "link": "https://arxiv.org/pdf/2512.24533v1",
      "tags": [
        "sr-bench",
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.00512v1",
      "title": "Study the property of $W^{\\prime}$ at future $e^-p$ collider",
      "abstract": "As a strong candidate for new physics beyond the Standard Model, the exotic charged gauge boson $W^{\\prime}$ has attracted extensive research interest. In this work we investigate the interactions of the $W^{\\prime}$ boson at the electron-proton colliders. The process $e^- u \\to ν_e d$ and $e^- u \\to e^\\pm jjj$ with $t$-channel $W^{\\prime}$ exchange are studied. The polarization of the initial-state electrons has a significant impact on the cross section of the studied process, while the angular distribution of the final-state leptons serves as an important observable for the interactions of the $W^{\\prime}$ boson. In some specific regions of the parameter space, the detectable mass range for the $W^{\\prime}$ boson can reach around 10 TeV, and the coupling strength can achieve a precision of approximately 1\\% relative to the interaction strength of the Standard Model. Especially, $e^- u \\to e^+ jjj$ process is forbidden within the Standard Model, which would constitute important evidence in the search for the Left-Right Symmetric Model.",
      "authors": [
        "Xinyi Yan",
        "Honglei Li",
        "Zhi-Long Han",
        "Fei Huang",
        "Ruiyu Xing"
      ],
      "primary_category": "hep-ph",
      "categories": [
        "hep-ph"
      ],
      "published": "2026-01-01 23:43:47+00:00",
      "link": "https://arxiv.org/pdf/2601.00512v1",
      "tags": [
        "sr-bench",
        "大厂llm"
      ]
    },
    {
      "id": "2601.00436v1",
      "title": "Anatomy of RHN DM relic in the vanilla scotogenic neutrino mass model",
      "abstract": "The scotogeneic neutrino mass models are very popular choices to generate light neutrino masses via radiative mechanism. In these models, the particles running in the loop are distinguished from the standard model due to an imposed $\\mathcal{Z}_2$ symmetry under which the loop particles are odd. Therefore, the lightest particle running in the loop can be a viable dark matter candidate. In this paper, we revisit the minimal scotogenic neutrino mass model and study the anatomy of right handed neutrino (RHN) DM relic, taking into account contributions from self-annihilation, co-annihilation, conversion-driven processes, as well as production via the freeze-in mechanism. We impose the constraints from direct detection and collider searches of DM including anomalous magnetic moment of muon, charged lepton flavor violation and low-energy neutrino oscillation data to show that the lightest RHN can be a viable DM in the mass range: $M_{h}/2\\lesssim M_{\\rm DM}\\lesssim2000 {\\rm GeV}$ (thermal DM) and $0.1 ~{\\rm GeV}\\lesssim M_{\\rm DM}\\lesssim 1000 {\\rm GeV}$ (non-thermal DM), where $M_h$ denotes the Standard Model Higgs mass and $M_{\\rm DM}$ is the RHN dark matter mass. We also find the displaced vertex signatures of long lived particles which can be probed at future colliders.",
      "authors": [
        "Sujit Kumar Sahoo",
        "Narendra Sahu",
        "Vicky Singh Thounaojam"
      ],
      "primary_category": "hep-ph",
      "categories": [
        "hep-ph",
        "astro-ph.CO",
        "hep-ex"
      ],
      "published": "2026-01-01 18:59:17+00:00",
      "link": "https://arxiv.org/pdf/2601.00436v1",
      "tags": [
        "sr-bench"
      ]
    },
    {
      "id": "2601.00288v1",
      "title": "Seesaw-I and II Hybrid $T^{\\prime}$ Symmetric Neutrino Masses with Mass Selection Rule",
      "abstract": "The present manuscript studies a recently proposed new neutrino mixing scheme with a neutrino mass selection rule, $m_ν^{13} + m_ν^{22} + m_ν^{31} = 0$, among a neutrino mass matrix elements. The neutrino mass matrix texture is achieved by means of $T^{\\prime}$ flavor discrete symmetry extension of the Standard Model gauge group. The model realizing the neutrino mixing pattern consists of a combination of type-I and II seesaw mechanisms in the minimal possible extension of the Standard Model. Stringent predictions are obtained for normal and inverted neutrino mass orderings. Some important predictions include $α_2 \\approx 2π$ (best fit), $m_{\\text{lightest}} \\approx 3 - 4 \\times 10^{-4}\\,\\text{eV}$, and $m_{ee}^{0νββ} \\approx 3 \\times 10^{-3}\\,\\text{eV}$ for normal neutrino mass ordering; $110^\\circ < α_1 < 170^\\circ$, $40(220)^\\circ < α_2 < 60(240)^\\circ$, $240^\\circ < δ_{\\text{Dirac}} < 310^\\circ$, and $m_{\\text{lightest}} \\approx 2 \\times 10^{-5} - 7 \\times 10^{-3}\\,\\text{eV}$ for inverted neutrino mass ordering.",
      "authors": [
        "Takaaki Nomura",
        "Oleg Popov"
      ],
      "primary_category": "hep-ph",
      "categories": [
        "hep-ph",
        "hep-ex"
      ],
      "published": "2026-01-01 10:08:13+00:00",
      "link": "https://arxiv.org/pdf/2601.00288v1",
      "tags": [
        "sr-bench",
        "大厂llm",
        "大语言模型"
      ]
    },
    {
      "id": "2601.00082v1",
      "title": "Can the FCC-hh prove the B-L gauge symmetry?",
      "abstract": "We present a phenomenological study of the discovery potential at the FCC-hh for a new heavy neutral vector boson, Z', predicted by the $U(1)_{B-L}$ gauge symmetry. Focusing on the parameter space currently not excluded by Large Hadron Collider data, we analyze the dilepton production channel $p p \\rightarrow Z^{\\prime} \\rightarrow l^{+} l^{-}$ ($l^{\\pm} = e^{\\pm}, μ^{\\pm}$) at a center-of-mass energy of $\\sqrt{s} = 100$ TeV. Full Monte Carlo simulations was performed for different ($M_{Z'}$, $g_{B-L}$) BSM scenarios and relevant Standard Model backgrounds (including irreducible Drell-Yan, diboson, single top-quark and top-quark pair productions) identifying optimal kinematic and angular selection cuts to guide future searches for this type resonance. We estimate the FCC-hh reach for an integrated luminosity of $\\mathcal{L}_{int}$ = 3~$ab^{-1}$. Our results demonstrate that the FCC-hh can exclude Z' masses up to $\\sim 40$ TeV with 95\\% C.L. for couplings of $g_{B-L} \\sim 1$, and up to $\\sim 15$ TeV for $g_{B-L} \\sim 0.1$. We find the kinematic and angular cuts that optimize the signal over background ratio and achieve a $5σ$ signal up to Z' masses of $\\sim 30$ TeV. These findings highlight the FCC-hh potential to uncover new physics signals in the high-mass regime.",
      "authors": [
        "Farinaldo S. Queiroz",
        "J. Zamora-Saa",
        "Ricardo C. Silva",
        "Y. M. Oviedo-Torres"
      ],
      "primary_category": "hep-ph",
      "categories": [
        "hep-ph",
        "hep-ex"
      ],
      "published": "2025-12-31 19:25:26+00:00",
      "link": "https://arxiv.org/pdf/2601.00082v1",
      "tags": [
        "sr-bench",
        "大厂llm"
      ]
    },
    {
      "id": "2512.25038v1",
      "title": "Anomalous (3+1)d Fermionic Topological Quantum Field Theories via Symmetry Extension",
      "abstract": "Discrete finite-group global symmetries may suffer from nonperturbative 't-Hooft anomalies. Such global anomalies can be canceled by anomalous symmetry-preserving topological quantum field theories (TQFTs), which contain no local point operators but only extended excitations such as line and surface operators. In this work, we study mixed gauge-gravitational nonperturbative global anomalies of Weyl fermions (or Weyl semimetals in condensed matter) charged under discrete Abelian internal symmetries in four-dimensional spacetime, with spacetime-internal fermionic symmetry $G=$Spin$\\times_{\\mathbb{Z}_2^{\\rm F}}\\mathbb{Z}_{2m}^{\\rm F}$ or Spin$\\times\\mathbb{Z}_n$ that contains fermion parity $\\mathbb{Z}_{2}^{\\rm F}$. We determine the minimal finite gauge group $K$ of anomalous $G$-symmetric TQFTs that can match the fermionic anomaly via the symmetry-extension construction $1 \\to K \\to G_{\\rm Tot} \\to G \\to 1$, where the anomaly in $G$ is trivialized upon pullback to $G_{\\rm Tot}$, computed by Atiyah-Patodi-Singer eta invariant. This allows one to replace a $G$-symmetric four-dimensional Weyl fermion by an anomalous $G$-symmetric discrete-$K$-gauge TQFT as an alternative low-energy theory in the same deformation class. As an application, we show that the four-dimensional Standard Model with 15 Weyl fermions per family, in the absence of a sterile right-handed neutrino $ν_R$, exhibits mixed gauge-gravitational global anomalies between baryon and lepton number symmetries $({\\bf B \\pm L})$ and spacetime diffeomorphisms. We identify the corresponding minimal $K$-gauge fermionic TQFT that cancels these anomalies and can be interpreted as a gapped, topologically ordered dark sector replacing missing Weyl fermions via symmetry extension, without invoking conventional Anderson-Higgs symmetry breaking.",
      "authors": [
        "Zheyan Wan",
        "Juven Wang"
      ],
      "primary_category": "hep-th",
      "categories": [
        "hep-th",
        "hep-ph"
      ],
      "published": "2025-12-31 18:36:29+00:00",
      "link": "https://arxiv.org/pdf/2512.25038v1",
      "tags": [
        "sr-bench",
        "大厂llm",
        "大语言模型"
      ]
    },
    {
      "id": "2512.25035v1",
      "title": "Large Neutrino-Dark Matter Interactions: From Effective Field Theory to Ultraviolet Completions",
      "abstract": "We develop a general effective field theory (EFT) framework for neutrino-dark matter (DM) interactions, and apply it to systematically find all possible gauge-invariant ultraviolet (UV) completions at a given EFT operator dimension. Our goal here is to find simple UV-complete models that can realize potentially large neutrino-DM interactions, while being consistent with all existing theoretical and experimental constraints. We first construct the leading non-derivative operator basis for neutrino-DM scattering in a low-energy effective theory with neutrinos and DM (DM-LEFT), together with its gauge-invariant embedding in the Standard Model EFT (DM-SMEFT). We then construct all renormalizable tree-level UV completions that generate the relevant DM-SMEFT operators up to dimension-8 using a topology-based classification. Using this framework, we present minimal UV-complete models for different DM types that can yield effective neutrino-DM couplings up to several orders of magnitude larger than the Fermi coupling, while satisfying all constraints, most notably from neutrino mass and from the charged-lepton sector. This includes a pseudo-Dirac fermion DM realization in the scotogenic neutrino mass model and models of Majorana DM inspired by type-II and inverse seesaw-based neutrino mass models. Phenomenological implications for DM thermal relic abundance and direct detection prospects, as well as various cosmological and laboratory constraints on the model parameter space, are also analyzed.",
      "authors": [
        "K. S. Babu",
        "P. S. Bhupal Dev",
        "Anil Thapa"
      ],
      "primary_category": "hep-ph",
      "categories": [
        "hep-ph"
      ],
      "published": "2025-12-31 18:31:51+00:00",
      "link": "https://arxiv.org/pdf/2512.25035v1",
      "tags": [
        "大厂llm",
        "大语言模型"
      ]
    },
    {
      "id": "2512.25019v1",
      "title": "Loop-Level Lepton Flavor Violation and Diphoton Signals in the Minimal Left-Right Symmetric Model",
      "abstract": "The left-right symmetric model (LRSM) could not only restore parity of the weak interaction, but also provide natural explanations of the tiny active neutrino masses via the seesaw mechanisms. The $SU(2)_R$-breaking scalar $H_3$ can induce lepton flavor violating (LFV) effects in the minimal version of LRSM at the 1-loop order, originating from the mixing of heavy right-handed neutrinos. If $H_3$ is light, say below the GeV scale, it will lead to rich signals, e.g. the LFV muon and tauon decays $\\ell_β\\to \\ell_α+ X$ ($X$ being either visible or invisible final states) and the anomalous supernova signatures. Combined with the diphoton coupling of $H_3$, the right-handed scale $v_R$ is excluded up to $2\\times10^9$ GeV. In the future, the $v_R$ scale can be probed up to $5\\times10^9$ GeV in high-precision muon experiments, and further up to $6\\times10^{11}$ GeV by supernova observations.",
      "authors": [
        "Shufang Qiang",
        "Peiwen Wu",
        "Yongchao Zhang"
      ],
      "primary_category": "hep-ph",
      "categories": [
        "hep-ph",
        "astro-ph.CO",
        "astro-ph.HE",
        "astro-ph.SR",
        "hep-ex"
      ],
      "published": "2025-12-31 18:14:08+00:00",
      "link": "https://arxiv.org/pdf/2512.25019v1",
      "tags": [
        "sr-bench",
        "大厂llm"
      ]
    },
    {
      "id": "2512.24868v1",
      "title": "Correlating Resonant Di-Higgs and Tri-Higgs Production to $H\\to VV$ in the 2HDM",
      "abstract": "The observation of resonant di-Higgs production, which would strongly suggest the existence of a new heavy neutral scalar $H$, has been searched for extensively at the LHC. In the two-Higgs-doublet model (2HDM) with $m_H\\gg m_h$, where $h$ is the Higgs boson of mass 125 GeV observed at the LHC, we show that a direct correlation between Br$(H\\to hh)$ and Br$(H\\to VV)$, with $V=Z,W$, emerges that depends only on $m_H$ (and $m_V$). In particular, for heavy scalar masses between 500\\,GeV and 1\\,TeV, we find that Br($H\\to hh$)/ Br($H\\to ZZ)\\approx 9.5$. The origin of this prediction is most transparent in the Higgs basis, where the term in the scalar potential proportional to $\\mathcal H_1^\\dagger \\mathcal H_1 \\mathcal H_1^\\dagger \\mathcal H_2$ (and its hermitian conjugate) generates the leading contributions to the $Hhh$ and $Hhhh$ couplings in the decoupling limit of the 2HDM. Moreover, the latter coupling governs the resonant prompt tri-Higgs production via $H\\to hhh$, which is also directly correlated to $H\\to hh$ and $(H\\to VV)$, and can yield rates large enough to be measured at the High-Luminosity LHC.",
      "authors": [
        "Guglielmo Coloretti",
        "Andreas Crivellin",
        "Howard Haber"
      ],
      "primary_category": "hep-ph",
      "categories": [
        "hep-ph",
        "hep-ex"
      ],
      "published": "2025-12-31 13:56:23+00:00",
      "link": "https://arxiv.org/pdf/2512.24868v1",
      "tags": [
        "大厂llm"
      ]
    },
    {
      "id": "2512.24804v1",
      "title": "Minimal Modular Flavor Symmetry and Lepton Textures Near Fixed Points",
      "abstract": "An extension of the Standard Model with $Γ_2\\simeq S_3$ modular flavor symmetry is presented. We consider the construction of the lepton sector, augmented by two right-handed neutrino states, in the vicinity of the fixed points $τ= i\\infty $ and $τ= i$. Due to the residual symmetries at these points, and with the aid of non-holomorphic modular forms (which constitute representations of $S_3$) and by assigning specific transformation properties to the fermion fields, highly economical models (without flavon fields) are constructed with interesting Yukawa textures. All presented models strongly prefer the inverted ordering for the neutrino masses.",
      "authors": [
        "Zurab Tavartkiladze"
      ],
      "primary_category": "hep-ph",
      "categories": [
        "hep-ph"
      ],
      "published": "2025-12-31 11:47:36+00:00",
      "link": "https://arxiv.org/pdf/2512.24804v1",
      "tags": [
        "大厂llm",
        "大语言模型"
      ]
    },
    {
      "id": "2601.00096v1",
      "title": "Soft Algebras in AdS$_4$ from Light Ray Operators in CFT$_3$",
      "abstract": "Flat Minkowski space (M$^4$) and AdS$_4$ can both be conformally mapped to the Einstein cylinder. The maps may be judiciously chosen so that some null generators of the $\\mathcal{I}^+$ boundary of M$^4$ coincide with antipodally-terminating null geodesic segments on the boundary of AdS$_4$. Conformally invariant nonabelian gauge theories in M$^4$ have an asymptotic $S$-algebra generated by a tower of soft gluons given by weighted null line integrals on $\\mathcal{I}^+$. We show that, under the conformal map to AdS$_4$, the leading soft gluons are dual to light transforms of the conserved global symmetry currents in the boundary CFT$_3$. The tower of light ray operators obtained from the $SO(3,2)$ descendants of this light transform realize a full set of generators of the $S$-algebra in the boundary CFT$_3$. This provides a direct connection between holographic symmetry algebras in M$^4$ and AdS$_4$.",
      "authors": [
        "Ahmed Sheta",
        "Andrew Strominger",
        "Adam Tropper",
        "Hongji Wei"
      ],
      "primary_category": "hep-th",
      "categories": [
        "hep-th",
        "gr-qc"
      ],
      "published": "2025-12-31 20:04:24+00:00",
      "link": "https://arxiv.org/pdf/2601.00096v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2601.00071v1",
      "title": "Diagnosing Metal-Insulator and Hawking-Page Transitions: A Mixed-State Entanglement Perspective in Einstein-Born-Infeld-Massive Gravity",
      "abstract": "We study mixed-state entanglement measures in Einstein-Born-Infeld (EN-BI) massive gravity theory, a model exhibiting both Hawking-Page transitions and metal-insulator transitions (MIT) at finite temperatures. Our comprehensive investigation reveals that the entanglement wedge cross-section (EWCS), a novel mixed-state entanglement measure, demonstrates unique properties in detecting phase transitions. For MIT, we find the higher-order terms of EWCS align closely with the critical point, outperforming measures like holographic entanglement entropy (HEE) and mutual information (MI) in finite temperature systems. This enhanced sensitivity provides a more accurate tool for probing quantum phase transitions in strongly correlated systems. In Hawking-Page transitions, we observe that all entanglement measures effectively diagnose both first-order and second-order phase transitions, with EWCS showing configuration-independent behavior. Importantly, we discover that all geometry-related quantities, including entanglement measures, demonstrate a universal critical exponent of 1/3 near the second-order phase transition point, suggesting fundamental connections between quantum information theory and critical phenomena in gravitational systems. Our results highlight EWCS's potential as a powerful probe for phase transitions.",
      "authors": [
        "Zhe Yang",
        "Jian-Pin Wu",
        "Peng Liu"
      ],
      "primary_category": "hep-th",
      "categories": [
        "hep-th",
        "gr-qc"
      ],
      "published": "2025-12-31 19:00:45+00:00",
      "link": "https://arxiv.org/pdf/2601.00071v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2601.00069v1",
      "title": "Diagnosing Critical Behavior in AdS Einstein-Maxwell-Scalar Theory via Holographic Entanglement Measures",
      "abstract": "We investigate the holographic mixed-state entanglement measures in the Einstein-Maxwell-Scalar (EMS) theory. Several quantities are computed, including the holographic entanglement entropy (HEE), mutual information (MI), entanglement wedge cross-section (EWCS), and butterfly velocity ($v_B$). Our findings demonstrate that these measures can effectively diagnose phase transitions. Notably, EWCS and MI, as mixed-state entanglement measures, exhibit behavior opposite to that of the HEE. Additionally, we study the butterfly velocity, a dynamic quantum information measure, and observe that it behaves differently from the static quantum information measures. We propose that the butterfly velocity is initially dominated by entanglement and subsequently by thermal entropy as the coupling constant increases. Moreover, we examine the scaling behavior of the holographic entanglement measures and find that all the critical exponents are equal to $1$, which is twice that of the scalar field. We also explore the inequality between EWCS and MI, noting that the growth rate of MI consistently exceeds that of EWCS during phase transitions. These features are expected to be universal across thermodynamic phase transitions, with the inequalities becoming more significant as one moves away from the critical point.",
      "authors": [
        "Zhe Yang",
        "GuangZai Ye",
        "Jian-Pin Wu",
        "Peng Liu"
      ],
      "primary_category": "hep-th",
      "categories": [
        "hep-th",
        "gr-qc"
      ],
      "published": "2025-12-31 19:00:26+00:00",
      "link": "https://arxiv.org/pdf/2601.00069v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2601.00066v1",
      "title": "From Rotating Attractors to Extremal Black Holes with Axionic Hair",
      "abstract": "We study extremal, rotating black holes in four-dimensional Einstein-Maxwell-axion (EMA) theory through a combined near-horizon and bulk analysis. At the level of the near-horizon extremal geometry (NHEG), using the entropy function formalism, we prove that regular rotating attractors with axionic hair exist only for configurations that are purely electrically or purely magnetically charged; regular rotating dyonic attractors are excluded by the axion equation of motion, a result that we established perturbatively and non-perturbatively within the NHEG system. On the global side, we construct families of asymptotically flat, rotating extremal EMA black holes that interpolate to the electric NHEG branch, confirming that horizon data are fixed by extremization of the entropy function and decoupled from asymptotic moduli in line with the attractor mechanism.",
      "authors": [
        "Etevaldo dos Santos Costa Filho"
      ],
      "primary_category": "gr-qc",
      "categories": [
        "gr-qc",
        "hep-th"
      ],
      "published": "2025-12-31 19:00:03+00:00",
      "link": "https://arxiv.org/pdf/2601.00066v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2601.00058v1",
      "title": "$2+2=4$",
      "abstract": "Motivated by the observation that $2+2=4$, we consider four-dimensional $\\mathcal{N}=2$ superconformal field theories on $S^2\\timesΣ$, turning on a suitable rigid supergravity background. On the one hand, reduction of a four-dimensional theory ${T}$ on a Riemann surface $Σ$ leads to a family $\\mathscr{F}[{T}, Σ]$ of two-dimensional $(2,2)$ unitary SCFTs, a two-dimensional analog of the four-dimensional theories of class $\\mathscr{S}$. On the other hand, reduction on $S^2$ yields a non-unitary two-dimensional CFT $\\mathscr{C}[{T}]$ whose chiral algebra is the same as the one associated to ${T}$ by the standard SCFT/VOA correspondence. This construction upgrades the vertex operator algebra to a full-fledged two-dimensional CFT. What's more, it leads to a novel 2d/2d correspondence, a \"$2+2 = 4$\" analog of the \"$4+2=6$\" AGT correspondence: the $S^2$ partition function of $\\mathscr{F}[{T}; Σ]$ is computed by correlation functions of $\\mathscr{C}[{T}]$ on $Σ$. The elliptic genus of $\\mathscr{F}[{T}; Σ]$ is instead computed by a topological QFT $\\mathscr{E}[T]$ on $Σ$. A central question is whether one can give a purely two-dimensional presentation of the family $\\mathscr{F}[{T}; Σ]$ of $(2, 2)$ theories. We propose an algorithm to realize the $(2, 2)$ theories as gauged linear sigma models when ${T}$ is an Argyres-Douglas theory of type $(A_1, A_{2k})$ and $Σ$ an $n$-punctured sphere. We perform stringent checks of our conjecture for $k=1$ and $k=2$.",
      "authors": [
        "Leonardo Rastelli",
        "Brandon C. Rayhaun",
        "Matteo Sacchi",
        "Gabi Zafrir"
      ],
      "primary_category": "hep-th",
      "categories": [
        "hep-th"
      ],
      "published": "2025-12-31 19:00:01+00:00",
      "link": "https://arxiv.org/pdf/2601.00058v1",
      "tags": [
        "sr-bench",
        "大厂llm"
      ]
    },
    {
      "id": "2512.24770v1",
      "title": "Lessons from the Klein paradox",
      "abstract": "We re-examine the Klein paradox from a many-particle perspective in quantum field theory. Specifically, we compute the expectation value of the particle current induced by a sufficiently strong step-like electric potential in 1+1 dimensions. First, for a constant (eternal) potential, we calculate the current for different Fock space ground states corresponding to distinct mode bases. While one basis yields a zero current, another produces the standard nonzero value. We then consider a potential that is rapidly switched on, recovering the standard current in the asymptotic future. This result is generalized to potentials that interpolate between different constant values at spatial infinity. Finally, we analyze a potential acting for a finite duration and again reproduce the standard current. A physical interpretation of these results is provided.",
      "authors": [
        "E. T. Akhmedov",
        "D. V. Diakonov",
        "V. I. Lapushkin",
        "D. I. Sadekov"
      ],
      "primary_category": "hep-th",
      "categories": [
        "hep-th"
      ],
      "published": "2025-12-31 10:35:19+00:00",
      "link": "https://arxiv.org/pdf/2512.24770v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2512.24743v1",
      "title": "S-Duality for Non-Abelian Monopoles",
      "abstract": "In $\\mathcal{N}=4$ super-Yang-Mills theory with gauge group $G$ spontaneously broken to a subgroup $H$, S-duality requires that the BPS monopole spectrum organizes into the same representation as W-bosons in the dual theory, where $G^{\\vee}$ is broken to $H^{\\vee}$. The expectation has been extensively verified in the maximally broken phase $G\\to U(1)^r$. Here we address the non-Abelian regime in which $H$ contains a semisimple factor $H^{s}$. Using the stratified description of monopole moduli space, we give a general proof of this matching for any simple gauge group $G$. Each BPS monopole state is naturally labeled by a weight of the relevant $W$-boson representation of $(H^{\\vee})^{s}$. We construct non-Abelian magnetic gauge transformation operators implementing the $(H^{\\vee})^{s}$-action on the monopole Hilbert space, which commute with the electric $H^{s}$-transformations and thereby realize the $H^{s}\\times (H^{\\vee})^{s}$ symmetry at the level of monopole quantum mechanics.",
      "authors": [
        "Shan Hu"
      ],
      "primary_category": "hep-th",
      "categories": [
        "hep-th"
      ],
      "published": "2025-12-31 09:28:53+00:00",
      "link": "https://arxiv.org/pdf/2512.24743v1",
      "tags": [
        "sr-bench",
        "大厂llm",
        "大语言模型"
      ]
    },
    {
      "id": "2512.24549v1",
      "title": "Kerr worldline-QFT action from Compton amplitude to infinite spin orders",
      "abstract": "We develop a quadratic-in-Riemann worldline action for a Kerr black hole at infinite spin orders by matching to a proposed tree-level Kerr Compton amplitude, originally obtained from higher-spin QFT considerations. A worldline action is an effective theory, and as such the tree-level matching needs to be corrected by loop effects, including UV counter terms, renormalization, and higher-order matching to general relativity. However, we anticipate that many features of the Wilson coefficients of the proposed tree-level action will remain unchanged even after a loop-level matching. While the worldline action is given in closed form, it contains an infinite number of quadratic-in-Riemann operators $R^2$, even for the same-helicity sector. We argue that in the same-helicity sector the $R^2$ operators have no intrinsic meaning, as they merely remove unwanted terms produced by the linear-in-Riemann operators, which are well-established in the literature. The opposite-helicity sector is somewhat more complicated, it contains both $R^2$ operators that removes unwanted terms, and $R^2$ operators that add new needed terms to the Compton amplitude. We discuss and classify all independent $R^2$ operators that can feature in the worldline action.",
      "authors": [
        "Maor Ben-Shahar",
        "Lucile Cangemi",
        "Henrik Johansson"
      ],
      "primary_category": "hep-th",
      "categories": [
        "hep-th",
        "gr-qc"
      ],
      "published": "2025-12-31 01:14:20+00:00",
      "link": "https://arxiv.org/pdf/2512.24549v1",
      "tags": [
        "sr-bench"
      ]
    },
    {
      "id": "2601.00774v1",
      "title": "A 3+1 Perturbative Approach to the Cosmic Dynamo Equation",
      "abstract": "In this work, we analyze the evolution of PMFs within a perturbed Friedmann-Lemaître-Robertson-Walker (FLRW) spacetime using the formalisms of Numerical Relativity (NR). We apply the 3+1 decomposition to first-order cosmological perturbations to derive the cosmological dynamo equation under the kinematic-dynamo approximation. Our objective is to study the interaction between the seed magnetic field and the growing modes of scalar perturbations, whose associated velocity fields are evolved numerically using the software \\texttt{Einstein Toolkit} and \\texttt{FLRWSolver}. We find that these velocity fields effectively drive the amplification of the PMF, demonstrating that the extent of this growth is dependent on the electrical conductivity of the cosmic medium. Our findings provide a computational description linking primordial magnetogenesis to the evolution of magnetic seeds, ultimately explaining the ubiquity of large-scale magnetic fields in the universe",
      "authors": [
        "Juan F. Bravo",
        "Leonardo Castañeda",
        "Héctor J. Hortúa"
      ],
      "primary_category": "gr-qc",
      "categories": [
        "gr-qc"
      ],
      "published": "2026-01-02 18:09:53+00:00",
      "link": "https://arxiv.org/pdf/2601.00774v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2601.00582v1",
      "title": "Interacting Ghost Dark Energy with Sign-Changeable Coupling in Brans-Dicke Cosmology",
      "abstract": "In this study, we analyze the ghost dark energy model in Brans-Dicke cosmology in the framework of a flat Friedmann-Lemaitre-Robertson-Walker universe. We consider an interaction between ghost dark energy and dark matter with a sign-changeable interaction term. To discuss the cosmological implications of the model, we consider a well-motivated logarithmic form of the Brans-Dicke scalar field. By deriving the cosmological evolution equations, we obtain the cosmological parameters such as the equation of state and deceleration parameters. We analyze the behavior of the cosmological parameters by plotting their graphs against the redshift parameter ($z$). We observe that the equation of state parameter shows quintessence-like behaviour during present and future epochs; however, phantom-like behavior is also possible for suitable values of the model parameters. Analysis of the deceleration parameter shows a smooth recent phase transition of the universe (deceleration to acceleration). An interesting result we observe is the decelerated expansion of the universe in the far future, i.e, the universe experiences another phase transition in the future. The physical significance of the well-known cosmological plane ($w_D-w_D'$ plane) is discussed in our model. We observe that the trajectories start in the freezing region with the same initial behavior, deviate from each other during the evolution and ends in the thawing region. Finally, we perform a detailed thermodynamic analysis and demonstrate that the generalized second law of thermodynamics is satisfied within the present interacting ghost dark energy model.",
      "authors": [
        "Kirti Mehta",
        "Pankaj Kumar",
        "N. Myrzakulov",
        "S. H. Shekh"
      ],
      "primary_category": "gr-qc",
      "categories": [
        "gr-qc"
      ],
      "published": "2026-01-02 05:48:27+00:00",
      "link": "https://arxiv.org/pdf/2601.00582v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2512.24753v1",
      "title": "Probing a NED inspired Magnetically Charged Black Hole in the Hernquist Dark Matter Halo",
      "abstract": "With an intent to examine the combined effect of non-linear electrodynamics (NED) and dark matter (DM), we obtain a static and spherically symmetric solution with the black hole (BH) magnetically charged and immersed in the Hernquist DM halo (MHDM). The position of the event horizon $r_h$ and the critical impact parameter $b_m$ are then probed to gauge the extent of influence magnetic charge $g$ and halo parameters $α$, $β$ have on them. A recurring outcome of our analysis with respect to different BH observables is the nullification of competing effects of charge and halo parameters, leading to observables obtaining values equal to those for a Schwarzschild BH. This is also observed for $r_h$ and $b_m$. We delve into unraveling the impact of NED and DM combined on the strong gravitational lensing (GL) and its related observables, such as the angular separation, relative magnification, and the angular position of the inner, closely packed bright ring. Interestingly, we find combinations of charge and halo parameters that leave the deflection angle unchanged from the Schwarzschild case, thereby leading to a situation where an MHDM BH and a Schwarzschild BH become indistinguishable. Similar results are also observed for lensing observables. Finally, utilizing observations related to the angular diameter of super-massive BHs (SMBHs) $M87^*$ and $SgrA^*$ and employing the $χ^2$ test, we extract bounds on $g$, $α$, and $β$ signifying the viability of our BH model as an SMBH.",
      "authors": [
        "Sohan Kumar Jha"
      ],
      "primary_category": "gr-qc",
      "categories": [
        "gr-qc"
      ],
      "published": "2025-12-31 09:55:18+00:00",
      "link": "https://arxiv.org/pdf/2512.24753v1",
      "tags": [
        "sr-bench"
      ]
    },
    {
      "id": "2601.00692v1",
      "title": "Hadronic Origin of Sub-PeV Gamma-Ray Emission from LHAASO J0621+3755",
      "abstract": "Very High Energy (VHE) gamma rays are primarily estimated to arise from high-energy electromagnetic interactions in pulsars and their halo through electron inverse Compton (IC) scattering. Hadronic channels like neutral pion decay have also been proposed to produce TeV-PeV gamma rays from the Pulsar halo. The neutral pions are expected to be generated from cosmic ray (CR) protons interacting with the ambient/cloud. The recent observations of sub-PeV gamma rays from the halo of pulsar PSR J0622+3749 by the Large High Altitude Air Shower Observatory Kilometre-Square Array (LHAASO-KM2A) detector provide a platform to explore different channels of their production. Previous studies support consistency with the leptonic modeling of the halo, which attributes its origin to slow diffusion in the interstellar medium. In this work, we investigated the possibility of proton-proton channel as the origin of these photons. To explain the observed gamma rays with energy $\\sim 4$ TeV by the High-Altitude Water Cherenkov (HAWC) telescope till 200 TeV by the LHAASO observatory, one requires the CR proton luminosity to be $η_p\\sim 0.1$ of the pulsar PSR J0622+3749 spin-down luminosity. In this case, we have considered the protons propagating in a one-zone superdiffusion environment, specifically $α= 1$ in a cloud of gas density 1 per cm$^{3}$.",
      "authors": [
        "Sonali Sahoo",
        "Ankan Roy",
        "Kritika Yadav",
        "Reetanjali Moharana"
      ],
      "primary_category": "astro-ph.HE",
      "categories": [
        "astro-ph.HE"
      ],
      "published": "2026-01-02 14:08:44+00:00",
      "link": "https://arxiv.org/pdf/2601.00692v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2601.00666v1",
      "title": "Spectral Shapes of Pair Annihilation Line Emission in Magnetar Giant Flares",
      "abstract": "We investigate the gamma-ray spectrum in the MeV range arising from electron-positron pair annihilation in fireballs associated with magnetar giant flares (MGFs), motivated by the recent observation of a MeV gamma-ray line feature in a bright gamma-ray burst, GRB~221009A. We develop an analytic model of line emission, demonstrating that relativistic beaming results in a broadened, power-law spectral feature with photon index -1. We then perform Monte Carlo radiative transfer simulations incorporating electron-positron pair production, annihilation, and Compton scattering. The dependence of the emergent spectrum on the baryon loading is also examined, showing that a baryon-poor fireball is more favorable for the detection of MeV gamma rays. We further assess the detectability of the line component. The simulation results indicate that a power-law MeV component from the initial spike of a Galactic MGFs could be observed with current instruments, such as Fermi/GBM, and will be well within the reach of upcoming MeV gamma-ray satellites, which are expected to detect O(100) photons from such events.",
      "authors": [
        "Tomoki Wada",
        "Shigeo S. Kimura"
      ],
      "primary_category": "astro-ph.HE",
      "categories": [
        "astro-ph.HE"
      ],
      "published": "2026-01-02 12:12:09+00:00",
      "link": "https://arxiv.org/pdf/2601.00666v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2601.00595v1",
      "title": "Asteroseismology study of a new faint ZZ Ceti J053009.62+594557.0 discovered in WFST",
      "abstract": "In this work, we present a detailed asteroseismological analysis of WFST J053009.62+594557.0, a newly discovered faint pulsating white dwarf by the Wide Field Survey Telescope (WFST) with a Gaia G magnitude of 19.13. Analysis of two nights of high-precision WFST g band photometry reveals three significant pulsation frequencies with high signal-to-noise ratios. Follow-up P200/DBSP spectroscopy classifies the object as a DA white dwarf with Teff=11,609 $\\pm$ 605 K and M = 0.63$\\pm$ 0.22 $M_{\\odot}$. To probe its internal structure, we construct asteroseismological models with the White Dwarf Evolution Code (WDEC). After exploring sufficient matching models, best-fitting solutions yield Teff=11,850$\\pm$ 10 K and M = 0.600 $\\pm$ 0.005 $M_{\\odot}$, consistent with independent constraints from Gaia color-magnitude diagram, Gaia XP spectrum, P200 spectral fitting, SED fitting, and Gaia parallax. It has shown that the asteroseismological distance agrees with the Gaia parallax to 1.45\\%.",
      "authors": [
        "Yang Yonghui",
        "Guo Jincheng",
        "Lin Jie",
        "Wang Tinggui",
        "Jiang Ning",
        "Wang Yibo",
        "Fan Lulu",
        "Fang Min",
        "Li Bin",
        "Li Feng",
        "Liu Hao",
        "Liang Ming",
        "Luo Wentao",
        "Tang Jinlong",
        "Wang Hairen",
        "Wang Jian",
        "Xue Yongquan",
        "Yao Dazhi",
        "Zhang Hongfei"
      ],
      "primary_category": "astro-ph.SR",
      "categories": [
        "astro-ph.SR"
      ],
      "published": "2026-01-02 07:07:45+00:00",
      "link": "https://arxiv.org/pdf/2601.00595v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2601.00594v1",
      "title": "The impact of cosmic voids on AGN activity",
      "abstract": "From the Eagle project, we study the properties of galaxies hosting AGN in cosmic voids and their surrounding structures, filaments and walls, at $z=0$, comparing them to non-AGN galaxies in similar environments. We found that the AGN fraction decreases as a function of void-centric distance, with void galaxies displaying the highest AGN fraction (12\\%), and galaxies in denser environments, showing the lowest AGN fraction (6.7\\%), consistent with observations. The AGN fraction is particularly high in most massive void galaxies when controlling for stellar mass.   When comparing AGN host galaxies to inactive ones, we find that AGN galaxies tend to have slightly more massive SMBHs, higher specific star formation rates, and reside in higher-mass haloes at a given stellar mass than non-AGN galaxies. At $\\rm M_{*} > \\rm 10^{10.2} \\rm M_{\\odot}$, AGN hosts in voids tend to have slightly more massive SMBHs than those in denser environments. Otherwise, the AGN population does not show a clear trend in relation to the global environment. In contrast, non-AGN void galaxies host more massive SMBHs, slightly higher sSFRs, and are located in more massive haloes than those in denser environments. Analysing the recent merger histories of both AGN and non-AGN populations, we find that a larger fraction of massive AGN galaxies have undergone major mergers compared to non-AGN galaxies, regardless of environment. Notably, AGN galaxies in voids show a higher frequency of recent mergers, especially major mergers, than their counterparts in other environments, especially at high stellar mass.   Our results suggest that the evolution of SMBHs in voids is closely related to that of their host galaxies and their surrounding environment, while the most recent AGN activity is more strongly linked to recent interactions.",
      "authors": [
        "Benedict Rouse",
        "Patricia B. Tissera",
        "Yetli Rosas-Guevara",
        "Claudia del P. Lagos"
      ],
      "primary_category": "astro-ph.GA",
      "categories": [
        "astro-ph.GA"
      ],
      "published": "2026-01-02 07:00:13+00:00",
      "link": "https://arxiv.org/pdf/2601.00594v1",
      "tags": [
        "sr-bench"
      ]
    },
    {
      "id": "2601.00500v1",
      "title": "Discovering pulsars in compact binaries with a hidden Markov model",
      "abstract": "Discovering radio pulsars in compact binaries, whose orbital periods $P_{\\rm b}$ satisfy $P_{\\rm b} \\lesssim 1 \\, \\rm{day}$, is computationally challenging, because the time-dependent pulse frequency $f_{\\rm p}(t)$ is strongly Doppler modulated by the binary motion. Here we present a new, fast, semi-coherent detection scheme based on a hidden Markov model (HMM) combined with a maximum likelihood matched filter, the Schuster periodogram. The HMM scheme complements traditional acceleration searches by dividing $f_{\\rm p}(t)$ into piecewise-constant blocks and tracking the block-to-block evolution efficiently using dynamic programming. Monte Carlo simulations show that the new method can detect compact binaries with flux densities $S \\geq 0.50 \\, \\rm{mJy}$ and orbital periods $P_{\\rm b} \\geq 0.012 \\, \\rm{day}$ under observing conditions (e.g.\\ cadence) typical of radio pulsar surveys, with and without impulsive, narrowband radio frequency interference. The new method is fast; it employs the classic Viterbi algorithm to solve the HMM recursively. The central processing unit run time scales nominally as $T_{\\rm run} \\approx 2.8 \\, N_B (N_T/10^2) (N_Q \\ln N_Q/10^4 \\ln 10^4) \\, {\\rm s}$ for $N_B$ subbands, $N_T$ coherent segments, and $N_Q$ frequency bins.",
      "authors": [
        "Joseph O'Leary",
        "Liam Dunn",
        "Andrew Melatos"
      ],
      "primary_category": "astro-ph.HE",
      "categories": [
        "astro-ph.HE"
      ],
      "published": "2026-01-01 22:44:10+00:00",
      "link": "https://arxiv.org/pdf/2601.00500v1",
      "tags": [
        "sr-bench"
      ]
    },
    {
      "id": "2601.00439v1",
      "title": "A global view of post-interaction white dwarf-main sequence binaries",
      "abstract": "Common-envelope evolution (CEE) is among the most uncertain phases in binary evolution. To empirically constrain CEE, we construct a uniformly selected sample of eclipsing post--common-envelope binaries (PCEBs). Starting from an unresolved white dwarf-main-sequence (WDMS) candidate sample within 200 pc selected from the Gaia color-magnitude diagram, we identify 39 detached eclipsing WDMS binaries using ZTF light curves. The binaries contain cool M dwarfs orbiting warm white dwarfs with orbital periods ($P_{\\rm orb}$) of 0.1-2 d. The sample's simple selection function allows us to model observational incompleteness and infer intrinsic properties of the PCEB population. We find an orbital-period distribution consistent with being log-uniform over 0.1-2 d, contrary to recent reports of a bimodal distribution. The companion-mass distribution peaks around $0.25~{\\rm M_\\odot}$ and declines steeply toward larger masses. The estimated local space density is $7.2\\times10^{-5}~{\\rm pc^{-3}}$, corresponding to a Galaxy-wide birth rate of 0.01 per year. Combining our results with recent Gaia-based constraints on wider WDMS binaries, we construct an empirical period distribution of post-interaction WDMS binaries spanning 0.1-1000 d. The emerging period distribution is roughly log-flat (d$N/{\\rm d}\\log P_{\\rm orb}\\propto P_{\\rm orb}^0$) at $P_{\\rm orb} < 2$ d and log-increasing (d$N/{\\rm d}\\log P_{\\rm orb}\\propto P_{\\rm orb}^1$) at $P_{\\rm orb} = 100-1000$ d. The 10-100 d regime remains poorly constrained, but a few nearby systems suggest it is also well-populated. Short-period PCEBs ($P_{\\rm orb}<2$ d) with M dwarf companions are roughly 2-3 times more common than wide ($P_{\\rm orb} = 100-1000$ d) WDMS binaries with FGK companions, which likely formed through stable mass transfer. These results provide direct observational constraints on CEE and an empirical benchmark for binary-population models.",
      "authors": [
        "Cheyanne Shariat",
        "Kareem El-Badry"
      ],
      "primary_category": "astro-ph.SR",
      "categories": [
        "astro-ph.SR"
      ],
      "published": "2026-01-01 19:00:01+00:00",
      "link": "https://arxiv.org/pdf/2601.00439v1",
      "tags": [
        "大厂llm"
      ]
    },
    {
      "id": "2601.00415v1",
      "title": "The Double-Peaked Calcium-Strong SN 2025coe: Progenitor Constraints from Early Interaction and Ejecta Asymmetries",
      "abstract": "Supernova (SN) 2025coe at a distance of $\\sim$25 Mpc is the third-closest calcium-strong (CaST) transient. It was discovered at a large projected offset of $\\sim$34 kpc from its potential host galaxy NGC 3277. Multiband photometry of SN 2025coe indicates the presence of two peaks at day $\\sim$2 and day $\\sim$11 after explosion. Modeling the bolometric light curve, we find that the first peak can be reproduced either by shock cooling of a compact envelope ($R_\\mathrm{env}$ $\\approx $6-40 $R_{\\odot}$; $M_\\mathrm{env}$ $\\approx $0.1-0.2 $M_{\\odot}$) or by interaction with close-in circumstellar material (CSM; $R_{\\mathrm{CSM}} \\lesssim 8 \\times10^{14}$ cm), or a combination of both. The second peak is dominated by radioactive decay of $^{56}$Ni ($M_{\\mathrm{ej}} \\approx $0.4-0.5 $M_{\\odot}$; $M_{^{56}\\mathrm{Ni}} \\approx 1.4 \\times 10^{-2}$ $M_{\\odot}$). SN 2025coe rapidly evolves from the photospheric phase dominated by He I P-Cygni profiles to nebular phase spectra dominated by strong [Ca II] $λλ$7291, 7323 and weak [O I] $λλ$6300, 6364 emission lines. Simultaneous line profile modeling of [Ca II] and [O I] at nebular phases shows that an asymmetric core-collapse explosion of a low-mass ($\\lesssim$3.3 $M_{\\odot}$) He-core progenitor can explain the observed line profiles. Alternatively, lack of local star formation at the site of the SN explosion combined with a low ejecta mass is also consistent with a thermonuclear explosion due to a low-mass hybrid He-C/O white dwarf + C/O white dwarf merger.",
      "authors": [
        "Aravind P. Ravi",
        "Sahana Kumar",
        "Raphael Baer-Way",
        "Stefano Valenti",
        "Maryam Modjaz",
        "Bart F. A. van Baal",
        "Anders Jerkstrand",
        "Yize Dong",
        "Lindsey A. Kwok",
        "Jeniveve Pearson",
        "David J. Sand",
        "Daichi Hiramatsu",
        "Alexei V. Filippenko",
        "Jennifer Andrews",
        "Moira Andrews",
        "Prasiddha Arunachalam",
        "K. Azalee Bostroem",
        "Thomas G. Brink",
        "Collin Christy",
        "Liyang Chen",
        "Kyle W. Davis",
        "Ali Esamdin",
        "Joseph Farah",
        "Ryan J. Foley",
        "Emily Hoang",
        "Griffin Hosseinzadeh",
        "D. Andrew Howell",
        "Brian Hsu",
        "Ruifeng Huang",
        "Abdusamatjan Iskander",
        "Daryl Janzen",
        "Saurabh W. Jha",
        "Ravjit Kaur",
        "Michael J. Lundquist",
        "Curtis McCully",
        "Darshana Mehta",
        "Yuan Qi Ni",
        "Nicolas Meza Retamal",
        "Kishore C. Patra",
        "Conor Ransome",
        "Manisha Shrestha",
        "Nathan Smith",
        "Bhagya Subrayan",
        "Kirsty Taggart",
        "Xiaofeng Wang",
        "Kathryn Wynn",
        "Yi Yang",
        "Shengyu Yan",
        "Weikang Zheng",
        "Dan Coe"
      ],
      "primary_category": "astro-ph.HE",
      "categories": [
        "astro-ph.HE"
      ],
      "published": "2026-01-01 18:09:25+00:00",
      "link": "https://arxiv.org/pdf/2601.00415v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2601.00373v1",
      "title": "Open Questions in Massive Star Research across Cosmic Scales",
      "abstract": "Massive stars are the engines of the Cosmos, shaping their environments and driving galaxy evolution across cosmic time. Yet, this general textbook picture faces many challenges when trying to turn abstract insights into quantitative predictions. Recent discoveries, such the surprisingly high metallicity and early nitrogen enrichment in high-redshift galaxies discovered by JWST, are challenging current descriptions of massive star evolution and add new pieces to a puzzle that is yet everything but complete.   The oncoming era of large surveys and advances in computational modeling create the potential to reach breakthroughs in our understanding. Yet, to resolve current problems and conflicting conclusions, we will also need to reconsider what we think we know. Are the objects we observe what we think they are? Are the models we use describing what is actually going on? And what can we learn from previous misconceptions? This short review highlights major open questions from individual stars and stellar systems back to the first galaxies while also discussing two examples - the weak-wind problem as well as the different flavours and impact of Wolf-Rayet stars - where recent discoveries might point in a new direction.",
      "authors": [
        "Andreas A. C. Sander"
      ],
      "primary_category": "astro-ph.SR",
      "categories": [
        "astro-ph.SR",
        "astro-ph.GA",
        "astro-ph.HE"
      ],
      "published": "2026-01-01 15:25:47+00:00",
      "link": "https://arxiv.org/pdf/2601.00373v1",
      "tags": [
        "大厂llm"
      ]
    },
    {
      "id": "2601.00059v1",
      "title": "Sub-Neptune Memories I: Implications of Inefficient Mantle Cooling and Silicate Rain",
      "abstract": "We explore the evolution of sub-Neptune (radii between $\\sim$1.5 and 4 R$_\\oplus$) exoplanet interior structures using our upgraded planetary evolution code, \\texttt{APPLE}, which self-consistently couples the thermal and compositional evolution of the whole structure. We incorporate stably stratified regions with convective mixing and, for the first time, ab initio results on the phase separation of silicate-hydrogen mixtures to model silicate rain in sub-Neptune envelopes. We demonstrate that inefficient mantle cooling can retain sufficient heat to Gyr ages: inefficient heat transport from mantle to envelope alone keeps radii $\\sim$10\\% larger than predicted by adiabatic models at late times. Silicate rain can contribute an additional $\\sim$5\\% to the radius, depending on envelope mass and initial metal abundance. The silicate-hydrogen immiscibility region may lie in the middle or even upper envelope, far above the envelope-mantle boundary layer, and bifurcates the envelope into two an upper, hydrogen-rich region and a lower, metal-rich region above the mantle. If silicate rain occurs, atmospheres should appear depleted of silicates while radii remain inflated at late ages. To demonstrate this, we present interior evolution models for GJ 1214 b, K2-18 b, TOI-270 d, and TOI-1801 b, showing that hot, liquid silicate mantles with thin envelopes reproduce their radii and mean densities, providing an alternative to water-world interpretations. These results imply that bulk compositions inferred from mean density must account for mantle thermal state and envelope mixing/phase separation history; such thermal ``memories'' may constrain formation entropies and temperatures when metallicities are better measured.",
      "authors": [
        "Roberto Tejada Arevalo",
        "Akash Gupta",
        "Adam Burrows",
        "Donghao Zheng",
        "Yao Tang",
        "Jie Deng"
      ],
      "primary_category": "astro-ph.EP",
      "categories": [
        "astro-ph.EP"
      ],
      "published": "2025-12-31 19:00:01+00:00",
      "link": "https://arxiv.org/pdf/2601.00059v1",
      "tags": [
        "大厂llm"
      ]
    },
    {
      "id": "2601.00055v1",
      "title": "Evolved Supergiants in PHANGS I: Red Supergiants in 19 Galaxies between 5-20 Mpc with HST and JWST",
      "abstract": "Red supergiants (RSGs) are important for our understanding of supernova progenitors, stellar populations, stellar evolution, mass loss and dust production. Extragalactic surveys of RSGs have a long history in the Local Group, but few studies exist beyond that due to the limited resolution and sensitivity of ground-based and previous space-based infrared observatories. Here we demonstrate the combined power of HST and JWST to push systematic searches of RSGs out to $\\sim$20 Mpc. We introduce a catalog of 97057 RSGs -- the largest single-survey release of RSGs -- with masses $\\gtrsim$10 M$_{\\odot}$ in 19 galaxies from the PHANGS HST+JWST Treasury program. We use HST F814W and JWST F200W photometry to select stars as RSGs based on predicted colors and magnitudes from PARSEC isochrones. The spatial distribution of our recovered RSGs follow the familiar pattern of mostly being concentrated in active star-forming regions such as spiral arms and central starburst rings. The RSG number density on kpc-scales is strongly correlated ($r_s$$\\sim$0.82) with local star-formation rate density ($Σ_{SFR}$) traced by extinction-corrected far-ultraviolet (FUV) from GALEX+WISE, and weakly correlated ($r_s$$\\sim$0.57) with the total stellar mass density ($Σ_*$), traced by near-infrared emission from WISE+Spitzer. The number of RSGs per mass of stellar populations with ages 6-30 Myr (the likely age range of RSGs $>$10 M$_{\\odot}$) is $\\sim$1 per 10$^{3.77\\pm0.27}$ M$_{\\odot}$, assuming constant star-formation rates from FUV+W4. Our sample will be a useful resource for tracking progenitors and feedback sites of future supernovae in PHANGS, age-dating stellar populations, and more.",
      "authors": [
        "Sumit K. Sarbadhicary",
        "David Thilker",
        "Adam K. Leroy",
        "Janice C. Lee",
        "Amirnezam Amiri",
        "Gagandeep S. Anand",
        "Ashley. T. Barnes",
        "Médéric Boquien",
        "Daniel A. Dale",
        "Simthembile Dlamini",
        "Simon C. O. Glover",
        "Ralf S. Klessen",
        "Kirsten L. Larson",
        "Daniel Maschmann",
        "Hsi-An Pan",
        "Jiayi Sun",
        "Leonardo Úbeda",
        "Thomas G. Williams",
        "Aida Wofford",
        "PHANGS Collaboration"
      ],
      "primary_category": "astro-ph.GA",
      "categories": [
        "astro-ph.GA"
      ],
      "published": "2025-12-31 19:00:00+00:00",
      "link": "https://arxiv.org/pdf/2601.00055v1",
      "tags": [
        "大厂llm"
      ]
    },
    {
      "id": "2512.25064v2",
      "title": "Feeling Blue: Constructing a Robust SALT3 UV Template and Constraining its Redshift Dependency",
      "abstract": "Upcoming cosmological surveys will obtain numerous rest-frame ultraviolet (UV) observations of Type Ia supernovae (SNe Ia), yet there is concern about how standardizable SNe Ia are in the UV. In this work, we train a robust optical--UV SED model for SNe Ia (SALT3-UV) with the open-source model-training software $\\texttt{SALTshaker}$. We incorporate a spectroscopic UV data sample from HST, including 67 UV spectra from 18 nearby SNe Ia. Unlike previous training spectra, the HST spectra have sufficiently precise calibration that they do not require additional warping to match coincident photometric data. Additionally, while including this new SN Ia sample necessitates incorporating auxiliary photometric data from ZTF and ATLAS that have insufficient calibration for cosmological analyses, the improvements in the calibration of these data is anticipated in the near future. Compared to the previous SALT3-K21 model, the SALT3-UV model shows a significant improvement in the UV down to $2000\\mathring{\\text{A}}$, with over a threefold improvement in model uncertainty and a more physically accurate continuum and line features. We further evaluate potential redshift evolution in the UV template by separating the UV training sample into low- and high-$z$ subsamples. Our results reveal a non-negligible $\\gtrsim 0.05$ mag difference between low- and high-$z$ SALT3-UV models in the $g-$band at $z\\gtrsim0.5$ and the $u-$band at $z\\gtrsim0.2$. We demonstrate that, if confirmed, such evolution could lead to a few-percent bias in the measurement of $w$ if high-$z$ rest-frame UV data are included in future cosmological surveys such as LSST and $\\textit{Roman}$.",
      "authors": [
        "Qinan Wang",
        "David O. Jones",
        "Justin D. R. Pierel",
        "Matthew R. Siebert",
        "W. D'Arcy Kenworthy",
        "Richard Kessler",
        "Mi Dai",
        "Ryan J. Foley",
        "Ori D. Fox",
        "Suvi Gezari",
        "Sebastian Gomez",
        "Peter McGill",
        "Armin Rest",
        "César Rojas-Bravo",
        "Melissa Shahbandeh",
        "Lou Strolger"
      ],
      "primary_category": "astro-ph.CO",
      "categories": [
        "astro-ph.CO",
        "astro-ph.HE"
      ],
      "published": "2025-12-31 18:58:12+00:00",
      "link": "https://arxiv.org/pdf/2512.25064v2",
      "tags": [
        "大厂llm"
      ]
    },
    {
      "id": "2512.24966v1",
      "title": "Cosmic Himalayas in CROCODILE : Probing the Extreme Quasar Overdensities by Count-in-Cells analysis and Nearest Neighbor Distribution",
      "abstract": "The recently reported Cosmic Himalayas (CH) -- an extreme quasar overdensity at z~2 -- poses an apparent challenge to the Lambda CDM framework, with a reported significance of 16.9-sigma under Gaussian assumptions. Such an event appears improbably rare, with a formal probability of P ~ 10^-68. In this work, we investigate whether CH-like structures can naturally arise in cosmological hydrodynamic simulations. Using the CROCODILE simulation, which self-consistently models galaxy-black hole coevolution, we examine quasar clustering through two complementary approaches: the count-in-cells (CIC) statistic, which probes large-scale overdensities, and the nearest-neighbor distribution (NND), sensitive to small-scale environments. CIC analysis reveals that the underlying distribution is heavy-tailed and non-Gaussian, and that conventional Gaussian-based evaluation substantially overestimates the significance of extreme events. When modeled with an asymmetric generalized normal distribution (AGND), the inferred rarity of the CH is substantially reduced and reconciled with standard Lambda CDM; for instance, regions appearing as 12-sigma outliers under Gaussian assumptions (P ~ 10^-33) are found to occur in the AGND regime with a probability of P ~ 10^-4. NND analysis further demonstrates that extreme overdense regions within the simulation can naturally sustain two-point correlation function values similar to those observed in the CH (r0 ~ 30 Mpc/h), suggesting that the strong clustering stems from sample selection biases and local environmental variations. These two analyses conclusively highlight the importance of adopting non-Gaussian statistics when quantifying extreme overdensities of quasars and establish that the CH is not an anomaly, but a natural outcome of structure formation in the Lambda CDM universe.",
      "authors": [
        "Yuto Kuwayama",
        "Yongming Liang",
        "Kentaro Nagamine",
        "Yuri Oku",
        "Daisuke Nishihama",
        "Daisuke Toyouchi",
        "Keita Fukushima",
        "Hidenobu Yajima",
        "Hyunbae Park",
        "Masami Ouchi"
      ],
      "primary_category": "astro-ph.CO",
      "categories": [
        "astro-ph.CO",
        "astro-ph.GA"
      ],
      "published": "2025-12-31 16:52:41+00:00",
      "link": "https://arxiv.org/pdf/2512.24966v1",
      "tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2512.24782v1",
      "title": "TTC: Transformer-based TDE Classifier for the Wide Field Survey Telescope (WFST)",
      "abstract": "We propose the Transformer-based Tidal disruption events (TDE) Classifier (\\texttt{TTC}), specifically designed to operate effectively with both real-time alert streams and archival data of the Wide Field Survey Telescope (WFST). It aims to minimize the reliance on external catalogs and find TDE candidates from pure light curves, which is more suitable for finding TDEs in faint and distant galaxies. \\texttt{TTC} consists of two key modules that can work independently: (1) A light curve parametric fitting module and (2) a Transformer (\\texttt{Mgformer})-based classification network. The training of the latter module and evaluation for each module utilize a light curve dataset of 7413 spectroscopically classified transients from the Zwicky Transient Facility (ZTF). The \\texttt{Mgformer}-based module is superior in performance and flexibility. Its representative recall and precision values are 0.79 and 0.76, respectively, and can be modified by adjusting the threshold. It can also efficiently find TDE candidates within 30 days from the first detection. For comparison, the parametric fitting module yields values of 0.72 and 0.40, respectively, while it is $>$10 times faster in average speed. Hence, the setup of modules allows a trade-off between performance and time, as well as precision and recall. \\texttt{TTC} has successfully picked out all spectroscopically identified TDEs among ZTF transients in a real-time classification test, and selected $\\sim$20 TDE candidates in the deep field survey data of WFST. The discovery rate will greatly increase once the differential database for the wide field survey is ready.",
      "authors": [
        "Ranfang Zheng",
        "Zheyu Lin",
        "Xu Kong",
        "Dezheng Meng",
        "Zelin Xu",
        "Lulu Fan",
        "Ji-an Jiang",
        "Ning Jiang",
        "Jie Lin",
        "Tinggui Wang",
        "Qingfeng Zhu",
        "Feng Li",
        "Ming Liang",
        "Hao Liu",
        "Zheng Lou",
        "Wentao Luo",
        "Jinlong Tang",
        "Hairen Wang",
        "Jian Wang",
        "Yongquan Xue",
        "Dazhi Yao",
        "Hong-fei Zhang",
        "Wen Zhao",
        "Xianzhong Zheng",
        "Yingxi Zuo"
      ],
      "primary_category": "astro-ph.IM",
      "categories": [
        "astro-ph.IM",
        "astro-ph.HE"
      ],
      "published": "2025-12-31 11:02:09+00:00",
      "link": "https://arxiv.org/pdf/2512.24782v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2512.24764v1",
      "title": "LUNCH: A Lightweight Unified Deep-Learning Framework for General Transients Classification in High-Energy Time-Domain Astronomy",
      "abstract": "The increasing data volume of high-energy space monitors necessitates real-time, automated transient classification for multi-messenger follow-up. Conventional methods rely on empirical features like hardness ratios and reliable localization, which are not always precisely available during early detection. We developed the Lightweight Unified Neural Classifier for High-energy Transients (LUNCH) - an end-to-end deep-learning framework that performs general transient classification directly from raw multi-band light curves, eliminating the need for background subtraction or source localization. Its dual-scale architecture fuses long- and short-scale temporal evolution adaptively. Evaluated on 15 years of Fermi/GBM triggers, the optimal model achieves 97.23% accuracy when trained on complete energy spectra. A lightweight version using only three broad energy bands retains 95.07% accuracy, demonstrating that coarse spectral information fused with temporal context enables robust discrimination. The system significantly outperforms the GBM in-flight classifier on three months of independent test data. Feature visualization reveals well-separated class clusters, confirming physical interpretability. LUNCH combines high accuracy, low computational cost, and instrument-agnostic inputs, offering a practical solution for real-time in-flight processing that enables timely triggers for immediate multi-wavelength and multi-messenger follow-up observations in future time-domain missions.",
      "authors": [
        "Peng Zhang",
        "Chen-Wei Wang",
        "Zheng-Hang Yu",
        "Ren-Zhou Gui",
        "Shao-Lin Xiong",
        "Xiao-Bo Li",
        "Li-Ming Song",
        "Shi-Jie Zheng",
        "Xiao-Yun Zhao",
        "Yue Huang",
        "Wang-Chen Xue",
        "Ya-Qi Wang",
        "Long-Bo Han",
        "Jia-Cong Liu",
        "Chao Zheng",
        "Wen-Jun Tan",
        "Sheng-Lun Xie",
        "Ce Cai",
        "Yan-Qiu Zhang",
        "Hao-Xuan Guo",
        "Yue Wang",
        "Yang-Zhao Ren"
      ],
      "primary_category": "astro-ph.IM",
      "categories": [
        "astro-ph.IM",
        "astro-ph.HE"
      ],
      "published": "2025-12-31 10:21:15+00:00",
      "link": "https://arxiv.org/pdf/2512.24764v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2512.24749v1",
      "title": "Coronal flux tube illuminated by strong shock spot: New Year's Eve solar eruption of 2023-Dec-31",
      "abstract": "Powerful solar eruptions are known to produce fast and wide shock waves in the solar corona and inner heliosphere. The relationship between the coronal shock waves, solar energetic particles and different types of radio emission is a subject of long-lasting research activity. In this work, we perform a case study of 31 December 2023 eruption that occurred near eastern limb of the Sun. It produced a X5.0 class X-ray flare, a global EUV wave, a fast $\\sim3000$ km/s Coronal Mass Ejection, strong radio emissions (including several type III and type II bursts), solar energetic particles in-situ, and long duration high-energy gamma-ray emission. We employ a technique that combines the reconstructed coronal shock from observations with background coronal MHD simulations to produce shock-mediated synthetic radio spectrum, assuming local emission at plasma frequency. We show that transient high Mach number and quasi-perpendicular coronal shock region explains both a ``hot flux tube'' precursor seen in EUV observations and reverse drifting radio spectral features observed by ground-based facilities. The occurrence of this evanescent strong shock patch was observed when it propagated across pseudo-streamer's cusp where the magnetic field was particularly low. We also find evidence that, at higher coronal altitudes, the low-frequency type II radio burst detected by several spacecraft, is triggered by the interaction of the shock with the heliospheric current sheet. This study provides additional evidence that high-$M_A$ regions of coronal shock surface are instrumental in energetic particle phenomenology.",
      "authors": [
        "Illya Plotnikov",
        "Alexis P. Rouillard",
        "Athanasios Kouloumvakos",
        "Immanuel Jebaraj"
      ],
      "primary_category": "astro-ph.SR",
      "categories": [
        "astro-ph.SR"
      ],
      "published": "2025-12-31 09:48:28+00:00",
      "link": "https://arxiv.org/pdf/2512.24749v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2601.00044v1",
      "title": "Born in the Dark: The Catastrophic Collapse of Fuzzy Dark Matter Solitons as the Origin of Little Red Dots",
      "abstract": "JWST surveys have uncovered a population of compact, red sources (\"Little Red Dots,\" LRDs) at $z \\ge 5$ that exhibit broad Balmer emission yet remain X-ray faint, implying heavy obscuration with $N_H \\ge 10^{24}$ cm$^{-2}$. We propose that LRDs may trace a short-lived, obscured phase associated with rapid baryonic inflow inside the deep solitonic cores of fuzzy dark matter (FDM) halos. Combining the soliton size scaling with (i) the observed compact radii ($r_e \\sim 30-100$ pc) and (ii) the requirement that Compton-thick columns be achievable within a region of order the core radius, we find that particle masses $m$ few $\\times 10^{-22}$ eV are plausible for soliton masses $M_s \\sim 10^8 - 10^9 M_\\odot$; we adopt $m_{22}=2$ as a fiducial choice. A conservative mass-budget estimate for the obscuring column, together with isothermal hydrostatic stratification, indicates that configurations reaching $N_H \\ge 10^{24} - 10^{25}$ cm$^{-2}$ require densities for which radiative losses (cooling and/or diffusion) occur faster than the dynamical time, suggesting that a long-lived static hot atmosphere is unlikely (an \"Opacity Crisis\") and that rapid inflow or radiation-pressure-driven evolution is favored. Using $512^3$ pseudo-spectral Schrödinger-Poisson simulations of idealized soliton mergers, we illustrate that compact, high-density soliton cores can form via violent relaxation under representative scalings. We discuss observational implications and tests, and outline the need for future radiation-hydrodynamic modeling to predict demographics and detailed spectra.",
      "authors": [
        "Tak-Pong Woo"
      ],
      "primary_category": "astro-ph.GA",
      "categories": [
        "astro-ph.GA"
      ],
      "published": "2025-12-31 09:19:49+00:00",
      "link": "https://arxiv.org/pdf/2601.00044v1",
      "tags": [
        "大厂llm"
      ]
    },
    {
      "id": "2512.24677v1",
      "title": "Destruction of the interstellar dust by a supernova",
      "abstract": "Destruction of the interstellar dust proceeds primary behind supernova shocks. The previous estimates of the mass of the interstellar dust destroyed in the SN remnant do not take into account the physical properties of the ambient medium. Here we consider how some parameters, i.e. gas density and metallicity, can influence the destruction of the interstellar dust. We show that there are two regimes of the interstellar dust grains destruction in SN remnants: rapid and almost complete in compact low-mass SN remnants expanding in dense medium, and gradual and weak destruction in massive remnants evolving in the low-dense environment. When time for thermal sputtering is close to the dynamical one, i.e. to the SN remnant age, the mass of the interstellar dust destroyed in the SN remnant reaches its maximum value. We find that change of the ambient gas density results in the reduction of the dust mass logarithmically. We argue that dust cooling suppresses the interstellar dust destruction up to a factor of 1.6 by mass. This factor decreases for higher density of the ambient medium. We found that the dust mass depends linearly on gas metallicity as ${\\rm log}~M_d \\sim {\\rm [Z/H]}$ or, in other words, on the dust-to-gas ratio as $M_d \\sim ζ_d$. In turn, the destruction efficiency is higher in low-metallicity environments due to relatively longer adiabatic phase. We point out that the mass of the interstellar dust destroyed per one SN in a high density environment of the high star formation regions like in local ultraluminous infrared and high-redshift massive galaxies is about several times smaller than that in the Milky Way diffuse medium.",
      "authors": [
        "Evgenii O. Vasiliev"
      ],
      "primary_category": "astro-ph.GA",
      "categories": [
        "astro-ph.GA"
      ],
      "published": "2025-12-31 07:05:47+00:00",
      "link": "https://arxiv.org/pdf/2512.24677v1",
      "tags": [
        "大语言模型"
      ]
    },
    {
      "id": "2512.24670v1",
      "title": "Dust destruction in bubbles driven by multiple supernovae explosions",
      "abstract": "Dust lifetime derived from an isolated supernova (SN) evolution in the interstellar medium is known to be an order of magnitude shorter than the time needed to replenish dust mass by its production in various Galactic sources. We show, using 3-D numerical hydrodynamical simulations, that destruction of dust in the case of multiple SNe in a star cluster is markedly different from that in an isolated SN. We find that the mass of dust destroyed in the bubble does not grow for a considerable time, while SNe continue to explode. This regime is attained at saturation timescale, which is proportional to SNe rate in cluster. We show that the mass of dust destroyed in bubble per SN decreases for higher SN rate. Thus, the destruction efficiency -- defined as the ratio of the the total mass of dust destroyed by clustered SNe to that destroyed by the same number of isolated SNe -- in bubbles evolved in a homogeneous medium drops for massive clusters, e.g. around clusters with $M_\\ast > 4\\times 10^4 M_\\odot$ it is less $0.4$\\%. For lower mass clusters, the efficiency is proportional to the average time delay between SNe. We found that each cluster with $M_\\ast < 4\\times 10^4 M_\\odot$ destroys the same mass of dust as a single isolated SN. In a clumpy medium in bubbles formed around clusters with $M_\\ast \\sim 4\\times 10^4 M_\\odot$ and up to 4 times around $M_\\ast \\sim 8\\times 10^5 M_\\odot$. We argue that the interstellar dust swept up by multiple SNe almost completely survives in the shells of bubbles around such massive clusters. Therefore, the destruction of the interstellar dust is controlled by SNe in low-mass clusters. We point out that the interstellar dust lifetime for a given SN rate is at least a factor $\\sim 10$ longer as compared to the estimates derived from an isolated SN. (abridged)",
      "authors": [
        "Evgenii O. Vasiliev",
        "Biman B. Nath"
      ],
      "primary_category": "astro-ph.GA",
      "categories": [
        "astro-ph.GA"
      ],
      "published": "2025-12-31 06:52:26+00:00",
      "link": "https://arxiv.org/pdf/2512.24670v1",
      "tags": [
        "大语言模型"
      ]
    }
  ]
}